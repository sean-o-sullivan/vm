{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 01:45:26 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 38.9MB/s]                    \n",
      "2024-08-24 01:45:26 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:45:27 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-08-24 01:45:27 INFO: Using device: cpu\n",
      "2024-08-24 01:45:27 INFO: Loading: tokenize\n",
      "2024-08-24 01:45:27 INFO: Loading: mwt\n",
      "2024-08-24 01:45:27 INFO: Loading: pos\n",
      "2024-08-24 01:45:27 INFO: Loading: lemma\n",
      "2024-08-24 01:45:27 INFO: Loading: constituency\n",
      "2024-08-24 01:45:27 INFO: Loading: depparse\n",
      "2024-08-24 01:45:27 INFO: Loading: sentiment\n",
      "2024-08-24 01:45:27 INFO: Loading: ner\n",
      "2024-08-24 01:45:28 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the doc is [\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"The\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 3,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"quick\",\n",
      "      \"lemma\": \"quick\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 4,\n",
      "      \"end_char\": 9,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"brown\",\n",
      "      \"lemma\": \"brown\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 10,\n",
      "      \"end_char\": 15,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"fox\",\n",
      "      \"lemma\": \"fox\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 16,\n",
      "      \"end_char\": 19,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"jumps\",\n",
      "      \"lemma\": \"jump\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBZ\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 20,\n",
      "      \"end_char\": 25,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"over\",\n",
      "      \"lemma\": \"over\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 26,\n",
      "      \"end_char\": 30,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 31,\n",
      "      \"end_char\": 34,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"lazy\",\n",
      "      \"lemma\": \"lazy\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 35,\n",
      "      \"end_char\": 39,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"dog\",\n",
      "      \"lemma\": \"dog\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 40,\n",
      "      \"end_char\": 43,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 43,\n",
      "      \"end_char\": 44,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"He\",\n",
      "      \"lemma\": \"he\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"PRP\",\n",
      "      \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 45,\n",
      "      \"end_char\": 47,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"then\",\n",
      "      \"lemma\": \"then\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"feats\": \"PronType=Dem\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"start_char\": 48,\n",
      "      \"end_char\": 52,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"runs\",\n",
      "      \"lemma\": \"run\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBZ\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 53,\n",
      "      \"end_char\": 57,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"away\",\n",
      "      \"lemma\": \"away\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"start_char\": 58,\n",
      "      \"end_char\": 62,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \",\",\n",
      "      \"lemma\": \",\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \",\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 62,\n",
      "      \"end_char\": 63,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"leaving\",\n",
      "      \"lemma\": \"leave\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBG\",\n",
      "      \"feats\": \"VerbForm=Ger\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advcl\",\n",
      "      \"start_char\": 64,\n",
      "      \"end_char\": 71,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 8,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 72,\n",
      "      \"end_char\": 75,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"dog\",\n",
      "      \"lemma\": \"dog\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 76,\n",
      "      \"end_char\": 79,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"behind\",\n",
      "      \"lemma\": \"behind\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"compound:prt\",\n",
      "      \"start_char\": 80,\n",
      "      \"end_char\": 86,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 86,\n",
      "      \"end_char\": 87,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"After\",\n",
      "      \"lemma\": \"after\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 88,\n",
      "      \"end_char\": 93,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"that\",\n",
      "      \"lemma\": \"that\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Number=Sing|PronType=Dem\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 94,\n",
      "      \"end_char\": 98,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \",\",\n",
      "      \"lemma\": \",\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \",\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 98,\n",
      "      \"end_char\": 99,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 100,\n",
      "      \"end_char\": 103,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"fox\",\n",
      "      \"lemma\": \"fox\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 104,\n",
      "      \"end_char\": 107,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"went\",\n",
      "      \"lemma\": \"go\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 108,\n",
      "      \"end_char\": 112,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"to\",\n",
      "      \"lemma\": \"to\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 113,\n",
      "      \"end_char\": 115,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 116,\n",
      "      \"end_char\": 119,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"forest\",\n",
      "      \"lemma\": \"forest\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 120,\n",
      "      \"end_char\": 126,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \"to\",\n",
      "      \"lemma\": \"to\",\n",
      "      \"upos\": \"PART\",\n",
      "      \"xpos\": \"TO\",\n",
      "      \"head\": 11,\n",
      "      \"deprel\": \"mark\",\n",
      "      \"start_char\": 127,\n",
      "      \"end_char\": 129,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 11,\n",
      "      \"text\": \"find\",\n",
      "      \"lemma\": \"find\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VB\",\n",
      "      \"feats\": \"VerbForm=Inf\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"advcl\",\n",
      "      \"start_char\": 130,\n",
      "      \"end_char\": 134,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 12,\n",
      "      \"text\": \"food\",\n",
      "      \"lemma\": \"food\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 11,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 135,\n",
      "      \"end_char\": 139,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 13,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 139,\n",
      "      \"end_char\": 140,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "Clause 1: The quick brown fox jumps over the lazy dog .\n",
      "Clause 2: He then runs away , leaving the dog behind .\n",
      "Clause 3: After that , the fox went to the forest to find food .\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "def extract_clauses(doc):\n",
    "\n",
    "    clauses = []\n",
    "    current_clause = []\n",
    "\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        \n",
    "        for word in sent.words:\n",
    "            if word.deprel in {'ccomp', 'xcomp', 'acl'}:  \n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause)\n",
    "                    current_clause = []\n",
    "            current_clause.append(word.text)\n",
    "\n",
    "        \n",
    "        if current_clause:\n",
    "            clauses.append(current_clause)\n",
    "            current_clause = []\n",
    "\n",
    "    return clauses\n",
    "\n",
    "def main(text):\n",
    "    \n",
    "    nlp = stanza.Pipeline('en')\n",
    "\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    print('the doc is', doc)\n",
    "\n",
    "    \n",
    "    clauses = extract_clauses(doc)\n",
    "\n",
    "    \n",
    "    for i, clause in enumerate(clauses):\n",
    "        print(f\"Clause {i + 1}: {' '.join(clause)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = (\n",
    "        \"The quick brown fox jumps over the lazy dog. \"\n",
    "        \"He then runs away, leaving the dog behind. \"\n",
    "        \"After that, the fox went to the forest to find food.\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    main(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 48.0MB/s]                    \n",
      "2024-08-24 01:47:16 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:47:16 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-08-24 01:47:17 INFO: File exists: /Users/sean/stanza_resources/en/default.zip\n",
      "2024-08-24 01:47:18 INFO: Finished downloading models and saved to /Users/sean/stanza_resources\n",
      "2024-08-24 01:47:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 33.8MB/s]                    \n",
      "2024-08-24 01:47:18 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:47:19 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-08-24 01:47:19 INFO: Using device: cpu\n",
      "2024-08-24 01:47:19 INFO: Loading: tokenize\n",
      "2024-08-24 01:47:19 INFO: Loading: mwt\n",
      "2024-08-24 01:47:19 INFO: Loading: pos\n",
      "2024-08-24 01:47:19 INFO: Loading: lemma\n",
      "2024-08-24 01:47:19 INFO: Loading: depparse\n",
      "2024-08-24 01:47:19 INFO: Loading: ner\n",
      "2024-08-24 01:47:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse,ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Document'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"In the heart of a city that never seemed to sleep, neon lights flickered like the last desperate gasps of a dying firefly. Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise-cracking, undead detective.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "print(type(doc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clauses(doc):\n",
    "\n",
    "    clauses = []\n",
    "    current_clause = []\n",
    "\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        \n",
    "        for word in sent.words:\n",
    "            \n",
    "            if word.deprel in {'ccomp', 'xcomp', 'acl', 'advcl', 'relcl'}:\n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause)\n",
    "                    current_clause = []\n",
    "            current_clause.append(word.text)\n",
    "\n",
    "        \n",
    "        if current_clause:\n",
    "            clauses.append(current_clause)\n",
    "            current_clause = []\n",
    "\n",
    "    return clauses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 41.7MB/s]                    \n",
      "2024-08-24 01:48:03 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:48:03 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-08-24 01:48:05 INFO: File exists: /Users/sean/stanza_resources/en/default.zip\n",
      "2024-08-24 01:48:06 INFO: Finished downloading models and saved to /Users/sean/stanza_resources\n",
      "2024-08-24 01:48:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 42.6MB/s]                    \n",
      "2024-08-24 01:48:06 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:48:07 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-08-24 01:48:07 INFO: Using device: cpu\n",
      "2024-08-24 01:48:07 INFO: Loading: tokenize\n",
      "2024-08-24 01:48:07 INFO: Loading: mwt\n",
      "2024-08-24 01:48:07 INFO: Loading: pos\n",
      "2024-08-24 01:48:07 INFO: Loading: lemma\n",
      "2024-08-24 01:48:07 INFO: Loading: depparse\n",
      "2024-08-24 01:48:07 INFO: Loading: ner\n",
      "2024-08-24 01:48:07 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1: In the heart of a city that never seemed to\n",
      "Clause 2: sleep , neon lights flickered like the last desperate gasps of a dying firefly .\n",
      "Clause 3: Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise - cracking , undead\n",
      "Clause 4: detective .\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse,ner')\n",
    "\n",
    "\n",
    "text = \"In the heart of a city that never seemed to sleep, neon lights flickered like the last desperate gasps of a dying firefly. Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise-cracking, undead detective.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "clauses = extract_clauses(doc)\n",
    "for i, clause in enumerate(clauses):\n",
    "    print(f\"Clause {i + 1}: {' '.join(clause)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import readability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nominalization(text):\n",
    "\n",
    "    results = readability.getmeasures(text, lang='en')\n",
    "    return results['word usage']['nominalization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominalization Score: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_paragraph = \"\"\"\n",
    "The government's decision to implement stricter regulations was met with widespread criticism. \n",
    "However, the justification for these regulations was primarily based on the perceived need to \n",
    "reduce environmental degradation. The opposition's argument was that such measures would \n",
    "lead to economic stagnation and job losses. Despite these concerns, the administration proceeded \n",
    "with the enforcement of the new laws, emphasizing the long-term benefits over short-term challenges.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "score = nominalization(test_paragraph)\n",
    "print(f\"Nominalization Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 105MB/s]                     \n",
      "2024-08-24 22:29:54 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 22:29:54 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-08-24 22:29:55 INFO: File exists: /Users/sean/stanza_resources/en/default.zip\n",
      "2024-08-24 22:29:56 INFO: Finished downloading models and saved to /Users/sean/stanza_resources\n",
      "2024-08-24 22:29:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 40.2MB/s]                    \n",
      "2024-08-24 22:29:56 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 22:29:57 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-08-24 22:29:57 INFO: Using device: cpu\n",
      "2024-08-24 22:29:57 INFO: Loading: tokenize\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/tokenization/trainer.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:57 INFO: Loading: mwt\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/mwt/trainer.py:170: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:57 INFO: Loading: pos\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/pos/trainer.py:139: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/common/pretrain.py:56: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(self.filename, lambda storage, loc: storage)\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/common/char_model.py:271: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:57 INFO: Loading: lemma\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/lemma/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:57 INFO: Loading: constituency\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/constituency/trainer.py:236: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:58 INFO: Loading: depparse\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/depparse/trainer.py:194: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:58 INFO: Loading: sentiment\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/classifiers/trainer.py:72: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:58 INFO: Loading: ner\n",
      "/Users/sean/Desktop/vm/datasets/vm3_310/lib/python3.10/site-packages/stanza/models/ner/trainer.py:197: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n",
      "2024-08-24 22:29:58 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Noisy Text: \n",
      "The government's decision to implement stricter regulations (Figure 2.4) was met with widespread criticism.\n",
      "However, the justification for these regulations was primarily based on the perceived need to reduce environmental degradation.\n",
      "According to recent studies (Smith et al., 2020), the degradation could cause economic losses up to $2.3 billion. \n",
      "The opposition's argument was that such measures would lead to economic stagnation (see Table 3), and possibly increase unemployment by 15%. \n",
      "Despite these concerns, the administration proceeded with the enforcement of the new laws (see Figure 1), emphasizing the long-term benefits over short-term challenges.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 154\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Noisy Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_paragraph\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# Reconstructed Text\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m reconstructed_text \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct_text_from_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReconstructed Text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreconstructed_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# Readability Scores\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[14], line 25\u001b[0m, in \u001b[0;36mreconstruct_text_from_doc\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     23\u001b[0m word_text \u001b[38;5;241m=\u001b[39m token\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Handle cases where there's no space after the word (e.g., punctuation)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmisc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeats\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpaceAfter=No\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mwords[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfeats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmisc\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     26\u001b[0m     reconstructed_text\u001b[38;5;241m.\u001b[39mappend(word_text)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "import stanza\n",
    "from textstat import textstat\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en')\n",
    "\n",
    "\n",
    "def reconstruct_text_from_doc(doc):\n",
    "\n",
    "    reconstructed_text = []\n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            word_text = token.text\n",
    "            \n",
    "            if 'misc' in token.words[0].feats and 'SpaceAfter=No' in token.words[0].feats['misc']:\n",
    "                reconstructed_text.append(word_text)\n",
    "            else:\n",
    "                reconstructed_text.append(word_text + ' ')\n",
    "    return ''.join(reconstructed_text).strip()\n",
    "\n",
    "\n",
    "def flesch_reading_ease(doc):\n",
    " \n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "\n",
    "def GFI(doc):\n",
    "\n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.gunning_fog(text)\n",
    "\n",
    "def coleman_liau_index(doc):\n",
    " \n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.coleman_liau_index(text)\n",
    "\n",
    "def ari(doc):\n",
    " \n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.automated_readability_index(text)\n",
    "\n",
    "def dale_chall_readability_score(doc):\n",
    "\n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.dale_chall_readability_score(text)\n",
    "\n",
    "def lix(doc):\n",
    "\n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.lix(text)\n",
    "\n",
    "def smog_index(doc):\n",
    "\n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.smog_index(text)\n",
    "\n",
    "def rix(doc):\n",
    "\n",
    "    text = reconstruct_text_from_doc(doc)\n",
    "    return textstat.rix(text)\n",
    "\n",
    "\n",
    "test_paragraph = \"\"\"\n",
    "The government's decision to implement stricter regulations (Figure 2.4) was met with widespread criticism.\n",
    "However, the justification for these regulations was primarily based on the perceived need to reduce environmental degradation.\n",
    "According to recent studies (Smith et al., 2020), the degradation could cause economic losses up to $2.3 billion. \n",
    "The opposition's argument was that such measures would lead to economic stagnation (see Table 3), and possibly increase unemployment by 15%. \n",
    "Despite these concerns, the administration proceeded with the enforcement of the new laws (see Figure 1), emphasizing the long-term benefits over short-term challenges.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "doc = nlp(test_paragraph)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Original Noisy Text: {test_paragraph}\\n\")\n",
    "\n",
    "\n",
    "reconstructed_text = reconstruct_text_from_doc(doc)\n",
    "print(f\"Reconstructed Text: {reconstructed_text}\\n\")\n",
    "\n",
    "\n",
    "flesch_score = flesch_reading_ease(doc)\n",
    "print(f\"Flesch Reading Ease Score: {flesch_score:.2f}\")\n",
    "\n",
    "gfi_score = GFI(doc)\n",
    "print(f\"Gunning Fog Index: {gfi_score:.2f}\")\n",
    "\n",
    "cli_score = coleman_liau_index(doc)\n",
    "print(f\"Coleman-Liau Index: {cli_score:.2f}\")\n",
    "\n",
    "ari_score = ari(doc)\n",
    "print(f\"Automated Readability Index: {ari_score:.2f}\")\n",
    "\n",
    "dale_chall_score = dale_chall_readability_score(doc)\n",
    "print(f\"Dale-Chall Readability Score: {dale_chall_score:.2f}\")\n",
    "\n",
    "lix_score = lix(doc)\n",
    "print(f\"LIX Score: {lix_score:.2f}\")\n",
    "\n",
    "smog_score = smog_index(doc)\n",
    "print(f\"SMOG Index: {smog_score:.2f}\")\n",
    "\n",
    "rix_score = rix(doc)\n",
    "print(f\"RIX Score: {rix_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Noisy Text: \n",
      "The government's decision to implement stricter regulations (Figure 2.4) was met with widespread criticism.\n",
      "However, the justification for these regulations was primarily based on the perceived need to reduce environmental degradation.\n",
      "According to recent studies (Smith et al., 2020), the degradation could cause economic losses up to $2.3 billion. \n",
      "The opposition's argument was that such measures would lead to economic stagnation (see Table 3), and possibly increase unemployment by 15%. \n",
      "Despite these concerns, the administration proceeded with the enforcement of the new laws (see Figure 1), emphasizing the long-term benefits over short-term challenges.\n",
      "\n",
      "\n",
      "Reconstructed Text: The government's decision to implement stricter regulations ( Figure 2.4 ) was met with widespread criticism . However , the justification for these regulations was primarily based on the perceived need to reduce environmental degradation . According to recent studies ( Smith et al. , 2020 ) , the degradation could cause economic losses up to $ 2.3 billion . The opposition's argument was that such measures would lead to economic stagnation ( see Table 3 ) , and possibly increase unemployment by 15 % . Despite these concerns , the administration proceeded with the enforcement of the new laws ( see Figure 1 ) , emphasizing the long - term benefits over short - term challenges .\n",
      "\n",
      "Flesch Reading Ease Score: 40.75\n",
      "Gunning Fog Index: 14.28\n",
      "Coleman-Liau Index: 15.01\n",
      "Automated Readability Index: 13.50\n",
      "Dale-Chall Readability Score: 11.79\n",
      "LIX Score: 43.26\n",
      "SMOG Index: 13.90\n",
      "RIX Score: 5.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def reconstruct_text_from_doc(doc):\n",
    "\n",
    "    reconstructed_text = []\n",
    "    for sentence in doc.sentences:\n",
    "        for token in sentence.tokens:\n",
    "            word_text = token.text\n",
    "            \n",
    "            if token.words[0].feats and 'SpaceAfter=No' in token.words[0].feats:\n",
    "                reconstructed_text.append(word_text)\n",
    "            else:\n",
    "                reconstructed_text.append(word_text + ' ')\n",
    "    return ''.join(reconstructed_text).strip()\n",
    "\n",
    "\n",
    "test_paragraph = \"\"\"\n",
    "The government's decision to implement stricter regulations (Figure 2.4) was met with widespread criticism.\n",
    "However, the justification for these regulations was primarily based on the perceived need to reduce environmental degradation.\n",
    "According to recent studies (Smith et al., 2020), the degradation could cause economic losses up to $2.3 billion. \n",
    "The opposition's argument was that such measures would lead to economic stagnation (see Table 3), and possibly increase unemployment by 15%. \n",
    "Despite these concerns, the administration proceeded with the enforcement of the new laws (see Figure 1), emphasizing the long-term benefits over short-term challenges.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "doc = nlp(test_paragraph)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Original Noisy Text: {test_paragraph}\\n\")\n",
    "\n",
    "\n",
    "reconstructed_text = reconstruct_text_from_doc(doc)\n",
    "print(f\"Reconstructed Text: {reconstructed_text}\\n\")\n",
    "\n",
    "\n",
    "flesch_score = flesch_reading_ease(doc)\n",
    "print(f\"Flesch Reading Ease Score: {flesch_score:.2f}\")\n",
    "\n",
    "gfi_score = GFI(doc)\n",
    "print(f\"Gunning Fog Index: {gfi_score:.2f}\")\n",
    "\n",
    "cli_score = coleman_liau_index(doc)\n",
    "print(f\"Coleman-Liau Index: {cli_score:.2f}\")\n",
    "\n",
    "ari_score = ari(doc)\n",
    "print(f\"Automated Readability Index: {ari_score:.2f}\")\n",
    "\n",
    "dale_chall_score = dale_chall_readability_score(doc)\n",
    "print(f\"Dale-Chall Readability Score: {dale_chall_score:.2f}\")\n",
    "\n",
    "lix_score = lix(doc)\n",
    "print(f\"LIX Score: {lix_score:.2f}\")\n",
    "\n",
    "smog_score = smog_index(doc)\n",
    "print(f\"SMOG Index: {smog_score:.2f}\")\n",
    "\n",
    "rix_score = rix(doc)\n",
    "print(f\"RIX Score: {rix_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 23:08:43 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 88.8MB/s]                    \n",
      "2024-08-24 23:08:43 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 23:08:44 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-08-24 23:08:44 INFO: Using device: cpu\n",
      "2024-08-24 23:08:44 INFO: Loading: tokenize\n",
      "2024-08-24 23:08:44 INFO: Loading: mwt\n",
      "2024-08-24 23:08:44 INFO: Loading: pos\n",
      "2024-08-24 23:08:44 INFO: Loading: lemma\n",
      "2024-08-24 23:08:44 INFO: Loading: constituency\n",
      "2024-08-24 23:08:44 INFO: Loading: depparse\n",
      "2024-08-24 23:08:45 INFO: Loading: sentiment\n",
      "2024-08-24 23:08:45 INFO: Loading: ner\n",
      "2024-08-24 23:08:45 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frazier Depth for each sentence:\n",
      "Sentence 1: 7\n",
      "Sentence 2: 5\n",
      "Sentence 3: 8\n",
      "Sentence 4: 5\n",
      "Sentence 5: 5\n",
      "Sentence 6: 7\n",
      "\n",
      "Average Frazier Depth for the entire text: 6.17\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "def calculate_frazier_depth(sentence):\n",
    "    \"\"\"\n",
    "    Computes the Frazier Depth for a given sentence based on its dependency parse.\n",
    "    Parameters:\n",
    "    sentence (stanza.Sentence): A Stanza Sentence object.\n",
    "    Returns:\n",
    "    int: The depth of the syntactic structure.\n",
    "    \"\"\"\n",
    "    def build_tree(words):\n",
    "        tree = {word.id: [] for word in words}\n",
    "        for word in words:\n",
    "            if word.head != 0:  \n",
    "                tree[word.head].append(word.id)\n",
    "        return tree\n",
    "\n",
    "    def depth(node_id, tree, current_depth):\n",
    "        max_depth = current_depth\n",
    "        for child_id in tree[node_id]:\n",
    "            max_depth = max(max_depth, depth(child_id, tree, current_depth + 1))\n",
    "        return max_depth\n",
    "\n",
    "    \n",
    "    dependency_tree = build_tree(sentence.words)\n",
    "    \n",
    "    \n",
    "    root_id = next(word.id for word in sentence.words if word.head == 0)\n",
    "    \n",
    "    \n",
    "    return depth(root_id, dependency_tree, 0)\n",
    "\n",
    "def frazier_depth(doc):\n",
    "    \"\"\"\n",
    "    Computes the average Frazier Depth for all sentences in a document.\n",
    "    Parameters:\n",
    "    doc (stanza.Document): A Stanza Document object.\n",
    "    Returns:\n",
    "    float: The average Frazier Depth for the document.\n",
    "    \"\"\"\n",
    "    depths = []\n",
    "    for sentence in doc.sentences:\n",
    "        depths.append(calculate_frazier_depth(sentence))\n",
    "    \n",
    "    if not depths:\n",
    "        return 0.0\n",
    "    \n",
    "    return sum(depths) / len(depths)\n",
    "\n",
    "def test_frazier_depth():\n",
    "    \n",
    "    nlp = stanza.Pipeline('en')\n",
    "\n",
    "    text = \"\"\"In the heart of a city that never seemed to sleep, where neon lights flickered like the last, desperate gasps of a dying firefly, Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise-cracking, undead detective. His overcoat flapped behind him like a ragged flag of rebellion, while his eyes, sharp and knowing, scanned the shadows for trouble. \"You know,\" he said to his companion, Valkyrie Cain, who was busy fending off a particularly persistent street vendor offering 'mystical' hot dogs, \"if I had a penny for every time someone tried to sell me something magical, I'd be richer than the most miserly dragon you can imagine.\" Valkyrie shot him a look that combined exasperation with a hint of amusement. \"And if I had a nickel for every time you made a joke that wasn't terrible, I'd still be broke, but at least I'd have a better sense of humor.\" Skulduggery chuckled, the sound echoing off the graffiti-covered walls, as he prepared for whatever dark and absurdly dangerous adventure lay ahead.\"\"\"\n",
    "\n",
    "    \n",
    "    doc = nlp(text)\n",
    "\n",
    "    \n",
    "    print(\"Frazier Depth for each sentence:\")\n",
    "    for i, sentence in enumerate(doc.sentences, 1):\n",
    "        depth = calculate_frazier_depth(sentence)\n",
    "        print(f\"Sentence {i}: {depth}\")\n",
    "\n",
    "    \n",
    "    avg_depth = frazier_depth(doc)\n",
    "    print(f\"\\nAverage Frazier Depth for the entire text: {avg_depth:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_frazier_depth()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vm3_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
