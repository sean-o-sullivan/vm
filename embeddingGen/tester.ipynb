{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-24 01:45:26 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 38.9MB/s]                    \n",
      "2024-08-24 01:45:26 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:45:27 INFO: Loading these models for language: en (English):\n",
      "============================================\n",
      "| Processor    | Package                   |\n",
      "--------------------------------------------\n",
      "| tokenize     | combined                  |\n",
      "| mwt          | combined                  |\n",
      "| pos          | combined_charlm           |\n",
      "| lemma        | combined_nocharlm         |\n",
      "| constituency | ptb3-revised_charlm       |\n",
      "| depparse     | combined_charlm           |\n",
      "| sentiment    | sstplus_charlm            |\n",
      "| ner          | ontonotes-ww-multi_charlm |\n",
      "============================================\n",
      "\n",
      "2024-08-24 01:45:27 INFO: Using device: cpu\n",
      "2024-08-24 01:45:27 INFO: Loading: tokenize\n",
      "2024-08-24 01:45:27 INFO: Loading: mwt\n",
      "2024-08-24 01:45:27 INFO: Loading: pos\n",
      "2024-08-24 01:45:27 INFO: Loading: lemma\n",
      "2024-08-24 01:45:27 INFO: Loading: constituency\n",
      "2024-08-24 01:45:27 INFO: Loading: depparse\n",
      "2024-08-24 01:45:27 INFO: Loading: sentiment\n",
      "2024-08-24 01:45:27 INFO: Loading: ner\n",
      "2024-08-24 01:45:28 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the doc is [\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"The\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 0,\n",
      "      \"end_char\": 3,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"quick\",\n",
      "      \"lemma\": \"quick\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 4,\n",
      "      \"end_char\": 9,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"brown\",\n",
      "      \"lemma\": \"brown\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 4,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 10,\n",
      "      \"end_char\": 15,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"fox\",\n",
      "      \"lemma\": \"fox\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 16,\n",
      "      \"end_char\": 19,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"jumps\",\n",
      "      \"lemma\": \"jump\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBZ\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 20,\n",
      "      \"end_char\": 25,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"over\",\n",
      "      \"lemma\": \"over\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 26,\n",
      "      \"end_char\": 30,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 31,\n",
      "      \"end_char\": 34,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"lazy\",\n",
      "      \"lemma\": \"lazy\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"xpos\": \"JJ\",\n",
      "      \"feats\": \"Degree=Pos\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"start_char\": 35,\n",
      "      \"end_char\": 39,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"dog\",\n",
      "      \"lemma\": \"dog\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 40,\n",
      "      \"end_char\": 43,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 43,\n",
      "      \"end_char\": 44,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"He\",\n",
      "      \"lemma\": \"he\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"PRP\",\n",
      "      \"feats\": \"Case=Nom|Gender=Masc|Number=Sing|Person=3|PronType=Prs\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 45,\n",
      "      \"end_char\": 47,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"then\",\n",
      "      \"lemma\": \"then\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"feats\": \"PronType=Dem\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"start_char\": 48,\n",
      "      \"end_char\": 52,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"runs\",\n",
      "      \"lemma\": \"run\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBZ\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 53,\n",
      "      \"end_char\": 57,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"away\",\n",
      "      \"lemma\": \"away\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"start_char\": 58,\n",
      "      \"end_char\": 62,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \",\",\n",
      "      \"lemma\": \",\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \",\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 62,\n",
      "      \"end_char\": 63,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"leaving\",\n",
      "      \"lemma\": \"leave\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBG\",\n",
      "      \"feats\": \"VerbForm=Ger\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"advcl\",\n",
      "      \"start_char\": 64,\n",
      "      \"end_char\": 71,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 8,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 72,\n",
      "      \"end_char\": 75,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"dog\",\n",
      "      \"lemma\": \"dog\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 76,\n",
      "      \"end_char\": 79,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"behind\",\n",
      "      \"lemma\": \"behind\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"xpos\": \"RB\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"compound:prt\",\n",
      "      \"start_char\": 80,\n",
      "      \"end_char\": 86,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 3,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 86,\n",
      "      \"end_char\": 87,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"After\",\n",
      "      \"lemma\": \"after\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 2,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 88,\n",
      "      \"end_char\": 93,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"that\",\n",
      "      \"lemma\": \"that\",\n",
      "      \"upos\": \"PRON\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Number=Sing|PronType=Dem\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 94,\n",
      "      \"end_char\": 98,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \",\",\n",
      "      \"lemma\": \",\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \",\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 98,\n",
      "      \"end_char\": 99,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 5,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 100,\n",
      "      \"end_char\": 103,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"fox\",\n",
      "      \"lemma\": \"fox\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"start_char\": 104,\n",
      "      \"end_char\": 107,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"went\",\n",
      "      \"lemma\": \"go\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VBD\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"start_char\": 108,\n",
      "      \"end_char\": 112,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"to\",\n",
      "      \"lemma\": \"to\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"xpos\": \"IN\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"case\",\n",
      "      \"start_char\": 113,\n",
      "      \"end_char\": 115,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"the\",\n",
      "      \"lemma\": \"the\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"xpos\": \"DT\",\n",
      "      \"feats\": \"Definite=Def|PronType=Art\",\n",
      "      \"head\": 9,\n",
      "      \"deprel\": \"det\",\n",
      "      \"start_char\": 116,\n",
      "      \"end_char\": 119,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"forest\",\n",
      "      \"lemma\": \"forest\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"obl\",\n",
      "      \"start_char\": 120,\n",
      "      \"end_char\": 126,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \"to\",\n",
      "      \"lemma\": \"to\",\n",
      "      \"upos\": \"PART\",\n",
      "      \"xpos\": \"TO\",\n",
      "      \"head\": 11,\n",
      "      \"deprel\": \"mark\",\n",
      "      \"start_char\": 127,\n",
      "      \"end_char\": 129,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 11,\n",
      "      \"text\": \"find\",\n",
      "      \"lemma\": \"find\",\n",
      "      \"upos\": \"VERB\",\n",
      "      \"xpos\": \"VB\",\n",
      "      \"feats\": \"VerbForm=Inf\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"advcl\",\n",
      "      \"start_char\": 130,\n",
      "      \"end_char\": 134,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"id\": 12,\n",
      "      \"text\": \"food\",\n",
      "      \"lemma\": \"food\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"xpos\": \"NN\",\n",
      "      \"feats\": \"Number=Sing\",\n",
      "      \"head\": 11,\n",
      "      \"deprel\": \"obj\",\n",
      "      \"start_char\": 135,\n",
      "      \"end_char\": 139,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 13,\n",
      "      \"text\": \".\",\n",
      "      \"lemma\": \".\",\n",
      "      \"upos\": \"PUNCT\",\n",
      "      \"xpos\": \".\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"punct\",\n",
      "      \"start_char\": 139,\n",
      "      \"end_char\": 140,\n",
      "      \"ner\": \"O\",\n",
      "      \"multi_ner\": [\n",
      "        \"O\"\n",
      "      ],\n",
      "      \"misc\": \"SpaceAfter=No\"\n",
      "    }\n",
      "  ]\n",
      "]\n",
      "Clause 1: The quick brown fox jumps over the lazy dog .\n",
      "Clause 2: He then runs away , leaving the dog behind .\n",
      "Clause 3: After that , the fox went to the forest to find food .\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "def extract_clauses(doc):\n",
    "\n",
    "    clauses = []\n",
    "    current_clause = []\n",
    "\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        \n",
    "        for word in sent.words:\n",
    "            if word.deprel in {'ccomp', 'xcomp', 'acl'}:  \n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause)\n",
    "                    current_clause = []\n",
    "            current_clause.append(word.text)\n",
    "\n",
    "        \n",
    "        if current_clause:\n",
    "            clauses.append(current_clause)\n",
    "            current_clause = []\n",
    "\n",
    "    return clauses\n",
    "\n",
    "def main(text):\n",
    "    \n",
    "    nlp = stanza.Pipeline('en')\n",
    "\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    print('the doc is', doc)\n",
    "\n",
    "    \n",
    "    clauses = extract_clauses(doc)\n",
    "\n",
    "    \n",
    "    for i, clause in enumerate(clauses):\n",
    "        print(f\"Clause {i + 1}: {' '.join(clause)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_text = (\n",
    "        \"The quick brown fox jumps over the lazy dog. \"\n",
    "        \"He then runs away, leaving the dog behind. \"\n",
    "        \"After that, the fox went to the forest to find food.\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    main(sample_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 48.0MB/s]                    \n",
      "2024-08-24 01:47:16 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:47:16 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-08-24 01:47:17 INFO: File exists: /Users/sean/stanza_resources/en/default.zip\n",
      "2024-08-24 01:47:18 INFO: Finished downloading models and saved to /Users/sean/stanza_resources\n",
      "2024-08-24 01:47:18 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 33.8MB/s]                    \n",
      "2024-08-24 01:47:18 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:47:19 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-08-24 01:47:19 INFO: Using device: cpu\n",
      "2024-08-24 01:47:19 INFO: Loading: tokenize\n",
      "2024-08-24 01:47:19 INFO: Loading: mwt\n",
      "2024-08-24 01:47:19 INFO: Loading: pos\n",
      "2024-08-24 01:47:19 INFO: Loading: lemma\n",
      "2024-08-24 01:47:19 INFO: Loading: depparse\n",
      "2024-08-24 01:47:19 INFO: Loading: ner\n",
      "2024-08-24 01:47:20 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse,ner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stanza.models.common.doc.Document'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"In the heart of a city that never seemed to sleep, neon lights flickered like the last desperate gasps of a dying firefly. Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise-cracking, undead detective.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "print(type(doc))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_clauses(doc):\n",
    "\n",
    "    clauses = []\n",
    "    current_clause = []\n",
    "\n",
    "    \n",
    "    for sent in doc.sentences:\n",
    "        \n",
    "        for word in sent.words:\n",
    "            \n",
    "            if word.deprel in {'ccomp', 'xcomp', 'acl', 'advcl', 'relcl'}:\n",
    "                if current_clause:\n",
    "                    clauses.append(current_clause)\n",
    "                    current_clause = []\n",
    "            current_clause.append(word.text)\n",
    "\n",
    "        \n",
    "        if current_clause:\n",
    "            clauses.append(current_clause)\n",
    "            current_clause = []\n",
    "\n",
    "    return clauses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 41.7MB/s]                    \n",
      "2024-08-24 01:48:03 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:48:03 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-08-24 01:48:05 INFO: File exists: /Users/sean/stanza_resources/en/default.zip\n",
      "2024-08-24 01:48:06 INFO: Finished downloading models and saved to /Users/sean/stanza_resources\n",
      "2024-08-24 01:48:06 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.8.0.json: 386kB [00:00, 42.6MB/s]                    \n",
      "2024-08-24 01:48:06 INFO: Downloaded file to /Users/sean/stanza_resources/resources.json\n",
      "2024-08-24 01:48:07 INFO: Loading these models for language: en (English):\n",
      "=========================================\n",
      "| Processor | Package                   |\n",
      "-----------------------------------------\n",
      "| tokenize  | combined                  |\n",
      "| mwt       | combined                  |\n",
      "| pos       | combined_charlm           |\n",
      "| lemma     | combined_nocharlm         |\n",
      "| depparse  | combined_charlm           |\n",
      "| ner       | ontonotes-ww-multi_charlm |\n",
      "=========================================\n",
      "\n",
      "2024-08-24 01:48:07 INFO: Using device: cpu\n",
      "2024-08-24 01:48:07 INFO: Loading: tokenize\n",
      "2024-08-24 01:48:07 INFO: Loading: mwt\n",
      "2024-08-24 01:48:07 INFO: Loading: pos\n",
      "2024-08-24 01:48:07 INFO: Loading: lemma\n",
      "2024-08-24 01:48:07 INFO: Loading: depparse\n",
      "2024-08-24 01:48:07 INFO: Loading: ner\n",
      "2024-08-24 01:48:07 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clause 1: In the heart of a city that never seemed to\n",
      "Clause 2: sleep , neon lights flickered like the last desperate gasps of a dying firefly .\n",
      "Clause 3: Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise - cracking , undead\n",
      "Clause 4: detective .\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "\n",
    "\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse,ner')\n",
    "\n",
    "\n",
    "text = \"In the heart of a city that never seemed to sleep, neon lights flickered like the last desperate gasps of a dying firefly. Skulduggery Pleasant strolled down the alley with the kind of nonchalance that only comes from being a wise-cracking, undead detective.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "clauses = extract_clauses(doc)\n",
    "for i, clause in enumerate(clauses):\n",
    "    print(f\"Clause {i + 1}: {' '.join(clause)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vm3_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
