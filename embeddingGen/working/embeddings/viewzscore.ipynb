{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embedding saved to: normalisedandready/normalized_ABB_30_embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embedding saved to: normalisedandready/normalized_ABB_70_embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embedding saved to: normalisedandready/normalized_AGG_30_embeddings.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
      "/tmp/ipykernel_539510/1132302773.py:122: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embedding saved to: normalisedandready/normalized_AGG_70_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def load_and_combine_data(file_paths):\n",
    "    dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "def calculate_discriminative_score(cv, kurtosis, skewness):\n",
    "    return (np.abs(cv) + np.abs(kurtosis) + np.abs(skewness)) / 3\n",
    "\n",
    "def visualize_features(combined_df, stats_data, output_file, dpi=300, discriminative_threshold=0.5):\n",
    "    numeric_columns = [col for col in combined_df.columns if col != 'embedding_id' and pd.api.types.is_numeric_dtype(combined_df[col])]\n",
    "    n_features = len(numeric_columns)\n",
    "    n_cols = 5\n",
    "    n_rows = (n_features - 1) // n_cols + 1\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4*n_rows))\n",
    "    fig.suptitle(\"Feature Distributions and Z-Scores\", fontsize=16, y=1.02)\n",
    "\n",
    "    for idx, col in enumerate(numeric_columns):\n",
    "        ax = axes[idx // n_cols, idx % n_cols]\n",
    "        \n",
    "        mean = stats_data.at[col, 'mean']\n",
    "        std = stats_data.at[col, 'std']\n",
    "        all_zeros = stats_data.at[col, 'all_zeros']\n",
    "        cv = stats_data.at[col, 'cv']\n",
    "        kurtosis = stats_data.at[col, 'kurtosis']\n",
    "        skewness = stats_data.at[col, 'skewness']\n",
    "        \n",
    "        discriminative_score = calculate_discriminative_score(cv, kurtosis, skewness)\n",
    "        is_discriminative = discriminative_score > discriminative_threshold\n",
    "\n",
    "        if all_zeros:\n",
    "            ax.text(0.5, 0.5, \"ALL ZEROS\", ha='center', va='center', transform=ax.transAxes, fontsize=12, color='red')\n",
    "        else:\n",
    "            z_scores = (combined_df[col] - mean) / std if std != 0 else np.zeros_like(combined_df[col])\n",
    "            \n",
    "            n, bins, _ = ax.hist(z_scores, bins=50, density=True, alpha=0.7)\n",
    "            \n",
    "            xmin, xmax = ax.get_xlim()\n",
    "            x = np.linspace(xmin, xmax, 100)\n",
    "            p = stats.norm.pdf(x, 0, 1)\n",
    "            ax2 = ax.twinx()\n",
    "            ax2.plot(x, p, 'r-', linewidth=2)\n",
    "            \n",
    "            ax2.set_ylabel(\"PDF\")\n",
    "\n",
    "        ax.set_title(f\"{col}\")\n",
    "        ax.set_xlabel(\"Z-Score\")\n",
    "        ax.set_ylabel(\"Frequency\")\n",
    "        \n",
    "        # discriminative_text = f\"Discriminative\" if is_discriminative else \"Not Discriminative\"\n",
    "        # discriminative_color = \"green\" if is_discriminative else \"red\"\n",
    "        # ax.text(0.5, -0.15, f\"{discriminative_text}\\nScore: {discriminative_score:.2f}\", \n",
    "        #         ha='center', va='center', transform=ax.transAxes, fontsize=10, color=discriminative_color)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(output_file, dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    return stats_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_statistics(combined_df):\n",
    "    numeric_columns = combined_df.select_dtypes(include='number').columns\n",
    "    numeric_columns = [col for col in numeric_columns if col != 'embedding_id']\n",
    "    stats_dict = {}\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        data = combined_df[col]\n",
    "        mean = data.mean()\n",
    "        std = data.std()\n",
    "        cv = std / mean if mean != 0 else 0\n",
    "        stats_dict[col] = {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'percentile_99.5': np.percentile(data, 99.5),\n",
    "            'percentile_0.5': np.percentile(data, 0.5),\n",
    "            'all_zeros': np.all(data == 0),\n",
    "            'cv': cv,\n",
    "            'kurtosis': stats.kurtosis(data),\n",
    "            'skewness': stats.skew(data)\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame(stats_dict).T\n",
    "\n",
    "def normalize_and_filter_embeddings(csv_of_embeddings, stats_data, features_to_omit, output_dir):\n",
    "    raw_embedding = pd.read_csv(csv_of_embeddings)\n",
    "    \n",
    "    normalized_embedding = pd.DataFrame()\n",
    "    if 'embedding_id' in raw_embedding.columns:\n",
    "        normalized_embedding['embedding_id'] = raw_embedding['embedding_id']\n",
    "    if 'author' in raw_embedding.columns:\n",
    "        normalized_embedding['author'] = raw_embedding['author']\n",
    "    \n",
    "    for col in raw_embedding.columns:\n",
    "        if col not in ['embedding_id', 'author'] and col in stats_data.index and col not in features_to_omit:\n",
    "            mean = stats_data.at[col, 'mean']\n",
    "            std = stats_data.at[col, 'std']\n",
    "            percentile_99_5 = stats_data.at[col, 'percentile_99.5']\n",
    "            percentile_0_5 = stats_data.at[col, 'percentile_0.5']\n",
    "            \n",
    "            if std != 0:\n",
    "                z_scores = (raw_embedding[col] - mean) / std\n",
    "                \n",
    "                # Calculate z-scores for 0.5th and 99.5th percentiles\n",
    "                z_score_0_5 = (percentile_0_5 - mean) / std\n",
    "                z_score_99_5 = (percentile_99_5 - mean) / std\n",
    "                \n",
    "                # Linear mapping of z-scores to [0, 1] range\n",
    "                normalized_value = (z_scores - z_score_0_5) / (z_score_99_5 - z_score_0_5)\n",
    "                \n",
    "                # Clip values to ensure they are between 0 and 1\n",
    "                normalized_embedding[col] = np.clip(normalized_value, 0, 1)\n",
    "            else:\n",
    "                # If std is 0, set all values to 0.5\n",
    "                normalized_embedding[col] = 0.5\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    file_name = os.path.basename(csv_of_embeddings)\n",
    "    output_file_path = os.path.join(output_dir, f\"normalized_{file_name}\")\n",
    "    \n",
    "    normalized_embedding.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Normalized embedding saved to: {output_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_future_csv(csv_path, stats_data_path, features_to_omit, output_dir):\n",
    "    \"\"\"\n",
    "    Normalize a future CSV file using pre-calculated statistics.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_path: Path to the CSV file to be normalized\n",
    "    - stats_data_path: Path to the pre-calculated statistics CSV file\n",
    "    - features_to_omit: List of features to exclude from normalization\n",
    "    - output_dir: Directory to save the normalized CSV\n",
    "    \"\"\"\n",
    "    stats_data = pd.read_csv(stats_data_path, index_col=0)\n",
    "    normalize_and_filter_embeddings(csv_path, stats_data, features_to_omit, output_dir)\n",
    "\n",
    "\n",
    "def visualize_normalized_data(normalized_file_paths, output_file, dpi=300):\n",
    "    normalized_dfs = [pd.read_csv(file_path) for file_path in normalized_file_paths]\n",
    "    combined_df = pd.concat(normalized_dfs, ignore_index=True)\n",
    "    feature_columns = [col for col in combined_df.columns if col not in ['embedding_id', 'author']]\n",
    "    n_features = len(feature_columns)\n",
    "    n_cols = 5\n",
    "    n_rows = (n_features - 1) // n_cols + 1\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 4*n_rows))\n",
    "    fig.suptitle(\"Distribution of Normalized Features\", fontsize=16, y=1.02)\n",
    "    for idx, feature in enumerate(feature_columns):\n",
    "        ax = axes[idx // n_cols, idx % n_cols]\n",
    "        sns.violinplot(data=combined_df[feature], ax=ax) \n",
    "        ax.set_title(feature)\n",
    "        ax.set_ylim(-0.1, 1.1)  \n",
    "        ax.set_ylabel(\"Normalized Value\")\n",
    "        ax.set_xticks([])\n",
    "\n",
    "    for idx in range(n_features, n_rows * n_cols):\n",
    "        fig.delaxes(axes[idx // n_cols, idx % n_cols])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "    plt.savefig(output_file, dpi=dpi, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    file_paths = [\n",
    "        'ABB_30_embeddings.csv',\n",
    "        'ABB_70_embeddings.csv',\n",
    "        'AGG_30_embeddings.csv',\n",
    "        'AGG_70_embeddings.csv'\n",
    "    ]\n",
    "\n",
    "    combined_df = load_and_combine_data(file_paths)\n",
    "    stats_data = calculate_statistics(combined_df)\n",
    "    stats_data.to_csv('embedding_stats.csv', index=True)\n",
    "\n",
    "    stats_data = visualize_features(combined_df, stats_data, 'feature_distributions.png', dpi=300, discriminative_threshold=0.5)\n",
    "    \n",
    "    output_dir = 'normalisedandready'\n",
    "    features_to_omit = [\n",
    "        \"ratio_of_sentence_initial_conjunctions\",\n",
    "        \"detailed_conjunctions_usage_correlative\",\n",
    "        \"normalized_assonance\"\n",
    "    ]\n",
    "    \n",
    "    for csv_file in file_paths:\n",
    "        normalize_and_filter_embeddings(csv_file, stats_data, features_to_omit, output_dir)\n",
    "    normalized_file_paths = [os.path.join(output_dir, f\"normalized_{os.path.basename(file)}\") for file in file_paths]\n",
    "    visualize_normalized_data(normalized_file_paths, 'normalized_feature_distributions.png', dpi=300)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vm2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
