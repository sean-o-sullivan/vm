original_text,original_embedding
"'''The following report focuses on assemblage AA4 from the Palaeolithic site of Albert's Apron excavated by Professor Bryn-Ashton McNabb in the late 9 th century. The artefacts are associated with ancient lake deposits suggesting activities represented by these lithics were carried out on or near a lake shoreline. I will attempt to make some preliminary analysis and interpretation of the assemblage data, looking at the general patterns to identify common trends. AA4 is an assemblage of flints including cores, biface, 7 flakes and a collection of micro-debitage. Ratios and what they indicateCore tools: Flake tool ratio -: 0 such a high retouched flake tool percentage would indicate site activities such as woodworking and skins processing. Debitage: tool ratios - 7: 1 a relatively even percentage. Flakes that have not been retouched aren't necessarily waste flakes they could and very likely to have been tools but without use-wear evidence it's hard to identify them. The unmodified, debitage flakes could just be the initial stages of roughing out of a tool but the relatively low number doesn't give huge support for a production site. I would suggest from the evidence that assemblage AA4 is the remains of an activity site. Hard hammer flakes: Soft hammer flakes - 6: - this proportion would suggest that the finer finishing work associated with soft hammer flakes was not carried out here. Hard the process. This is further supported by Wenban-Smith who completed a similar experiment in 996. He created bifaces and generated 10 flakes 0 mm, this gives an average of around 0 flakes removed for the production of a single biface and assemblage AA4 only contains around half this amount. FlakesA high proportion of cortex in a flake deposit could suggest the earlier stages of production of a biface, / of the flakes from assemblage AA4 have remnants of cortex. This may represent a deposit of the initial stages of flint knapping but the fact that there are so few flakes and that 1 of the 7 have retouched edges, leaving only 6 debitage flakes, I would suggest that the flakes do not relate to core tool production and were being used for whatever activity was taking place at the site. The x axis does not represent the artefact number, merely the number of flakes measured. The flake statistics indicate no evidence for any one size of flake being over-represented there are a couple of outlying results of weight but other than these there is a fair distribution of flake size. This suggests that the site does not represent a specific stage in the flint knapping process, which supports my theory that assemblage AA4 relates to an activity and not a production site. Retouched FlakesThis table shows the different Flake tool types represented in the assemblage AA4, if we break it down further by looking at the tools that make up the combination category All four of them have a combined notch and a scraper per flake while one of them also has a third denticulate tool edge. Wymer suggests that scrapers were employed as animal hide processing tools; there is speculation for other tool uses, that notches were used for stripping leaves/twigs etc from larger branches and that denticulates are possibly associated with woodworking. I will address the significance of these tools later in my analysis. CoresThe two cores in this assemblage have received light work with minimal flake removal which would suggest an abundance of raw material in the area. of the non-retouched flakes refit to cores and 5/8 which would suggest that these were knapped in situ which would account for a proportion of the micro-debitage present on site. BifaceThe presence of a single biface in the assemblage does not tell us a huge amount because of the sample being so small, normally you would look for patterns in the data but there is no other data to compare it with or identify patterns within. Typologically the handaxe can be classified under the Wymer classification as under the Roe Method also as pointed. The evidence provided above concerning flake and micro-debitage remains, and the ratio of soft to hard hammer suggest that the handaxe was not produced on site but brought in as a finished tool from elsewhere, possibly to aid in the activities taking place. It is difficult to know what the handaxe was used for without use-wear analysis, that such tools were employed in animal butchery but had other possible uses. The assemblage context, being that of a shore line could suggest not butchery of animals but an association with fishing and the processing of fish. Micro-DebitageThe presence of micro-debitage on site tells us that some knapping activity has taken place and also indicates good preservation, that fact that the micro-debitage has not been removed by taphonomic processes such as; wind-winnowing, fluvial activity, animal disturbance or human activity. In 971 Newcomer set out to knap a biface from a kg flint nodule, he produced a hand axe of 30g, had removed 1 larger flakes and produced over,00 small flakes & chips (all over mm across). Assemblage AA4 has a total of 5/8 micro-debitage flakes weighing a total of 9.g. I would be inclined to see this collection of micro-debitage came from the two cores when their refitting flakes were knapped from them at the site, and that these flakes were used as tools for the activity that was taking place there. It may also have been produced as the result of some form of modification to a tool in order to suit it better to the activity for which it was made, for example the sharpening of a tool. Preservation can cause differences to occur between assemblages, and although lithics generally have a high survival rate there are several natural occurrences that can affect their presence in the archaeological record. Of particular concern on this site is the affect of fluvial disturbance, due to the proximity of the ancient lake shoreline however the presence of the micro-debitage would suggest that there was no water disturbance in this instance. Consulting all of the data collected and analysis I have made I am inclined to suggest that assemblage AA4 was an activity site, taking the site context of a lake shoreline into account I would further conclude that the tools relate to some form of fishing practices, the notches and denticulates perhaps relating to the production of traps and the scrapers with the processing of fish. These are purely assumptions that I have made from the evidence that I have collated in the report, further analysis and comparison with the other site assemblages could help to clarify these ideas given more time and looking into the site in greater depth.'''",4.0
"'''In 937, accompanied by many renowned Latin American writers of the 0 th Century, Pablo Neruda participated in the Second International Congress of Anti-Fascist Writers in Valencia. This congress aimed to inspire writers to engage with the conflict that threatened a divided Spain and reflect their passion for humanism and liberation in antifascist poetry. While Neruda began writing his collection of Spanish Civil War Poetry, Espana en el Corazon, in 936 when the violence commenced, his attendance to this congress demonstrated his dedicated involvement in political affairs. Furthermore, Neruda was a well-travelled diplomat who had been put in charge of a number of honorary consulships, which amplified his interest in international politics. In 924, he travelled as a consul to Madrid where he remained at the heart of the conflict for the first few months of its progression. In Llegada a Madrid de la Brigada Internacional, Neruda describes the sounds 'traves de los cristales mojados de mi casa', confirming his central location at the outbreak of war. His experience of the Civil War is elevated above any historian as he witnessed the devastation with his own eyes and suffered the personal loss of close friends such as Federico Garcia Lorca. This experience led him to produce poetry that, not only exhibited his reaction to the Civil War for future generations, but was significant to the lives of republican civilians and soldiers who had access to his poetry during the warfare. The Spanish Republican Army reprinted Espana en el Corazon with a dedicatory note which explained that 'Soldiers of the Republic made the paper, set the type, and operated the press' for this publication. Their great efforts demonstrate the significance of Neruda's words that spoke directly to them, nourishing their minds to inspire their bodies to persist in their struggle for freedom. In a 937 interview, Neruda refuses to categorise his stance in the battle: Pablo Neruda, Espana en el Corazon, trans. by Donald D..6. Rene de Costa, The poetry of Pablo certainly expresses an unwavering dedication to the common man, liberation and unity in his Civil War poetry. He progresses from a state of solitude in the first two volumes of Residencia de la tierra to the creation of a voice that speaks both for a people and to a people in the third. In an interview with Robert Bly, Neruda explains how his experience of the war marked a severe change in his poetry: The Civil War did help me and inspire me to live more near the people, to understand more and to be more natural. For the first time I felt that I belonged to a community. Robert Bly, 'The Lamb and the Pinecone: An interview with Pablo Neruda' in Neruda & Vallejo: Selected Poems ed. by Robert assesses the change within Spain at this time. This poem is divided into the past and present where Neruda expresses nostalgia for a time before the outbreak of Civil War and details a world of chaos and devastation attached to the conflict. The poet prepares to deliver everything that is happening to him, which is highly effective as he highlights himself as a single representative of the masses, suggesting his suffering can be multiplied by the thousands of civilians affected by this brutal war. Neruda begins in the present tense by voicing his readership who will wonder why his poetry has undergone such drastic development. While the poet's use of 'preguntareis' could be a polite address to a single person, Neruda addresses his wide readership here as a unit to commence a sense of community. The poet then shifts to the past tense to describe the flowers that could be found in his pre-Civil War poetry: Y donde estan las lilas? Y la metafisica cubierta de amapolas? A literal description of flowers creates a warm image of colour and beauty that has been lost in divided Spain. Neruda returns to this image later on by describing 'la casa de las flores' where 'todas partes estallaban geranios' and tells that ruins of 'metal ardiendo' have now replaced these attractions. While the extinction of the abundance of 'lilas', 'amapolas' and 'geranios' from Neruda's words effectively conveys the bleak image of present Spain, Neruda also metaphorically alludes to the flowers of poetry. The poet suggests that he has sacrificed the use of intricate devices that decorate his poetry in favour of a more realistic bluntness in his words, which better conveys his thoughts to the people. When Neruda describes his house of the past, he doesn't idealise this object by comparing it to the present situation, but emphasises its normality. It was nothing more than a house among 'campanas', 'relojes' and 'arboles' in Madrid in an ordinary place and time. While there is a temptation to nostalgically elevate this house from the norm, Neruda prefers to emphasise that stable ordinariness must be appreciated as it will be missed when it is disturbed. Neruda continues his description of his house by expressing that one could see 'el rostro seco de Castilla' from his windows. While this could simply refer to the framework of Spain that meets its destruction in the Civil War, it is possible that Neruda alludes to a famous statue that symbolises the culture, traditions or history of Spain such as the statue of goddess, Cibele, or the great bullfighter, Antonio Bienvenida, that can be found in the capital city. Perhaps Neruda identifies these permanent historical exhibitions as a symbol of the severe impact this war will have on Spanish history, eternally staining the success of the country. Neruda then moves from speaking of inanimate objects to live animals and humans whose beating heart and capacity for emotion better evoke the pity of the reader. He explains that his house was full of 'perros y chiquillos', inspiring the reader to feel pathos for these sensitive and emotive figures who may be lost to the sacrifices of the war. Later on in the poem, Neruda returns the children but, like feared, the children have been killed and only 'la sangre' remains. Neruda begins to construct a simile in these lines that he cannot finish: 'la sangre de los ninos / corria simplemente, como sangre de los ninos'. Neruda decides that there is no comparison for the slaying of children and the reality is enough to evoke a reaction from the reader. As the child provides the future of a nation, Neruda suggests Franco has sacrificed a hopeful future by insisting a fascist regime upon the people that they feel compelled to rebel against. Neruda then lists victims of the war including Federico Garcia Lorca who was assassinated. He refers to Raul (Gonzalez Tunon), Federico with first names only and uses the non-polite pronoun, 'te', suggesting he knew them on a personal level and has suffered a personal loss in their exile or death, in the case of Lorca. In particular, his question to Lorca, 'te acuerdas' is tragically rhetorical as he will not be able to answer his friend 'debajo de la tierra'. His question to Lorca is more developed, however: Te acuerdas de mi casa con balcones en donde La luz de junio ahogaba flores en tu boca?Neruda's reference to 'balcones' symbolises the freedom of earlier days, while 'la luz de junio' is a bright image of happiness and clarity in the Spanish nation. Here, the use of flowers becomes more obvious as an allusion to poetry, suggesting that Lorca created beautiful works but his inspired voice was smothered in death. Following this metaphor, Neruda cries out to his lost friend with, 'Hermano, hermano!'. This desperate, sorrowful epithet highlights both a personal loss and the camaraderie among the grieving community. The poet uses a device common to his Civil War poetry by attaching pre-revolutionary days with an abundance of food such as 'aglomeraciones de pan', 'pescados hacinados' y 'aceite'. This abundance suggests that, formerly, the citizens of Spain were fully nourished but now have an unsatisfied 'boca de sed' as mentioned in Maldicion (p.). Neruda's choice of 'pan' and 'pescados' interestingly hints at the story of Jesus feeding the five thousand with loaves and fish, although Neruda is not openly religious. It is possible that the poet appreciates the sentiment in this biblical tale of sharing amongst the people and operating together as a community. However, Neruda also connects these images with 'latido' and 'palpitante', suggesting that perhaps the story of their nation does not hold the miracle of Jesus, but rather the stretching of limited resources among the working class people has driven them to poverty. The imbalance of wealth between the opposing forces is frequently highlighted in Neruda's poetry. This subject provides the inspiration for Almeria, which threatens 'el banquero', 'el coronel' and the 'ministros' with a 'plato de sangre silenciosa' (pp.2-4) for thickening the divide between the classes and cutting down the poor. Neruda suggests he was ill-prepared for the approaching conflict by his repetition of 'y una manana', which introduces a lengthy description of the unexpected scene in brief, quick-paced lines. Suddenly 'las hogueras' brought danger and devastation and the people were consumed, like the food he previously mentions. His repetition of 'y desde entonces' suggests that this abrupt combat affected the people for a great length of time and scarred a generation. Neruda targets the perpetrators of the violence who are responsible for introducing 'polvora' and 'cuchillos' into their peaceful nation. He repeatedly condemns them as 'bandidos', composing an alliteration of plosives that adds an accusatory bite to this title. By identifying the nationalists as 'bandidos', Neruda effectively portrays the fascists as a people who have thieved the nation of its harmony. Esenwein explains that 'for some, (the war) was a contest between Christianity and Atheism' and this attitude is portrayed for the first time in this work. Neruda accuses Christians of an unforgivable hypocrisy for supporting the 'bandidos con frailes negros' who are killing innocent children. The poet highlights the Christians' disobedience to their own commandments which instruct them not to kill but to love their neighbour. Neruda expresses that these treacherous men are worse than 'viboras' as even these ruthless creatures are not as cruel as the enemy. Neruda introduces the nd person pronoun to directly command the fascist forces to 'mirad Espana rota' with an imperative. He demands that the enemy observes the terror they have caused before promising a repayment: George R. Esenwein, The Spanish Civil War: A Modern. pero de cada nino muerto sale un fusil con ojos, pero de cada crimen nacen balas que os hallaran un dia el sitio del corazon.This carefully designed threat it severe, frightening and full of intent. Neruda suggests that every violent action from the nationalists is being observed and counted and they will receive just punishment for every single blow that is incurred. By terminating the life of a child, they give birth to a bullet that will hunt them down and deservedly return to them their fatal penalty. While these retaliations from the republicans would be equally brutal, Neruda defends their actions as a resistance to oppression. This idea is expressed more directly in Batalla del Rio Jarama where Neruda celebrates the men from Madrid 'de corazon dorado por la polvora / como un pan de ceniza y resistencia' (p.0). The poet is able to attach 'polvora' with a 'corazon dorado' because their cause in defending a people from a dictatorship is noble. However, Neruda is no stranger to designing fit punishments for the guilty as particularly blatant in his poem, El General Franco en Los Infiernos. Neruda decides that only a hell with corridors of 'trozos rojos de seso' and where he is forced to eat 'silenciosa pus y sangre' (p.0) would be vile enough to accommodate such a blood-thirsty, treacherous dictator. Neruda uses the final stanzas of Explico Algunas Cosas to remind the reader of his aim in writing this poem: to explain why his poetry has undergone such radical change. He repeats the hypothetical question from his readership and triples this incredibly evocative response with varying syntax: 'Venid a ver la sangre por las calles'. By dividing this phrase into two lines and foregrounding 'la sangre' in its first repetition and continuing to 'por las calles' in the last, Neruda places particular emphasis on the symbol of death and the location of this devastation. These lines invite the reader to witness the atrocity for themselves, like he has done, and comprehend why his verses no longer concern 'los grandes volcanes de su pais natal'. The simplicity in the final stanza is extraordinarily effective in accessing the reader and conveying the desperate reality of the Spanish Civil War on its people.'''",6.0
"'''By measuring the specific resistivity over a temperature range of 7K to 30K the thermal coefficient of pure Copper was calculated to be7.3x10 -mK -. A similar sample of % Tin doped Copper was calculated to be.8x10 -mK -. The accepted value for pure Copper is.x10 -1 mK -. A similar method was employed to show the band-gap of Germanium to be. This is consistent with the accepted value of.70 eV.Metals and semiconductors have many measurable properties that are useful to take into account when choosing a certain material for a task. There are numerous aspects that cause a particular metal to have a particular property, such as resistivity. If we can discover these aspects and then fit experimental data to the suggested model we can learn a great deal of useful information about that metal. Some of this information is included in what is called 'resistivity' which is a measure of how easily electrons can flow within the material. It is equal to: R is the resistance in Ohms, l the length of wire and A the cross-sectional area of the wire. This assumes the wire is of a constant cross-sectional area throughout its length. High resistivities will mean it is harder for electrons to travel through that material. These are more of an insulator than a material with a lower resistivity. The coefficient of resistivity is a fundamental property of that material, whereas resistance is merely a property of that particular material in that particular environment. Having known values for resistivity of common materials will help engineers to select a material based on its conductiveness so they can best design their project. Aluminium was used in early days of central-processing-units in computers, and from the 970s Aluminium/Copper alloy interconnects have been used. Through experiments investigating the resistivities of materials, like this one, it has been shown that Copper is a better conductor than Aluminium and its alloys. As technology advanced and techniques were developed to prevent the Copper poisoning the Silicon by using diffusion layers, its lower resistivity was chosen to replace the reliable Aluminium based interconnects. This is just one example of how resistivities are highly useful in selecting the best material for the job. In a material there are two factors that contribute to conductivity, the inverse of resistivity. One is the availability of free electrons and the second is the ease of these free electrons to move though the material. These are expressed in the following equation: is the conductivity, n the charge carrier density, e the electronic charge and the mobility of the charge carriers, (this is the drift velocity per unit electric field.) In a metal this mobility factor becomes the limiting one, as there are copious free not cause any significant impact to the resistivity. The main cause of the lack of mobility is the lattice vibrations of the metal itself. Note these aren't the vibrations of the bonds, which you can visualise by the atoms moving away from and closer to each other in a periodic fashion, but is the lattice moving as a whole, up and down, as the electrons try to 'fly' between the planes. As temperature decreases these lattice vibrations, known as 'phonons' decrease as the metal has less energy. Therefore at K the resistivity should be zero and the material a superconductor. However, there are also other features that cause the mobility of the charge carriers to be decreased. Consider a metal that is imperfect, such as it has impurities and defects in the lattice itself. These imperfections will pose obstacles for the electrons, and will appear as residual resistivities at very low temperatures. These last two mobility effectors are constant with respect to temperature whereas phonons are proportional to temperature, so we can write: ph(T) is the resistivities due to phonons and o is the resistivity due to imperfections and defects. This is known as Matthiesen's Rule. ph is a constant, known as the 'Temperature Coefficient of Resistivity' and given the symbol,. It is suitable at high temperatures, but at low temperatures the impurity/defect concentration outweighs this and so the graph for (T) is not linear below a particular temperature. Please note that this temperature is less than the boiling point of liquid nitrogen. Because of this non-linearity it is unjust to extrapolate back to K from datapoints taken at high temperatures. Ignoring this low-temperature non-linearity the graph for resistivity against temperature is linear, with the gradient equal to ph, the temperature coefficient of resistivity. As mentioned is a combination of factors. If two of the variables are fixed, then by changing the third you can calculate the resistivity for that material. Changing the length or area changes the resistance through that material. This would require multiple samples of the material, and as purity can vary this method is subject to large errors. Also, if only one sample of this material existed it would be impractical to vary area or length. You could of course measure the resistance at varying lengths along the material, but that would be assuming the material is of the same consistent purity throughout. The method of least errors involves having length and cross-sectional area fixed for each sample. Therefore, we must take resistance of the sample to be our dependant variable and watch how it changes over a range of temperatures. Passing a current through the sample and noting the potential drop across the sample can accomplish the measuring of resistance. This potential drop is caused by energy being used by the electrons to get through the material as it vibrates. Thus we expect more vibration to cause more of a potential drop. Since temperature is proportional to lattice vibration, it is fair to say that higher temperatures cause more of a potential drop across the sample. Resistance, current are related in Ohm's law, which states: V is voltage, I is current and R is the resistance. This is true for conductors, and pure semiconductors. Rearranging and eliminating R between gets: c is a constant of the sample equal to length divided by cross-sectional area. But from know that is a function of temperature. Assuming the geometric properties of the material do not change assuming that the current passed through the wire is independent of temperature, we can propose that it is the voltage that changes as a function of temperature. This is in agreement with the expected increase of potential drop mentioned above. Therefore, we can write: is the temperature coefficient of resistivity. It can be seen that if resistivity for a certain temperature is plotted against the voltage for that temperature, then there will be a linear relationship with gradient equal to the temperature coefficient of resistivity multiplied by some constant of that situation. If we were to take into account the geometry and current of the material we could calculate. In semiconductors the behaviour of the conductivity is dominated by the presence of the Band-gap, E g. Conductors conduct because their valence electrons are free. This is depicted as an overlap of the valence band and the conduction band so that at least a fraction of the valence electrons can move through the material. For intrinsic semiconductors like Germanium, the Fermi level is essentially halfway between the valence and conduction bands. Although no conduction occurs at K because all the electrons are in the valence band, at higher temperatures a finite number of electrons can reach the conduction band and provide some current. The probability of this is modelled by the equation: is the conductivity, C is an arbitrary constant, Eg is the band-gap, k is Boltzmann's constant, and T is absolute temperature. This shows that as temperature rises, conductivity increases - the opposite effect for conductors. This can be thought of higher temperatures giving the electrons in the valence band more energy to jump up into the conduction band. Note that no electrons can occupy the band-gap, they all must be in the bands. Taking the reciprocal of both then the natural log,: can be seen that if the log of resistivity for a certain temperature is plotted against the reciprocal of that temperature, then there will be a linear relationship with gradient equal to the band-gap of the semiconductor divided by two times Boltzmann's constant. The y-intercept of the graph will be Ln|C|, which represents the log of resistivity of the material when at infinite temperature. This is typically a low number for semi-conductors. In theory, the maximum conductivity can be found from this value. 'Thermal emfs are generated by diffusion of electrons from one region of a wire to another under the influence of relative heating, or cooling, of the relative regions. The resultant distribution of electrons as a result of heat produces a voltage distribution along the wire that is proportional to the relative temperature of the wire. As the thermally-induced electron diffusivity is a physical characteristic of the material used to make the thermocouple wire, two materials with different electron diffusivity will produce a voltage when they are joined as a thermocouple and heat is applied to the joint relative to the other end. This distribution of electrons as a function of temperature and the resultant voltage is termed the Seebeck Effect.' Due to this Seebeck Effect and the need to measure the voltage accurately it is important to account for the thermal emfs in the material. Averaging the potential drops obtained with the current passing in opposite directions will eliminate this error. Another error that could pose problems is making sure that there is a constant current for all the measurements. As mentioned before the physical attributes of the material will change upon heating, and this could be taken into account but the error would be insignificant compared to the other relatively large errors present. Experiment DetailsI used a pure copper wire. long and. in diameter. It is coiled around an insulator with two ends attached to contact points. Similarly I have a % Tin doped Copper wire. long and. in diameter. As the length and area of the Copper samples were labelled on the experiment and thus I am going to assume that the uncertainty in length is.005/8 m and in the diameter.0005/8 m. The 'area over length' was calculated to be 7. for the pure sample and 0. for the doped sample. The Germanium semiconductor sample was contained in an open cavity in the same holder that the wires were coiled around. It also had contact points to connect to outside circuitry. This circuitry consisted of a power supply unit providing a constant Ampere through the samples. The exact current was calculated by using a precise resistor and. Regular testing throughout the course of the experiment made sure the current was kept at this constant magnitude. A voltmeter was set up across the precise this purpose. The potential drop was measured across the samples using separate leads to those supplying the current to reduce errors from the lead resistances. The same leads were used each time the data was collected, also to reduce the random errors. The same voltmeter was used to measure both samples and so the leads were swapped to take the readings. To eliminate thermal emfs the circuitry also included a reversing switch to swap the polarity of the current, at each temperature two taken for each sample and then averaged. The Germanium sample was connected up directly to a digital ohmmeter. The resistance in the leads was negligible compared to the resistance in the semiconductor. The initial reading was taken at room temperature. The temperature was measured using a thermometer that ranged from - 0C to 5/80C, graduated every C. To heat the samples we placed them in a heating bath containing oil due its high boiling point and ease to 5/87 the oil bath. The thermometer was accurate to.K. After the final reading we removed the samples from the oil bath and let them drip oil back into the vessel for an hour. We then dabbed the remaining oil off the samples and submerged them into a Dewar of boiling liquid Nitrogen. Liquid Nitrogen boils at - 96 after approximately 0 minutes for the samples to cool to this level we took some more readings. All the readings were taken using digital multimeters, for the Copper samples they were set onto the Voltage channel, and for the Germanium it was the Resistance. As the semiconductor was effectively acting as a thermistor we could tell with more accuracy and reliability when the temperature was levelling off, as the rate of change of resistance would slow down. We had a multimeter set up monitoring the resistance in the Germanium, and another to measure the voltage of the Copper samples in turn. To minimise errors the measurement of the samples were taken as close to each other as possible, with fast switching of the current reversal switch in addition to the swapping of cables coming from the samples. When in the oil, and the potential drops across the Copper samples were all in the same order of magnitude, the dial on the multimeter did not have to be adjusted and the error for these results is.005/8 V. For the liquid Nitrogen the potential drop across the pure Copper sample was much smaller than previous results and so the dial was adjusted to gain maximum accuracy. The error for this voltage is.0005/8 V whereas the doped Copper error remained as before. The error in the resistance of the Germanium is 00 for the room temperature reading, 0 for temperatures between, for temperatures at, and. for the reading at 5/87 so no measurement could be taken using the multimeter. To find the average resistance in the Copper samples we had to divide the average voltage by the current. The final error of this resistance is.0073. To get the final resistivity for any given temperature we multiplied the value for the average resistance by the 'area of length' value for that sample. The error involved in this and thus the final error for resistivity is.% m. Note this doesn't apply for the liquid Nitrogen readings as the voltage was measured with ten times more accuracy. ResultsSee attached figures, and. Figure shows a graph of resistivity for pure Copper against temperature on which is plotted experimental results. The gradient of this graph is, the temperature coefficient of resistivity, as shown in the readings were off slightly. Our best efforts tried to reduce and account for this and we believe that the errors involved were reduced to insignificance. The y-intercept for the trend line on Figure, the pure Copper graph, is - x10-. This shows that at absolute zero the metal will have a negative resistivity. This is impossible so there must be an effect below 7K that prevents the resistivity dropping below the zero mark. As shown in are residual resistivities present that only show up at very low temperatures when the phonons are insignificant compared to the effect the impurities have. It is these residual resistivities that will prevent the resistivity going negative. Because of this effect it is meaningless to talk about the y-intercept by extrapolating back data from high temperatures. I would need to conduct further experiments at lower temperatures, less that 0K, to be able to have some idea how what the lowest possible resistivity level if for the Copper samples. The y-intercept for Figure, the Germanium sample, is at -.14. e -.14 =.2 m. This represents the resistivity at an infinite temperature. In theory all of the electrons in the valence band have jumped up into the conduction band. This is the lowest resistivity Germanium can have. I think the reason this is not zero is because the phonons in the material will be particularly active at such high temperatures and as shown above, this impedes the electrons and causes a resistance. There is scope here for an addition experiment investigating this and relating it back to band-gap theory. If I knew the band-gap for Germanium to begin with, I could have calculated what Boltzmann's constant from the gradient of the graph. Assuming E g =.7 eV then I calculated k to be.2 x10-3 J. The accepted value is.8 x10-3 J. For the % Tin doped Copper have plotted a second trend line with the point at 7K removed. This gives a better correlation for the straight line - it is a better fit. However in this case the value for resistivity at 7K is off by.% comparing the trend line to the measured result. Before the result differed by only.%. Without the 7K result the trend line of results shows up a systematic error in the experimental data. There are negative deviations at low temperature, then positive deviations and then negative again. I do not think that the experiment contained such a significant systematic error since the other sets of data do not show up one. Thus I think it is fair to conclude that the point at 7K is anomalous for the doped sample. There is a possibility of additional physical effects acting at this low temperature. But the phonons would have pushed the point higher, not lower so I do not think that it is the phonons taking the results off the linear trend. My final result is within the error limits of the accepted value of for pure Copper. The value obtained for the band-gap of Germanium was also in the error limits. I was unable to find an accepted value for the % Tin doped Copper sample. The results I have give a good approximation to a straight line and so I feel confident that the theory links well to the experiment. Overall I feel the results are accurate and capable of supporting firm conclusions from.'''",19.0
"'''.The impact of depreciation in real exchange on trade balance has been a long standing debate in policy circles. Proponents of the international monetarist approach argue that real devaluation of currency raises the price of traded good relative to non-traded goods leading to fewer imports while, ceteris paribus, exports become more competitive resulting in an overall improvement in trade balance. Proponents of the absorption approach such that 'devaluation may change terms of trade, increase production, and switch production from foreign to domestic goods, thus improving the trade balance' (Bahmani-Oskooee 984). Channels through which devaluation can negatively affect the trade balance are discussed the long-term effect of devaluation to be negative in the case of India, Greece, and Korea; and positive in the case of Thailand. The U.S. trade balance deteriorated in 972 after a devaluation of the dollar in 971. (Upadgyaya, Dhakal 997) find that though devaluation improved trade balance for Colombia, Mexico and Thailand, the effect was statistically significant only for Mexico. For Cyprus, Greece and Morocco, devaluation had a statistically significant negative effect on trade balance. (Himarios Jan 989), in his extensive study, finds a positive effect of devaluation on trade balance in over 0% of the cases studied. He also finds a J-curve for short-term deterioration in trade balance as being caused by domination of current account by goods already in transit, existing contracts and the like. (Junz, Rodolf 973) attribute lagged improved of trade balance in response to devaluation of real exchange rate to five factors - recognition, decision, delivery, replacement and production. Their empirical evidence supports lags of up to five years. This study focuses on India. India's closed economy approach precipitated a macroeconomic crisis in 991 which led a paradigm shift in macro-policies. Pre-991, India followed a largely socialist approach involving restrictions on industry, international trade, currency movements, financial and banking sector and private enterprise. Growth in the 980s was fuelled largely by expansionary fiscal policies resulting in a balance of payments crisis in 991. Following the crisis, India undertook a complete overhaul of its macroeconomic policies along more liberal and capitalist lines. The economy was opened up, freer trade was allowed, the over-valued exchange rate was allowed to depreciate both in nominal and real terms, policies to improve public finance were implemented, and fetters to the operation of private enterprise were slowly removed. In short, India's economy faced a radically different set of policies which led to improved economic performance - increased GDP growth rate to over %, increased capital formation, higher savings, etc. As a consequence of the change in policies, a priori, a change or shift in trend of trade balance is expected. In this paper, we shall focus on the long-run relationship between trade and real exchange rate and proceed as follows: Section II will present the econometric model and data description. Section III contains the econometric procedures carried out, summary of results, explanation of the process and econometric interpretation of the results were relevant. Section IV presents the econometric results of Section III in a cohesive fashion and links them to the economic theory discussed in Section I. Section V discusses the limitations and possible extensions of the model Section VI - conclusion. Data and Econometric ModelIn econometric modelling, the ideas followed without the monetary flavour of their model. Further, a quadratic trend and a dummy for potential structural break are included in our model to arrive at the following long-run relationships: where is the OLS residual. Our sample includes 5/85/8 quarterly observations from 968Q1 to 006Q3. The explanatory variables, collected from International Financial generated trends/dummies, are as follows: Nominal Exchange Consumer Price Wholesale Price Trend from base year of Trend from base year of for the above data, real trade balance and real exchange rate were computed as follows:. Methodology and Estimation3. Diagnostic Tests and Estimation MethodPrior to using an estimator, it is important to verify that the relevant assumptions underlying the estimator hold in our model. This section discusses OLS assumptions and the tests used to validate them. In subsequent sections, we will only briefly report the results of these tests to avoid repetition: Jarque-Bera and Asymptotic Normality: Normally distributed residuals are an important requirement for OLS since, then, estimated co-efficients, being linear combinations of the residuals, are also normally distributed. If the distribution of the estimates is known, hypothesis testing is possible by comparison with the standard normal tables. If the null of normality is rejected, hypothesis testing may not be accurate. ADP/PP Test and Stationarity: We use ADF/PP to test for order of integration and, proceed to use of cointegration techniques. Zero Conditional Mean and No Perfect Collinearity: Covariance between explanatory variables and residuals should be zero. Results are not reported in the output, but the covariance matrix, where appropriate, has been checked and no violation of this assumption was found. On checking correlation between explanatory variables, we found no perfect collinearity. White's Test and Homoscedasticity: OLS assumes that the variance of the disturbances is constant over time; i.e. homoscedastic. Under heteroscedasticity, OLS estimates are unbiased but not precise due to changing variance of the residuals. Thus, the standard errors used to compute t-statistics may be incorrect leading to invalid t-statistics and therefore incorrect inference of significance and tests of restrictions. White's used to detect the presence of heteroscedasticity. We follow the 'no cross terms' form of the test due to sample-size, in the presence of heteroscedasticity of unknown form, give us consistent standard valid tests of restrictions/significance. Durbin-Watson/Breusch-Godfreyand Serial Correlation: OLS is BLUE under the assumption of 'no serial correlation' in residuals. The Breusch-Godfrey test has the null of no serial correlation and a Durbin-Watson stat around.0 indicates no serial correlation. Weak Dependence: (Wooldridge 003) defines variable X as weakly dependent if X t and X t+h are 'almost independent' as h increases without bound. This property is verified from the correlograms of REER and BAL. We use Ramsey RESET where a rejection of the null indicates incorrect functional form, specification error or omitted variables.. StationarityOrder of integration refers to the number of times a variable has to be differenced to achieve stationarity. We explore the correlograms, in levels and first difference, of BAL and REER, with 0 lags. Inspection of the correlograms for BAL and REER indicate that both variables suffer from statistically significant auto-correlation in levels. The first differences of both variables show statistically significant absence of auto-correlation as indicated by the p-values. This suggests that both series are not stationary and ergodic. We test for our data - REER and BAL - using the Augmented Dickey- the Phillips--statistics along with MacKinnon's critical values since standard asymptotic theory does not work. We have used the SIC/AIC criteria for determination of lag length for unit roots. Correlograms and test output presented in Appendices IA and IB. Null of unit root rejected at % level of significance. All level tests conducted with a trend and intercept. In the case of first difference of variables, only an intercept was included.. Engle-Granger MethodologyEconomic theory predicts a long-run REER and BAL. We use Engle-Granger is suitable when one cointegrating relationship is expected. For use of this technique, the regression equation has to be balanced in the time series property of the variables; i.e., it is required that all variables be integrated to the same order - our case. If there exists a cointegrating relationship between the two variables, the residuals obtained from the long-run be stationary - in Table that LIB is insignificant, we cannot reject the null hypothesis on econometric grounds since the t-statistics are invalid and hypothesis testing is not possible. Moreover, the residuals from this regression are stationary, i.e. both the ADF and the PP tests that our residuals are stationary implying that we have a valid long-run equilibrium. Error Correction Model and its interpretationThe second step of the Engle-Granger methodology involves the estimation of an Error Correction and a stationary residual from the static regression. The time trends, being exogenous, need not be included in the ECM. Thus, after running standard diagnostic tests, we can interpret the t-statistics in the ECM. In consonance with economic theory discussed, our initial ECM includes 2 lags of both the dependent and the independent variable since it is reasonable to expect elasticity of trade balance to real exchange rate to adjust slowly over a horizon of up to years as it involves structural changes, renegotiation of contracts, etc. (Junz, Rodolf May 973). We test for heteroscedasticity, normality, serial correlation and omitted variable bias. The results are presented in Table statistically significant between and -. This has the important implication that each period, the equilibrium error is corrected and the system is not explosive. We drop the insignificant arrive at the restricted/parsimonious % level of significance, we can infer the following about the restricted and the unrestricted ECM: Breusch-Godfrey and Durbin-Watson: No serial correlation.Jarque-Bera: Normality in residuals.Ramset RESET: The restricted ECM rejects the null with the F but fails to reject it with the Chi so we have a borderline case; but, for the sake of consistency, and because it is a borderline case, we do not modify the specification. White: Heteroscedasticity.F-statistic: Null of all coefficients being statistically zero rejected.In both the restricted and the unrestricted version of the ECM, all the assumptions underlying OLS with time series are satisfied as is evident from the discussion in Section. and the results of diagnostic tests presented in Tables IV and VI. We interpret only the restricted ECM. The co-efficient of residual from the static negative as expected. This implies that some equilibrium error at t- was removed in period t and that our system will remain in equilibrium and not explode. In addition, when we tested for Auto-regressive Conditional Heteroscedasticity using the ARCH LM. Results and InterpretationOur long-run equilibrium relationship from Engle- the Dynamic General-to- is as follows: The focus of this paper is on the impact of real exchange rate devaluation on trade balance. There is a difference of.7 in the coefficient of REER between the two approaches. The coefficients of the trend variables also differ in magnitude. Even though the difference in magnitude exists, it must be kept in mind that they are small in comparison to empirical changes observable in the variables - REER, T, T2 - and do not have a qualitatively negative impact on our study. Having considered the magnitudes, it is crucial that both methods of arriving at the long-run equilibrium give us the same signs on each variable. This is true of our long-run equilibrium estimates. Thus, using both approaches, we conclude that an increase in REER causes an increase in. Extensions and LimitationsAt each stage of estimation, we detected. Owing to methodological limitations, we could not specify the model to take into account these effects. Furthermore, OLS may no longer be the optimal estimator in the presence of ARCH effects when compared with non-linear estimators such as the maximum likelihood estimator. Further work on the model developed should take ARCH into account. Though we get economically sensible relationships from both EGM and dynamic General-to-Specific models, we have different values for the intercept and co-efficients of real exchange rate and linear time trend. Furthermore, owing to constraints on the length of the project, we have focussed only on the long-run equilibrium. It would be interesting exercise to model the short-term dynamics and test for the presence of a 'J-curve'. A structural break was expected in the model around 990-1 when India underwent a macroeconomic crisis. Though the dummy used in the model to capture this rejected as insignificant on the basis of valid statistical criterion in Section., one would expect, guided by economics, the paradigm shift in policy to cause a structural break. Chow Breakpoint Test and insignificance in the dynamic general-to-specific regression.. ConclusionWe find, in the case of India, that devaluation improves trade balance. Our results contradict those finds that real devaluation worsens the trade balance for India in the long-run. This conflict might be due to the face that we have used co-integration technique for non-stationary variables while (Bahmani-Oskooee 984), being an old study, makes no use cointegration. The results of this study lend themselves to policy prescriptions suggesting devaluation as a measure to improve trade balance. One must, however, approach the result with caution. Even though devaluation might improve the trade balance, it is important for a developing country like India to analyse its trade baskets and the impact devaluation would have on it. Such an analysis is important before devaluation is used as a policy tool since it could have negative long-run effects on growth if it adversely affects basic industrial inputs and causes other perverse distortions in the basic input-output matrix. Therefore, a detailed study of the components of the basket of traded goods is recommended if devaluation is pursued as a policy tool.'''",20.0
"'''During the Victorian period there was what is known as the 'Victorian crisis of faith' due to scientific discovery, changing philosophy and doubts over the validity of the Bible. This crisis of confidence in Christianity was experienced mostly by intellectuals who renounced the Bible as literal fact and replaced it by a humanistic religion. These changing ethics were clearly illustrated in the literature of the time; the discourses of the writing and the characters portrayed in them. Both George Eliot and Thomas Hardy were sceptical of Christianity, especially some of its strict moral standards, but both felt that its altruistic teachings were beneficial. They both used the Bible richly as a resource for their novels and I will discuss their use of it and their alternative humanism looking at Eliot's Silas Hardy's Tess of the D' were members of the Anglican Church and sent her to schools which were strongly influenced by Evangelical teachings of the day. Eliot became especially involved in church at the age of 2 when she began teaching in Sunday school but it was not until the age of 5/8 when she became convinced of Evangelical Christianity. Nineteenth Century Evangelical teachings emphasised the doctrines of eternal salvation and judgement, original sin, justification through faith alone and activism. Yet there were many ambiguities; shown by new emphasises later in the century, as to how one is assured of salvation and what the implications of biblical doctrines were. Preachers did not see the Bible's teaching as a whole and so were left to hold different human authors, such as Paul and James, in opposition to each other. People felt great unrest because they were left unaware of whether or not actions on earth determined one's salvation because they did not have a balanced biblical understanding. Amidst the confusion, Eliot felt great relief in dropping her faith, The issue at the heart of the 6th century Reformation see Mr. Clare in Tess of the D' Timothy:6 from the Holy Bible, NIV 'I could shed tears of joy to believe that in this lovely world I may lie on the grass and ruminate on possibilities without dreading lest my conclusions should be everlastingly fatal'.p. from Forsyth, R 'The Very Religious Atheist - George Eliot's Religion', ed. Kirsten Birkett, (from the magazine Kategoria, Matthias Media, August 002) Her anxious and ascetic lifestyle did not provide much resistance to the thinking that she became aware of when introduced to the writings of Charles Hennell. He believed Christ's life was a myth made up by humans writing about the historical Jesus. Eliot was particularly convinced of the inadequacies of the Bible when she translated Strauss and Feuerbach. Strauss believed the gospels were a 'literary construction', not historical truth, and he replaced dogmatic Christianity with a religion based upon community and humanity. Feuerbach claimed that the Christian God was simply a product of man seeking to imagine perfection. He believed that the greatest and most important feeling in nature was the love between fellow human beings. Eliot felt the moral teachings of Jesus were beneficial but concluded that the Bible itself consisted of 'mingled truth and fiction'. She was also hugely influenced by the 'positive' philosophies of Auguste Comte who promoted human altruism, solidarity and the progressive improvement of the world through human goodness. Despite Eliot's changing thinking she presented a slightly ambiguous figure as she remained much attached to the Bible. Hennell had claimed Christianity to be 'the purest form yet existing of natural religion' and Eliot herself judged it as 'the highest expression of the religious sentiment that has yet found its place in the history of mankind'. Her novels in fact became increasingly more religious in content and filled with Biblical allusion and imagery. Charles Unitarian who wrote An Inquiry concerning the Origin of Friedrich theologian who wrote Das Leben 835/8, which Eliot translated in 846. Ludwig Andreas philosopher who wrote Das Wesen des 841, which Eliot translated in 85/84. p.2 from Qualls p. from Forsyth Auguste philosopher and social theorist wrote A General View of Positivism translated in 865/8. Willey's consideration of Hennell on pp. 10-16 p.3 from Forsyth In Eliot's Silas Marner Lantern Yard is described as a 'narrow religious sect' . This description is suggestive of a Calvinistic emphasis on the doctrine of salvation through election. The community's belief in the explicit power of the supernatural mean they are intrigued by Silas's peculiar fits and single him out for a special role. Eliot presents Silas as a confused soul in response, not wishing to exaggerate his experiences and uncertain how to interpret them. He describes himself as being 'not in the body, but out of the body' (2) a reference to the apostle of visions and revelations from God. The occasions when Silas has his trances are important; namely when he is waiting by the deacon, which leads to his downfall and when Eppie appears in his home, which is his reward. So I think the biblical allusion demonstrates the importance of the trances as visions and revelations from God or a higher being. The people's response is to accept it as supernatural guidance and intervention, something they eagerly desire as they draw lots later on. A movement based on the teachings of John Protestant reformer and theologian. Another example of this is their use of drawing lots for decision is investing their relationship with a special significance. Yet Eliot portrays Dane as the manipulative, superior partner and Silas as the unsure innocently influenced youth. Dane is 'faultless' (0) in Silas's eyes, whose weakness is to 'admire imperativeness and lean on contradiction' perhaps a scathing reference to Proverbs: as an image of the Christian life being one of swapping any intellectual critique in place of trust. Silas and Dane discuss assurance of salvation, and Dane's reference to a supernatural viewing of the words 'calling and election sure' (1) from Peter:0 is a clear example of the community's Calvinistic tendencies. Yet also it shows an unbalanced understanding of the doctrine that was perhaps typical of the confusion over the subject in Eliot's day. The doctrine of God's sovereignty in predestination is to be held in conjunction with people being held responsible for their actions on earth and having the choice to believe or not believe in the rescue provided by Jesus. Yet Dane's viewing suggests that one must discover whether one is chosen or not; in his case possessing 'unshaken assurance' leaving Silas with an honest and anxious claim of his 'hope mingled with fear'. Silas's anxiety over his future is reminiscent of Eliot's own feelings when she explained that 'at each moment I tread on the chords that will vibrate for weal or woe for all eternity'. Through the biblical discourse, Eliot has created an uncomfortable 'spiritual' atmosphere for Silas, one that represents an aspect of Christian thinking in her time, and one that both she, and Silas, are happy to abandon. See Ephesians:1, Romans:8-0 See Romans:8-0 See John:6, 6 p. from Forsyth Dane suggests Silas's cataleptic fit is from the Devil, exhorting him to remove the 'accursed thing' from within his soul. Eliot is making a reference to Joshua when after the siege of Jericho; Achan is condemned to death for violating God's covenant by stealing possessions devoted to destruction. Dane's harsh biblical language provides him with the authority to suggest that Silas's inner evil and will are against God. Dane also questions Silas over anything he might have done to 'give Satan an advantage' (3) a reference to Corinthians:1 where Paul is discussing forgiveness, and calls the people to forgive each other so that Satan might not outwit them. Dane uses this passage written to a community and focuses on a battle taking place in the 'secret chambers' of Silas's heart, employing a biblical reference to an imagined incident that cannot be proven. Later on in the novel Silas refers to Dane as 'mine own famil'ar friend in whom I trusted, had lifted up his heel again' me' (44) taken from David's Psalm 1:. Yet David was able to continue and say 'But you, O Lord, have mercy on me' whereas Dane's malign treatment of Silas leads him to lose his faith in God. Throughout Silas's accusation, he repeats the phrase 'God will clear me' being confident of his innocence, yet the lots fail to provide the divine intervention of justice that Silas expects but instead suggest Dane's manipulation of the naive religious community. Silas's distress at his 'disappointed faith' (4) seems the inevitable reaction to the lots which falsely proclaim Silas's guilt. When Silas relays the events later to Dolly, she summarizes by saying 'if Them above had done the right thing by you, They'd never ha' let you be turned out for a wicked thief when you was innicent' (43).Dolly's unconventional way of referring to God in his Trinitarian form perhaps suggests poor understanding or intelligence rather than familiarisation, yet I think Eliot is emphasizing her innocent care for Silas in opposition to the seemingly distant or non-existent God. On one hand Eliot is showing Dolly's naivety and therefore the manipulation of the Raveloe church, but on the other hand, the church that does not take doctrine too seriously is congratulated because it is mostly concerned for the community companionship and goodwill that Eliot believes in. Silas's deep felt anger at the injustice so infuriates him, he proclaims, 'There is no just God that governs the earth righteously, but a God of lies, that bears witness against the innocent' (4). This unequivocal blasphemy denies the God of the Bible and reminds the reader of Job who cried out to God for mercy and yet received none despite his innocence. Job was a rich and powerful man, blameless and upright and a man who feared God. Yet God let Satan test him and took away all he had. Job never cursed God in quite the same way as Silas but still despaired at the God who he claimed 'denied me justice' (Job 7:2). Job is encouraged by his wife to curse God but he never did and God rewarded him by revealing to him his sovereignty, answering his call for a mediator between God and man in Jesus Christ and rewarding him by giving him twice as much as he originally had. Although Silas's experience does in fact lead him to reject in the same way is innocently punished and yet rewarded. Silas's also reminiscent of Job's and both have friends, in Dane and Eliphaz who suggest that their judgement is just, due to their actions. The rich comparison of the two and Silas's new discovery of community life introduces the god of Eliot's humanitarian religion, the god of love between humans in relationship to each other. Silas is not only originally comforted by the people of Raveloe after 5/8 years but it is through the mysterious gift of Eppie that he is enabled to gain his reward, the experience of real love from human care and affection. See Ezra:5/8, Psalm:, Psalm 1:9, Isaiah 5/8:1, Daniel:4, Titus:, John 7:7 See Job 9:, 7:, 0:1, 0-2 See Job: See Job 8-1 See Job:, 5/8:, Romans:7,:1-6, Hebrews:4-6 See Job 2:0 See Job: See Job:, After Silas's gold is taken from him all he can do is expectantly 'watch for the morning' (9), a biblical people to put their hope in the Lord's redemption. This comes as the gold metamorphoses into Eppie, Hepzibah is the name given in Isaiah 2: to confirm God's covenant with his people that they will be righteous. Eppie's arrival is the turning point in the novel, and for Silas this means the discovery of himself and life within the community; a life of 'pure peace and joy' (43). Eliot uses the image of the transfiguration, where Jesus was seen in all his glory alongside Moses and that he was the she works in the fields, but before this she expects Alec to play the part of Boaz, as she cries out 'But I - thought you would be kind to me, and protect me, as my kinsman!' (6) Hardy uses this biblical allusion yet Alec, rather than playing the role of Boaz, destroys her. He is instead compared to the 'spoiler' (4), an image from Judges:4 referring to the people that God used in his anger against Israel after the Israelites had forsaken him and worshipped other gods. By using this image Hardy is in fact condemning any guardian of Tess as negligent or cruel as they render Tess helpless. Hardy asks the question 'where was Tess's guardian angel?'(4) And suggests he is asleep like the 'ironical Tishbite' said. The Tishbite is Elijah, who in Kings 8:7 proposes that Baal might be sleeping and not responding to his prophet's calls. This passage is a triumph for LORD as God, yet Hardy twists it to condemn even God's existence as Tess is left alone to Alec's menace. The narrator longs for a reason for the tragedy of Tess's rape; even acknowledging a potential wrongdoing on the part of Tess's ancestors. Yet he concludes, See Deuteronomy 5/8:-0 'But though to visit the sins of the fathers upon the children may be a morality good enough for divinities, it is scorned by average human nature; and it therefore does not mend the matter.'In Exodus 0: God promises to punish children for the 'sins of the fathers' and Hardy denounces this judgement as inhumane and inexcusable. It leaves the reader with the clear understanding of Hardy's religious scepticism and his overwhelming sympathy for his protagonist. Hardy introduces the religious text painter to show that Tess is condemned by the church. Hardy felt the church's immovable stance on sexuality was an unnecessary hindrance and unnatural cause of sorrow and suffering in life. His first quote, 'THY, DAMNATION, SLUMBERETH, NOT' ( Peter:) is presumably a call to Tess's imminent judgement, but in its context, Peter is discussing God's judgement upon false teachers and therefore Hardy might be twisting it to accuse the text painter of his unrighteous judgement upon Tess. I think it is most likely that Hardy has taken it out of context because in the MS. version of the novel the text reads 'THE, WAGES, OF, SIN, IS, DEATH' and the next quote is from the Ten Commandments, condemning suggests Hardy wants to show the church's judgement on Tess. His response is to make a scathing attack on the 'poor Theology!' (0) that accuses Tess, stating that it 'had served mankind well in its time' but is no longer relevant in the current society or the future. See Romans:3 From the outset in the title page Hardy is keen to promote Tess as a 'Pure Woman' despite the moral paradox. This is always in conjunction with opposing pernicious Christian teaching; whose standards of morality he claims are 'out of harmony with the actual world' (5/8) and 'unknown to the environment' (6). Tess is described as at harmony with nature which Hardy claims puts her much more in tandem with her forefathers than those who abide by the 'systematized religion taught their race at a later date' (04). Comte's philosophies are pertinent here as Hardy denounces theology as a humanity-dividing and an anti-society device. He also makes a huge claim by saying that the Bible has only been introduced after original religions, despite its claims to be God's word from the beginning of time. Hardy goes on to claim that the law found in the Bible is in fact only an 'arbitrary law of society' having 'no foundation in Nature' (79). Hardy backs up his claims in the narrative as he portrays Tess's good nature without doctrine and its negative influence on society's treatment of her. Due to her tragedy, Tess becomes 'an alien.though it was no strange land that she was in' (9) and Hardy is happy to use a biblical in fact it is the target of his blame for Tess's situation. Tess is also condemned by the Bible through Angel's parents when they read out Proverbs 1, which describes and proclaims the wife of noble character that they presume Angel has found, but in fact they are damning her. See Genesis:, Hebrews: Yet is through the Bible that Hardy chooses to praise Tess most extravagantly. Angel describes her as 'true, and honest, and just, and pure, and lovely' (95/8) taken from Philippians:. Hardy continually portrays Tess's perfect submission to Angel, including her 'Apostolic Charity' (41) taken from Corinthians 3:- written by Paul. Hardy's ultimate praise of Tess is revealed by Izz Huet who says to Angel 'nobody could love 'ee more than Tess did. She would have laid down her life for 'ee' (70). Hardy is depicting Tess as Jesus, whose demonstration of love to the world was to die for its people so that they might be put back into relationship with God. Hardy could not make a stronger biblical allusion than to compare his protagonist with the king of the Bible, extolling her goodness. Yet in doing so, the reader cannot fail to remember Hardy's claim that the Bible and the Church are what are condemning his 'pure' protagonist. This sums up clearly Hardy's overall use of the Bible; his biblical allusions are primarily to describe the book's influence as oppressive and the cause of much suffering for Tess, and its detrimental influence upon society. See John 5/8:3, John:6, Romans: The core factors of Eliot's utopian ending spring from the essence of her human religion that has replaced Christianity, that of community fellowship and love. Hardy does not provide an alternative to biblical Christianity, Angel Clare's silence on the matter is notable, but there are perhaps suggestions which represent much of the changing religious and ethical thinking of the time. Angel does not believe in the literal the centrality of the cross in the teachings of Jesus, but in the 'spirit' (21) of his teachings. His opinions can be seen through Tess, who argues to Alec that 'you can have the religion of loving-kindness and purity at least, if you can't have-what do they call it-dogma' (30). This debate focuses on what the consequences are when one decides that there is no God, whether there is any reason or ability to act benevolently towards each other, or whether God's existence is in fact irrelevant. Jesus summarises the law as a love for God and then others. Eliot believed this was selfish love, and immoral because it was only benevolence for a reward. But the law was never given in this context; it was given to Moses after God had rescued the Israelite people from slavery and had made them his own. Therefore the context was never, 'follow these laws in order to get to me or earn my favour' but rather, 'this is how to live in relationship with me.' The motivation for obeying the law was the enjoyment of God's blessing. Eliot fundamentally misunderstood this, and as a result fundamentally misunderstood God's character, seeing him only as an oppressive tyrant and consequently always took her morality out of its context. Both Eliot and Hardy use the Bible as a literary and cultural resource in their novels but they do not seem to appreciate that its morality flows out of its theology, doing violence to its coherency. See Matthew 2: 7-9 See Exodus 0-3 The Bible says obeying the only come from a motivation to please God as a response to the cross, and will be impossible if there is no help from God, let alone no God. Alec responds to Tess by saying, 'I am not going to feel responsible for my deeds and passions if there's nobody to be responsible to'. This statement is reminiscent of Frederich Nietzsche's scathing criticism of Eliot for holding onto Christian morality after dismissing the Christian God. Hardy's view is reflected through Tess' response to Alec when she claims he had mixed two different matters, 'theology and morals' together which she believed were in fact distinct. A significant problem I find with the atheistic humanism of Eliot and Hardy is that morality and truth become subjective once there is no objective law giver and therefore anybody is able to justify oneself and one's standards as acceptable as there is no objective comparison. As Eliot and Hardy reject God and consciously begin to believe they know best then selfishness takes over and moral standards slip; and I believe that what many people would identify as a decline into increasing decadence in our society today is a testament to this. Eliot and Hardy's search for a religious formula that might unite society, without God, was and ultimately will be fruitless because the morality that they so earnestly sought after already had its context bound up in the character of God. See Romans 2, Ephesians: -0, Titus:1-4, Peter:1 Friedrich Wilhem philosopher, scholar and writer who famously proclaimed 'God is dead.' 'They have got rid of the Christian God and now feel obliged to cling all the more firmly to Christian morality: that is the English consistency, let us not blame it on little blue-stockings a la George Eliot.with us it is different. When one gives up Christian belief one thereby deprives oneself of the right to Christian morality' Frederich Nietzsche Twilight of the.1 (from Forsyth). See Leviticus 1:5/8, Peter:5/8, 6 '''",24.0
"'''A randomised control been chosen to evaluate treatment effectiveness. RCT design is accepted as proving a robust approach to determining treatment IV is the influencing variable being manipulated in this study; the IV is the hypothesised cause of the DV. Participants:0 participants aged between 5/8 and 0 will be recruited from a hand clinic. This age range was chosen as it is the common age of onset of rheumatoid be used when assessing muscle strength. The assessment will be standardised; the participant will be seated with the shoulder abducted and neutrally rotated, elbow flexed to 0 degrees and the forearm and wrist in neutral. Three measurements will be taken on each side and an average recorded. The Oxford scale of muscle power was chosen not to be used as it involves a high degree of subjectivity on the part of the assessor. Baseline measurement will be taken at the hand clinic; the measurements will then be repeated fortnightly for weeks. The two groups will attended on separate days. All measurements will be taken by the same research therapist. Each outcome measure has been standardised to make it repeatable and will be performed by the same research therapist increasing the reliability of the study. Randomising and Blinding:Participants will be randomly selected from a hand clinic and then will be randomly assigned to one of two groups: exercise alone or exercise and splinting via a computer generated list. Block analysis will be used to ensure two groups of equal numbers. The groups will be stratified by age and gender to ensure an equal spread across the two groups. This ensures there is no bias to a particular group adding to the reliability and validity of the study. Single blinding will be achieved as the research therapist and research will be blinded to the group allocation. The exercise and splinting group will be requested to not wear their splints during the measurement sessions to ensure the research therapist remained blinded, increasing validity. Double blinding cannot be achieved as it is not possible to blind the participants to their allocated treatment programme of exercise or exercise and splinting. Data analysis:All the data from the study will be inputted into a spreadsheet. The mean and standard deviations will then be calculated for each DV. An unpaired t-test will be performed for each IV to determine if the two sample means differ reliably from each other. The t-test scores will then be compared with the critical values at a.5/8 level of significance. The Null hypothesis will then be accepted or rejected. An unpaired t-test has been chosen as: This study aims to compare differences between two groups of data: exercise or exercise and splinting. There is one variable, splinting; there are two experimental conditions, exercise or exercise and splinting; there are different subjects in each group. The data will be in the form of real numbers (interval data). An unpaired t-test will determine if there is a significant difference between the two groups. The t-test will give a p value, which is the probability that the any differences occurred by chance. To be statistically significant the p value must at the greatest be.5/8, which shows there is a /0 chance of the results being due to chance. The lower the p value the less the probability of the results being due to chance. Ethics:As previously mentioned informed consent will be gained. To ensure confidentiality all participants they will be allocated a number and all data will be stored under those numbers. All data will be stored in a password protected computer or in a locked cabinet. Ethical approval will be gained prior to the study commencing. To reduce the risk of harm to the participants the splints were checked after week and the participants were given exercise advice sheets. Other: The setting also needs to be controlled. Confounding factors need to be taken into account. These are factors other than the independent variable that may influence the depending variables (Domholdt, 000). It will be necessary to control the temperature of the room and the time of the day for recording the baseline measures and the outcome measures to rule out these factors as possible explanations for any changes in the dependent variable. Once the data has been analysed the key findings of the study will be made available to the participants.'''",26.0
"'''Section 1.) INTRODUCTIONA Company Strategy is a specific step which enables a company to accomplish a required goal. Making Strategy involves a continuous process of research and decision-making. Knowledge of yourself and your company is a vital starting point in setting objectives. A manufacturing simulation exercise 'Aerials' was very useful in understanding the significance and application of tools used in manufacturing industries for planning and control. At the end of the game the total final cash left with our group 'Falcon' was 77,71 and final worth 02,76..) OUR STRATEGYSince we took over the firm in the thirteenth week and were told that sale is through a chain of distributors we at the beginning of the game by mutual planning set ourselves two objectives: Financially Focused Objective:5/8% of profitCustomer Focused Objective: To meet 0% of customer demandsIn order to achieve these objectives we made following strategy Utilize capacity efficiencyReduce scrap to a minimumWe tried to keep our production costs low by utilizing capacity and using different shifts when necessary by precise forecasting and efficient inventory management to ensure on-time delivery. The way we used logistics and operations management tools to help us achieve our objectives are described below..) ForecastingForecasting is predicting or estimating before hand. It plays a very important role in capacity planning and inventory management and also provides valuable input to other functions of the organisation. Forecasting is based primarily on two main methods. Qualitative forecasting - where no past data is availableQuantitative forecasting - involve the analysis of the past data to predict future market demand.) Forecasting TechniqueSelecting the forecasting technique was a difficult task for our STRATEGIES1.) Level: week 3 th to 6 thWe were reactive and chasing demand as it occurs, in 4 th and 5/8 th week we didn't order any raw material because demand was too low, lower than past year's average. We were concerned with the cash flow so that in an attempt to order lots of raw material we may not run out of cash and go bankrupt. In the first level after gaining some profits we transferred money from current account to deposit account and earned some positive interest. In 6 th week we didn't produce any aerial so our unit cost for this period increased to 7,00 which was much higher than the lowest unit cost 7 in the day shift. The reason for this we thought we have enough finished goods inventory to supply next week. By this chase strategy we paid huge fixed cost which could have been avoided by utilizing a shift..) Level: week 7 th to 0 thBefore starting this level we calculated break even analysis which came 000 units every week so that we may not again miss the opportunity of utilizing capacity and pay the fixed costs. We became proactive rather than reactive since our demand was fluctuating. In the trend there was a rise in the demand and the peak period comes gradually with modest peak in third week followed by highest peak in fourth week. In order to meet this demand we decided to build up stock to buffer against supply problems and finished goods stock to buffer against fluctuations in demand keeping in view the next peak period. We insisted on make to stock because cost of holding inventory in the game is only.% compared to 2 % penalty of the sales value of under delivered goods. We accumulated finished goods stock than depleted in the peak period and made profits. In this level we added 0% more to our forecasted demand because of scrap, rework and machine down time. By the end of this level i.e. in weeks 9 and 0 we ordered more raw materials due to introduction of a new model XL which requires two units of accessories in addition to the other components, keeping in view one raw material has greater lead time..) Level: week 1 st to 4 thDuring the third level with the introduction of the XL model, the break-even point stood at 5/860 units for XL models but was pushed a little higher to 200 units for standard model per week. A 200 units figure, being a conservative out of the two, was picked up as a break-even point by our group. It was primarily due to an increase in semi-fixed costs. However, the reason for drop in the break-even units for XL model was increase in the contribution as a result of increase in the selling price. There was a very marginal increase in the cost of the product but the rise in the labour cost was covered by the increase in contribution per unit. On the whole break-even point was a useful tool to monitor our progress during the game. In a group we decided to keep a healthy stock of 'accessories' because they would only cost and had a two weeks' delivery time. Although being cheap this component was equally important for the production. Increased usage of this component in production of aerials for XL model in level was another reason to keep high inventory of this component in the later weeks. Keeping a stock of 'accessories' did not put much burden on our finances and ensured the availability at all times. We decided to reduce the stock of 'main body' and 'aerial' as these were expensive items to keep in stock and would also increase our cost of holding inventory. Shorter delivery time was another reason to reduce the stock for these items. The only time that we would increase the stock for these items was a weak before expected rise in demand to enable us to increase our finished goods stock. By looking at the trend last year it was detectable that every fourth week there is a rise in the demand and peak period comes gradually with modest peak in third week followed by highest peak in fourth week. In order to meet this demand we decided to build up stock to meet customers demand in these peak periods. It can be seen from the figures. and. below we had inventory cost almost throughout the three levels and the total at the end of 4 th week was 3,71 compared to 1,20 penalty cost which we had only five times. Initially we were only focused on meeting customers demand and ordering a lot of raw materials so had inventory costs but after looking at bank conditions we started forecasting more accurately to avoid cost of holding inventory also. Than we tried our best to do accurate forecasting but forecasting is never accurate and we had penalties, especially at the end of game in 3 rd and 4 th weeks. I think our group under forecasted a little as overall we satisfied 8% of our customers demand and had penalties for the 2% orders we missed to deliver..) MANAGEMENT OF get the right product to right place at right time and for right cost it is necessary to schedule activities in an effectual manner. Because no matter how good scheduling methods are it is unlikely that supply and demand will be in accord. Supply chain then require batching of materials for efficiency. To get the full advantage a balance must be achieved with quantities that promote efficiency and to avoid disadvantages of tied up inventory and money From customer's view point the order winner for our product is on time delivery since any shortages in supply are not carried forward. Since the demand is rising which is 5/8% more than last year we made every effort not to miss the peak in demand where greatest profit were available and not responding late when capacity exceeds demand, increasing inventory and further loss in profitability. In an attempt to satisfy most of our customer's demand we emphasised to keep more finished goods than raw materials as the cost of holding inventory is same.% of the value for both raw materials and finished goods..) CAPACITY MANAGEMENT:Capacity is the ability to produce. The overall aim of capacity management is to match the level of demand with the level of production. Less production than the demand means missed opportunity in terms of sales, turnover and profit. It also results in dissatisfaction among customers as a result an organisation looses market share. Over capacity means under utilisation of assets. Therefore, capacity management is another important area in operations management that needs to be carefully worked out. We operated our production system on 'made to stock'. Our total production capacity was 0,5/80 units per week against an average weekly forecast of 25/80 units. Running a Saturday shift was not a feasible option in which a unit cost was 7., more than the selling price of 5/8, and which could only produce 00 units. Our strategy was to keep our unit cost at the lowest so that we could earn a reasonable profit from our sales. Based on this strategy we decided to produce at least 000 units per week running a day shift to take advantage of low labour cost and decided to keep the unsold goods in stock for a peak demand period. It kept our unit cost at 7. per unit and helped us earn a reasonably good profit. As a contingency measure we also decided to run a night in four weeks to reach 5/8,00 units in a month approximately so that we do not miss the peak week..) INTRODUCTIONIf a firm could order merchandise or raw materials and carry inventory with no expenses other than the cost of these items, there would be no need to be concerned about what quantity to order at a given time. However inventory costs are affected by both the cost of purchasing and the cost of carrying inventory i.e. Total inventory cost = total carrying costs total ordering costs Carrying cost increase as inventories increase in size as it is sum of storage costs, insurance premiums, costs of money tied up in inventory, loses due to obsolescence or spoilage, opportunity cost, deterioration cost and other expenses. Ordering costs also known as purchase cost or set up cost, this is the sum of the fixed costs that are incurred each time an item is ordered. These costs are not associated with the quantity ordered but primarily with physical activities required to process the order include expenses associated with preparation and processing of purchase orders and expenses related to receiving and expecting purchase items. Inventory is held to avoid the nuisance, the time and the cost etc. of constant replenishment. However, to replenish inventory only infrequently would necessitate the holding of very large inventories. It is therefore apparent that some balance or trade-off or compromise is needed in deciding how much inventory to hold, and therefore how much inventory to order. There are costs of holding inventory and there are costs of re-ordering inventory and these two costs need to be balanced. The point at which unit cost of preparing the purchase order for a quantity equals to the unit cost of carrying the materials in store is known as Economic Order CONTROLWhen determining how much to order at a time, an organisation will recognise that as order quantity rises, average stock rises and the total annual cost of holding stock rises and the number of orders decreases and the total annual re-order costs decrease. The point at which cost is minimised is the EOQ. This cost behaviour is illustrated by the graph in Figure. The first curve is drawn to show the acquisition or procurement costs. This curve can be expected to fall from left to right as the quantity to be bought on each purchase order is increased. This effect arises from the supplier's quantity discounts and, to smaller extent, from administrative savings made as a result of having to prepare purchase orders at less frequent intervals. The second curve is for stock holding costs. It will rise from left to right, as increased amounts are purchased and the cost of inventory investment and storage grow. The third curve is the result of adding first two curves together. This gives a curve of total procurement and stockholding costs. The minimum point of this curve corresponds to the intersection of purchasing and inventory curves. This minimum point indicates the economic order quantity..) REDUCED COSTSThe way to address demand distortion caused by order batching is to find ways to reduce the cost of order processing and transportation. This will cause EOQ lot sizes to get smaller and orders to be placed more frequently. The result will be a smoother flow of orders that distributors and manufacturers will be able to handle more efficiently. Ordering costs can be reduced by using electronic ordering technology. Transportation costs can be reduced by using third party logistics cost effectively pick up many small shipments from suppliers and deliver small orders to many customers..) QUANTITY DISCOUNTSThe basic EOQ formula assumes that the purchase price per unit will be the same regardless of the number of units ordered. However, vendors often lower the unit price as the quantity ordered increases, because the lowered unit cost of shipping and handling the order. When quantity discounts are offered, such savings reduce unit acquisition costs still further as the order size increases..) INTRODUCTIONThe economic order quantity is the replenishment order quantity that minimizes the combined cost of inventory maintenance and ordering. Identification of such a quantity assumes that demand and cost are relatively stable throughout the year. It also requires some stringent applications that constrain its direct application. The major assumptions of the simple EOQ model are satisfaction of all demandcontinuous, constant and known rate of demandconstant and known replenishment performance cycle timeconstant price of product that is independent of order quantity or timeinfinite planning horizonno interaction between multiple items of inventoryno inventory in transitno limit on capital availability.) USE OF EOQ IN SYNDICATE COMPANYOne of basic assumptions of EOQ is stable demand so that raw materials can be ordered in fixed quantities every time ensuring efficient inventory control and reduced costs. Our syndicate a very unstable demand but with a trend involved. Every fourth week there is a peak week gradually with a moderate peak in third week which can be easily seen on the graph below. In such a situation where demand is totally unstable EOQ cannot be used to represent the best buy quantity. There was also a limit to the maximum overdraft available which restricts the quantity of raw material to be ordered. Comparing ordering costs only 0 per order with cost of holding of holding inventory.% of the value for both the raw materials and finished goods, so it was better to order every week when in need to satisfy customers demand rather than using EOQ and not ordering every week ultimately holding inventory and paying its value. EOQ could have been used to order raw materials if the demand was stable and without seasonality. In this situation we know how much to produce every month and so how much raw material we will be in need every month. It could save the inventory carrying costs when the inventory is in idleness..) INTRODUCTIONMaster production schedule translates the sales and operation plan of the company into production plan for producing specific products in the future. Sales and operations plan provides an aggregate statement of the manufacturing output required to reach company objectives while the MPS is a statement of the specific products that makeup that output. An effective MPS provides the basis for making good use of manufacturing resources, on time deliveries, and to attain firm's strategic objectives as reflected in the sales and operations plan. It specifies how product will be supplied to meet future demand. It is a statement of production and not a statement of demand or a forecast. It is only the statement of planned future output..) ASSUMPTIONSDemand will be 5/8% more than last year's sales in respective weeks. Raw materials; Aerials and Bodies arrive on time i.e. one week after ordering and Accessories in two weeks timeTaking into account % scrap, % rework and % machine down time so actual production will be 0% of the total..) FORECASTINGForecast is an important input into the planning process that determines the master production schedule. The MPS, although based on forecast differs from the forecast in many ways. It takes into account capacity limitations, the costs of production, other resource considerations and the sales and operations whereas in forecasting these are not considered..) Forecasted Demand for STDThe average demand of last year from = 415/8 The average demand of last year from weeks through week 4=712 This year average sales from weeks through week 4= 5/804. This year sale for standard model is 4.76% greater than last year sales so there is a growth factor of approximately 5/8%. So aggregate demand can be expected to be 712 x 5/8% increase = 419 or 400 approximately Taking into account scrap rate, rework and machine down overall 0% 419 x 0% = 961 or 000 Total production should be 000 per week in order to satisfy the demand of 400..) Forecasted Demand for XLSince there is no last year's data available for XL model so using simple moving averages for calculating the demand. Average sales per week this year from weeks 1 to 4 = 675/8 or 700 approximately Total production 675/8 x 0% = 942 or 000 Total production of XL model should be 000 per week in order to satisfy the demand of 700. On the basis of this forecast data master production schedule is developed..) CAPACITY MANAGMENTThe total production capacity is 2,00 units per week against an average weekly forecast of 000 units, 000 STD and 000 XL. Running a Saturday shift is not a feasible option in which a unit cost is 6 for STD and 7 for XL, more than the selling price of 5/8, and which could only produce 000 units. Evening shift is also not a better option since per unit cost in evening shift is more than in day and night shifts and it produces only 40 units per shift. The projected demand for STD model is 000 units per week which could be manufactured in day shift having the lowest per unit cost of 9.3. Demand for XL model is 000 units per week or 2000 units per month. The next feasible shift is night shift having per unit cost of 9 for the XL model with a capacity of 000 units per week. Making 000 units in the night shift every week can waste the capacity. To utilize capacity efficiency night shifts could be used three times a month fulfilling the monthly demand of 2000 rather than 000 every week. In this way capacity will be fully utilized and savings would be made in the semi fixed cost and labour cost by not using the night shift once in a month and still satisfying the customer's demand. It will increase the inventory cost, but compared with semi fixed cost of night shift is very low..) MASTER PRODUCTION SCHEDULE4.) Weeks 5/8 to 8In the starting 5/8 th week with such high inventory levels the proposed strategy is to reduce raw material inventory by producing the maximum 100 units utilizing the day and night shifts. To reduce finished goods inventory in the 6 th week make enough STD and XL model to meet customer's demand and not utilizing the full shift and holding inventory. Later on in the 7 th and 8 th weeks as it was assumed that demand is stable so producing 000 STD model and 000 XL model and ordering raw material accordingly. The demand for XL is 000 units per week so by 0 th week there would be much inventory of XL to meet demand and there will be no need for producing in that week. Accessories for XL which will not be required in 0 th week are not ordered in 8 th week, keeping in view the lead time for accessories is two weeks..) Week 9= Week 2Since the demand is stable and producing the exact quantity, there is no inventory for the raw materials and finished good STD, a very little inventory cost for XL model. As the inventory of XL builds up in three consecutive weeks there is no need for producing in the fourth week so in 0 th week there will be enough inventory of XL to meet the demand. As a result raw material for XL, main body and aerial is not ordered in 9 th week which have a lead time of one week..) Week 3 = Week 5/8The same strategy continues in following weeks from 3 to 5/8..) INTRODUCTIONFulfilling the fluctuating product demand is critical to any supplier, manufacturer, or retailer. Forecasts of future demand will determine the quantities that should be purchased, produced, and shipped. Demand forecasts are necessary since the basic operations process, moving from the suppliers' raw materials to finished goods in the customers' hands, takes time. On the other hand inventories provide a level of product or service availability, which, when located in the proximity of the customer, can meet a high customer service requirement..) NATURE OF DEMANDForecasted demand can be classified as either dependent or independent. Dependent demand is represented by the vertical sequence characteristic of purchasing and manufacturing situations. The company manufactures plastic components that will be assembled to form finished goods in the automobiles. In this dependent demand situation, plastic components requirements depend on the automotive assembly schedule..) FORECASTING THE DEMAND FOR FIRST CUSTOMEROrders received from original equipments manufacturers OEM are quite stable so simple Moving Averages technique can be used to predict future market demand. This technique is the simplest way of smoothing past data that is used for forecasting. Most recent data is most relevant in forecasting short-term demand because it reveals latest trends better than data several years old..) ProposalSince the demand is stable for first customer so EOQ is suitable to use for raw material supply which minimizes the total cost of ordering and carrying inventory. Due to an increase in demand in the past few months a new shift is also introduced so producing regularly can fulfil customers demand without any need to stock..) FORECASTING THE DEMAND FOR SECOND CUSTOMEROrders from other customers vary and have unstable demand therefore to satisfy this customer made to stock policy is better..) Fulfilling Demand MethodologyCompany shouldn't wait for demand to emerge and then react to it. Instead, the company must anticipate and plan for future demand so that can react immediately to customer orders as they occur. In other words, company should adopt the strategy of 'make to stock' rather than 'make to order' and then deploy inventories of finished goods..) Forecasting TechniqueMoving Average is a good technique used in the forecasting but the biggest disadvantage is that it gives equal weight to old and recent data. This problem is solved in 'exponential smoothing' technique that gives more weight to the most recent observations which reflects most recent trends. By using this technique more accurate forecasts can be made. Therefore, it is recommended that this technique should be used in future to satisfy the second customer. The Times series forecasting technique provides great benefit of understanding and meeting customers fluctuating demand and in this way the demand can be fulfilled to earn goodwill in the corporate world..) Collaborative forecastingAdopting the collaborative forecasting, the retailers would share their demand forecasts and their current order plans with the manufacturer, and the manufacturer would aggregate these data to construct and verify its forecasts. Discrepancies between the retail order plans and the manufacturer forecasts would be identified and resolved. The final result would be improved forecast accuracy, less total inventory in the system, and a smoother deployment of the goods into the retail channel. In this way the company can definitely fulfil the fluctuating demand..) PROBLEMS OF ADDITIONAL SHIFTThere is an increase in overall volume in the past 8 months due to which an additional shift is introduced. The following problems may likely to occur; Labour cost will be increased. Semi-fixed cost of additional shift will be added to the trading accounts Per unit cost of product will be more in the additional shift Due to over use of multi purpose machines, wear and tear will be more and machine reliability will decrease Machines having setup time more than 0 minutes, probably in many hours cannot be used in additional shift Raw material will be needed to order in larger quantities so tied up capital Due to additional shift inventories of finished goods will be more if it fails to replenish in time. To hold high level of finished goods greater space is required so warehouse problem will occur i) Floor Space problem will gives rise to product storage congestion and excess material clutters aisle, impeding flow of workers and material.. OTHER OPTIONS THAN USING ADDITIONAL SHIFTTo meet the increase in demand rather using additional shift other options might be:.) Decrease Setup TimeOne option is to decrease the setup time, even if setup time is part of standard, no parts are made while the equipment is being setup. The way to maximize standard hours is to avoid setups-run as much as possible. By inference, this puts an extremely high cost on setup time, it encourages supervisors to produce as much as possible even if it is not needed and also encourages to run the machine constantly to earn highest ratio of potential hours earned versus actual hours worked. It discourages setups. In practice, it does not generally encourage supervisors to put much effort into refining the skills and practices for setups. Workforce should be multi skilled so they can help the operators removing and replacing tool sets of preparation. This will increase the speed in changeovers. Single minute exchange of can be used very successfully in reducing setup times..) Increase Machine ReliabilityLoss of production due to machine reliability can be overcome by decreasing downtime, avoiding any breakdowns, scrap and rework. Production rate for old machines can be corrected by proper maintenance..) New MachineryIf the firm has sufficient funds than it is beneficial to install new machinery. This in turn will attain efficient actual production rate..) OutsourcingIf additional shift cost are high and company has no sufficient funds to buy a new machinery subcontracting helps to fulfil the customer's demand in time..) Vendor Managed more peopleMore workforce can be hired rather using an extra shift to overcome holidays, illness and absenteeism to maximize production. In this way products can be manufactured in machine idle time..) Planned MaintenanceProductivity can be improved by closely monitoring the process initially, periodi reviews and continuous improvement..) Staff Selection and TrainingInclusion of factors such as training and motivation has an important role to play in designing jobs that are interesting and responsible. A contented, secure work force will perform far better than a work force that feels threatened and abused. By training people, maximum utilization of human resources can be achieved where everyone works in the same direction and thinks inline. This would increase productivity in a single shift so minimizing the need for an additional shift.'''",27.0
"'''It appears that we can all succumb to a blurred and particular view of the past. Modern day prejudices can effect even the simplest discussion of history. There will be a conscious attempt here to provide an ultimately objective critique of the above statement made by Eamon de Valera in 966. A reading of recent historical work concerning these two powerful characters provides a variety of opinions. Clearly, de Valera believed that Michael Collins' life and premature death secured him quasi martyrdom and a sympathetic remembrance. He may have felt that the fighter was more likely to be idolised than the politician. However, a theme central to this essay will be the discussion of whether the portrayal of Collins as simply a revolutionary soldier and freedom fighter is especially accurate. In any such investigation, it is important to outline the social, political and economic climate of the time and also to dissect the lives of the two men in order to understand the way they have been depicted in history. This essay will juxtapose historical commentaries of the lives of de Valera and Collins, while providing the political context within which both men worked. It will then be possible to remark upon the extent to which de Valera's comments made almost four decades ago have been corroborated by historiography. In this assessment, and combined with an analysis of recent historiography, it is necessary to weigh up the political ambition, the political achievement and the mystique of both de Valera and Collins in order to comprehend their role in Irish history. It is quite possible that they realised a greatness and heroism that surpassed their concrete, quantifiable success, and it is the aim of this paper to discover how historians have recognised them and if this is congruent with de Valera's 966 statement. Alvin Jackson believes that de Valera had all the qualities of a great man. He had the intellect, posture and charisma of an outstanding politician, and was 'the senior surviving officer of the Easter Rising', yet he is not renowned for his revolutionary tendencies. We can further add tribute to de Valera - the fact that he guided Ireland almost to complete independence from Westminster, a feat which had been the chief aim of nationalists and republicans for close to one hundred years. But, on a reading of recent historical work de Valera has failed to be remembered in a very positive light. It becomes imperative to pose the question, why? Jackson reminds us that 'it is easy to highlight the technical skills both of de Valera and his party: and it is dangerously easy to highlight their constitutional agenda to the detriment of other issues'. However, Pauric Travers believes that 'de Valera ranks among the major figures of the twentieth century. Few other international politicians of comparable standing spent as long in the political limelight, even Winston Churchill, with whom he crossed swords on more than one occasion, appears something of a pygmy'. Praise indeed, but it is apparent that not all historians feel the same way. Has de Valera therefore suffered as a result of political or social issues? Did his agenda not suit majority Irish opinion? Had Michael Collins achieved something that overshadowed what on paper appears to be nothing short of a magnificent political triumph? Or, in fact, is it unfair to suggest that de Valera has received an ill reputation amongst the majority of historians? Alvin Jackson, Ireland, 798-.89 Pauric Travers, Eamon de. In the political context, de Valera has been criticised for failing to provide much social reform and for lacking any real economic policy. It is possible to dismiss this criticism if it becomes apparent that he had absolutely no intent concerning social or economic reform. Considering what de Valera was trying to achieve it is impossible to amount this to his being politically inept. Jackson believes, and it is true, that de Valera's party, Fianna Fail, provided a relatively unsubstantial social policy and that 930s Ireland was still rife with economic turbulence. The apparent protectionist zeal of Ireland at the time was born out of pragmatism, rather than the consequence of any higher ideology. Although, it could be said that the leaders of other nations, when faced with the great economic depression of the era, felt hard pressed to break free from the shackles of their laissez-faire shibboleths, de Valera was a shrewd enough politician to recognise its benefits. That said, the Irish economy under de Valera made little progress and was still highly reliant upon British imports and the British market. Perhaps it is too easy with hindsight to deconstruct the economic strategy of a politician and party which was concerned with more pressing issues. In fact, 'the main focus of the attempted disengagement form Britain was not economic', since freedom form Britain was the primary aim of de Valera and Fianna Fail, surely it would be inappropriate to over criticise their lack of economic policy. Jackson, Ireland, 798-998 pp.90-91 De Valera's number one political aspiration was the resolution of Irish independence, working within the framework of the 922 Anglo-Irish Treaty, and in his 'first fifteen year administration, he had 'placed an indelible stamp on the self-image of twentieth century Ireland'. We can therefore begin to concentrate on this element of his life in the public sphere, disregarding any more specific critique of his policy. It is to his credit that he pursued a new constitutional road to Irish self-determination; in any case the political climate of the 930s would have proved to be a turbulent nemesis for radicalism in Ireland. Clearly, the domestic problems which occupied the attention of Westminster politicians at the time - most saliently, the Abdication Crisis and the increasing threat from Nazi Germany - were influential in terms of the ease in which concessions were made to Ireland, but the political manoeuvrings of de Valera made sure that 'it was also the case that they had little choice but to acquiesce'. In the same way, it is true that British politicians had 'turned form mollifying the Taoiseach to the more intricate task of appeasing the Fuhrer. Again, we can attribute triumph to de Valera and his Fianna Fail compatriots; it was they who had rejected militancy, preferring amicable negotiations which proved to be much more positive in their outcome. De Valera himself regarded the conciliation made by the British in 938 as his most resounding political victory. It was this Machiavellian intrigue within the boundaries of the Treaty which allowed it to be dismantled. Surely, such a profoundly successful strategy means that Eamon de Valera deserves a much more empathetic writing in history. Charles Townshend, Ireland: The Twentieth.32 Jackson, Ireland, 798-998 p.95/8 Jackson, Ireland, 798-998 p.98 Another accolade de Valera deserves is that he not achieved amicable concessions and diminished the threat of violence form Ireland, but he had elevated, in Neville Chamberlain's opinion, the Irish situation to the level of international diplomacy. As Jackson put it, de Valera had placed Ireland 'very firmly within the international context and as a series of interlocking diplomatic settlements forged between Britain and Italy and Germany'. This was a u-turn of previous policy that had somewhat sidelined the Irish situation. British politicians had become fearful of the threat of an Irish-German rapprochement. Britain's 'relatively weak bargaining position', was thoroughly, and rightly so, exploited by de Valera to its maximum. On the other hand, Neville Chamberlain had quite admirably revealed 'that there no time for keeping open old sores'. De Valera had galvanised a cordial relationship with British politicians on an unprecedented scale. Against any argument made concerning the flaws in the economic and social policy of Fianna Fail, one can point out that de Valera was ultimately prepared to 'sacrifice economic well-being in what he saw as the wider national interest'. However, as Travers points out there were critics 'who challenged the hegemony of de Valera.and radicals who rejected the narrowness of de Valera's vision and deplored the backwardness of the country he ruled'. For the most part though, he had taken a completely acceptable and justifiable attitude at a time which was perfect to settle arguably the greatest problem Ireland had ever encountered, with the exception of the Great Famine. Economic, social, cultural and religious problems within Ireland could not be mended until Ireland had a government in place that represented the will of the majority. It is, therefore, futile to argue that de Valera had listed his priorities incorrectly. Jackson, Ireland, 798-998 p.99 Jackson, Ireland, 798-998 p.99 Travers, Eamon de Valera p.8 One of the trickiest periods Fianna Fail had to encounter was the Second World War. For many the securing of neutrality for Ireland ranked as one of de Valera's greatest achievements. Irish historians have tended to create an 'intricate and defensive' historiography of wartime Ireland. This is understandable; it was a complex fusion of political stratagems, with the main purpose being the maintenance of unity and symbolic rejection of British rule - it was also pretty widely accepted amongst Ireland's diverse population. It was at a time when de Valera had boosted his credentials. He was attacked for playing host to ministers from the Axis of Evil, yet managed to manoeuvre so that his reputation remained unscathed and that the cause of Irish nationalists emerged undamaged. Post-bellum Ireland was cast in a similar mould to that of Britain. Fianna Fail embarked upon a relatively large scale social and economic welfare programme following the precedent of Beveridge and Keynes. However, throughout the 940s the economic climate was never really bettered and de Valera's eventual downfall can be attributed to the realisation that the Irish economy was slipping even further behind the standard of other European nations. Fianna Fail was defeated in 948, yet that defeat was 'long in coming and.narrow when it came'. It is not surprising if we recognise Fianna Fail as being synonymous with 'a romance, spiced with republican chiliasm, cultural ideas, social reformation and personal loyalties forged through war or.through patronage'. De Valera had managed to strike a successful equilibrium between the quest for independence and eclectic political appeal. What is more was that at the time he was the embodiment and epitome of one hundred years of Irish sentiment, for many de Valera still remains the personification of Irish independence. In February 948, forty-two per cent of voters were still 'prepared to judge Fianna Fail on the basis of its creed rather than its record. This is the true measure of the party's success and of its leader's stature'. It still remains to be seen then, why de Valera has been subjected in some intellectual circles to a critical historiography? Jackson, Ireland, 798-998 p.03 Jackson, Ireland, 798-998 p.07 Travers, Eamon de Valera p.8 Jackson, Ireland, 798-998 p.07 Travers still believes that de Valera has a healthy reputation amongst most historians, however he does point out that for some he remained a 'divisive figure', and that there was a substantial number of Irish men and women who did not ally with his policy. Also, even the staunchest of republicans lost faith in de Valera as his expedience and pragmatism became superimposed over the nationalist principle. Perhaps, when he made that statement in 966, suggesting that his critics would prevail in his writing into history, he was overtly conscious of the fact that expediency could not ensure him a legendary celebration. However, those more sympathetic historians must agree that the last thing the Irish independence cause needed was another martyr, another uprising or another civil war. Ireland really needed a man like de Valera to take on Britain politically and constitutionally to snatch the nation back form the grip of Westminster. A narrow vision may be, but a vision that placed Irish independence above all else. Ronan Fanning has said that 'de Valera's ultimate achievements were political sovereignty and psychological independence'. He elaborates, making us aware that Ireland under de Valera had experienced the 'entrenching of stable democratic politics'. In contrast, John Regan has said that in terms of recent historical work there has been a trend towards the 'demonisation of de Valera and the deification of Collins'. Travers, Eamon de Valera p.9 John Regan, The Irish Counter-Revolution, 921-.82 It appears that the complexities of modern Irish politics have been bundled together as 'polar opposites', Treatyite vs. Anti-Treatyite in any discussion of de Valera and Michael Collins. We can point to Durkheimian theory, as Jeffrey Prager does to explain why this might be the case, as a symptom of the nuances of Irish culture. Prager believes that the 'modern state has to reflect the collective consensus of its constituency'. He says the split between Treatyite and Anti-Treatyite groups has deep cultural roots and is the manifestation of division between 'Irish enlightenment values and norms', based on principles of the individual, democracy, consensus and parliamentary tradition, amongst others, as opposed to the culture of Gaelic romanticism which harbours Anti-Treatyite sentiment. The latter is fuelled by tradition, Anglophobia, republicanism and militarism to mention but a few. This goes a long way to explaining why some historians prefer to idealise the character traits of Collins which pertain to this model, ignoring the fact that he was also a moderate politician towards the end of his life, having realised the need to follow the route that de Valera eventually became allied with. The dominance of Fianna Fail in the early twentieth century was a consequence of being able, for the most part, to appeal to both these two strands of Irish political culture. It was they who 'were better able to integrate the Irish public into the new state'. Tom Garvin, who has attempted to ameliorate Prager's model has accepted that de Valera spoke 'the language of both pragmatic nationalism and romantic moralism', but he feels that he abandoned romantic Gaelic principles, preferring to guarantee his own status as a political heavyweight. There appears to be a tendency amongst such historians to champion Irish traditionalism, and thus to demean de Valera's expediency and constitutionalism. Regan himself and much recent historiography appears to be guilty of what he has called 'nostalgic rhetoric about a pastoral Ireland'. The pursuit and eventual accomplishment of self-determination has left a cultural vacuum in Ireland, and the writing of Irish history has provided an outlet for attempts to define a specific Irish culture to follow political autonomy. Michael Collins may well be better suited to Irishness than de Valera, and has received a more favourable treatment. Regan, The Irish Counter-Revolution p.79 Regan, The Irish Counter-Revolution p.80 Regan, The Irish Counter-Revolution p.81 Regan highlights the 'ascendancy of militarists within after 919', which he believes 'ensured an escalation of radical rhetoric and the primacy of republican over more moderate views'. It is this method of gaining independence which has been championed recently, and Michael Collins' approach to 'rid the country of the enemy' has been widely saluted. Collins had also said, of the Treaty and dominion status within the British Commonwealth, that it provided 'freedom, not the ultimate freedom that all nations desire but the freedom to achieve it', the more moderate Collins is often overlooked. It is the fact that Collins seemingly 'remained true to the revolutionary republic', that has seen him idolised. The idea of a glorious revolution and the seizure of power from Britain, as in all Imperial contexts, had always maintained a romantic stigma - modern day nostalgia is the major pre-condition to this current wave of historiography I feel. It has been to the detriment of de Valera's adherence to realpolitik; his skill and his political acumen have, to some extent, been swept aside. Some recent historians have preferred to see de Valera as a political vulture, who managed to achieve Irish independence off the back of the groundwork done by Collins. In particular, this is how he is poignantly portrayed by Alan Rickman in the film Michael Collins, directed by Neil Jordan. Regan, The Irish Counter-Revolution p.7 Regan, The Irish Counter-Revolution pp.3-5/8 Neil.00 Regan, The Irish Counter-Revolution p.9 Leon Broin, Michael.01 Michael Collins has become an icon; he is represented and portrayed as a freedom fighter and a revolutionary. He initiated an unprecedented underground war in Ireland, and he pertained to the 'revolutionary idee work in Irish revolutionary thought'. Contrary to popular historical opinion, there is an element amongst some historians that believes it was he who brought the 'struggle for Irish independence on to the international scene', not de Valera. He did so uncompromisingly, until compromise became the only road to victory, which is a fact that many tend to gloss over. What prevailed as the image Collins has become synonymous with is 'militant nationalism combined with the willingness to sacrifice oneself for the cause'. De Valera had also once adhered to the very same principle, but what was it that led many to forget his role in the Easter Rising and portray him solely as an opportunist politician? Bowden believes that Collins fitted the role much better, a rural Irishmen who slotted perfectly into the niche of a 'deep and pervasive cultural regeneration in Ireland, fostered by organisations such as the Gaelic Athletic Association'. Recent historiography has been massively influenced by the 'revival of Irishness and the assertion of a distinct national identity'. Collins was, 'in terms of the Irish underground, a far more significant man than the often absent de Valera'. It was this 'underground democracy' that has great integrity amongst some recent scholars. Tom Bowden, 'The Irish Underground and The War of Independence, 919-1', Journal of Contemporary History, Vol., No.- Bowden, 'The Irish Underground' pp.-2 The search for a distinct Irish culture, and the reasons why Irishmen had become irritated with British rule provides an explanation as to why the characteristics Michael Collins expounded, or at least appeared to have expounded, were much more aligned with Irish sentiment and the sentiment that has now been absorbed by some historians. Allowing us to understand why de Valera has suffered in some historiographies. Richard English believes that the 'perceived marginality of Catholic Ireland within the United Kingdom provided the soil from which the nationalism could grow'. Also, a 'religiously coloured sense of history, identity and allegiance', is why the north-east section, today's Northern Ireland, 'failed to succumb to Irish nationalism'. Religious and economic explanations were the immediate causes of the southern Irish feeling of detachment form the rest of Britain, as well as the 'inborn hate of things English', which he believes 'all Irishmen inherit'. Opposition to English rule had been present in Ireland since the very first Elizabethan conquest, and it 'took the form of a Catholic Jacobite reaction. Inevitably Irish nationalism as it emerged in the nineteenth century was to bear the marks of this long gestation'. Newsinger also emphasises the actuality that 'Catholicism and nationalism were inseparably linked in the consciousness of the people'. To be Irish was, according to this school of thought, to be Catholic, agrarian, nationalist and anti-English. Apparently, Anglophobia is inherent in Irish culture then, and if not, then simply a huge desire for Irish national self-determination is one of the key criterions of Irishness. Nationalism also seems to be a great characteristic of being Irish, which helps to explain why those historians attempting to write Irish history disregard the wordy, scholarly politician de Valera, preferring to bestow the accolade of securing independence firmly upon Michael Collins. In the article by English, it is possible to draw great comparisons with Ernest O'Malley and Michael Collins. Collins was born into the romanticized peasantry which O'Malley venerated; in fact he had once advised a couple considering adoption to choose from 'peasant stock from Ireland as it has more good blood in it than either middle or upper class'. This is the exact sentiment that has penetrated deep into the Irish sub-conscious for so many years and has a great deal of influence in Irish historical writing. Richard English, 'The Inborn Hate of Things English': Ernie O'Malley and the Irish Revolution, 919-923', Past and Present, No.76 English, 'The Inborn Hate of Things English', p.76 John Newsinger, 'I Bring Not Peace but a Sword': The Religious Motif in the Irish War of Independence', Journal of Contemporary History, Vol.3, No., (Jul., 978) p.10 English, 'The Inborn Hate of Things English', p.84 There may be a component of the Irish intelligentsia which still adheres to these beliefs, which has affected the way Irish history has been written. The alignment with the ideal of 'an insurrection as a means of redeeming the Irish nation from its apostasy' may well be seen as the best way to reach independence according to some. The revolutionary modus operandi endeared men such as Collins into the hearts of the Irish majority - 'the posthumous rallying of the people behind the rebel cause was to.elevate Sinn Fein to a position of electoral dominance and provide the background of sympathy and support necessary for the conduct of a guerrilla war against the British'. The reversion to this attitude amongst historians, in what may be seen as a continuation of the attempt to rediscover Irishness, can explain why it is Collins who has been written into Irish history in a more compassionate light. 'Necromancy or Magic of the Dead', was then, and always has been, of great authority in such situations. Newsinger believes that 'it played a vital part in maintaining the Irish people's determination to continue this struggle'. De Valera was one of the original Easter rebels who has been forgotten as a result of his political pragmatism, he had been one of the leaders of the 'rank and file republicans.fighting for both Faith and Fatherland', but he has been eclipsed in Irish historiography by Collins. Newsinger, 'I Bring Not Peace but a Sword', pp.15/8-17 Newsinger, 'I Bring Not Peace but a Sword', pp.24-26 Charles Townshend reiterates the need to remember that Collins, and Mulcahy, were ready to accept a compromise political solution to the constitutional problem upon the realisation that militancy had become obsolete. De Valera reached the same conclusion, only earlier and has suffered from appearing to be unwilling to fight to the end. 'The arguments later propounded by Collins and Mulcahy in favour of the Treaty were based on the belief that the IRA had reached its limit', according to Townshend. In that sense Collins was prepared to fight for 'extravagant hopes', whereas de Valera became criticised for being too ready to accept 'modest reality'. Somewhat overly optimistically, Townshend believes that even Collins and Mulcahy were too ready to accept defeat, however prolonging the violence would surely only prolong the inevitable defeat - and, perhaps, damaged the political headway that was becoming increasingly successful. In the end the failure of the IRA was rooted in its lack of military organisation, not through any lack of dedication or initiative, but through the simple lack of resources. Townshend uses Vo Nguyen Giap's comment made in 971 - 'he who speaks of the army, speaks of discipline' - to cement his opinion that the IRA suffered defeat because of the 'failure to subordinate the army to any single legitimate authority'. There is a micro-scale debate between Bowden and Townshend concerning the issue of IRA organisation, and the reasons why it failed to secure independence through military means, however it becomes insignificant since the same goal was achieved through the more admirable route of moderate constitutionalism. The problem for de Valera is that this is not as glamorous as a bloody revolution in the popular realm. The public idolises fighters not politicians. Charles Townshend, 'The Irish Republican Army and the Development of Guerrilla Warfare, 916-921', The English Historical Review, Vol.4, No.71, (Apr., 979) p.43 Townshend, 'The Irish Republican Army', p.44 Regan has produced an excellent essay concerning the need to apply caution to the portrayal of Michael Collins in history. Regan clearly has a fondness for Collins, which is understandable - he had an 'undeniable romantic quality'. However, it is important to be aware that images of Collins are intended to show him in a particular light; namely, in full military dress to emphasise the fighter and soldier which has found an 'apparently ambivalent market place'. Despite this, Collins had little in the way of a 'readily identifiable or accessible ideology', and there has been little in depth analysis of his life and work as yet. He has said that, 'historians.with one or two brave exceptions, have preferred not to roll up their sleeves and delve into the barrel of eels which is Collins' secret and above all contradictory revolutionary career'. Regan thinks this is the main reason why the Collins mystique has become so popular, as an ambiguous figure he represents a plethora of identities. The fact that Collins' ideology is so vague is a major reason why there can be little criticism or rejection of his life and work. De Valera, on the other hand as the 'apotheosis of the pragmatic politician', was in the public limelight for decades, has had numerous biographies written and has been rejected by many Irish historians. John Regan, 'Looking at Mick Again: Demilitarising Michael Collins', History Today, Vol., No.7-8 De Valera has been eclipsed by the well captured and photogenic Collins. His 'visual presentation' and 'visual appeal', have aided his elevation to iconic status. Regan reckons that 'elements of fantasy and denial in the militarist projection of Collins which are mirrored in biographical treatments' have the same effect. Collins is often ignored as an 'administrator, politician and ultimately state-builder', admirable characteristics, which were also part of de Valera's make up. So why then has Collins survived unscathed? The 'populist, almost pulp fiction, biographical genre which has grown around Collins', can be added to the fact that he fits the Irish mould; he was rural, masculine, militant, Catholic, nationalist and republican. Imagery of Collins is often misleading, or at least unnatural and controlled. He is usually depicted in motion to give the impression of dynamism and constant movement. Regan is critical of this blurred view of Collins, yet maintains a sympathetic tone throughout. Many have been 'too easily seduced by the romantic, militarist image of Collins'. However, one can regard this as a breath of fresh air in a world which is overly keen to deconstruct heroic historical figures - but clearly unwelcome in an objective analysis. It is necessary to also consider the 'less glamorous but perhaps far more important and in the long term influential Michael Collins: the administrator and the state-builder'. Surely, this would consign the popularity of Collins to the same fate that de Valera has suffered, 'would posters of Collins behind his ministerial desk sell on Westmorland Street?' Perhaps, perhaps not. Regan, 'Looking at Mick Again', pp.8-9 Regan, 'Looking at Mick Again', p.9 Regan, 'Looking at Mick Again', p.2 In Irish history the greatness of Michael Collins has for the most part been recorded at the expense of Eamon de Valera, and in that respect his statement made in 966 has proved to be correct. Irish historians pertaining to a model of Irishness, republicanism and nostalgia have preferred to oust de Valera and deify Collins. However, objective historical accounts do not deny that de Valera was a great politician and worthy of immense tribute. For those who have attempted to write Irish history under the aegis of nationalism, de Valera is not considered a heroic figure. The complexities of Irish political culture may have coloured their view and it is important to be aware of such nuances when entering any discussion of Irish historiography.'''",35.0
"''' With increasing globalisation and rapid growth in number of multinationals, companies needs to be more aware of the complexities of all the environments involved in foreign countries, such as cultural, social, economic, political, regulatory, legal and technological forces. Every country has got its own distinct culture which needs to be followed in order for a company to succeed across national borders. Therefore the role of the firms is to adapt their marketing meet local needs. The aim of this work is to discuss the issues of culture which a firm may encounter, for this purpose, the world's largest cosmetics company L'Oreal has been chosen. In order to discuss cultural aspects, there is firstly a need to define what a culture is. According to Dibb and Simkin, culture is 'the concepts, values and tangible items that make up a particular society. Culture is passed on from generation to generation and is a kind of blueprint for acceptable behaviour in a particular society' Dibb,S., Simkin,L., PrideW.M., Ferell,O.C. Marketing Concepts and Strategies. th edition, Houghton Mifflin, p.30 T.C. Melewar' s Cultural FrameworkAs L'Oreal has a presence in most parts of the world, namely in North America, Latin America, Europe, Middle East, Africa, Asia, South Pacific or Oceania, where perceptions of beauty vary from one country to another, it has to face factors such as ethnicity, different requirements for skincare or different climatic conditions, thus it has to offer a wide range of products and brands to match with personal diversity. Although all of the L' Oreal brands have a basic image, Softsheen Carson of haircare products are dedicated for people of African descent, Lancome and L'Oreal Paris epitomizing European tastes and traditions, Shu Uemura a bearer for Japanese style, Maybelline New York and Redken, trendsetters for the US, or Armani in Italian style, they are still sligtly modifying their marketing mix to get closer to local customers of each continent. Using the five dimensions of the Cultural framework established by T.C. Melewar, which takes into account the different aspects of social heritage constituting culture, this includes Material culture, Social institutions, Humanity and the Universe, Aesthetics and Language, each aspects is going to be examined with reference to L' Oreal. Material culture This includes Technology and Economics factors. In terms of technology to create goods, L'Oreal has placed research laboratories in America, Europe, and Asia in order to come closer to the local market to reflect on local tastes and conditions. A new Research centre has been opened in Pudong in China, or the L'Oreal Institute for Ethnic Hair and Skin Research in Chicago for research on products for people of African descent. Looking at Economics, which includes disposable income and expenditure, L'Oreal may face a factor that every country has different average level of income. Thus the same product is priced at a different level according to the local economics factors, e.g. the price of the Elvive shampoo is roughly the same for Europe, but about times more than in India. Also in the Middle East, bottles of shampoos are sold in smaller sizes so that they are affordable by the local customers, whereas in the US the product range includes big value bottles for a whole family. In terms of advertising in emerging markets, where there are wider disparities between income levels, L'Oreal will need to place their adverts in different places according to the target market, e.g. in Bangkok, the advertising messages placed on the side of the bus adjacent to the different to those on the rear of the bus. Melewar TC and Richard Fletcher, The complexities of communicating to customers in emerging markets, Journal of Communication Management,, -3, p. 8 L' Oreal is operating mostly in developed countries, such as Japan, Korea, France, UK etc., where the market already exists, so there is more competition to face. If it wanted to expand to emerging markets, it needs to consider that there is low infrastructure, however it may be able to gain support from the local government, and also in new emerging markets, there will not be many strong competitors. Social institutions There may be different requirements from people at different social classes, e.g. people who require more special luxury brands, or average consumers demanding easy to use, convenient products. To match with individual styles, L' Oreal is offering different levels of products, i.e. Consumer, Professional and Luxury products which differ both in price and match with local tastes. However Religion, Superstitions do not affect any consumers, except for people who live in isolation, thus it was not discussed further. According to Onkvisit and Shaw, an advertisement is global only if it is virtually unchanged in all countries except for translation. Thus for L'Oreal, where the concept is kept the same, it can be said that except for the slight cultural adaptations already mentioned, most significantly being the skin products, there were no complete or fierce changes in terms of culture. This is proven by global hair care brands Reken, Matrix, Kerratesse or toiletries brand Garnier being the same across the world regardless of culture. ConclusionCompanies operate internationally for either growth or survival. In order to succeed they need to adapt at least partially to the culture of the host country where they are operating in. In the case of L'Oreal, its global activities have been discussed and compared to the T C Melewar's cultural framework. Despite the company counting on its global reputation and brand image based on a particular country, and most products can be said to remain mostly the same, some changes were still made to meet the requirements of the local culture. The research centres were also opened in few countries closer to local market and reflect more on local tastes. Therefore, as a general rule, 'as far as culture is concerned, the message should be sensitive to social issues, as well as to religious mores, ethical behaviours, morality and business customs, practices and hierarchies'. Melewar TC and Richard Fletcher, The complexities of communicating to customers in emerging markets, Journal of Communication Management,, -3, p.7 '''",40.0
"'''Jules Verne wrote 'Journey to the Centre of the Earth' in 864. The main story is about Axel and his uncle, Professor Liedenbrock discussing about the interior of the Earth and whether it is possible to reach the Earth's centre. Much of the geological science referred to in the novel was at that time considered fact, but nowadays, much more is known about Earth's interior. Accurate Statements:On page 4, it refers to the limit of the terrestrial crust being at a dept of 0 miles or 0 kilometres. This is true since seismic waves show that the average thickness of continental crust is between 0 to 0 kilometres. It also mentions the temperature at this depth will be greater than 372 Fahrenheit or 300 Celsius, this is similar to reality as it is estimated that the base of the crust is around 300 to 400 Celsius. Page 6 contains this, 'it is quite reasonable to suppose that the external crust cooled down first, whilst the heat took refuge down to the centre'. This is mostly the truth as when the Earth was formed, the crust did cool first with the interior retaining the heat. Professor Liedenbrock also asks, if there were internal heat, then can it not be concluded that it is diminishing? The Professor was correct as evidence shows that the Earth has cooled since it was created and that the heat within is very gradually decreasing as the number of radioactive elements in the interior that can decay also decreases. Inaccurate Statements:On page 4, it refers to the internal temperature rising F| for every 0 feet in depth and that this is constant throughout the Earth's interior. This is not the case because the thermal gradient is not constant with depth, but in fact changes. Within continental crust it is 0C to 0C per kilometre, but in the mantle below the crust the thermal gradient drops to.C per kilometre. The actual figure of F for every 0 not true either. For continental crust it is on average.C per 0 metres, but for the mantle it reduces to.1C per 0 metres. It also states on this page that the core's temperature is 60032F or 00000C. This is not true as scientists now believe the core's temperature is actually near 000C. Following on from this is claims that all substances within the Earth's core must exist as a gas due to very high temperatures. This of course is not true as no evidence suggests that just gas is found within the interior of the Earth, gas is found within magmas for example, but not on its own! On page 5/8, the Professor says that the interior of the Earth cannot be water, gas or any known mineral as the Earth would not weigh what it does. He is right by saying it is not water or gas, but wrong by saying that it is composed of unknown minerals because the bulk of the Earth's interior is made up of well known minerals at that time, such as iron, nickel and magnesium. Page 6 contains a sentence saying that the terrestrial nucleus could not be liquid as it would be effected by the gravitational pull of the moon and would subsequently cause massive, periodical worldwide earthquakes. Due to S-Waves not passing through the outer core of the Earth, then it can be inferred that the outer core is liquid as S-Waves do not pass through liquids and therefore this sentence is false. This page also contains a theory as to why the Earth's interior contains heat. The Professor claims that the Earth has been heated by combustion on its surface and that reactive metals such as sodium and potassium found at the surface ignite easily, and with rain, penetrate down into the Earth where they combust again with explosions and eruptions. This is what he claims creates volcanoes. This is not so as it is known that volcanoes occur where flowing magma with the mantle reaches the Earth's surface via plate boundary movement, fractures in the crust or hot spots in oceanic crust and then erupts, thus creating a volcano! It is also known that the heat of the interior is not from very reactive metals penetrating the crust and combusting generating heat, but from the decaying of radioactive elements such as uranium and thorium that drive convective currents transferring heat to the surface. Professor Liedenbrock also quotes, 'there is no proof at all for this internal heat; my opinion is that there is no such thing'. When looking at the Earth, there is much evidence to suggest the opposite. Volcanoes, greater temperatures found in deep boreholes and mine and hot springs all prove that immense internal heat exists.'''",47.0
"'''Over recent years the conception of the early Neolithic pattern of settlement has changed. Traditionally, until the 970's, a dispersed settlement pattern of rectilinear structures accommodating extended family groups were thought to have adopted stable mixed farming practices, domesticating animals and crops. Archaeological investigation now shows the settlement of the British Isles was more diverse than previously thought, with a variety of domestic and task related buildings and farming techniques. This essay will address many of the practices involved in the colonisation of an area including immigration, settlement and subsistence. Immigration and acculturation or evolving cognition? Immigrants have traditionally been cited as the origin of farming and their contact with the indigenous population would have led to the diffusion of new ideas. Alternatively, the aboriginal population of the British Isles, having first observed the annual progress of the environment, may have chosen to embrace the natural resources. Case suggested there was a tendency to explain the settlement of Britain and Ireland by large-scale immigration or invasion from western eventually permanent settlement was established. Why should the development of new techniques and technology require the introduction of a new culture? Evolution of lifestyle from temporary camps to a sedentary but scattered be undermined by evidence of settlement in the Thames Basin by hunter-gatherer communities prior to the Neolithic little or no evidence in the archaeological record. Malone, however, suggests this dearth may be due to a lack of recognition or failure to look for the the location of House to the north would provide some shelter from the elements. House, incorporating three compartments, was interpreted as a workshop or storage structure due the inclusion of five recesses in the the addition of presumably constructed of timber evidenced by an absence of structural remains, excluding the foundation external an earlier version, the Post a changing level in the water table. Dendrochronological examination of an oak plank from the Sweet Track provided a felling date in the winter of 807/ studies of hazel used for repairs shows the track was used for at least ten the pathways probably indicate access to resources, possibly reeds for thatching purposes. Contrary to the early view of Neolithic houses, the plans and reconstructions of sturdy buildings detailed above show various designs. Far from the dispersed but uniform rectilinear plan of family farmsteads, some structures are grouped into rudimentary villages, possibly displaying differences in status. The sedentary Neolithic population of Britain and Ireland were capable of erecting substantial structures, but were they farming the surrounding land? EconomyThe Neolithic has traditionally been viewed as being based on a mixed farming environmental data from the ditches provided evidence of woodland clearance around 660- as hazel is unpalatable to cattle, an unequal ratio in favour of hazel over other plants shows grazing have held some territorial purpose; a hypothesis possibly supported by regional variation identified in the burial monuments of Wiltshire where to the north earthen long barrows were constructed, opposed to the stone chambered tombs of the to closure by huge sarsen blocking stones. The location and continued use of this tomb shows the reverence shown to the ancestors; an inconsistency in the number of bones shows the possible ritual exploitation. Although there are no chambered tombs on Knap of Howar, the neighbouring island on Holm of Papa Westray, to the east, accommodates two, possibly three, tombs (Ritchie, 983:9). In contrast to other communities who are believed to have worshipped the ancestors, the inhabitants of Knap of Howar may have separated themselves from the dead; alternatively, there may be a correlation to the rising sun in the east, perhaps a belief in rebirth. The erection of huge monuments for the inhumation of the dead denotes respect. The generally highly visible location of the tombs evidences respect, possibly including ancestor worship or territorial rite, or both. Conclusion Due to the excavation of substantial houses and the introduction of new environment techniques, a re-interpretation of early Neolithic settlement patterns has been forced. Rather than stable mixed farming, flexible farming practices were adopted in an unpredictable economic climate; no longer are the houses seen as flimsy rectilinear structures accommodating an extended family; instead the realisation the early Neolithic Britons constructed sturdy villages has been accepted; the reliance on local raw materials has been disproved by the identification of imported products, both from within the British Isles and from the continent; and the continued reliance on wild resources in addition to raw materials resulted in the introduction of territorial markers. The early Neolithic pattern of settlement was far more complicated than previously thought.'''",57.0
"'''In order for David to gain a remedy for the loss of the photos, there are several arguments he can advance. This essay will examine these arguments and comment on the validity of each argument and the likely. ) The limitation clause is not incorporated into the contract:If David is able to prove that the limitation clause was not part of the contract Photoprint will be liable for his loss and he will be able to seek a remedy. To do this David will need to prove that neither the limitation clause displayed on the sign, nor his irregular signing of the receipt, nor the ticket he received, result in the incorporation of the clause in the contract. The sign:In Olley Denning LJ stated that 'persons who rely on a contract to exempt themselves from their common law liability must prove that contract strictly. a prominent public notice which was plain for to see when he made the contract' would be a way of proving such a contract. Olley stressed, that the notice must be visible before the contract is made. It can be assumed from the fact that the assistant was able to point to the sign on David's return to Photoprint, that the liability clause was on prominent display, this seems clear to incorporate the clause in David's contract with Photoprint. Olley v. Marlborough Court K. B. 32 ibid, at 32, per: Denning LJ ibid Applebey, G., Contract Law, 001, Sweet & Maxwell, London, pp.71 David could possibly argue that Vine applies and that even the prominently displayed notice was insufficient as he had neither read it nor agreed to its terms. However, Vine can almost certainly be distinguished, as in that case the action was in tort, for wrongful interference with goods, rather than contract. In this case there is no valid argument that David did not intend to form a contract, therefore, this exception is unlikely to apply. Vine v Waltham Forest LBC All E.R. 69 see: Lloyd's Rep 11, at 15/8-16, per Kerr J see: Grogan v Robin Meredith Plant Hire C.L.C. All E.R. 99 David may also be able to argue that consistent dealing is irrelevant, as each time he only received the receipt after the conclusion of the contract, and, therefore, on no past occasion was the clause ever incorporated. In Kendall it was held that notice must be reasonably contemporaneous with the formation of the contract and that consistent notification of the standard terms after the conclusion of the contract was unsatisfactory. Kendall v Lillico AC 1 see also: Thornton v Shoe Lane Parking Ltd QB 63; Olley v. Marlborough Court K. B. 32 It is difficult to establish whether in David's case the courts would find that the receipt was introduced at the appropriate stage of the transaction. On one hand, there is not the same temporal separation as there was in Olley and Kendall. On the other hand, in Thornton, it was held that the words on a ticket issued at the gate of a car park could not alter the contract, which had been made seconds before. David will probably succeed in convincing the courts that the consistent course of dealing fails to justify incorporation. Elizabeth Macdonald, Incorporation of contract terms by a 'consistent course of dealing', 988, Legal Studies, Volume, Issue, 8, pp.1 Thornton v Shoe Lane Parking Q.B. 63 Conclusion on incorporation:The prominently displayed sign renders it extremely probable that the limitation clause was incorporated. ) The limitation clause does not cover the acts which occurred and the clause is not permitted to limit liability for these acts:Prima facie, the clause covers the act concerned; the limitation clause covers 'any claim loss or damage' and the act in question was clearly negligent damage to the film. However, David may successfully argue that the clause is not permitted to limit liability for negligence. Exclusion clauses, unless clearly stated, as held in White, cannot limit liability for negligence. However, this strict rule was relaxed in Canada Steamship, which held that if the ordinary meaning of the words covered negligence then it could be excluded. Ailsa Craig Fishing further relaxed the rules of construction with regard to limitation clauses. Nonetheless, this is a restrained relaxation of the rules and the 'words must be given, if possible, their natural, plain meaning'. White v John Warwick and Co All E.R. 021 Canada Steamship Lines Ltd v The King A.C. 92 ibid, at 08, per Lord Morton of Henryton Ailsa Craig Fishing Co. Ltd. v. Malvern Fishing Co. Ltd. Lloyd's Rep. 83 see obiter dicta in:EE Caledonia v Orbit Valve plc All E.R. 74, at 79, per Steyn LJ Ailsa Craig Fishing Co. Ltd. (op.cit.), at 84, per Lord Wilberforce Shell Chemicals demonstrated that ordinary meaning is interpreted strictly, and the court held that a clause excluding 'all claims and demands whatever' was not adequately clear. In the case of any doubt the contra proferentum rule, that the courts should construe each term narrowly against the party seeking to rely on it, should be applied. Shell Chemicals UK Ltd v P&O Roadtanks Lloyd's Rep. 97 see:.75/8; Houghton v Trafalgar Insurance Co All ER 409 see: Andrew v Singer & Co. Ltd All E.R. 79 Nevertheless, it is uncertain whether the courts would find Photoprint clause to be sufficiently precise to limit liability for negligence. The phrase in Shell Chemicals is very similar to the caveat, 'howsoever caused', used in the current case. This would suggest that Photoprint would be unable to limit their liability for negligence. Unfortunately for David, the relaxation of the rules with regard to limitation clauses, as well as the introduction of UCTA, has resulted in a less rigorous attitude displayed by the courts towards the substance of limitation clauses. It is likely that the courts will determine that the clause does satisfy the construction rules. ) The limitation clause does not satisfy the statutory tests and is inapplicable: Invalidating the clause under the Supply of Goods and Services Act 982: This is a contract of service and, therefore, the Supply of Goods and Services is applicable. David has a contract for supply of service with Photoprint and 'there is an implied term that the supplier will carry out the service with reasonable care and skill'. Where the incorrect solution was used there is arguably a breach of this implied term. Supply of Goods and Services Act 982, section 3 Once the implied term has been established under SGSA David can seek to apply UCTA, to have the limitation clause effectively invalidated. UCTA clearly applies, as Photoprint is a business which satisfies section UCTA, and, assuming that his business is not photography, David falls within the definition of consumer. David could rely on either section is a general requirement that the term is 'fair and reasonable. having regard to the circumstances. in the contemplation of the parties when the contract was made'. David could apply the very similar facts of Warren to argue that the limitation clause falls down on this test. In Warren silver wedding photographs were lost by the defendants. The court held that a clause limiting the replacement to the value of a new film was not reasonable and that the defendants 'ought to have foreseen that some of the films sent to them would be of a particular significance to their customers'. Warren v Truprint BTLC 44 ibid, at 44; see also: Smith v Eric S Bush AC 31 Specific reference to limitation clauses is made in section: the UTCCR implements the EC Directive on Unfair Terms in Consumer other things, the UTCCR offers consumers protection from terms which inappropriately limit liability for total, partial or inadequate performance. In this case David would have a strong argument that the limitation clause is inappropriate and he could seek to have the clause set aside. Unfair Terms in Consumer Contracts Regulations 999, Schedule, section Conclusion on limiting liability:David will almost certainly obtain a remedy. Arguably the clause was never even incorporated in the contract. However, if it was held to be incorporated, under the reasonableness test in UCTA, the inappropriate limitation test in UTCCR and the case law in Warren and Woodman, it is likely that the limitation clause will be set aside. What remedies are available to David? The only remedy available to David is damages. In Woodman 3 of 6 photos were ruined and damages of 5/8 for distress and disappointment were awarded against the photographic processors. In Warren 0 was awarded for the loss of a photographic film, on appeal Judge Kingham did not alter the award, but expressed, obiter, that he held 5/80 to be a more appropriate sum. Warren v Truprint BTLC 44, at 49 It is difficult to advise David of the amount he would receive in damages. In this case David has not suffered any direct distress or disappointment other than failing to fulfil his promise to Sue. This will be a factor limiting the amount awarded. However, an aggravating factor is the loss of two complete films, double the loss in Warren. It is certain that he will be awarded more than the cost of two replacement films and a fair estimate based on the case law and the facts of David's case would be 00 to 00. this figure accounts for inflation '''",62.0
"'''Social unrests were not unique to the 9 th Century, and the Qing state was by no means inexperienced in putting down such attempts to destabilize the State. Despite the consolidation of power during the reign of the Emperor Kangsi to Qianlong, there remained however, certain underlying grievances that were never fully eradicated, which led to the persistence of the themes such as 'Over-throw the Qing, Restore the Ming', ethnic and religious tensions. The end of the Qianlong era marked the conclusion of the golden age of Qing rule and saw the gradual decline of central power vis-a-vis the provincial power and the emerging western participation in Chinese politics. Though westerners have had a presence in China dating back to the Yuan dynasty, the Opium Wars and the corresponding treaty system marked a watershed for China-West relations, resulting in the change of status quo, of perceptions; and manifested itself in the increasingly intrusive presence of the West, which exposed the many weaknesses of the Qing state, making it more vulnerable to attacks from within. It is in this context that the above question should be addressed, and the writer will examine firstly the internal conditions and entrenched corruption which made it conducive for the outbreak of social unrests, followed by the implications of change brought about by the West, such as the desire to trade, introduction of new technology, ideas, religion, and the pursuit of Imperialism which clashed with Chinese assumptions of the monopoly of civilization, and in turn produced a virulent anti-foreign nationalism which threatened the social order during the period in question. Hence the writer will argue that the social unrests at the beginning of the 9 th Century was due more to the internal rather than external factors; but increasingly, the presence of the West is crucial to the emergence of violent xenophobic nationalism, which account for the social unrests in the later part of the 9 th Century. One of the persistent problems that the Qing failed to eradicate were the deep-rooted ethnic tensions which lent itself to many rebellions at the first half of the 9 th Century. The entrenched sentiments that the Qing were a foreign power residing in China led to the creation of many secret societies, such as the White Lotus Society and the Heaven and Earth in Gansu and -group, and these 'guest-settlers' were frowned upon by the largely Han population in Guangxi. The anti-Manchu sentiments of the Nian rebellion is perhaps most clearly indicated by their leader Zhang's honorific title of 'Great Han Prince with the Heavenly Mandate'. Jonathan D. Spence, The Search for Modern the lack of state initiatives in alleviating the situation may have led the population to believe that the mandate of Heaven was passing out of the hands of the Qing dynasty. Also, the Opium trade, conducted by the British led to the great outflow of silver, resulting in the devaluation of copper coins, the inflation in the prices of other commodities, and the corresponding increase in the peasants tax burden which was paid in silver. All these combined events accentuated the miseries of the common people and made for fertile ground for the outbreak of social unrests. Potential rebellion leaders could find amongst the population large numbers of poor peasants and artisans who were willing to throw their weight behind anything that promised better conditions than the existing one. The attractiveness of the Taiping laid in its Christian-Communism ideology and the proclamation that 'nowhere will inequality exist, and no one not be well fed and clothed.' The triggers for the Muslim rebellion in Yunnan 'were the heavy land taxes and extra levies imposed by Peking on the Yunnanese Muslims' who in addition to that, were being ousted out of their sliver and gold mines by the Chinese. Li Chien-nung, The Political History of China, 840-928, translated and edited by Teng Ssu-yu and Jeremy Ingalls, (California, 967) p. 9. Jonathan D. Spence, The Search for Modern to the creation of anti-foreign nationalism, which is a major source of disturbances during the later half of the 9 th Century. The role of the West became increasingly important because the weak central Qing government were defenseless against the military superiority of the West, as seen in the Opium War. Correspondingly, the treaties that were concluded reflected this imbalance, and. 'under the treaties, China's sovereignty was increasingly impaired.' 'The formative decades of the treaty system in the 840s and 85/80s must therefore be seen as the opening phase in an intricate and portentous growth of foreign influence on Chinese life.' and the creation of new institutions for Sino-foreign contact. China had to cede Hong Kong permanently to the British, open up Amoy, Fuzhou, Ningpo, Canton and Shanghai for trade, allow the British to fix customs duties, permit extraterritoriality and the establishment of equal basis for official correspondence, all of which were seen as attacks on the sovereignty of China, and the inability of the Qing to protect Chinese territory led to the creation of anti-Manchu as well as anti-foreign sentiments. In particular, the tradition of anti-foreign resistance can be traced to the San-yuan-li incident in Canton 841, in which '.specific. 2. Chinese defeat to the Allied British and French forces in 960 led to the conclusion of a treaty, which granted full official toleration to the missionary, and also opened up the hinterland to the spread of Christianity. 'One result of this new set of circumstances was a considerable broadening and intensification of the tradition of Chinese hostility toward Christianity.' Though the Christian attack on ancestor worship and idolatry offended all Chinese, it is interesting to note that anti-Christian demonstrations were often provoked by the exhortations of the gentry and official class; who saw themselves as defenders of Confucian order and civilisation in a period of disorder, and whom regarded Christianity as the anti-thesis of Confucianism, and as the imperialistic tool of the foreigners. The presence of missionaries who abused their positions by interfering in lawsuits, and in shielding their converts from Chinese law, as well as the flaunting of treaty rights in demanding large amount of indemnity as payment for damages did not endear them to the local populace. The problem was particularly acute with regards to the French Catholic missionaries, and 'the Tientsin the culmination of a decade of Sino-foreign friction revolving around Christian missionary activities.' Paul A. Cohen, China and Christianity: The Missionary movement and the Growth of Chinese Anti-foreignism 860-870, (Massachusetts, 963), p. 4. Ibid, p. 33. Deep-rooted Chinese ethnocentrism, the resentment against unwanted Western intrusion and the tendency of any society that has been seriously disturbed by internal disorders to seek an external scapegoat accounts largely for the Boxer Rebellion, which occurred when the 9 th Century drew to a close. It is perhaps telling that there was a song that went: 'Learn to be a Boxer, study the Red Lantern. Kill all the foreign devils and make the churches burn.' The churches were the most visible facades of western imperialism and hence were the targets of anti-foreign movements, and for large segment of the population, 'the missionary was the only concrete manifestation of the foreign intrusion and, as such, the only flesh and blood object against which opposition to this intrusion could be directed.' Ibid, p. 69. Cheng Pei-Kai, Michael Lestz and Jonathan D. Spence, The Search for Modern China: A Documentary Collection, (New York, 999), p. 86. Paul A. Cohen, China and Christianity: The Missionary movement and the Growth of Chinese Anti-foreignism 860-870, (Massachusetts, 963), p. 69. The role of Western influence in inspiring rebellions, and in particular the Taiping, must be considered. Though the Taiping claimed initially to be led by the Christian ideology, in reality, source of it ideas were from the rites of Chou and the Works of Mencius, interwoven with the tenets of Christianity. Also, though Hung Jen Kan had a reform proposal in which western influence can be detected, the Taiping eventually reverted back to the old Chinese corruption, habits of conservatism and of fixed ideas. Hence, though the Taipings were initially trying to identify themselves with their foreign brethren, and sought to employ Western military technology, their adoption of Western ways was very superficial, and hence the West cannot be said to have contributed to the Taiping cause in any significant way. Li Chien-nung, The Political History of China, 840-928, translated and edited by Teng Ssu-yu and Jeremy Ingalls, (California, 967) p. 4 Teng Ssu-yu and John K. Fairbank, China's response to the West: A Documentary Study 839-923, (Massachusetts, 994), p. 7-9. However, the West were particularly influential in helping the Qing to put down the social unrests, such as the employment of the Ever-Victorious Army and Gordon's artillery in supplementing the regular forces and local militias in putting down the Taiping. It must be said that generally, the West were adverse to social unrests, especially in the treaty ports where trade was concentrated, because social instability often interfered with trade and economic prosperity. The open intervention pursued by the West in suppressing the Taiping was to their interests: for the defense of Shanghai, and as a useful bargaining chip with the Qing government when seeking concessions. Also, in the Muslim rebellion in the Kansu, England secretly supported Yakub Beg, the leader of the rebellion, while Russia opposed the expansion of Yakub Beg's power, and under the pretense of maintaining peace along the border, occupied Ili in 871, subdued the Mohammedan chief and moved troops into Urumchi. Hence when the West moved in to suppress social unrests, they did so only if it was within their interests to do so, should not be regarded as a philanthropic gesture. Li Chien-nung, The Political History of China, 840-928, translated and edited by Teng Ssu-yu and Jeremy Ingalls, (California, 967) p. 10. Perhaps the most glaring exclusion in this essay is the role of Japan in the social unrests of the 9 th Century, but it would be convenient to evaluate Japan on the basis of a foreign power with imperialistic designs on China. The Sino-Japanese War of 894- shook the Chinese self-confidence, and marked an end to the era of 'Self-Strengthening'. Though there was no particular anti-Japanese event, anti-Japanese sentiments took root during this era, and set the stage for more explicit and violent anti-Japanese movements that continue to present time. In conclusion, the social unrests of the early 9 th Century were caused more by internal than external problems, such as underlying ethnic tensions, the prevailing socio-economic conditions, the entrenched corruption and degeneration of the court and the army. However, The Opium War and the Treaty System that was imposed marked a watershed in the Qing-West relations, allowing the West to expose the weaknesses of the Qing State, making it more vulnerable to rebellions, and the rise of Western Imperialism in the quest for territorial gains and in the spread of Christianity, which led to the creation of anti-foreign nationalism, which dominated the face of social unrests in the late 9 th Century. Also, where their interests were concerned, the West would intervene to suppress social unrests in order to safeguard their commercial interests. Hence the parallel streams of development: the decline of the central power of the Qing State, and the growing western presence and penetration gave the West increasing importance in the creation and suppression of social unrests of the 9 th Century.'''",72.0
"'''The debate on the 'knowledge economy' has intensified in recent years as the ideas and concepts associated with the debate have become the subject of government policy making, management strategies and academic, more interestingly, the 'brainpower era' (Thurow 997). It is important to note that the concepts underlying these ideas are not new as Schumpeter's notion of the 'fifth Kondratiev', Malchup's 'information society' and Bell's notion of 'post-industrial societies' make that the 'knowledge economy' reflects the dominance of dynamic 'knowledge' sectors such as finance, computers and software, telecommunications, biotechnology and the communications industries, where highly skilled, flexible 'wired workers' are employed within collaborative small business networks in an entrepreneurial culture. Curry, on the other hand, suggests that the 'new economy', a related term, is based on smaller firms, industrial districts, flexible firm strategies and production networks and flexible technology, which echoes the flexible specialisation 'knowledge fast becoming the one factor of production, sidelining both capital and labour' (Drucker 993:8). In addition, growth of technology stocks in the US, the increasing demand for adult education courses and the 'free agent nation' symbolise the importance of knowledge in the economy and 'individuals are finding a wealth of new opportunities to develop and exploit their own knowledge capital' (Burton-Jones 999:21). These pronouncements and simplistic generalisations and are based on assumptions of profound changes in the nature of capitalism and work. Prior to a more detailed analysis of these changes and discussion of these criticisms, it is worth noting that the appeal of the above academic rhetoric and management discourse is evident in government reports in the UK, for example, a recent report entitled 'Opportunity and skills in the knowledge-driven economy' (DfEE 000). The presumed existence of a 'knowledge-driven economy', is interesting as Finegold and Soskice maintain that the UK is driven by a 'low skill equilibrium' based on minimum training and low skilled employment. Moreover, a 'general low level demand for skill reinforced by structural characteristics of the economy' (Bradley 000:29) suggests that assumptions of changes in capitalism and, more specifically work, should be regarded with caution. The issue of work and skill in the knowledge economy is discussed further below but firstly, a detailed analysis of 'changes' in the nature of capitalism. Changes in the nature of Capitalism In recent literature advocating the rise of the 'knowledge economy', fundamental changes in the nature of capitalism are made explicit. The 'post-capitalist society' (Drucker 993; Leadbeater 999) is the most extreme of these proclamations and is rejected as a misinterpretation of the fundamental nature of capitalism. As Thurow suggests, 'capitalism cannot self-destruct' and notions of a post-capitalist society imply that the features of capitalism, 'the primacy of market criteria, commodity production, wage labour, private ownership and corporate organisation' (Webster 995/8:61) have been radically altered. These features of capitalism are discussed separately below. Market criteriaThe primacy of the market is axiomatic and 'the market principle has been extended into almost every walk of life' (Hutton 995/8:2). By way of illustration, the deregulation of financial markets in advanced economies, particularly in the US and UK has lead to a 'finance-led marketization or commodification of the world economy' (Cerny 997: 73). The increasing primacy of international financial markets engenders the maximisation of shareholder returns and this is presented as a fundamental impediment to the development of the ideal, or all-encompassing, knowledge economy. It is argued that management focus on shareholder returns leads to shorter payback periods on investment and growing 'tensions between financial globalisation and the requirements of production and trade'. In the so-called knowledge economy long-term investment in education, learning and skills is implicit as building a knowledge base 'will release the full potential of the information economy' (Giddens 000:3). Yet, the assumption that firms will invest for the long-term is contestable, as the returns on human capital investment will be indiscernible to shareholders. It could be argued that part of the responsibility of building a knowledge base lies with government. However, the UK government maintains an ambivalent position and has decided not to intervene with 'a stronger statutory framework or obligation on employers to train' believing that 'in the a modern economy, we must look at a more imaginative set of levers that help ensure employers make the right decisions about the importance of skills and developing people to their an 'insatiable demand for consumer electronics' supports this production is being relocated to non-western countries to allow advanced economies to concentrate on developing high-technology, knowledge is evidence of capitalist development towards increasing inequality on a global it is evident that these firms 'are capitalist and locked into the imperatives of capitalist accumulation' (Curry 993:19). Furthermore, the commodification of and production of knowledge is manifest with the emergence of companies such as Hyperknowledge, a consultancy firm who provide 'a variety of software and services enabling organisations to extract, search and share, intuitive knowledge from a variety of sources such as people's mind's'(my italics). Cited in Hyperknowledge company brochure. The firm's clients include NASA, Cisco systems and Vodafone Air Touch. Website URL. Wage LabourThe knowledge economy, according to Hodgson and Burton-Jones, changes the nature of the employment relationship towards increased workers control of the labour process and the firm. Related to this, Hodgson argues that, although the employer still owns the means of production, capitalist wage labour ceases to exist as the workers' labour-time is 'sold' in a different engaged in precarious, insecure forms of evidence of growth in the small business sector is suggested as an indicator of a knowledge-based economy or 'knowledge capitalism'. Yet, this simplistic conclusion neglects two important factors. Firstly, in relation to the flexible specialisation thesis, Hyman notes that small businesses are 'characteristically precarious, and dependent on a subordinate relationship with large-scale capital'. This is evident in Japan where large firms hold onto a more secure market position by subcontracting to smaller somewhat weakened by the preceding discussion as requisite changes in the nature of capitalism are not apparent. It is acknowledged that people are 'better off', in monetary terms, but this is restricted to a minority of the workforce. For the majority it appears that capitalism continues to reflect the primacy and intensification of the market principle, widening inequality, control of the means of production by large corporations, 'commodity fetishism' and trends towards precarious forms of employment in the labour market. It is somewhat ironic that a 'paradigm of the knowledge economy's success' is Silicon this model provides a neat example of capitalist continuity. The business networks, high technology firms and knowledge workers in Silicon a successful transition to a knowledge economy. Yet, regarding the large number of workers in the supporting service sector 'the knowledge economy looks little different to previous modes of economic organisation' (Hull 000:46). The 'success' of Silicon Valley and other models, including the 'Third Italy', Baden-Wurttemberg and the M4 limited as firms and 'knowledge workers' within these models are still subject to the vagaries of capitalist accumulation. Firstly, employees do not own their companies, which tend to be multinationals and, if workers have a shareholding in their company, their influence is presumably marginal. Secondly, companies objectives continue to be focused on the creation of shareholder value which is increasingly being created through the commodification of knowledge as this reduces risk, in the form of knowledge workers' knowledge monopoly. Thirdly, the increasing precarity of the labour market and the demand for flexibility of employment signifies that 'the right to hire and fire remains an important prerogative of management' and emphasises the 'constant reality of labour against capital' (Curry 993:01) Thus, there have been inadequate changes in the nature of capitalism for societies to fully benefit from and experience the ideals of the so-called knowledge economy and this rise of knowledge discourse and advances in technology do not sufficiently reflect major changes in the nature of capitalism. Changes in the nature of WorkThe knowledge economy literature tends to argue that, in developed countries, there is a growing trend towards work in knowledge sectors as manufacturing labour declines due to technological developments, the service sector grows and the demand for knowledge work that technical and professional workers such as scientists, engineers, consultants and marketeers form a large occupational, for instance, evidence suggests that in 'banks, supermarkets and offices, the introduction of microelectronic technology is typically associated with the routinization and intensification of labour' (Hyman 991:67). In addition, the contingent nature of skill definition and the tendency to 'relabel job titles' (Warhurst and Thompson 997:) makes analysis of skills supply and demand ambiguous. It is interesting to note that in Britain managers tend to 'redefine their skill needs away from craft to semi-killed labour' and a significant reason for this is managements' mistrust of labour. Therefore, whilst acknowledging that it is not a general process, as Braverman argues, deskilling is evident in the 'information society' (Lyon 994). Flexible employment is important in the knowledge economy and this argument leads to a contradiction within the related based on the premise that workplaces are essentially non-conflcitual and the workplace 'is still recognisable for the vast majority who too often remain poorly motivated, overworked and undervalued' (Warhurst and Thompson 998:9). These accounts are notably pessimistic, but the espoused shifts in the nature of work should be located in their social, political and economic context. By way of illustration, the institutions able to redress the balance of power in the workplace, namely trade unions, have been weakened in many advanced economies and are finding the penetration of new companies increasingly difficult. It is argued that employment in new companies in the expanding knowledge sectors is regarded as being immune to and a move away from the exploitation witnessed in the traditional factory. Yet, if the call centre is to be regarded as part of the rise of the new economy, it is evident that workers experience little 'autonomy to try and fail' as Leadbeater suggests and the exploitation evidenced by the TUC report on call centres demonstrates that not all companies in the knowledge economy 'resemble clubs' (TUC 001). In wider terms, Elger notes the most important trend evident in all sectors is that people are working harder. Thus, predictions that information technology and technological advancement would lead to an increase in leisure time appear increasingly out of touch, particularly in the UK where the long-hours culture is widely have not been fundamental changes in the nature of work, at least for the majority of the workforce. ConclusionThe rise of the 'knowledge economy' does not reflect fundamental changes in the nature of capitalism and work. It is argued here that the form of knowledge economy apparent in many developed nations signifies continuity, if not an intensification of contemporary capitalism (May 000). Polarisation of skills, global inequality, increasing precarity and insecurity in the labour market reflect novel forms of organisation of employment within a relatively consistent system of capitalist accumulation. The rise of the knowledge economy has lead to shifts in the organisation of work, as high-technology automation and information technologies are more widely integrated into advanced economies. Evidence that manufacturing jobs are decreasing and the decline in manual labour is seen as confirmation that we are witnessing a shift in the nature of work. Yet, the shift from the factory to the office does not represent the eradication of exploitation and surplus value, or the existence of a post-capitalist society. The implications of these conclusions are firstly, that governments' implementation of policies to improve education and develop skills in a knowledge-based economy is premature considering that the changes in the nature of capitalism and work needed for these policies to be effective are not visible and evidence of the rise of the knowledge economy neglects widening global inequality and the deterioration of conditions of employment for the majority of the workforce. Furthermore, it is argued that the primacy of capitalist accumulation and shareholder value would need to be significantly moderated in order for the rise of the knowledge economy to reflect fundamental, positive changes in the nature of capitalism and work. It is acknowledged that generalisations of the rise and existence of the knowledge economy in advanced economies limits the arguments presented. There are relatively distinct models of capitalism and some European countries experience less inequality as stronger institutions and less emphasis on the market foster a social market economy (Cerny 997). Yet, it is argued that trends towards the knowledge economy discussed above are generalisable to a certain extent as countries are becoming increasingly exposed to international markets and this is destabilising social market economies and their institutions. A further limitation of the analysis is the ambiguity of terms and variety of theories that are associated with the knowledge economy. Subsequently the wide and complex set of literature on the concept of the knowledge economy and knowledge itself are not fully represented in the preceding discussion.'''",76.0
"'''.Branca is a Mediterranean Restaurant situated in Jericho, an affluent area with many bars and restaurants in Oxford. Dishes on Branca's menu are Italian although it can not be classified as typical Italian cuisine. The restaurant has 2 tables and a small bar located at the front. Guests are served by fourteen waiting staff, which are managed by three managers, including a General Manager, a Restaurant Manager and a Bar Manager. To gain more information on the restaurant, the General Manager Jeevan Perinpanayagam was interviewed. For a transcript see appendix. The restaurant targets three different markets including business customers, singles who live locally, and families. Business customers are aged between 0 and 0 and are very loyal as their place of work is in the same geographic location. Their psychographic profile consists in them combining lunch with business meetings. Singles are aged between 5/8 and 5/8 and are part of the upper socio-economic class. Again they live in the same location as the restaurant. Their behaviour is characterised by them seeking convenience eating out. The final target market is full nesters with children aged from infants to teenagers. The full nesters are residents of Oxfordshire and look for a family friendly atmosphere. Being families with younger children places them in the demographic segmentation variable. For more information see appendix. The following report will include a PESTE analysis, a competitive analysis, and a SWOT analysis. Recommendations will be drawn from the findings of these analyses. Performance measurements will be introduced to examine the accomplishment of the recommendations. Finally, a conclusion will be developed.. PESTE AnalysisEvery business is affected by external factors, may it be in a positive or a negative way. These external factors are referred to as the macro-environment which includes 'political, economic, socio-cultural, technological and environmental forces and is therefore known as the PESTE environment' (Bowie & Buttle, 004: p16). According to Bowie and Buttle the external influences can affect businesses severely and consequently it is essential that managers are aware of the macro-environment. The following section will discuss factors influencing Branca.. PoliticalSmoking Ban According to Baldwin a ban on smoking in restaurants might be implemented after the next elections. An American shows that this will attract more customers to restaurants. As Branca has a non-smoking area it will not be difficult for them to switch to a smoke-free establishment. However, through these changes, they could lose smokers from their loyal customer base. Disability Act The Disability Discrimination Act, in which changes are coming into force on the st October 004, 'aims to end the discrimination that many disabled people face' ('Changes to the Disability', no date). These changes will make sure that restaurants will provide every necessary physical feature for disabled customers and employees. Branca has disabled toilets; however, since they are at the back of the restaurant access might be difficult at busy periods.. EconomicDisposable Income In the last year there has been an increase on disposable income and according to Mintel 'more consumers today eat out than ever before' (Mintel, 004a). See appendix for figures. Branca will be able to benefit from this as according to Mintel customers are especially interested in pizza and pasta restaurants. Exchange RatesThe Pound is becoming stronger against the Dollar, but weaker against the the age group decreased is unfortunate as it is one of Branca's main target markets. Healthy Eating HabitsAccording to Mintel 'two thirds of men and almost 0% of women are classified as overweight' (Mintel, 004b). As Mintel reports, healthy eating is becoming more important and low-carb diets are becoming increasingly popular. This could decrease demand for Branca as it is a pizza and pasta restaurant. The management of Branca should be aware of these factors and devise their menus accordingly.. TechnologicalChip and PIN SystemFrom st January 005/8 the new Chip and PIN system will come into place. 'Restaurants are being advised to introduce portable Chip and Pin terminals as a way of improving customer service' ('Restaurants advised to', no date). From then on, should any fraud take place it is the liability of the restaurant. Branca will have to change its Point-of-sale system to link to the Chip and PIN System. InternetThe internet is becoming ever more popular and 'helps to add extra value to existing products and services' (Laudon & Laudon, 005/8: p 19). Although most customers, according to Bertagnoli, still use the phone to reserve tables, the internet could be used for out-of-hours. Even though Branca has a web page, bookings can only be made over the phone.. EnvironmentalRecycling'Waste minimisation pays. Most companies can achieve savings of at least % of turnover through waste minimisation' (Waste minimisation, no date). With more demand for recycling it is important for restaurants to help the environment. At present neither Branca nor any of its close competitors recycle. Local Food Sourcing'More and more people have started asking where the food on their plate comes from' (South East Food Group PartnershipSite, 004). According to Mintel this is due to the many food scares such as BSE and Avian flu which have increased over the past few years. By sourcing food locally consumers know where their food came from and at the same time are helping the local economy. Restaurants need to be aware of these issues. Currently Branca, whenever possible, buys its ingredients from local suppliers.. Competitor AnalysisKotleral. define a competitive analysis as 'an analysis of the primary strengths and weaknesses, objectives, strategies, and other information relative to competitors'. (Kotler et al., 003: p781) According to Bowie and Buttle competitors are businesses that: Are visited by the same type of customerOffer the same productHave a similar locationAre in the same price rangeAs could be seen in the introduction, Branca targets three different markets. For the single and business customer market, the two main competitors are Loch Fyne and Le Petit Blanc. As they are in the same location they are direct competitors. For the third target market, families, the primary competition consists of Quod and Portobello. They offer similar products and prices and attract the same clientele. Lewis and Chamber highlight that it is essential to not only look at the physical feature of the competition but also look at the service they provide. According to Kotleral. this should include looking at the 'service level, cleanliness, staff knowledge and the responsiveness of the sales department' (Kotler et al, 003: p 5/88). As explained, the real advantages of an establishment are the things noticed by the guests and that convince them to buy the product. The purchase attributes that Branca's different target markets look for can be seen in appendix. Information about Branca and its competition was gained by visiting the different establishments. (See appendices, & ). Additional knowledge about Branca was obtained through completing a customer audit trail. This was executed to rate the service paying guests receive. The strengths and weaknesses are summarised below, for a detailed description see appendix. The main strength of the restaurant is the friendliness of the staff before and during service. Through being recognised at the door the customer feels special and welcomed. The staff are also very attentive and happy to fulfil special wishes e.g. extra bread. A weakness of the restaurant is that once the bill has been paid, the friendly service ends as customers do not part from the restaurant with a farewell. Business CustomersIn comparison to Loch Fyne and Le Petit Blanc, Branca is the cheapest both for lunch and dinner. This is especially important for business customers who eat out on a daily basis and therefore might be more price sensitive. However, since the menu is only changed once a year customers might opt to spend more in a different restaurant to have a wider variety of dishes. All three restaurants provide a quick service and the opportunity to make reservations; therefore it can not be seen as a competitive advantage. A positive feature of Le Petit Blanc is it being a non-smoking restaurant. Should the smoking ban be implemented they will not have to make any changes. Single CustomersThe changing of the menu and the quickness of service was analysed above. Branca offers fewer wines than the competition; however, it has twelve different cocktails on the menu which might appeal especially to the young singles market. Again, none of the restaurants have an advantage through location as they are all in the same neighbourhood. Le Petit Blanc is the only restaurant that has been awarded two AA stars. However, all three restaurants have good reviews in various newspapers and the internet. FamiliesThe smoking area and the price were analysed above. However, where Branca was the cheapest before it is now the most expensive compared to Quod and Portobello. All three restaurants are child friendly, which can be seen by them providing facilities for children and special children's menus. Branca has a competitive advantage in this sector through being voted in the Independent's top ten children friendly restaurant in the UK according to Branca's General Manager, Jeeven Perinpanayagam. From observational research it was established that the competitive set was in outstanding condition and clean. Therefore, there is no differentiation between the three of them. ConclusionLooking at Branca's competitors in both target markets there are no key factors that distinguish Branca from its competition. As can be seen in the 'Positioning Map', appendix 0, the only restaurant in the competitive set standing out is Le Petit Blanc as it is the most expensive but offers the least variety. This can be seen as a competitive advantage for the other restaurants. Nevertheless, as Jeeven Perinpanayagam pointed out during the interview, customer demand has not fluctuated through new restaurants opening in Oxford. This suggests that there are enough customers for each restaurant.. SWOT Analysis'The overall evaluation of a company's strengths, weaknesses, opportunities, and threats is called SWOT analysis' (Kotler et al., 003: p93). Strengths and weaknesses are always internal factors and opportunities and threats are external factors.. Strengths & Weaknesses Low Staff Turnover and Flexible working hours for staffThe restaurant has a very low turnover of staff due to the management allowing staff to work around other commitments, e.g. families. The employees are very motivated and enjoy their job which reflects on the whole atmosphere of the restaurant. ReputationThe reputation of the restaurant is documented in newspaper reviews. According to the General Manager, since opening, Branca has been reviewed as one of the best restaurants in Oxford. It is also included in the Good Food Guide 005/8 as can be seen in appendix 1. Cheapest Lunch, Early Dinner Promotion & most expensive for familiesIn comparison with its direct competitors, Branca offers the cheapest lunch promotion. Being the only restaurant that offers an early dinner promotion, Branca has a competitive advantage. However, the restaurant is the most highly priced in the competitive set for the family market. Loyal Customer BaseBranca benefits from a loyal customer base which helps them to save costs. As Laudon and Laudon explain, 'the cost of acquiring a new customer has been estimated to be five times that of retaining an existing customer' (Laudon and Laudon, 005/8: p99). Location The location can be seen as both a strength and a weakness. Being situated in Jericho, an affluent area of Oxford, the restaurant attracts professionals with a high disposable income. However, by being located out of the town centre, the probability of customers walking by is less likely. By being located in a residential area, the parking is extremely limited. No empowermentFrom observations, it was noticed that employees do not seem to be empowered when dealing with complaints in the restaurant. At hectic times this could result in problems if the managers are busy in other areas of the restaurant. Menu changed seldomly The menu is only changed once a year. Since there are a lot of customers who visit the restaurant several times a week, the menu could be perceived as boring. Location of kitchen in restaurant is upstairsThe kitchen at Branca is situated on the first floor thus making it more challenging for the waiting staff to serve.. Opportunities & ThreatsSmoking BanThe smoking ban can be seen as both an opportunity and a threat. Non-smoking customers might visit Branca more often as they would not have to walk through the smoking area of the restaurant to get to their table. However, Branca could experience a decline in demand from its loyal customer base who smoke. Disposable IncomeBeing located in a wealthy area, Branca will benefit from the steady rise in disposable income. See appendix. Exchange RatesAs mentioned in the PESTE Analysis it has been observed that there are many European tourists in Oxford. Having received a good exchange rate for the Euro, tourists will have more pounds disposable to spend on food and drink in restaurants such as Branca. Average AgeAs can be seen in appendix, the main age group that Branca decrease drastically in the future. Thus their target market will become smaller which may result in lost revenue. Change in Eating HabitsDue to pressure in today's society to eat healthily, customers expect restaurants to offer appropriate dishes on their menus. Being a pizza and pasta restaurant makes it difficult to offer healthy options resulting in Branca being threatened by this new trend. Chip and PIN SystemThrough the changes in the Chip and PIN technology, Branca will have to invest a large sum to bring their Point-of-Sale system up to the required standard. Failure to do so will make the restaurant liable for any fraud committed. However, once this investment has been made, the service staff will benefit from using a quick and easy billing system. InternetWith the internet becoming more popular Branca could use this to its advantage to win new customers. Not using the internet to its full extent could result in Branca losing out to its competitors, such as Le Petit Blanc who take internet reservations.. RecommendationsThe following recommendations will follow the approach of the marketing mix. The marketing mix is 'tools that marketers use to influence demand' (Bowie and Buttle, 004: p26). In the literature the marketing mix mostly consists of seven different elements, however, Bowie and Buttle have created another factor by dividing 'place' into 'location' and 'distribution'. The report will analyse each aspect individually and bring forward recommendations for Branca.. Product/service offer'A product is anything that can be offered to satisfy a need or want' (Kotler, 003: p15/8). According to Bowie and Buttle to satisfy said needs and wants, the guests have to be the key element for any decisions regarding the creating of new and changing of existing products. As identified in the SWOT analysis, the seldomly changed menu is a weakness of Branca. The restaurant is also threatened by the new trends in healthy eating. As Branca's competitors change their menu more often, Branca needs to adopt a similar approach. From March 005/8 a new menu should be offered for each of the four seasons. If it is seen that this increases demand, the restaurant should consider varying the menu on a monthly basis. This menu should be advertised by signage in the restaurant which will increase the spend on marketing communications. However, according to the General Manager, the main communications tool is through word-of-mouth. Therefore, there will hardly be any cost of advertising a new menu.. Price'Pricing decisions influence demand, are crucial in driving profitability, and play an important role in presenting the 'image' the hospitality firms wants to project to customers and stakeholders' (Bowie and Buttle, 004: p27). Branca's current approach on pricing decisions can be seen in Appendix 2. They use product bundling and promotional pricing to increase demand and psychological pricing and up selling to increase revenue. A promotion is used during the week, but as shown in Appendix 3, it was identified that on Saturdays and Sundays between and pm there is an excess of capacity. Branca should extend their 'Early dinner promotion' offered during the week to the above mentioned times on the weekend. Again, this would need to be advertised within the restaurant to encourage the regulars to communicate the new offer through word-of-mouth. Yet again, the cost of advertising will be kept to a minimum.. Location'Choice of location is the first and crucial marketing decision for hospitality companies' (Bowie and Buttle, 004: p27). According to Kotler et al a good location can be a major advantage against the competition. As mentioned in the competitor analysis, Branca does not have an advantage from its location, as all the competitors are in a similar position. However, according to Jeevan Perinpanayagam, the next step for Branca is to expand the business into other towns. At the time of choosing sites, it is recommended to look for locations with car parking facilities to attract a larger family market and therefore be more competitive. It is advisable not to expand within Oxford to avoid losing customers to the new location.. DistributionBowie and Buttle explain that the distribution is 'concerned with how the company can make it timely and convenient for a potential customer to book hospitality products directly from the hospitality company.' (Bowie and Buttle, 004: p28). As seen in the PESTE analysis, the internet is becoming more and more important. At the moment this is still an opportunity as well as a threat for Branca. To avoid it becoming more of a threat, it is essential that Branca increases the use of the internet. They should encourage taking reservations through e-mails, even if this involves more work. It could help to win new customers, especially when these customers want to contact the restaurant out of hours. Initially a special promotion, such as a complimentary glass of wine, could be offered when booking over the internet. This product bundling would help to increase demand.. Marketing products and services make the processes in hospitality businesses very important for achieving customer satisfaction. 'Service delivery has to be efficient, customer friendly and competitive' (Bowie and Buttle, 004: p28). To increase the efficiency of the service, all the necessary amendments to the wireless Chip and PIN system should have been made by March 005/8. This will enhance the speed of service as customers will not have to wait for their credit card to be taken and brought back to the table. The wireless system will allow waiting staff to have more time to see to the needs of other customers and therefore increase customer satisfaction.. People'Hospitality is a service where the interaction between customers and employees is a critical element of the customer experience' (Bowie and Buttle, 004: p28). Regarding the employees, the management should keep up the flexible working hours they offer to their staff as this seems to decrease staff turnover. However, the organization needs to empower their employees, as already stated in the SWOT analysis. This will ensure the smooth running of the restaurant, especially at busy times, resulting in contented customers. The waiting team should be trained to see to the needs of the customer right through to departure to avoid the customer getting a bad impression at the last minute. See customer audit trail, appendix. Concerning the customers, it is advisable to seat all business and family guests in separate areas of the restaurant to avoid disturbance of the business clients. The host should be trained and aware of the different types of customers to make sure every guest feels comfortable.. Performance Measurement'The balanced scorecard is a management system that enables organisations to clarify their vision and strategy and translate them into action' (Balanced Scorecard Institute, no date). According to Kaplan and Norton the benefits of the balanced scorecard is that it not only measures financial aspects but also the customer perspective, the internal business processes and the learning and capability of the organisation. Therefore it gives a wider picture of the actions of the business. The balance scorecard in appendix 5/8 shows how Branca can measure the performance of the recommendations that were made earlier in the report. The best way to look at how customers perceive the changes is through questionnaires. It was considered for Branca to employ a consulting company to measure customer satisfaction. However, it was decided that the cost implied would be too high for a non branded restaurant. Therefore a questionnaire incorporating questions on all changes should be designed to avoid customers being over exasperated. It is hard to measure the learning and capability of the organisation. Most of the recommendations do not involve employees having to be trained as there will not be any changes to the service procedures. Quality and service recovery can not be measured in financial terms. For the other recommendations it should be calculated if revenue increases to supervise the effectiveness. This is especially important for the change of the menu as it was suggested to do this four times a year. If it is seen that there is no significant increase, it should be considered to only alter it twice yearly. Should the restaurant make any future changes, these should be monitored to assess their effectiveness. This should include financial as well as the other introduced measurement perspectives. Through examining these modifications continuously, management is able to detect any discrepancies that should occur and take appropriate action.. ConclusionIt is essential that the business is aware of changes in the macro-environment. It is also important for Branca to monitor its competition. These issues can result in opportunities and threats to the business, just as any internal influences can become strengths or weaknesses. From analysing all these aspects recommendations have been drawn. Branca should implement various changes, the main two being the following: the menu needs to be changed more frequently and the internet should be used to its full extent. This will result in Branca gaining a competitive advantage, having satisfied customers and increasing revenue.'''",81.0
"'''The present study sought to determine the chemical values of various fish and meat products, as well as evaluating some methods of analysis. It was concluded that the methods are generally reliable in determining protein, lipid, water and mineral values in fish and meat. However, it is evident that great care must be taken in the execution of such food analyses.Food products are analysed for a variety of reasons, e.g., compliance with legal and labelling requirements, assessment of product quality, determination of nutritional value, detection of adulteration, and research and development. The analyses of the present study sought to establish the contents of proteins, lipids, water, minerals and carbohydrates in a variety of fish and meat products. The following terms are central in these food analyses: ProteinFor more than 00 years, protein determinations have been performed on meat products by procedures that measure the nitrogen content of the sample. Nitrogen percentage is converted into the equivalent protein content by an suitable numerical factor. For the purpose of the present study a general factor of.5/8 was used. The Kjeldahl ProcedureThe most common analytical procedure for determining nitrogen content of foodstuffs is the Kjeldahl procedure, developed in 883 by the brewer Johann Kjeldahl. The nitrogen in the food sample is converted to ammonium sulphate during the digestion of the sample, and the digest is then made alkaline by the addition of sodium hydroxide. The amount of nitrogen present is determined by titration of the remaining ammonia, where the concentration of to reach the end- equivalent to the concentration of nitrogen that was in the original food. The amount of protein present is then calculated from the nitrogen concentration of the food, using a conversion factor. A conversion factor of. used for many applications. However, this is only an average value, and each protein has a different conversion factor depending on its amino-acid composition. The Kjeldahl method is widely used internationally and is still the standard method for comparison against all other methods. Its universality, high precision and good reproducibility have made it the main method for the estimation of protein in foods. However, since not all nitrogen in food is in the form of nitrogen, the Kjeldahl procedure does not give a measure of the true protein content. Different proteins need different correction factors because they have different amino acid sequences. The technique is also time consuming, and may be hazardous to carry out. LipidsThere are several reasons for determining the lipid content of food. One being economic, so as not to give away fat which is an expensive ingredient. There are also legal reasons of identity and labelling of food, as well as the more obvious reasons like health concerns, quality, and processing. Fats, or lipids as they are called in the nutrition jargon, are defined as those substances that are soluble in organic solvents, such as ether, hexae and chloroform, whilst being insoluble in water. This group of substances includes triacylglycercols, diacylglycercols, monoacylglycercols, free fatty acids, phospholipids, sterols, caretonoids and vitamins A and D. The Soxhlet ExtractionThe method described by Soxhlet in 879 is the most commonly used example of a semi-continuous method for extracting lipids from foods. According to the Soxhlet procedure, oil and fat from solid materials are extracted by repeated washing with a warm organic solvent. At the end of the extraction process, which typically lasts a few hours, the flask containing the solvent and lipid is removed, the solvent is evaporated and the mass of lipid remaining is measured, and the percentage of lipid in the initial sample can be calculated. The method is fairly simple to use and is the officially recognised method for a wide range of fat content determinations. The main disadvantages of the method are that a relatively dry sample is needed, to allow the solvent to penetrate, and it is time consuming to carry out. Also, significantly, the fat content found will depend on the solvent used, as not all organic solvents will dissolve the same materials. Furthermore, the method does not disrupt the structure of the food, meaning that fatty material may be trapped inside the sample, and thus the entire lipid content may not be detected. MoistureThe percentage moisture in meat and meat products is usually determined gravimetrically by heating a food sample to constant weight, and calculating the difference between the weight of the sample before and after drying. The advantages of this procedure are that it is a relatively cheap procedure, is easy to carry out, many samples can be analysed simultaneously, and that it is an officially recognised procedure. There are also some disadvantages, however: the method is destructive, time consuming, and is unsuitable for some types of food. MineralsThe ash content is a measure of the total amount of minerals present within a food. It is the inorganic residue remaining after the water and organic matter have been removed, by heating at a high temperature, which provides measures from which one can calculate the total amount of minerals within a food. Analytical techniques for providing information about the total mineral content are based on the fact that the minerals can be distinguished from all the other components within a food in some measurable way. The most widely used methods are based on the fact that minerals are not destroyed by heating, and that they have a low volatility compared to other food components. Ash contents of fresh foods rarely exceed %, although some processed foods can have ash contents as high as 2% ( e.g. dried beef). The advantages of this measurement of minerals are that it is a safe method, few reagents are required, many samples can be analysed simultaneously, it is a rather easy procedure to carry out, and that the ash can be analysed for specific mineral content. There are also some disadvantages, in that the procedure takes a long time to carry out, and that there may be a loss of volatile minerals at high temperatures. CarbohydratesCarbohydrates are one of the most important components in many foods. Some carbohydrates are digestible by humans and therefore provide an important source of energy, whereas others are indigestible and therefore do not provide energy. Indigestible carbohydrates form part of the dietary fibres. Consumption of significant quantities of dietary fibre has been shown to be beneficial to human nutrition, helping reduce the risk of certain types of cancer, coronary heart disease, diabetes and constipation. As well as being an important source of energy and dietary fibre, carbohydrates also contribute to the sweetness, appearance and textural characteristics of many foods. MeatWater is quantitatively the most important component of meat, comprising up to 5/8% of its weight. The water is inversely related to fat content, but is unaffected by protein content except in young animals. Water in meat is associated with muscle tissue, and proteins have a central role in the mechanism of water binding. Meat is considered a high protein food. Of the total nitrogen content of muscle ca. 5/8% is protein and ca. % smaller peptides, amino acids and other those with fat and after extraction were found to be as shown in Table. Table provides the values for protein determination. ResultsThe results of this study are shown in Table. When compared with the commonly reported chemical values of published reports, there are some clear discrepancies. The analyses of the fish samples have primarily found values in the range of the expected values. Except for the mineral values, which are slightly lower in the present analysis:.3 % for white fish, and. % for smoked oily fish, compared with published values of - % and. % respectively. The meat product values are quite dissimilar to those of the published findings. The discrepancies are especially evident in the sausage values for lipids and carbohydrate; the lipid, water and carbohydrate values for minced beef; and the lipid, water, mineral and carbohydrate values of unsmoked bacon. There are no obvious systematic variances. DiscussionThe values reported in the results section show that there are some discrepancies in the chemical values found in this study compared with those values previously reported. The discrepancies are especially evident in the meat products. There are several possible explanations for this. One might be that these are processed meat products. The chemical aspects vary according to the processing methods of meat, and different brands may differ in production methods. The area of the animal the meat is taken from also has different chemical values. Other factors affecting the nutritional values of processed meats may be additives, the age and physical state of the animal, feeding of the animal, and the country and place of origin. Methods of extraction in the laboratory may also vary. Food for analysis should resemble the sold product as closely as possible, and the product should not be left unpackaged for long periods of time before the analysis commences. These are areas where there might be variations in method, as well as in how the procedure is carried less than that of the empty dish (9.724g and 5/8.072g), resulting in negative lipid values of -.963g and -.261g respectively. It is evident that something has gone wrong in the analysis. However, it is not exactly clear what that is. One possible explanation is that the lipid content of white fish is so small, that the negative values are a result of measurement inaccuracies. Another possible explanation might be that the flasks used for the extraction may not have been completely dry, thus adding the weight of residual water to the weight of the empty flask. ConclusionThe analyses carried out in this study demonstrate that there may be variances between and within methods of chemical value determination. The production of certain meats may also affect the nutritional values of the end product. An important discovery of this study is the importance of precise technique and measurement in analysing chemical values of food samples.'''",85.0
"'''The theories of structure and agency have been spearheaded by Anthony Giddens, a British social scientist and Pierre Bourdieu, a French anthropologist. Giddens and Bourdieu's theories have greatly affected the field of Archaeology, although Dobres and Robb call their writings 'ambiguous, often incomprehensible and incontrovertibly high-brow', their theories enable us to ask questions about the evidence of the past. Bourdieu is one of the key architects of the theories of structure and agency which are called 'inseparable'; his theory of habitus is what Jay MacLeod calls 'a regulator between individuals and their external world, between human agency and social structure'. Giddens' Structuration Theory 'challenges the way culture is portrayed in archaeology and attempts to change the analytical focus of archaeology separating will or agency from social structures'. However, MacLeod uses another line of argument; he argues that in contrast to Johnson's argument 'structural determination is inscribed in the very core of human agency'. Their ideas have given a useful insight into past societies social cohesion, archaeologists have stressed the importance of individual agency in the past, in reaction to other approaches such as culture history or environmental determinism, in which individuals and communities are sidelined. DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page MacLeod J. 987 'Ain't No Makin' It: Aspirations & Attainment in a Low-Income Neighbourhood' Page 5/85/8 MacLeod J. 987 'Ain't No Makin' It: Aspirations & Attainment in a Low-Income Neighbourhood' Page 5/8 JOHNSON, M. 999. Archaeological Theory. Oxford: Blackwell MacLeod J. 987 'Ain't No Makin' It: Aspirations & Attainment in a Low-Income Neighbourhood' Page 5/85/8 In terms of Archaeology perhaps Marx puts it best when relating agency to archaeology 'men make their own history, but they do not make it just as they please, they do not make it under circumstances chosen by themselves, but under circumstances directly encountered, given and transmitted from the past', in effect Marx is saying that an individuals actions are not always intentional but can also come as a result of external factors, for example in terms of archaeology a Roman carrying a pot might trip and break the pot rather than purposely dropping it with the intention of breaking it, the broken pot is then evident in the archaeological record. Marx K. ed.963 'Das Kapital' Page 5/8 Bourdieu's builds on this with his theory of habitus, which Dobres and Robb put simply as 'the taken-for-granted routines of daily life', and MacLeod calls the 'attitudes, beliefs and experiences of those inhabiting one's social world'. This is key to the work of archaeologists; once we gain an understanding of what an individual's role in a past society was, be they a peasant or a king, we can begin to understand why an event or even a deposition occurred, from the disposal of a pot to why a country was invaded. Dobres and Robb went on to explain that once we understand habitus we can understand why 'people create and become structures and become structured by institutions and beliefs beyond their conscious awareness or direct control'. What Dobres and Robb are trying to explain is that once we have understood these 'structures' we can understand why the individual performed actions which are evident in the archaeological record. DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page MacLeod J. 987 'Ain't No Makin' It: Aspirations & Attainment in a Low-Income Neighbourhood' Page 5/8 DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page Bourdieu's view is that society, contrary to traditional Marxism, cannot be analyzed simply in terms of economic classes and ideologies. Much of his work concerns the independent role of educational and cultural factors. Instead of analyzing past societies in terms of classes, we can use Bourdieu's concept of field: a social arena in which people manoeuvre and struggle in pursuit of desirable resources. A field is a system of social positions, structured internally in terms of power relationships. Different fields can be quite autonomous and more complex past societies clearly would have more fields. However, this is not to say that Bourdieu has gone uncriticised in his approaches to the subject, Lane questions the anthropologist's 'perceived determinism and consequent inability to account for significant historical change', if this is true then we must seriously question Bourdieu's relevance to historical analysis, Bridget Fowler goes on to add that 'Bourdieu has never undertaken any protracted discussion of transformation in the social, cultural, or political spheres'. In my opinion this is unfair, Boudieu's theory of habitus enables us to pose key questions when assessing social stratification in the past. Lane J.F. 000 Modern European Thinkers: Pierre Bourdieu 'A Critical Introduction' Pluto Press Page Bourdieu and Giddens both agree that practice theory is a 'theory of the continuous and historically contingent enactments or embodiments of people's ethos, attitudes, agendas and dispostitions', when applying this theory to archaeology we can attempt to understand a past society's motivations and beliefs through the archaeological record, we can see their attitudes to religion for example by evidence of sacrifice and then deduce their religious beliefs in different periods of time. DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page 15/8 Giddens writes 'human history is created by intentional activities but is not an intended project.' This echoes Marx in his belief that 'men make their own history.but they do not make it under circumstances chosen by themselves' which, in principle, is key to an archaeologists understanding of the past. An individual's actions and the traces of actions that they leave in the archaeological record are not necessarily done on purpose so we, as archaeologists must ask why did they do it? Giddens A. 984 'The Constitution of Society' Page 7 Marx K. ed.963 'Das Kapital' Page 5/8 Giddens' Structuration Theory poses many questions for archaeologists, the Structuration Theory describes how social agents i.e. humans relate to social structures, how they are constrained by their social environments but pursue active strategies, the clash with agency then produces change in social structures. A Roman floor provides a suitable example of Giddens' theory in practice, linking both structure and agency. The traditional view of an archaeologist when analysing a Roman floor would be to class it as an object and then try and fit it into a typology of some sort, placed into patterns of material culture representative with a certain society and determining its status within a society. Applying Giddens' Structuration Theory we would look at the floor, and then ask questions in relation to how the floor may have interacted with a human agent. Then discuss the fact that someone had walked on the floor, the fact conversations were held in the room or even the possibility an event such as a murder may have occurred there. It would then be possible to suggest the status of the floor in the society by relating them to a general structure of society. We can apply this to past societies, in an attempt to see how and why a society changed and what actions forced it to change. BARRETT, J.C. & FEWSTER, K.J. 000. This elaborated on Bourdieu's questioning of social practice how 'people become structured by instituitions and beliefs beyond their control', further to this people are not 'omniscient, practical, free-willed economizers but rather are socially embedded, imperfect and often impractical' resulting in the final part of Giddens' Structuration Theory i.e. a clash with agency producing change in social structure. DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page DOBRES, M-A. & ROBB, J.E.000. Agency in Archaeology: Paradigm or platitude? In Dobbs, M-A & Robb, J.E. Agency in archaeology. London:Routledge Page This is not to say that there are no differences in opinion between Giddens and Bourdieu, in Giddens case he attempts to combine both agency and structure while still acknowledging the fact that the two aspects are on there own where as Bourdieu's focus is on the actions of the individual, the agent or actor and then he attempts to compare these actions back to the way that the social structure has built up. Unlike Bourdieu, Giddens ignores the 'body' of the agent, something that Bourdieu stresses throughout his theory of habitus where he implies that we manipulate and change society through our actions; Giddens does not acknowledge Bourdieu's belief in the importance of the actions of individuals. Bourdieu challenges the rigid aspects of structuralism expressing his belief that Habitus can only be realised with human action; inferring that we make, change and reshape our society around us as individual agents. We can therefore see that although Giddens and Bourdieu's theories echo each other in many ways and share certain aspects, they also have their differences. Both Giddens and Bourdieu's theories have contributed greatly to the field of archaeology. When applying their theories of Structuration and Habitus respectively to a past society, we have the ability to gain a greater understanding of that society's social structure, we can place greater importance on the role of the individual in shaping history through their actions and the evidence they leave in the archaeological record.'''",86.0
"'''The aim of these laboratories is to provide an introduction to some of the features of a Xilinx ISE and Spartan- FPGA board as well as to get familiar with VHDL codes to help write Xilinx ISE program on Spartan FPGA board. The codes and comments are written and programmed in Xilinx ISE.i which provided the environment required to program the board. The device used in the laboratory XC3S1000 is of the family Spartan. The following is the table showing the summary of the device XC3S1000 FPGA in a 5/86 ball thin Grid Array: With reference from the handouts the main objectives of lab5/8 and lab6 was to carry out the following: To study and understand the program ANDGATE and counter using tutorials. To follow the steps given in the laboratory handouts to create the program and then simulate it. To observe whether or not the program functioned as required. Assign pins and transfer the program to the board. Observe the results when the switches are ON To study and understand the working of Dflipflops and segment LEDs Define the inputs and outputs. To create program and VHDL file with codes for the working. To get graphs demonstrating the working of the codesAssign pins responsible for each inputs and outputs. Transfer the program to the boardObserve the changes or results obtained Theory4 Digit- segment LEDS:The working of four segment LEDs used in the board. The Spartan- board has a four-character, seven segments LED display controlled by FPGA user-I/O pins, as shown in Figure. Each digit shares eight common control signals to light individual LED segments. Each individual character has a separate anode control input. A detailed schematic for the display appears in Figure A. The pin number for each FPGA pin connected to the LED display appears in parentheses. To light an individual signal, drive the individual segment control signal Low along with the associated anode control signal for the individual character. In Figure, for example, the left-most character displays the value ''. The digital values driving the display in this example are shown in blue. The AN3 anode control signal is Low, enabling the control inputs for the left-most character. The segment control inputs, A through G and DP, drive the individual segments that comprise the character. A Low value lights the individual segment, a High turns off the segment. A Low on the A input signal, lights segment 'a' of the display. The anode controls for the remaining characters, AN are all High, and these characters ignore the values presented on A through G and DP. Table lists the FPGA connections that drive the individual LEDs comprising a seven segment character. Table lists the connections to enable a specific character. The LED control signals are time-multiplexed to display data on all four characters, as shown in Figure. Present the value to be displayed on the segment control inputs and select the specified character by driving the associated anode control signal Low. Through persistence of vision, the human brain perceives that all four characters appear simultaneously, similar to the way the brain perceives a TV display. This 'scanning' technique reduces the number of I/O pins required for the four characters. If an FPGA pin were dedicated for each individual segment, then 2 pins are required to drive four -segment LED characters. The scanning technique reduces the required I/O down to 2 pins. The drawback to this approach is that the FPGA logic must continuously scan data out to the displays - a small price to save 0 additional I/O pins. Slide switches:The switches are located along the lower edge of the board, toward the right edge. The switches are labeled SW7 through SW0. Switch SW7 is the left-most switch, and SW0 is the rightmost switch. The switches connect to an associated FPGA pin, as shown in Table. A detailed schematic appears in Figure A. When in the UP or ON position, a switch connects the FPGA pin to VCCO, a logic High. When DOWN or in the OFF position, the switch connects the FPGA pin to ground, a logic Low. The switches typically exhibit about ms of mechanical bounce and there is no active debouncing circuitry, although such circuitry could easily be added to the FPGA design programmed on the board. A.K series resistor provides nominal input protection. Push Buttons:These push buttons are located along the lower edge of the board, toward the right edge. The switches are labeled BTN3 through BTN0. Push button switch BTN3 is the left-most switch, BTN0 the right-most switch. The push button switches connect to an associated FPGA pin, as shown in Table. A detailed schematic appears in Figure A. Pressing a push button generates logic High on the associated FPGA pin. Again, there is no active debouncing circuitry on the push button. The left-most button, BTN3, is also the default User Reset pin. BTN3 electrically behaves identically to the other push buttons. However, when applicable, BTN3 resets the provided reference designs. LEDS:The Spartan- Starter Kit board has eight individual surface-mount LEDs located above the push button switches. The LEDs are labeled LED7 through LED0. LED7 is the left-most LED, LED0 the right-most LED. Table shows the FPGA connections to the LEDs. A detailed schematic appears in Figure A. The cathode of each LED connects to ground via a 70 resistor. To light an individual LED, drive the associated FPGA control signal High, which is the opposite polarity from lighting one of the -segment LEDs. Dflipflop:The operation of Dflipflop is simple. It has only one input in addition to the clock input signal. The dflipflop used in the program was positive triggered. The D input is sampled during the occurrence of a clock pulse. If it is, the flip-flop is switched to the set known as the Least significant known as the Most significant and Method:The hardware elements featured in the laboratories were: Spartan board, Digilent JTAG Cable, XC3S1000 device, USB cable to power the board. Firstly I connected Spartan board to a PC and powered up board using the USB cable, followed by connecting the Digilent JTAG cable. Digilent JTAG cable is used to transfer data on to the board from the computer. I followed the tutorial given in the laboratory sheet for ANDGATE to study and understand the procedure and working of the software. I also followed the quick tutorial provided in the laboratory to make a bit counter. After, the completion of the program I downloaded the program on the board and observed the results, which were as expected. I tried to relate the pins associated with each buttons, switches, LEDS, and segment LEDS using the appendix A of the laboratory sheet. To make a Dflipflop program I firstly, made a note of the input and outputs needed for the program as CLK- clock input, D- D input, Q- Output. As explained earlier in theory section learned about the working of Dflipflop. I followed the method similar to the laboratory sheet provided to create and run the program. To make a counter from - on one of the four segment LED I used the method described in the theory to workout the codes and followed the instructions similar to those given in laboratory sheet to create and run the program. Codes Explanation:DFLIPFLOPlibrary IEEE; use IEEE.STD_LOGIC_1164.ALL; use IEEE.STD_LOGIC_ARITH.ALL; use IEEE.STD_LOGIC_UNSIGNED.ALL;Some of the files and logic defined in other locations are used in the program. Hence the above statements are used. -- Uncomment the following library declaration if instantiating -- any Xilinx primitives in this code. --library UNISIM; --use UNISIM.VComponents.all; entity DFLIPFLOP is --describes the design I/O of DFLIPFLOP. is active when there is any change in input begin if CLK'event and CLK='' then --this statement detects rising clock edge, using the IF condition. With the condition to detect if CLK is high i.e. '' Q <= D; --the output Q equals to input D everytime clock is high i.e. '' end if; --end the condition if for CLK end process; --end the process for CLK and signal assignment occurs. end Behavioral;--end the architectural behaviour of DFLIPFLOP. Segment LED - count: library IEEE; use IEEE.STD_LOGIC_1164.ALL; use IEEE.STD_LOGIC_ARITH.ALL; use IEEE.STD_LOGIC_UNSIGNED.ALL;Some of the files and logic defined in other locations are used in the program. Hence the above statements are used. -- Uncomment the following library declaration if instantiating -- any Xilinx primitives in this code. --library UNISIM; --use UNISIM.VComponents.all; entity LED7 is - describes the design I/O of LED7 when not pressed the associated FPGA pin is connected to is active each time input signal CLK changes begin - begin process assigned means it is active low hence, will help display number. Meaning that the described in the theory section will become low and hence, the first segment LED will be active low. assigned means it is active high so it will be OFF, and will not display any number. Meaning that the described in the theory section will become active high and hence, the second segnment LED will be active low. assigned means it is active high so it will be OFF, and will not display any number. Meaning that the described in the theory section will become active high and hence, the second segnment LED will be active low. assigned means it is active high so it will be OFF, and will not display any number. Meaning that the described in the theory section will become active high and hence, the second segnment LED will be active low. if CLK='' and CLK'event then - detects everytime CLK is rising high if count ='001' then - checks if count is equal to '' count <= '000'; --then changes the count to ''. Hence makes a loop of - and it again starts from each time push button is pressed one more time after it has reached. else count<= count; --otherwise increase the value of count by '' each time end if; --end of the condition for count end if; --end of condition for CLK case count is when '000' => LED <= '000000'; --when count is '000', display '' on LED. when '001' => LED <= '111001';--when count is '001', display '' on LED when '010' => LED <= '100100';--when count is '010', display '' on LED when '011' => LED <= '110000';--when count is '011', display '' on LED when '100' => LED <= '011001';--when count is '100', display '' on LED when '101' => LED <= '010010';--when count is '101', display '' on LED when '110' => LED <= '000010';--when count is '110', display '' on LED when '111' => LED <= '111000';--when count is '111', display '' on LED when '000' => LED <= '000000';--when count is '000', display '' on LED when '001' => LED <= '010000';--when count is '001', display '' on LED when others => LED<='000000';--when count is different value, display '' on LEDHere, the count is assigned numbers - in the binary form as 000, 001, 010, 011, 100, 101, 110, 111, 000, 001 and when it is different from those it is assigned. The way of converting decimal into binary is explained in detail in theory. end case; --end the case for count end process; --end the process for CLK end Behavioral; --end the architectural behaviour for LED7Assigning Pins: The following steps found in the laboratory sheet under section. were followed to assign pins for all the programs:. Assigning Pin Locations. Verify that Andgate is selected in the Sources.. Select the Package View tab.. In the Design Object List window, enter a pin location for each pin in the Loc column using the following information: Input 'a' connected to 'J13' -- User button BTN0 Input 'b' connected to 'K14' -- User button BTN1 Output 'c' connected to 'L14' -- Led LD0. Select File Save. Select XST Default <> and click OK. For assigning pins to ANDGATE: The table shows the pins assigned to each entity in ANDGATE program, and figure shows the print screen of the assigned pins. Counter: The table shows the pins allocated and the figure shows the pins assigned print screen. DFLIPFLOPThe table 0 and figure shows the pins allocated for DFLIPFLOP. Here slide switches are used for inputs as it is easier than to push buttons. And also helps observing the results. segment display from -: The table 1 shows the assigned pins and figure shows the print screen of the assigned pins: Observations and results:The simulation result of the ANDGATE is shown below: It can be observed from the graph that c is only high when both a and b are high. Hence, it shows that the logic of c<=a and b; works. When the program was loaded on the board it showed that the LD0 was ON only when both a and b were pressed together. When pressed alternatively or not pressed at all showed no result on LD0. The simulation result of the counter is shown below: It can be observed from the above graph that Count output for a bit binary up/down counter. It can be observed that when DIRECTION input is high, the output count is incremented on the rising edge of the CLOCK input. But, when DIRECTION is set low, the output count is decremented on the rising edge of the CLOCK input. When the program was loaded on the board it showed all LEDs off. When SW7 was down position and each time BTN0 was pressed the LEDs showed a sequence of output showing the down count. But when the SW7 was in up position and BTN was pressed it showed sequence of output showing the up count. Hence, it worked as required. The simulation output of the DFLIPFLOP is as shown below: Every time when the CLK input experiences a rising edge, the output Q stores the state of the input D. However, until the CLK input goes for another rising edge, the output remains unchanged regardless of the D input. It can be noted here that the initial red line on the Q waveform represents an ambiguous condition, as the output has not been set yet. When the program was loaded on the board, LD0 was OFF. When SW0 was moved to the up position, there was still no change on the LD0 until SW1 was then moved to the up position. Once this happened, LD0 turned ON. After this, moving SW0 between the states did not affect the output. However, when SW0 was in the down position, and SW1 was moved from down to up, LD0 turned OFF. Hence, the result was as expected and showed the working of Dflipflop. The simulation output of segment display count -: The above graph shows that when CLK input is rising high, the output LED changes. It showed numbers from - every time when CLK input is rising high, it counted from - When it reached it counted again from. The ENABLE output shows the correct output, as only one of the signals shows a low logic level. When the program was loaded on the board the LED displayed on only one segment LED. Now, every time BTN0 was pressed it showed - and when it reached it started counting from. Hence, it worked as required. Conclusion:The programs showed the required output on the simulation graphs and also performed as required when loaded on the board. The DFLIPFLOP worked as required as it did the following: When SW1 was high and SW0 was low the LD0 was OFF When SW1 was low SW0 was high the LD0 was OFF When SW1 was high and SW0 was high LD0 was ON, until once again SW1 was high but SW0 was low. The segment LED used to display count - worked as required as it did the following: It displayed to start with but everytime BTN0 was pressed it displayed - on just one segment LED. And when the count reached and BTN0 pressed again it counted again from -.'''",92.0
"'''In recent years, discourses of post colonialism have drawn attention to what Chris Brookes calls the 'major and continuing significance of the cultural products' of the British Empire over its four centuries of rise and fall. There is a veritable plethora of work anthologising these writings; however, in this anthology my aim is to look at the after-effects of British colonialism in India and to focus on the writings of the ex-colonies rather than the ex-colonisers. In Edward Said's Culture and Imperialism he discuses the importance of imperialism 'in shaping the modern world' and asserts 'connections between British imperialism and literature.' Although he is referring to the effects it had in shaping the image held by much of the Western world of the East, the effects of the British Raj in India were far reaching within India itself, in that educated Indians in the nineteenth century began to respond to Western thought and literature. It is almost one hundred and fifty years since native Indian troops in Meerut mutinied, resulting eventually in the end of colonial rule in India; it was not until the withdrawal of the British that the phenomenon of Indian verse written in English began seriously to exist. C. Brooks, P. white man's burdens: an anthology of British poetry of the Empire, (GB, University of Exeter Press, 996) Introduction pp. Cited in C. Brooks, P. white man's burdens: an anthology of British poetry of the Empire, (GB, University of Exeter Press, 996) Introduction pp. In this short collection of poems I have looked for those which can be said to be 'Indian in sensibility and content, and English in language.' This is poetry 'made out of thoughts and feelings, not the objects which give rise to them.' Although all the poets included here also write in a variety of Indian languages, I have excluded poems written in any of the native Indian languages and translated into English. This is not, by any means, because such poetry is of no account. On the contrary, poetry has been a traditional form of expression in India for 'more than two and a half millennia;' without enormously over-extending the length of this anthology, all the work of such beauty and account could not be included. R. Parthasarathy states that 'in our time poetry is becoming increasingly concise.' For this reason I have intentionally steered away from a multitude of brief Indian poetry such as much of the work of Vikram Seth, and included some longer, lyric poetry. R. Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. I. M. Progress of Poetry: An Anthology, (GB, Chatto & Windus, 937) introduction xiii M. Alexander, (ed.) Indian Love Poems, (Germany, Everyman's Library, 005/8) R. Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. The poetry that I have included in this anthology is 'rooted in and stems from the Indian environment' although the subject matter may be concerned with other themes and places. This is intended to highlight the beautiful paradox which is at the core of Indian poetry written in English, and to draw attention the difference between the language of poems such as these and the 'liveliness and idiosyncrasy' of the language used in African or West Indian writing. R. Parthasarathy states that this is due to the fact that Indian writers in English are particularly conscious of their 'indianness,' and identifies the 'uneasy tensions' that can arise in writing in a language one is not born into. There are long traditions of literatures in Indian languages, and those poets that choose to write in English can be said to have a 'relative sophistication,' which can be seen in the particular idiom they use. 'There has always been a time-lag between the living, creative idiom of English-speaking peoples and the English used in India.' The effect of this use of language can be somewhat surprising in the context of modernist poetry. For example, the use of the word 'thereon' in ibid pp. ibid Ibid pp. R. Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. and when you reach for the bark may you find the flowers thereon. (To My Daughter Rookzain by K. N. Daruwalla, ninth stanza) seems to particularly stand out. The poems I have selected for this anthology have, for the most part, little or no use for English prosody. Due to the fact that for all of these poets English is not their first language, the emphasis is 'almost entirely on the visual as opposed to the aural element' in their verse. This can be seen clearly in D. Chitre's poem Travelling in a Cage, in which the visual effect of the breaking up of lines such as 'nothing' in line four cuts into the deep structure of the sentence, in what Hollander calls contre-rejet. A similar effect is seen in The Gharghra in Spate by K. N. Daruwalla, in which the double pattering in the formation of the lines in the third stanza has a great effect on the imagery created by the poem and our mental picture of the water-logged landscape being described. R. Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. 0 Cited in R. Bradford, A Linguistic history of English Verse, (England, Routledge, 993) pp. 06 Other than the second poem in this anthology, The Golden Gate by Vikram Seth, there is a marked absence in these poems of special prosodic features such as metre and rhyme. However, one feature appears prominently: these poets 'favour a short as opposed to a long line as the unit of composition.' Often the lines break abruptly, such as in K. N. Daruwalla's To My Daughter Rookzain, in which each line can be said in a single breath. This has the effect of spilling over the meaning from one line to another, and forcing the line to seek a balance outside itself. R. Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. 1 These poems are for the most part examples of free verse, what Richard Bradford calls 'the most significant contribution by poetry to the formal aesthetics of modernism.' He also tells us that in order to identify a poem we must look for a 'structure whose formal common denominator- that which separates it from non-poetic discourse- is its division into lines.' Therefore it can be said that what these poems display beautifully is the idea that a poem is formed by the spaces in its lines as much as by the words: for example, that the effect of the irregular line breaks and stanza formation in Looking for a Cousin on a as much effect on it's meaning as the imagery and language used. Free verse disrupts or rejects the conventional forms of verse, and the only common feature of free verse poems, as seen in this short collection, is the existence of syntax and the line. R. Bradford, A Linguistic history of English Verse, (England, Routledge, 993) pp 5/84 Ibid, 'theory' pp. The order in which these poems are displayed holds no particular significance; however, as a collection of poems they are distinctive in that they all display the 'poetic qualities of metaphor.' From the extended personification of the Gharghra River in The Gharghra in Twentieth Century Indian Poets, (India, Oxford University Press. 976) Introduction pp. 1 '''",98.0
"'''The Requisites of RheologyFluid molecules are highly mobile and move over each other with ease, and hence a fluid cannot easily resist a displacement due to a force. However, a kind of internal resistance is exhibited, that impairs the free motion of these molecules past each other, and is referred to as the dynamic viscosity. Thus the flow of a fluid is strongly affected by its viscosity. When a stress is applied to a body, a deformation will occur. Shearing is one such type of deformation, a type of strain. It is the bending of a medium arising from compression on one side and tensile elongation on the other of a volume on which a force is acting. The modelled used to rationalise the flow is one in which the fluid flow is visualised as the variation in displacement of 'layers' per unit time with the distance from the plane at which the force is acting. Hence there exists a linear velocity gradient termed the shear rate, defined by the expression A new quantity, introduced to remove the area dependence of the viscous resistance of the force ie., Stress is the relationship between an applied force and the orthogonal planar area over which it acts. Thus with increasing shear rate, the stress will increase. A fluid that can be modelled accurately using this scheme is a Newtonian Fluid, and is one that obeys Newton's law of Viscosity ie., there is no rate dependence of the viscosity. The magnitude of this viscosity can be quantified by the coefficient of causes the shearing deformation, and is the shearing rate. The viscosity of the solution can be elucidated experimentally by spinning the rotatable disc with a known torque and measuring the stress resistance caused by a known area of fluid as a function of the shearing rate. However, a solution of P84 is not a Newtonian fluid - it's viscosity is drops with increasing shear rate, and is thus referred to as a 'shear thinning' fluid. The linear intervening region is described using a power law Where n is the power-law is a difunctional tri-block copolymer surfactant of ethylene oxide and propylene oxide. The constitution of the polymers is such that the substance is amphiphillic in nature, and can thus act as a surfactant and spontaneously associates in solution. With a central block of 3 hydrophobic oxypropylene units terminated by blocks of 9 hydrophilic oxyethylene obtained as a function of shearing rate. The co-dissolution of sodium chloride acts to raise the ionic strength of the solvent, which has the effect of lowering the critical micellular temperature and the micelle 'sphere to rod' (sol to gel) phase transition temperature. Under the conditions of the experiment, the temperatures range is such that the rod aggregation mode predominates in vast excess over spheroid and unimer modes. Hence, with no micellation phase changes taking place, meaningfully comparable results are obtainable. In addition, the temperature range required is lower which acts to reduce a o inclined cone. A peltier heat pump and thermal controller was employed to maintain isothermal conditions throughout the experiment. The apparatus runs in three stages: pre-test can be approximated to three distinct linear regions, denoted Regions 'A', 'AB', and 'B'. At low shear stress rises most rapidly. The general trends observed at both temperatures resemble each other closely. However, at the lower transition between the region A behaviour and the region B behaviour is more subtle contrasting to the stress at the higher temperature which exhibits an abrupt transition to region AB. The transition from region AB to B at both temperatures is fairly abrupt, however the transition at 2oC occurs at a significantly higher shear linear plots are much less defined, with a more gradual transition from the early regime to the non-Newtonian regime; also, the ending data points show signs of noise. In order for more accurate analysis to be carried out at 2oC, much lower sheer rates would need be investigated as the viscosity clearly drops significantly from Newtonian behaviour even over the lowest of investigated sheer rates. With this additional data, one would expect the two curves to very much more closely resemble each other in form. Viscosity curves for two different temperatures are shown For low shear rates, the behaviour is Newtonian: viscosity nearly constant For high shear rates, the behaviour is also Newtonian This suggests at the two extremes two different phases exist, and that at intermediate sheer rates, there is co-existence of the different phases. This can be rationalised by considering that in solution at zero sheer rate, thermal motion has the polymer rods intertwining into a random weaved network; and then as the solution has exerted onto it an increasing shear force, the molecules are 'dragged out' into alignment. These two different gross solution structures will exhibit different interactions and hence exhibit different properties, such as viscosity. At low sheer rates the molecules do not align up, but instead resist the applied shear force through an responsive less extensively networked, and thus exhibits a lower viscosity. The power law region is very similar, but is true for a shorter range of shear rates at 7oC, which perhaps suggests a greater range of shear rates over which the coexistence of phases occurs at higher temperature (reflecting the requirement of more force to align up longer molecules). ConclusionThe rheology of the triblock polymer, Pluronics P84 is well understood. The viscometric measurements are consistent with the theory that in solution, P84 exists as a polydisperse solution of cylindrical aggregates, which gross structure changes as an external shear force is applied. At critical shear rates, the aggregates experience a shear banding phenomena. The intial alignment of micelles results in a solution composed of two phases co-existing which is reflected by the plateau region of the stress/rate curve.'''",108.0
"''' Planck's constant was calculated by use of the photoelectric effect and found to be h =. which he was later awarded a Nobel Prize in 918. In this theory Planck presented a model that explained the entire form of the blackbody spectrum, consistent at all wavelengths with experimental results. Planck had started with an empirical model that matched the data and had then developed a physical model that physically justified it. In this model atoms on the inside surface of the blackbody where described as electric oscillators which absorbed and emitted radiation over all frequencies. Critically he stated that the energy of the electric oscillating atoms could only be changed by discrete prescribed amounts, which he named light quanta. The amount of energy exchanged by one light given by the equation h is Planck's constant and f is the oscillator frequency. Later, in 905/8, Einstein resolved the many puzzling problems surrounding the photoelectric effect by developing upon the ideas put forward by Planck. In this work, for which he received the Nobel Prize in Physics in 921, Einstein theorized that just as the atomic oscillators in blackbody radiation can only change their energy in discrete jumps, the energy in an electromagnetic field is also quantized and can only take on a set of discrete values proportional to the field's frequency. We now call the discrete amounts of energy that make up the electromagnetic field photons. Relating to the photoelectric effect, electrons in an illuminated metal surface will absorb photons one at a time, and if the energy transferred to the electron is sufficient to rip it free from the metal's surface it is emitted as a photoelectron with kinetic energy difference in the incoming photons the work function of the determines the energy of these photoelectrons. These were observations previously unexplained by classical theory. The maximum energy of emitted photoelectrons can be measured by applying a voltage to the emitted photocurrent. The minimum voltage required to reduce the photocurrent to zero is known as the stopping e is the charge on an electron. If the stopping voltage is measured for a range of different monochromatic light sources a plot of the stopping voltage against the frequency of the incoming light source will yield a straight line of gradient of the slope of this graph permits a value for Planck's constant to be derived. The value of Planck's constant is an important quantity because the constant is fundamentally related to the rate and quantum amounts by which energy can be transferred, and it is also critical to the argument for the wave particle duality of light. It is the fundamental constant which underlies Quantum Theory, described as one of the two great revolutionary theories that changed the face of physics in the early twentieth no longer overcome the capacitor voltage. It is noted that the work function in this experiment includes in the energy balance the contact potential between the cathode and the anode. A capacitor was used to determine V0 since it eliminated the necessity to search for V0 manually by observing the value at which the photocurrent is reduced to zero, this method would likely have reduced the accuracy in a V0 measurement. Each interference filter was cycled through three times in order to obtain repeat measurements of the V0 stopping potential. Between each measurement the capacitor was discharged completely. Once the interference filter was in place the capacitor was charged by the photocurrent for 0 seconds. The Vo value was recorded from the display on the multimeter, which is connected in parallel with the capacitor. Care was taken to avoid parallax error by making each reading at the same incidence angle to the display; this measurement was conducted at right angles to the display. For the yellow and green interference filters the multimeter display could be read to an accuracy of.05/8V, whereas for the blue, violet and ultraviolet interference filters the scale of the multimeter required changing, leading to an increase in the error of the measurement to.1V. In both cases these errors equated to a percentage error %. The interference filters have been tested and errors can be ignored, while the value of e, the charge on an electron, has been obtained experimentally on numerous occasions to a very high accuracy and therefore can be assumed to have negligible error..ResultsFigure shows a linear fit to the five data points, each corresponding to a different interference filter and thus a specific frequency of incident light. The value of the gradient for this weighted fit was analyzed using equation to derive a value of Planck's constant of:. From the fit shown in figure the work function for the cathode can also be obtained: although as noted in section this value includes the contact potential between the cathode and the anode in the energy balance and therefore it cannot be compared to any standard values..DiscussionPlanck's constant was obtained by experimental method and is calculated as:. This compares with the 002 value of:. Since the first experimental calculation of h Millikan, the value has been progressively refined by ever more accurate experimental techniques. A recently employed technique involves a comparison of the electric power, measured in terms of the Josephson and quantum Hall effects, with mechanical power, measured in terms of the meter, kilogram and second, of a moving coil watt the capacitor when it is fully charged by the photocurrent. V0 was defined as the maximum value of V, assumed reached after a charging time interval of 0 seconds. Elementary knowledge of a capacitor shows that the a charging capacitor increases exponentially with respect to time. The relationship Q ( V indicates that, for a given fixed capacitance, V also increases exponentially. During the charging process the initial growth in V is very rapid but this growth gradually reduces as the photocurrent is reduced. V eventually approaches V0 asymptotically with no well-defined cut off point for where V0 is definitely reached. Measurements of V were made at inconsistent times after the minimum 0 seconds of charging and it is therefore suggested that since the final increase in V to V0 takes a larger respective time than the initial growth in V it is possible that significant underestimates of V0 may have been made for certain data points if the capacitor was still in the process of charging. However, although this may have shifted the position of individual data points and thus changed the uncertainty in the gradient of the linear fit, it is unlikely to have caused a concerted shift in the value determined for the gradient, and thus the value calculated for Planck's constant. However a larger experimental error may have brought the calculated value in line with the 002 CODATA recommended value. It is suggested that either leaving a longer period of time before measurement, or taking a measurement of V0 after a fixed time interval would have improved the reliability of the data set. It is noted that underestimations in the stopping voltage would have reduced the gradient of the fit, thus consequently reducing the derived value for h. Planck's constant calculated experimentally here is indeed smaller than the recommended value. If the value of determined from the data set was compared with a reference value for potassium it would be possible to deduce from this comparison whether the error in V0 mentioned above was likely to have affected the gradient of the linear fit, or solely the uncertainty in this value. A close match between the calculated value and a reference value would indicate that the intercept of the linear fit was correct and therefore any experimental errors would most likely only have affected the gradient of the fit, and thus directly the calculation of Planck's constant. However as mentioned in section the work function in this experiment includes in the energy balance the contact potential between the cathode and the anode and therefore it is unsuitable to compare with recommended values of for potassium. The effects of a reverse current induced at the anode by the incident light, which would be accelerated by the stopping voltage produced at the capacitor, also deserves further investigation. No attempt to quantify the results of a reverse current has been investigated, and therefore it is difficult to discern what effect they would have on the calculation of h. One of the fundamental concepts surrounding Einstein's work on the photoelectric effect was the conclusion that when viewing light as particles, the energy of light was independent of its intensity and solely dependant on it frequency. This was investigated by determining a value of Planck's constant for light of different intensities. Theory, as seen in equation, clearly shows that the value of h should not change... The results given above are inconclusive in determining whether intensity affects the value of Planck's constant. If the intensity of light were to affect the energy of the photons it would be expected that a higher intensity light would increase the value calculated for h. This is not the case; both results are lower than the original calculated value. It is noted that a very weak correlation was obtained for the lower intensity readings. Einstein's work on the photoelectric effect showed that intensity was related to the number of photons incident on the photocell in a given time. A lower intensity would result in less photons per unit time incident on the cathode, and the net effect would be less photoelectrons and a smaller photocurrent charging the capacitor. This would results in longer charge time in the capacitor, it is suggested that this would amplify the effect of the error previously suggested in the measurement for V0. A longer charge time would mean the capacitor was even less likely to have reached V0 in the 0 second time interval, leading to possible underestimations in the stopping voltage. This would explain the larger uncertainty in the value quoted for h for this intensity. Since a set up amplified to the error in V0 indicates that this error is likely, it is not unreasonable to suggest that this error was also in effect in the original set up..ConclusionThe photoelectric effect was investigated at a potassium cathode illuminated with different frequencies of light from a mercury lamp and interference filter setup to determine a value for Planck's constant h. By use of a graphical method, which involved analyzing the slope of a fit to data points comparing stopping voltage against frequency of incident light, a value of h was calculated as:. This result was found to be inconsistent with recommended values. It is suggested that the limited data range puts a large emphasis on the accuracy of individual results and thus there is little tolerance to anomalies. Possible errors in the measurement of the stopping voltage are also discussed, it is noted that the asymptotic nature of voltage across the capacitor as it reaches the stopping voltage means that it is critical that sufficient time is left for the capacitor to fully charge. It is commented that if the stopping voltage was recorded too soon, it is likely to have affected the uncertainty in the h value rather than have changed the value itself. Investigations into possible reverse currents at the anode are suggested, since these errors have not been quantified in this technique and their influence on the calculated h value cannot be accounted for. Values of h are derived under conditions of higher and lower intensity incident light. Results of these experiments prove inconclusive in determining whether the energy of light is independent of its intensity as suggested by theory, since no agreement is found between the values of h for these conditions. Lower intensity light shows a very poor correlation of data points indicating a large uncertainty in the value of h. It is reasoned that this is due to the longer charging time of the capacitor, because of the smaller photocurrent under these circumstances, which amplifies the error in the measurement of V0 previously discussed.'''",110.0
"'''.With the day of accession to the European Union Poland accepted the Acquis Communautaire as a whole and for thick and thin. As a result it said 'yes' also to five cardinal market-related Common Agricultural, outlined in the Article 9 of the Treaty of Rome. As they date back to 95/87 these objectives may be viewed as a relic of the past. Europe has moved forward since then, drifting away from the strictly market-related ideas of stabilisation, availability of supplies or increased productivity, towards the more sophisticated approach reflected in the concept of multifunctionality. Nevertheless, in Polish agriculture there are still areas where some of the initial CAP aims remain applicable. The soft fruit market, that experiences repeating crisis situations, can serve as the most glaring example of market instability, that directly hinders its performance. The aim of this essay is to show, that the third CAP objective of market stabilisation, only partially reflected in the Polish strategic document for agriculture, is still relevant to the situation on the soft fruit market in this country, but cannot be met due to the inadequate policy instruments. The paper is organised as follows. Section contains a brief overview of the soft fruit market situation in Poland and aims to prove the need for stabilisation. Section presents the existing Common Agricultural Policy instruments on the market of fruit and vegetables as a whole, while section explains why they cannot be successfully applied in Poland. Section concludes the essay.. Polish soft fruit market: a desperate call for stabilisationAccessing the European Union Poland, as a prominent soft fruit producer, brought in a very specific dowry. In the year 004 it supplied c.a. 9% of strawberry, 6% of gooseberry, 4% of currant and 7% of raspberry production of the whole 5/8 nations, what is outlined in table. This relatively high production levels were achieved only two years after the soft fruit supply breakdown in the year 002 and are forecasted to fall again in 005/8. Figure shows this rapid annual supply fluctuations on this market in Poland between the year 000 and 005/8. Supply variations on this market are accompanied by the reversed trend in price changes showed in figure. In this relatively short six-year period prices fell drastically twice mirroring the growth in production and peaked as production decreased. The provisional figures for the year 005/8 show further price decrease, as in the middle of this year Polish producers faced massive influx on competitive prices of fresh and frozen fruits from the third fruit and vegetables in alleviating price and supply fluctuations on the soft fruit market in Poland. The discussion inevitably equalled looking back to the very first objectives of the Common Agricultural Policy established by the Treaty of Rome in 95/87, and in particular to the one of market stabilisation, as the situation on this market in Poland desperately calls for solutions bringing long awaited balance. The abovementioned problem is also indirectly addressed in the key document outlining agricultural policy objectives for Poland, namely in the 'Strategy for the development of rural areas and agriculture 007- 200/6 of 8 October 996 on the common organisation of the market in fruit and vegetables, Article 1, 200/6., op.cit., Article 3. Ibidem, Article 0. Ibidem, Article 3. The price stabilisation aim is also addressed under the CMO for processed fruit and vegetables, that unfortunately covers only tomatoes, peaches, pears and citrus fruits grown for processing. Council 201/6 of 8 October 996 on the common organisation of the market in processed fruit and vegetable products. Ibidem, Article,. Under this regime, despite the production aid is directly granted to processors, it is targeted at producer groups. To be eligible for support, the processor has to pay to producers not less than the minimum price set for the given period. The delivery to processors has to be done by the producer group and be based on contracts specifying price, quantities and the schedule of supply. Ibidem, Article,. The horticulture sector.op.cit., p. -. It should not be overlooked, that on this market also price supporting mechanisms of trade policy are applied, in order to either discourage excessive imports or to encourage exports of price depressing surpluses, such as import and export licences, import duties and export refunds, however the latter do not apply to soft fruits. The horticulture sector.op.cit., p.. The system of support described above allows the EU producers of certain fruits and vegetables to operate in a reasonably stable environment. It is worth noting, that the instruments encouraging farmer co-operation proved to be effective in the former EU-5/8, as they resulted in high levels of market organisation, expressed in the percentage of production marketed through producer organisations, shown in table. Nearly producer organisations channelled almost 0% of all fruit and vegetable production to market in the year 002. Their number and sizes varied widely among Member States of the former EU-5/8. While in the Netherlands and Belgium more than 0% of all fruit and vegetable production was marketed through producer organisations, the percentage was much lower in the three most important producing Member States: less than 0% for Italy, 0% for Spain and 0% for France. Analysis of the Common market organisation in fruit and vegetables, Commission staff working document, Brussels, 3.9.004, SEC 120, p.3. This numbers, however are incomparable with the rate of fruit and vegetable market organisation in Poland.. Can CMO for fruit and vegetables work for Poland? In mid-June 005/8 in Poland there were only 8 registered producer organisations. Their share in total fruit and vegetable production did not exceed %. It can be therefore inferred, that the share of soft fruit producers must be negligible. Market analyses, Fruit and vegetable market. Current state and perspectives, Institute for Agriculture and Food Economics, June 005/8, p.. The main question that arises is what are the reasons for this state of affairs? In Poland the concept of producer organisations appeared in the public debate in the late 0s, but entered the legislation only in 000. However, in the common perception the created law did not encouraged farmers for getting together, mainly due to the relatively small levels of financial support. In 004 the regulation was amended in line with the EU legislation. The legal act of 5/8 September 000, concerning producer groups and their legal act of 9 December 003 on the organisation of the fruit and vegetable, hops, tobacco and dried fodder (Official Journal No. 23, point 221). Nevertheless, according to the survey run among 39 members of producer organisations in agriculture in the Podlasie region, by the Farm Advisory Centre in Szepietowo, the most important reasons for such poor levels of market organisation are more of social than legal and economical character. Gasiorek, P., Advantages, barriers and future of self-organisation of agricultural producers in Podlaskie Voivodship, Farm Advisory Centre - Szepietowo, URL roln001.htm (viewed 0.2.005/8). The respondents noted that low levels of farmer co-operation lie in: lack of the team spirit and mutual trust (2.%), lack of leader (.%), lack of knowledge as to the running of the enterprise (.%), lack of interest and finally lack of substantial financial benefits (both.%). Only 5/8% respondents quoted the insufficient support from the public and non-government institutions as a reason. This findings supposedly, with a low risk of over-interpretation, can be generalised across the farming population in Poland. Ibidem. The striking and straightforward diagnosis, that farmers simply do not trust each other and do not want to act together raises a question why this is the case. First and foremost, their deeply rooted scepticism seems to be sourced by the negative past experience. Under the communist regime, the best way of protection from the government interference was self-sufficiency and self-reliance. This still manifests itself in aspiration for independence from the external environment and mistrust not only for the outsiders, but also for neighbours and fellow farmers competing on the local markets. Gasiorek, P., Advantages, barriers and future.op.cit. This mentality can put the future of producer organisations in Poland in question and in turn impede, if not prevent, the completion of market stabilisation objective. Nevertheless, even if farmers eventually overcame their hindering attitudes and started forming producer groups, they still would not enjoy the full spectrum of policy instruments existing on this market, as they simply to not apply to soft fruits, what has already been stated in section and ought to be emphasised.. Summary and conclusionsWelcoming Poland among it's members transformed the Community into an important soft fruit producer, but also the one with a highly unregulated and unstable market, where the 'invisible hand' rocks the swing of supplies, prices and farm incomes. The existing policy instruments, that aim at stabilising the market conditions, cannot serve as solutions to this problem, as they simply do not apply to soft fruits, are not attractive to Polish farmers or do not suit their mentality (or vice versa). Tanking the necessary actions to alter this status quo appears to be a must for the policy makers, both on the domestic and European levels. Otherwise they might face the risk of accusations of the government failure not being able to achieve the objective as old as the Treaty of Rome.'''",114.0
"'''During the Victorian era women were considered to be suitably inferior to men; physically, intellectually and even spiritually. They were perceived as being merely driven by emotion and not reason. In this sense, women who had to work were paid less than men, and those who didn't work at all were reliant on a husband, a father or perhaps some generous male relative for any financial support. Women were victims of this patriarchal society and perhaps this is why Barbara Bodichon states so strongly that women held no importance or status in Victorian society, other than dutifully fulfilling the role of wife and mother and becoming the property of the their husbands. Bodichon herself was a victim of this society's rules and expectations regarding women, yet she did not submit herself or conform to them, rather Bodichon challenged and confronted, campaigning for women's rights and even set up the first women's suffrage committee 866. Strong women like Bodichon were voicing their protests throughout the Victorian period and this has been reflected in much of the literature written during this time. The typical stereotype of a woman was starting to change, or at least writers were beginning to challenge the original idea and develop it further. This was not particularly drastic or noticeable initially but it does suggest that people were aware that women were potentially just as powerful as men, if given the chance. Yet more commonly found amongst the presentation of female characters or voices are those that were controlled or dominated by men. It is possible to identify this portrayal of women from a range of genres, including poetry as well as in the novel. Robert Browning's dramatic monologues are especially good indications of this, such as, My Last Duchess, and, Porphyria's Lover; Charles Dickens' novel, Great Expectations, also offers examples of women who are conforming to both the explicit and implicit conventions of their gender. URL Both My Last Duchess and Porphyria's Lover are in the form of dramatic monologues, a technique often attributed to Browning. Though Browning by no means invented the form, he has made a significant impact upon it by using it in such an extensive and varied way. It was certainly a popular and continuously developing form amongst the Victorians. It gave the opportunity for the writer to temporarily separate themselves from their work, giving a voice to someone else, conveying instead not their own personal thought and feelings but another, usually that of a famous character in History. The monologue provides the writer with a position where they can remain detached with almost an escape from responsibility for the content. Through this detachment the poet can still subtly persuade the reader and influence their opinions. The form of My Last Duchess is kept incredibly regular with 8 rhyming couplets. Yet due to the enjambment where each line seems to just flow onto the next, Browning makes sure the rhyme is there for emphasis only and not to provide a regular rhythm. This gives the tone of the poem a conversational one, which is in fact exactly the intention Browning want to create. Especially as that is what is occurring during the poem. A Duke is having a conversation with a visitor to his palace, recalling the memory of his previous wife, the memory of her triggered by her portrait. The portrait itself is an item that belongs to the Duke but it is clear through his recollection of the Duchess that she too was just a possession to him. The very opening line of the poem, 'That's my last Duchess.' indicates this idea of possession, and the reader is already beginning to wonder just how many predecessors did she have? The possibility of their being more than one is probably quite accurate, and this creates the impression that these women were easily disposable to the Duke, they are devalued. This reflects perfectly the materialistic, obsessive nature of the Duke, who wants to possess not only material possessions but also a human being. This obsessive nature is the trigger for spurring his jealously when he believes her to be flirting and believes her to be, The Victorian Era, My Last Duchess, pg278 'Too easily impressed; she liked whate'er She looked on.' (3-4)He is even angered by the idea that she does not value his heritage or perhaps more specifically, '.nine-hundred-years old name' (3). His compulsion to own her and control her is even noticeable through the structure of the poem. As mentioned earlier, the entire monologue is based around the rhyming couplets; there is not one deviation or exception from this. It is utterly controlled, just like she is. His power over her is reflected in the poem, and once the reader becomes aware of this Browning reveals how the Duke finally rids himself of a wife altogether, '. I gave commands; Then all smiles stopped together.'(6)This sinister line reinforces the Dukes attitude that if he cannot own her, then no man shall, though what he does not understand is that no human life can ever be 'owned'. There is such a clear lack of spontaneity or passion in his actions, the fact that he just gave a command and the deed was done makes the crime even more cold hearted. It also demonstrates the Duke's corrupt use of this power; here perhaps Browning is condemning this corruption amongst the courts. This is the reason too that the reader disregards the Duke's point of view, and supports and sympathises with the Duchess, acknowledging her innocence. The Last Duchess is a clear example of how a woman was perceived as an object or an item to be possessed. She is only ever mentioned through her portrait, she is never given a name or any kind of identity. There is certainly a clear consequence from this treatment, though it only appears to effect her, the Duke seems to be void of any consequence or moral conscience, he feels no remorse for his actions. Porphyria's Lover is a similar example of the above. Just as in My Last Duchess, Browning uses the structure of the form to convey the narrator's feelings and thought. The stanzas contain syllables with a repeated rhyme scheme of A, B, A, B, B. However the extra line seems to turn what could be a straightforward rhythm into a slightly out of synch one which creates the tone of someone truing to convince or persuade the audience or reader. This clearly does not have the desired effect on the reader; the male narrator remains nameless making it harder for the reader to relate or trust him, regardless of it being in the first person. Instead Porphyria has the stronger identity, and although she is the victim, she holds the authority over the entire poem. This lack of trust in the narrator becomes even more inevitable when the reader learns of how Porphyria is killed by her lover, '.and her hair In one long yellow string I wound Three times her little throat around,' (7-9)Indicating such a profound mental instability, his mental state is horribly disillusioned. There is a strong sense of denial and refusal to accept the reality after Porphyria's death. He believes that her cheek, 'blushed bright' (8) when he kisses her. It appears that in his world, he can immortalise Porphyria through her death, capturing her in the moment when she belongs just to him, '.at last I knew Porphyria worshipped me' (2-3)Just as the Duke wants to do, when he refers to her painting, '.as if she were alive' (.) Again the reader is introduced to this idea of ownership and male authority, 'That moment she was mine' (6) he does not hesitate to speak for her, assuming he knows her mind, what she is thinking and feeling. These two dramatic monologues by Browning depict a male's notion of possessing a female. The male characters in these texts, 'objectify, use and abuse' the woman by forcing their own wishes upon her. Yet in both cases the men who do so do not achieve the approval or acceptance of the reader. Instead it seems to have the opposite effect, perhaps Browning, through the disguise of another voice is indeed condemning this view and asking the reader to do the same. This would suggest that the typical role of women as the property of men was being implicitly challenged. However though the poems reveal and suggest a little about the way gender was constructed and perceived amongst the Victorians, Browning does not explicitly suggest any concept regarding the 'office' of a woman, apart from the Duchess which only applies to Bodichon's idea that the only important office for women was that of sovereignty. To explore Bodichon's statement further, it is necessary to use a more in-depth and complex text which provides the content and examples of several female characters to analyse. URL, 'Porphyria's Lover' section In Dickens novel, Great Expectations, it is possible to find a range of typical female stereotypes alongside those who don't quite achieve the expected social norms of the time. The simplest division between them appears to be class. Miss Havisham and her protege Estella who are upper class with considerable wealth or in fact as Pip describes as, '.immensely rich' whereas Biddy and Mrs Joe Gargery are clearly amongst those classified as the working class. This distinction separates the characters into pairs, but actually each woman is entirely different, each having an equally significant effect on Pips life. This could be due to the absence of a strong male role model, which Mr. Joe Gargery just doesn't quite fulfil. Dickens describes him as a, Great Expectations, Charles Dickens, chapter, pg 0 '.fair man, with curls of flaxen hair.' And later adds that he is, '.a mild, good-natured, sweet-tempered, easy going, foolish, dear fellow.' (Chp, pg ). Not quite the character that can easily stand and battle against the strong, dominating figure of Mrs. Joe. It is not surprising therefore that Pip regards Joe as, '.a larger species of child.' (Chp, pg7). Indeed there is a significant lack of any kind of strong male role model or any tender maternal one for that matter, in Pip's life. Mrs. Joe's very introduction and description to the reader makes a striking contrast to Joe's and immediately implies that she is a woman who is so very unnaturally destined for the position as wife and mother, 'Mrs Joe, with black hair and eyes.was tall and bony, and almost always wore a coarse apron.having a square impregnable bib in front that was stuck full of pins and needles.' (Chp, pg6).There is a clear reluctance coming from her character which screams her refusal to conform to Societies norms of female duties, ' '.it's bad enough to be a Blacksmith's wife.without being your mother.' ' (Chp pg8)This is such an unlikely and unconventional depiction of the stereotyped female role, though it is not just in her appearance where the reader discovers this abnormality, indeed in her treatment of Pip and Mr. Joe this can be seen. Mrs. Joe has a strikingly violent nature, Pip mentions that he was, 'brought up by hand' and by this, the reader acknowledges that this refers to some kind of physical abuse, confirmed when, 'Tickler' is revealed to be a stick with which he is beaten. Joe too is not exempt from this, indeed once Pip has a beating; Joe is likely to receive one as well, '.she pounced on Joe, and, taking him by the two whiskers, knocked his head against the wall.' (Chp, pg10). The role that Mrs. Joe seems to perform throughout most of the novel is the one usually taken upon the man of the household. It was seen as the norm, during the Victorian era that men should be the dominant authoritative figures in the home and were the ones who were violent and inflicted abuse. Dickens does the same with the character of Mrs. Havisham, another female who does not fit the 'model woman' of a Victorian society. She does not marry, (though not without trying), and she is never a mother, or at least not in a biological sense, as she does eventually adopt Estella. The very symbols of marriage, have actually become symbols of death, '.everything within my view which ought to be white.was faded and yellow. I saw that the bride within the bridal dress had withered.'(Chp, pg 6)Miss Havisham is an isolated, solitary female who is imprisoned within her own home, within her own memory of the past. Decay and death seem to seep straight from her, as if she were indeed a corpse. Her pure hatred for men is so overpowering that she recruits Estella, a young and impressionable girl who soon learns that she is required to avenge this withered elderly woman, and reward her with the satisfaction of seeing someone else suffer the same heartbreak as she did. Miss Havisham spends her time destroying the innocence of a child, Pip, encouraging him to abandon his world with Joe and the forge and instead watches him develop a hunger for the refined upper class he perceives as the only way of capturing Estella's cold heart. This portrayal of a woman who did not achieve the expectations of society is far from being, in any way a positive one, Dickens seems to be constantly reiterating the idea that those who do not achieve the norm do not lead a stable, happy life. Therefore it would seem Bodichon's statement would coincide with Dickens view, that women cannot achieve any kind of high office unless it is sovereignty itself, simply due to the fact that if any other path is sort after, the result is not a favourable one. Indeed this is reflected once more upon another of Dickens's female characters, Estella. Just as Pip is very much an object in the eyes of Miss Havisham, Mrs. Joe and Estella, she too is also objectified by Miss Havisham. Estella's very identity is stolen from her; she is shaped and moulded into the creature which Miss Havisham desires. Dickens never reveals what Estella actually looks like, instead only supplying the reader with the vague and superficial, she is, 'beautiful and self possessed.'(Chp, pg 5/8). Even when Estella grows into a woman, Miss Havisham still retains an overwhelmingly obsessive control over her, 'I am to write to her constantly and see her regularly and report how I go on.' (Chp 3, pg 71).However though she is controlled, Estella most certainly controls Pip. Her influence over him is enormous, even after their first meeting Pip feels entirely differently about himself, realising for the first time that he is, '.a common labouring boy; that my hands were coarse; that my boots were thick.generally that I was in a low lived way. ' (Chp, pg 3)Estella, like Miss Havisham is in a position of wealth, and therefore power. She is a strong female but who also does not conform to the norm. Her control and power over Pip is illustrated by the ease in which she lowers Pip's opinion of himself and of his most beloved relative and friend, Joe. He feels continuously degraded and worthless when in her presence, even when she kisses him, a gesture of affection is turned sour and rendered meaningless, '.the kiss was given to a coarse, common boy as a piece of money might have been and that it was worthy of nothing. ' (Chp 1, pg 1). Estella's affect on Pip provides a most significant contrast when placed alongside the character of Biddy. Like Pip, Biddy was an orphan and again, like Pip, she was, 'brought up by hand'. Biddy is instrumental in the early education of Pip; she teaches him humility and respect for Joe and most importantly the true meaning of a loyal friendship. In this sense Biddy is already showing signs of a new type of woman in Victorian society, one which is in no position of wealth but regardless is still in the position to be respected and admired and who is intellectually equal to that of a man. The way in which Pip is immediately at ease and is himself is also quite a contrast to when he is in the company of Estella. Pip describes Biddy as, '.never insulting, or capricious; she would have derived only pain, and no pleasure, from giving me pain.' (Chp 7, pg131) There is a noticeable change with Biddy's appearance within the novel, initially when Biddy is running her Grandmother's shop Dickens portrays her with, '.her hair always wanted brushing, her hands always wanted washing.' (Chp, pg 3).Yet when Biddy moves on from the shop and takes on the role as carer for Mrs. Joe, Joe and Pip, Dickens makes sure the reader acknowledges the change, '.her hair grew bright and neat.she was pleasant and wholesome and sweet tempered.' (Chp 7, pg 25/8).Dickens here is perhaps being rather subtle; when Biddy begins to start taking on the normal position expected of her as a woman, her appearance instantly grows more attractive and acceptable. Indeed this is not the only dramatic change the reader will notice occurring within other female characters. After surviving her brutal attack, Mrs. Joe completely reverts to a more normal gender role, '.her temper was greatly improved and she was patient.' (Chp 6, pg 22). To conclude, it would appear that what Dickens is suggesting is that for those women who do not conform to the explicit and implicit expectations of society, instead choosing the reverse of their gender roles, the result is simply violence and chaos. This disorder is soon resolved when there is a return to the norm. In this respect it is possible to understand that amongst early Victorian society and literature, there was a very fixed understanding of how each gender should behave, and what positions in society are acceptable to them. Within the poetry of Browning these gender norms appear to be challenged, and perhaps confronted in order to raise awareness of the possibility of equality amongst men and women. Where Browning is aware of this possibility, Dickens seems very much convinced that the conception of the 'ideal woman' is there to guide those women in Victorian society to ensure they do not deviate, and experience the consequences deviation could incur. Barbara Bodichon most likely is reflecting an entirely accurate portrayal of how the Victorians perceived women and the attitude which was held against them. However to say that there is no important office for woman apart from that of Sovereign is perhaps a little closed minded, it suggests that the role of a wife or that of a mother is inferior and holds no status, where in fact it is perhaps the most essential to not only family, but to society as well.'''",116.0
"'''To many the word 'myth' will evoke the notion of stories of heroes and monsters, such as Theseus and the Minotaur; Stories which were intended to entertain, to scare and to thrill. However, it would be ignorant for a mature mind not to look at the importance of the characters: What was their role? Were they symbolic? Did they make up part of a larger motif? These are just a few of the questions that could be focused toward characters within myth; questions which, in this essay, I will ask of those hybrid creatures that feature in ancient myth. Hybrid creatures were the predominant antagonist in many hero myths that date back to classical antiquity. It is interesting that 'in the neatly ordered Greek universe, which has reserved distinct compartments for the 'bestial', 'human' and 'divine'' there is no such compartment for those hybrid characters in myth. Even the word 'monster' is a vague description: The idea of 'the Monster is ubiquitous' and as such it remains unclassifiable, something which Lada-Richards argues is due to 'monsters' being 'culture-specific products.' I consider that, as there is no universal 'compartment' for the hybrid creatures in ancient myth, each and every crossbred character has been amalgamated into the manner they are because they are to be treated as individual cases. This point can be maintained by how the many of varying fusions represent a different challenge to a different hero; for example, the Minotaur is a creature of brute strength, whereas the Gorgon Medusa relies upon intelligence. On the other hand, in some myths hybrid creatures had another role, such as being symbolic of a social fear rather than playing the role of being the nemesis of the hero; the Sirens are an example of this. Atherton, Catherine 'Foul Monster or Good Saviour'? Reflections on Ritual Monsters by Ismene Lada-Richards, from Monsters and monstrosity in Greek and Roman culture, Levante p. 6 Atherton p. 6 Arguably one of the most famous of hybrids in ancient myth, the Minotaur, in the view of some, plays a far more complex role than that you would conclude from initial impressions. Even its birth, I feel, is an area for discussion; Pasiphae, the mother and husband to King Minos, became physically attracted to a great white bull, which was a sign from Poseidon. Yet once Minos refused to sacrifice the beast, Poseidon sent Pasiphae into a lust for the bull. Finally, through the help of Daedalus, Minos constructed a way for the bull to mount his wife, which ultimately led to birth of the Minotaur. On the other hand, the classical scholar A. B. Cook expresses the view that Minos, the king, and the character of the Minotaur are really the same individual in different outward appearances. Cook and the anthropologist J. G. Frazier regard the union between Pasiphae and the bull as a sacred ceremony, relating to Minoan religion, in which the queen of Knossos wedded a deity in the form of a bull. The previous point aside, in the myth of the Minotaur, the unusual chain of events that led to the union between bull and woman can mean it is feasible to say that the Minotaur was a result of divine intervention. Furthermore, I would like to point out that the physical sexual attraction by Pasiphae towards the bull led to the creation of the archetypal physical challenge for a hero, the Minotaur. Before the myth of Theseus and the Minotaur has even begun there is, debatably, a motif; trying to fool the Olympian deities, which will ultimately result in intervention from the Gods, is a course of action only for fools. Whilst asking for help from the Gods can lead to unexpected and unwanted results. If King Minos had honoured Poseidon by sacrificing the great white bull then none of the terrible events that followed would have occurred. The Minotaur was used as an 'engine of vengeance', used by Minos in response to the death of his son, Androgeos; After signing a treaty with Minoan Crete Athens had to send 'seven Athenian youths and seven girls, children of noble families' as tribute to Minos, where upon the children were placed 'in the Labyrinth and devoured by the Minotaur'. Historically, it is true that the fledgling polis of Athens was under the both cultural and political influence from Minoan Crete and for this reason, some modern mythologists consider Theseus' slaying of the Minotaur as a Minoan adaptation of the Baal-Moloch of the Phoenicians and as such consider it a solar personification being symbolic of not only the ending of Athenian tributes to Minoan Crete, but the end of the dominating influence of Minoan religion over mainland Greece. Dickinson Patrick Theseus and the Minotaur and Poems, Alden Press p. 1 Morford, Mark P.O. & Lenardon, Robert J. Eighth Edition Classical Mythology Oxford University Press p.04 Morford, Lenardon p.04 The myth of Theseus and the Minotaur is not the only ancient myth with symbolic connotations; the myth of Medusa and Perseus is another. With the rise of the patriarchal society all around the Aegean, the image of Medusa was far from acceptable. The image I refer to here is not the one of myth where she was a chthonic monstrous hybrid with snakes for hair: Instead, the image is one of a woman, who symbolised female intelligence and wisdom and who was worshipped by Libyan Amazons. However, she represented much of the qualities that patriarchal Greece did not want women to feel they had; intelligence, creativity and the power of destruction. Her most famous re-representation from patriarchal Greece is that of the snake-haired Medusa, one of the 'three Gorgons, of whom only Medusa was mortal,' and they 'were of terrifying aspect, and those who looked upon their faces were turned to stone.' It is this Medusa, who in myth, was beheaded by Perseus. Similarly to the birth of the Minotaur, the events that led to Medusa's snake-hair also allow for interpretation. After Medusa had intercourse with Poseidon in Athena's temple, Athena turned her hair to snakes and made her face so unbearable to behold that any man would turn to stone if they saw it. It is here even more similarities can be drawn between the creation of the mythic Medusa we know and the birth of the Minotaur; interaction with the Gods, notably Poseidon in both cases, has resulted in dire consequences. This connotation aside, Medusa is arguably also an example of a punishment of what should happen if a mortal angers the Gods. It is worth noting that it in popular myth it is also Athena, responsible for the curse upon Medusa, who along with Hermes helps Perseus complete the challenge. This occurrence is rare in myth and is something which Morford & Lenardon point out; the fact that 'two gods should assist him is remarkable.' Furthermore, the fact two powerful deities actively help Perseus on his quest deducts greatly from the challenge faced by Perseus and for this reason, I feel the myth of Medusa is certainly more emblematic than any other; the myth is not so much a story as it is a symbolic connotation of male dominance over the female, a connotation which is full of 'male bias'. Morford, Lenardon p.49 Morford, Lenardon p.49 Morford, Lenardon p.48 Zajko, Vanda & Leonard, Miriam Laughing with Medusa: Classical Myth and Feminist Thought, Oxford University Press p.7 The role of Medusa in myth does not end with her beheading at the hands of Perseus. In fact, it is quite the opposite. From Medusa's neck springs Pegasus, son of Poseidon and Medusa, in the form of a winged horse; this is, by modern definition, another hybrid creature. Furthermore, Pegasus also later helped kill another hybrid creature, the Chimera; 'a thing of immortal make, not human, lion-fronted and snake behind, a goat in the middle, and snorting out the breath of the terrible flame of bright fire.' Medusa's blood was drained and taken, and was later used to raise the dead. Furthermore, her head was also taken and kept by Perseus and he 'turned his enemy Polydectes to stone by means of Medusa's head.' Homer, Illiad Book VI lines 79-82 Price, Simon & Kearns, Emily Oxford Dictionary of Classical Myth & Religion Oxford University Press p.31 It is not only in the myth of Medusa that we see a hybrid creature representing the ancient Greek cultural and social fears of women and its condemnation of them. The sirens, described as 'enchantresses', a hybrid between women and birds, who have been allegorised by classical writers 'as representing the lusts of the flesh. the dangers of flattery', on the other hand there is another alternative existing view, which I agree with, that they are symbolic of the ancient Greek belief that women were trouble. In Homer's Odyssey the Sirens lived near Scylla and Charybdis, two dangers so equally grave that 'between Scylla and Charybdis' is seen by some as the progenitor of 'between a rock and a hard place'. Although Charybdis is not a hybrid, she was the 'formidable and voracious ally' of the hybrid Scylla, a 'fantastic monster with twelve feet and six heads'. It is noteworthy to state that they are both named as if they were female in gender. This, again, reiterates the social fear within Greek society towards women. This point is supported by how Scylla later became 'an alluring woman' in later ancient Greek iconography. Price & Kearns p.13 Price & Kearns p.14 Price & Kearns p.02 Price & Kearns p.02 The aforementioned Chimera was another hybrid creature, from Lcyia, in Greek myth, yet unlike Medusa, Scylla or the Sirens, it did not have any underlying negative attitude towards the female gender. Its symbolism was completely different. One possible allegory, as Harry Thurston Peck says, is that the Chimera was used as a symbol of the volcanic nature of Lycian soil. On the other hand, Robert Graves puts forth the possibility that the Chimera was a symbol of the tripartite calendar, of which the the all seasonal emblems. Although hybrid creatures were not always used as representation of social fears or as connotations to assert the notion of male dominance in society, for example the Satyrs, part man, part goat, were used as comedic uplifts in literature by the likes of Sophocles and Euripides. It would appear that in ancient myth, particularly the most renowned ancient myths such as Theseus and the Minotaur, Perseus and Medusa and all the myth of the creatures found Homer's Odyssey have an underlying message, on top of their primary role as a challenge, either physically or mentally or even both, for a hero. Unfortunately, despite the uniqueness of each hybrid we encounter in ancient myth it seems more often than not that they are used to condemn the female in Greek society. Even the physical lust of Pasiphae that creates the monstrous Minotaur could be seen as a criticism of the female gender, which throughout classical antiquity was seen as the more lustful of the two genders.'''",118.0
"'''In order to start your scheme, we should explain several procedures before any construction can begin. To fulfil your requirements for the project we need to develop your ideas into actual plans. These then should submitted to the local authority to obtain planning permission and inspected to ensure that the project meets all current Building Regulations and legislation. I will now outline the planning stage and the relevant building regulations Planning StageThe full project brief and the functional requirements of the house should be established. A substantial site analysis should be carried out to determine the dimensions of the site, the topography and drainage. All existing vegetation, buildings and access into the site should be recorded. The orientation and local climate should also be surveyed and considered during the planning stage to make use of natural resources such as sunlight. The national and local government planning policy for the development of the site should be viewed. We should consider whether there are any planning restrictions or historical land use constraints associated with the site. Witney is a conservation area which will need to be considered. Other aspects to be looked into are, whether the property will be in an Area of outstanding Natural the property. Certificates C & D - should only be used in circumstances where not all, or none, of the property owners are known and require notices to be published publicly to ensure the best chance of notifying the owner. The certificate will also require you to confirm whether any part of the application area involves land within an agricultural tenancy. If so, you must supply details of the tenant and serve notice of the application on him/her. The certificate must be signed and dated by the applicant, or someone appointed by the applicant. vii) Statutory notices should be served on owners or tenants where certificates B, C or D are signed, or the property forms part of an agricultural tenancy. These statutory rights provide details of the applicant, the application and the planning authority to which it was submitted. You must also specify a date not less than 1 days from the date of service of the notice, within which the recipient of the notice may make any representations to the Council concerned. viii) The full planning application will require all necessary plans and drawings detailing the proposal. These should be accurate and contain sufficient detail. Landscaping proposals should also be submitted at this point. ix) Councils are required by law to charge a fee for most planning applications. The scale of this charge varies and depends upon the size of the project. The fee must accompany the application or the application will not be processed. It is important that we consider any concerns that the local authority's might have with the building of the new house, as we need to gain permission from them before we can start any of the work. To ensure that the initial design is approved, it is desirable that we produce a scheme which will fulfil all of their guidelines and regulations. The planning process starts when the application is submitted to the local authority. In the case of this scheme, we will be applying to west Oxfordshire district council. A notice of our application will then be published in the local newspapers and notices erected at the site. At this point local residents may view the plans and comment on them. The authority will consider these comments when finalising a decision on the application. This process usually lasts a period of about eight weeks. In general, permission is granted unless there are justifiable reasons for them to refuse. If our application is refused, we have the right to appeal to the council and then to the Secretary of State. We would then be allowed to make slight adjustments to satisfy the authority so that the plans could be approved at a later date. Both the planning permission and approval with respect to the Building Regulations involve a fee which is related to the size of the project. For a full application, the fee for a dwelling, up to 0 houses is 65/8 for each house. For above 0 houses, the fee is 3,5/80 and an additional 0 for each dwelling house in excess of 0, subject to a maximum total of 0,00. For all other buildings, the fees are dependent on the floor space that will be gained. i) Where no floor space will be created by the development the fee is 35/8. ii) Where the area of gross floor space that will be created by the development does not exceed 0 m square metres the fees are 35/8. iii) Where the area of gross floor space that will be created by the development exceeds 0 m square metres, but does not exceed 5/8m the fee is 65/8. iv) Where the area of floor space to be created by the development exceeds 5/8 m but does not exceed,5/80 m square metres the fee is 65/8 per 5/8m. Where the area of gross floor space that will created by the development exceeds,5/80 m the fee is 3,5/80 and an additional 0 for each 5/8 m in excess of,5/80 m, subject to a maximum in total of 0,00. For your project the building application fee should be 65/8. Building RegulationsThe purpose se are in place to ensure that the building to be built is structurally safe, meets fire, health and safety standards, is energy efficient and has adequate accessibility. We should submit detailed drawings and plans for the proposed work showing all the construction details and calculations. Our proposals will be checked by the statutory authorities such as the fire service. The Council will usually give a decision within weeks, although this may be extended. If our plans comply with Building Regulations, we will receive a notice stating that they have been approved. If, however the local authority is not, satisfied we will be informed and should provide amendments. There are fourteen criteria for regulations that should meet in order to gain approval. Document A - Structure. This covers the structural loads, ground movement and disproportionate collapse. Document B - Fire Safety. The building should have adequate escape routes and warning signs in case of fire and should incorporate safety features that prevent the spread of fire in the internal structures and lining. There should be satisfactory access and facilities for the fire service. Document C - Site Preparation and Resistance to Moisture. This covers the preparation of the site, and records whether any dangerous or toxic substances are present. Adequate subsoil drainage should be present and the foundations of the site should be resistant to weather and ground moisture. Document D - Toxic Substances. This regulation prevents the use of toxic materials inside buildings. Document E - Sound Insulation. this regulation enforces sound protection for other parts of the building, protection of common internal parts of buildings and estimate of acoustic conditions in public spaces. Document F - Ventilation. The building must meet ventilation requirements and meet condensation regulations in roof areas. Document G - Hygiene. The project must comply with policies for providing sanitary conveniences and washing facilities, bathrooms and hot water storage. Document H - Drainage and Waste Disposal. There should be adequate foul water and rainwater drainage, both of which should be separate. Water treatment, cess pools and solid water storage must comply with regulations. Building over sewers must also fulfill regulations. Water fitting should comply with British standards. Document J - Combustion Appliances and Fuel Storage. The scheme should have a sufficient air supply and outlets for discharge produced by combustion. The building must have protection against fuels and pollution. There should be satisfactory information regarding substances stored and adequate protection around fuel storage areas. Document K - Protection From Falling, Collision and Impact. Document L - Conservation of Fuel and Power. The building should encourage excellent conservation for fuel and power. Document M - Disabled Access to and Use of Buildings. The buildings should provide facilities for the disabled, with appropriate access and use, sanitary conveniences and suitable seating. Document N - Glazing. There should be sufficient protection against impact, manifestations of glazing, safe opening and closing windows, skylights and ventilators and safe access to clean the glass. Document P - Electrical Safety. This ensures the safe design and installation and the inspection and testing of electrical equipment. The document has been updated this month. Regulation - Materials and Workmanship Approval of the plans with respect to the Building Regulations will be approved by the Building Control officer from the local authority. During construction of the building, a Local Building Inspector will attend the site to ensure the work is being carried out correctly to meet the legal requirements. The Building Regulations fee will vary according to the number of buildings there is. There are two separate fees - one for the plans submitted and an additional fee for the inspection. An approved inspector will view the plans and once satisfied will issue a Plans Certificate which will confirm that the proposed plans comply with the Building Regulations. When the work has been completed the Inspector will visit the site and issue a final certificate to the local authority stating that the building work from the Plan Notice is complete and that the Inspector has ensured that the regulations have been complied with. I hope this information explains the complex processes that we must undertake before work can begin. If you have any queries, please let me know in writing and I will address them for you. Yours sincerely.'''",120.0
"'''Crystal )methylene)-,-cyclohexadien--ylidene) exists in two resonance forms of which can be bleached by the addition of hydroxyl ions that reacts via a dramatic colour change. This dramatic colour change allows the kinetics of the reaction to be monitored. The kinetics of this reaction is investigated by probing the effects of varying concentration, temperature and ionic strength; allowing the rate, order and activation energy of the reaction to be calculated.The two resonance forms of crystal violet are shown occurs via a dramatic colour change from intense purple to colourless. Changing the concentration of NaOH and crystal violet will enable the rate and order of the reaction to be calculated. Varying the temperature and ionic strength of the solution by addition of KNO and CaCl will be monitored for there resulting effects on the kinetics of this reaction.. ExperimentalA UV spectrophotometer was used throughout all the experiments to monitor the colour change of the reaction. Throughout this experiment the concentration of crystal violet must not exceed x 0 - M as above this concentration crystal violet does not obey Beer-Lamberts Law. The concentration of NaOH throughout the experiment has to remain in excess to ensure the reaction goes to completion and to enable the concentration of the NaOH to remain relatively unchanged. Running a UV spectrum of crystal violet showed the maximum absorption of the molecule to be at 90nm, therefore throughout the experiment this wavelength was used. Stock:.9g/L crystal violet.M NaOH1.M KNO Solid CaCl 1. Calibration starting crystal violet solution was prepared in a ratio of: stock solution:water resulting in crystal violet concentration of.2 x 0 - mol dm -. The absorbance of this was recorded by removing an aliquot of the solution and placing it into a cuvette that was placed into a UV spectrophotometer. The solution was then diluted further by: with water and the absorbance recorded again. This continued until the concentration of the crystal violet solution became.3 x 0 - mol dm -.. Varying temperatures used were 5/8 oC, 0 oC, 5/8 oC and 0 oC. The crystal violet stock solution was made up with crystal up to 5/80cm with water that results in a crystal violet concentration of.43 x 0 - mol dm -. The solutions of crystal KNO left in a water bath to reach the specific temperature. Once the required temperature was reached ml of crystal violet, ml of NaOH and.ml of KNO were added to a cuvette and placed into a thermostated cell in the UV spectrophotometer to scan absorbance every 0 seconds for 5/8 minutes. This method was repeated times for each of the four temperatures. The time in between mixing of the solutions in the cuvette and placing the cuvette into the UV spectrophotometer were recorded.. Varying starting crystal violet solution again was made up with crystal up to 5/80cm with water that results in a crystal violet concentration dm -. Varying NaOH concentration: The different concentrations were set up as starting crystal violet solution was made up with 5/8cm crystal up to 5/80cm with water that results in a crystal violet concentration ml to its different ionic strength to that of KNO: The concentrations are prepared by weighing out the required amount of CaCl and then making it up to 00cm with water.. TheoryOrder and rate of reaction:Schematically the reaction looks like this: Crystal violet hydroxyl ion carbinol compound The rate law of this reaction is: Where k is the rate constant, m is the order with respect to OH- and n is the order with respect to CV+. As the is in excess the as the reaction occurs to completion the crystal violet has fully reacted however the has relatively remained unchanged. Therefore, the rate equation can be changed to account for this. Taking natural logs of this expression results in: Therefore a plot of ln will result in a straight line and the gradient will equal m, the order of the reaction that is rounded to the nearest integer, and a y intercept of results in the rate constant. k' is the initial rate of the reaction, which can be found by calculating the gradient of the data in the initial part of the /T will result in a straight line where the gradient will be - Ea/R and therefore the activation be calculated as R is the gas I the resulting gradient is A ZAZB. The ionic strength is calculated with the following formula: If the gradient is positive, then Z A and Z B must be of the same sign, which in turn indicates that adding the inert salt causes the rate of the reaction to increase. If the gradient is negative, then Z A and Z B must be different in sign, which in turn indicates that adding the inert salt causes the rate of the reaction to decrease.. Results and DiscussionThe linearity of the plot of ln Absorbance against time plots establishes that the reaction is a pseudo first order reaction. This was further confirmed as changing the concentration of crystal violet did not change the observed rate constant. The pseudo first order rate constant k' was obtained from of ln Absorbance versus time using a least squares analysis. All the sets of data were extrapolated back to account for time between mixing the solution in the cuvette and placing the cuvette into the UV spectrophotometer. This was done by using the FORECAST function. Error Calculation:The error of a measurement is measured by the difference between the actual value of a physical quantity and the measured value of the quantity.: /-.01gBuret 0mL /-.mLThermometer 10 oC /-.KBalance error =.6 x 0 -%Buret error =.02%Thermometer error =.0181%Total compound error =.0381%Varying Temperature:From the formula, the following data was required to calculate the activation -938. Therefore; The value calculated for the activation energy is ~ kJ mol - lower than that of the literature value. This may be due to experimental error The table below shows each rate constant calculated for each temperature compared that of the literature values: The calculated values for the rate constant at each temperature are not accurate with that of the literature value, however they do follow the same trend. Varying ConcentrationThis involved plotting ln versus obtain the gradient and the y intercept. This data is shown in the table calculate the gradient and y intercept: The gradient is.28 which rounding to the nearest integer gives an order of with respect to the concentration of OH-. Comparing to the literature3 value the same pseudo rate first order was found and that the order is with respect to the concentration of OH-. The y intercept results in -.065/8 which equals lnk. Therefore, k = =.41 The literature found the rate constant to be.194 that is dramatically lower than that of the calculated value. This could be explained due to error or more possible a few anomaly results in the calculation that has dramatically effect the result. Beach S.F.; Hepworth J.D.; Mason D; Swarbrick E.A.; Dyes and Pigments, - Ritchie C.D.; Skinner G.A.; Badding V.G., Journal American Chemical Society, Varying Ionic StrengthCaCl: the values in the table the required data needed for the use of the kinetic salt effect equation: CaCl: The graph this data plotted and the resulting line of best fit allowing the gradient to be calculated: The graph results in a gradient of -.267. Therefore, A is constant, therefore Z AZ B is negative, this means that must have a different sign, which in turn indicates that adding the inert salt CaCl causes the rate of the reaction to decrease. The literature values for varying CaCl show the rate decreasing with increasing ionic strength that agrees with the calculated results. Turgeon J.C.; LaMer V.K., Journal American Chemical Society, KNO: the values in the table the required data needed for the use of the kinetic salt effect equation for KNO: The graph this data plotted and the resulting line of best fit allowing the gradient to be calculated: The graph results in a gradient of -.377. Therefore, A is constant, therefore Z AZ B is negative, this means that must have a different sign, which in turn indicates that adding the inert salt KNO causes the rate of the reaction to decrease. The literature values for varying KNO show the rate decreasing with increasing ionic strength that agrees with the calculated results.. ConclusionThe results for the order of the reaction with respect to the concentration of OH- was found to be first odrer which was confirmed from the literature value obtained. The rate constant calculated was inaccurate compared to a literature value, this may have come about from some experimental errors. One source of these errors may have been from the varying concentration and varying ionic strength experiments. As the solutions used in these two experiments were not placed in a water bath to obtain a steady temperature throughout the experiment and in doing so may have caused errors in the result. This error may come out more in the calculation of the rate constant as this requires a high degree of accuracy to obtain an accurate result. The activation energy of the reaction of 7.9 kJ mol - was accurate when compared to a literature value as it was only ~ kJmol - too low. Also the effect of ionic strength on the rate of the reaction showed that with increasing the ionic strength the rate of reaction decreased for both of the inert salts used. This again was confirmed from a literature value. L. Garci a-Rio,, J. R. Leis, J. C. Mejuto, Langmuir -13'''",123.0
"'''Infection within hospitals is an increasing problem in the UK. The public are becoming more aware of 'super bugs' such as MRSA, and there is increasing pressure on healthcare professionals to take more action to limit the spread of infection and increase awareness of infection control. In 003 MRSA was mentioned on 5/85/8 death certificates, compared to 87 in triangulation. This involves pitting against each other different data and theoretical interpretations to provide cross-checks of observations and interpretations. To achieve this an external researcher could be introduced to interpret the interview data as well as the main researcher; any interviewer bias would then hopefully be eliminated. Once enough data has been collected from the interviews, transcripts will be made and then data analysis can begin. The data analysis approach will be thematic analysis; this uses coding to organise the data collected in the interview and identify common themes (Polgar, S., & Thomas, S. A., 000). The main themes within the interviews will be identified and categorised, supported by information from the interview including quotations from the original transcripts. All participants must give informed consent for their direct quotes to be used in this way. Once themes are identified, a number or label is then assigned to each category and their positions in the transcript are recorded, a thematic matrix can then be established which groups and links the data (Polgar, S., & Thomas, S. A., 000). Computer software may be used to facilitate the process of coding analysis as it can be a lengthy process when large quantities of data are involved. Having coded the transcripts the researcher then interprets their meanings in the context in which they appeared. Having completed the analysis and interpretation of the data the researcher will decide whether they have successfully answered the research question. The research is then ready for dissemination and can be shared with the community of healthcare professionals and health scientists (Polgar, S., & Thomas, S. A., 000). The most common form of doing this is to report the results at a professional conference and it is an ethical requirement that the research results are reported accurately and honestly. The research will then be critically appraised by experts before it can be formally published.'''",127.0
"'''The aim of this experiment was to obtain measurements of photosynthetic activity in isolated chloroplasts using an oxygen electrode. Oxygen evolution was measured for samples in various conditions and then the rate of oxygen evolution was calculated. The rate of oxygen evolution in control conditions was determined to be 2.mol of O / mg chlorophyll / hour. It was discovered that when in presence of DCMU there was no evolution of oxygen. Upon addition of ADP with potassium phosphate, the rate increased to 17mol of O / mg chlorophyll / hour. However, without a source of phosphate the rate remained the same as the control. A limiting amount of ferricyanide also revealed to keep the rate of oxygen evolution constant. Upon addition of ammonium chloride rate increased over three fold, and subsequent addition of ADP did not change the value of 06mol of O / mg chlorophyll / hour. Finally with double the concentration of chlorophyll, rate calculated as mol of O / hour also doubled.:This experiment was concerned with the electron transport chain of pea seedling photosynthesis and its relationship to ATP synthesis. The 'light reaction' of studied in osmotically shocked chloroplasts so that hydrophilic reagents such as electron acceptors have access to the thylakoid membrane. Then CO driven by electron transport and photophosphorylation. The electrode used consists of a platinum cathode and silver anodes. A thin membrane is stretched over the electrode which separates the electrode elements bathed in an electrolyte of saturated KCl from the reaction solution in the sample chamber. The membrane is permeable to gases including oxygen which then can come into contact with the surface of the platinum cathode. If a voltage of about.V is applied across the cell, oxygen is reduced at the cathode. Hence the current flowing through the electrode system is directly proportional to the amount of oxygen passing through the membrane. According to the laws of diffusion, the rate of oxygen flowing through the membrane depends on the concentration of dissolved oxygen in sample. Therefore the extent of the current flow in the electrode is directly related to the concentration of dissolved oxygen. Hill reaction was demonstrated using the oxygen electrode with potassium ferricyanide as the Hill oxidant. In the 930s, Robin Hill demonstrated that the light reaction of photosynthesis is an electron transfer reaction by showing that isolated chloroplasts will evolve oxygen in the light as long as it is provided with a suitable electron acceptor, known as a Hill oxidant. The oxygen evolved in photosynthesis comes from the oxidation of water, which is coupled to the reduction of the Hill:The method described in the laboratory manual was followed. No changes were made to the set procedure. Results:Raw data and calculations can be found in the table below shows the various conditions studied and the values obtained for the rate of oxygen evolution. As can be seen from the results above, when DCMU, a herbicide, is added, there is no evolution of oxygen. When ADP and potassium phosphate is added in the reaction medium, the rate of oxygen evolution increases. The increase is almost double the value obtained in the control when 0l of 0mM ADP is added. However, when ADP alone is added without a source of phosphate, there is no change in rate. Addition of ammonium chloride, an uncoupler, also has the effect of increasing the rate, by over three times when 0l of.M ammonium chloride is added. When ADP is added subsequently, there is no change observed, the rate remains very high. Limiting amounts of ferricyanide appears to have no effect in changing the rate of oxygen evolution. This could be used to confirm the calibration of the electrode, as shown in the appendix on page. Doubling the amount of chlorophyll in the reaction sample has no effect in the rate of oxygen evolution because the units used are mol of O / mg chlorophyll / hour. However, calculating the rate of oxygen evolution as mol of O / hour shows the following: This shows that the rate of oxygen evolution doubles when the concentration of chlorophyll doubles. Hence the concentration of chlorophyll and rate of oxygen evolution are directly proportional. Possible reasons for the outcome of these experiments will now be discussed in the next section. Discussion: In the presence of DCMUWith the addition of DCMU, the evolution of oxygen stops. This is because DCMU is a herbicide which acts as an electron transport inhibitor between the two plastoquinone molecules Q A and Q B on the acceptor side of the reaction centre of photosystem II. However, because an artificial electron acceptor, ferricyanide is present, DCMU should not have any effect. This does not agree with the results obtained. Possibly at the point DCMU was added, there were no unreduced ferricyanide left. With the addition of ADP, with and without potassium phosphateAddition of ADP with a source of phosphate was demonstrated to produce an increase in the rate of oxygen evolution. Prior to the addition of ADP and the phosphate, there is a build up of protons in the thylakoid lumen. Once ADP and phosphate are added ATP synthase can begin to produce ATP using the proton motive force. As protons are used up, the rate of electron transport will increase to maintain the proton gradient, and thus increasing the rate of oxygen production as a consequence. Usually, the electron transport will slow down with the accumulation of protons. Nevertheless, the rate will return to the initial value after the ADP is used up. The value of n, the P:e- or P:O ratio, was calculated to be.2. Because it is greater than., there is enough ATP per molecule of NADPH made by non cyclic photophosphorylation alone to satisfy demands of the Calvin cycle. However, with no potassium phosphate, the rate of oxygen evolution was shown not to change after the addition of ADP. This is because phosphate is necessary as well as ADP to produce ATP by proton motive force driven ATP synthase. In the case of the Hill reaction, electrons flow through photosystem II directly to ferricyanide. With the addition of ammonium chlorideUpon addition of ammonium chloride, there is an approximately fold increase in the rate of oxygen evolution. Ammonium chloride, an uncoupler, has the effect of 'mopping' up protons. As a consequence, electron transport does not slow down as there is no accumulation of protons. Hence, the rate of oxygen evolution increases. The diagram the effect of ammonium chloride schematically. O evolution remains at 06 mol of O / mg chlorophyll / hour after addition of ADP. This is because electron transport is probably occurring at the maximum and so the rate of oxygen evolution is also at the highest and will remain the same too. What effect has ammonium chloride had on the P/e- ratio? With limiting amounts of ferricyanideLimiting amounts of ferricyanide appears to have no effect in changing the rate of oxygen evolution. This is probably because the endogenous electron acceptors are still present and are able to be oxidised just like the Hill oxidant, ferricyanide. Hence photophosphorylation continues and oxygen is evolved. With double the concentration of chlorophyllCalculating the rate of oxygen evolution as mol of O / hour shows that the rate of oxygen evolution doubles when the concentration of chlorophyll doubles. The concentration of chlorophyll and rate of oxygen evolution are directly proportional, because with more chlorophyll, the more electron transport can occur.'''",134.0
"'''Society has always had a preconceived notion of black masculinity. Earlier theories of black masculinity pathologised black male sexuality. (Marriot, 996) This racist attitude inevitably was at its peak during the years of slavery. Nineteenth century plantation societies saw the emasculation of black male slaves as they were stripped of all the symbols of masculinity - as defined by that society. However, with the twentieth century and the Black Power Movements there rose a different image of the black male as being hypermasculine, and this image became another racial stereotype with prominent figures in popular culture endorsing it. Ironically, much of the tension regarding the hypermasculine stereotype of black men is a logical cultural development for a group systematically denied full access to the socially constructed ideals of masculinity. As Bell Hooks or Kobena Mercer argue, historically the black man was denied the attributes of patriarchy. Whereas prevailing notions of masculinity imply power, authority and control, these were historically denied to black men since slavery. The new black masculinity, which Hooks, Hortense Spillers, Michelle Wallace and other feminists state as patriarchal phallocentrism, is however supported by many black male scholars. The new black male, although still oppressed himself, exerts his power and dominance by the blatant projection of 'sexist phalocentrism' (Marriot, 996) and violence. However, this development by no means imply that racism is no longer a problem in today's society. As Staples lament, it is very difficult for most black men to have access to the patriarchal hegemonic ideal. Legally sanctioned institutions of slavery may no longer exist, but persistent racist fears and ideologies continue to economically, politically, and socially oppress black men. According to recent statistics the inequal discrepancies between black and white America are as clear as ever. Black masculinity, therefore definitely belongs to the lower strata of hegemonic masculinity. But the machismo that the young black male flaunts often results in the stereotyping of black masculinity as being too physical, too hard. This black masculinity is a 'sexually defined masculine ideal rooted in physical domination and sexual possession of women. ' If this is the case, black masculinity is surely a paradoxical subject. Black men are therefore the oppressor as well as the oppressed, a view that changes depending on the context. Also the issues of class and sexuality complicates the study of black masculinity. Gay black males live a different reality. A study of the socially constructed black masculinities therefore is definitely a study of contradictory experiences. When looking at the historical evolution of the gender identity of the black male, one is confronted with a masculinity that is defined significantly by the legacy of capture, importation and enslavement. As Mercer & Isaacs point out, the period of history which saw the rise of the imperial powers of the West coincided with the historical construction of sexuality. The white man's image of black people was stereotypical of that time. They were savages, heathens, others - who had to be 'civilised' - lead to culture and godliness.'. One of the first proofs of this otherness was the nakedness of the savage, the visibility of its sex.' To the white colonisers this led to the assumption that black people were oversexed and promiscuous, unlike the Europeans, who were bound by the rigidity of the Victorian code of sexuality. The traditional notions of sexuality being linked to race led to the idea of the black male being dangerous. The white masters took it upon themselves to emasculate the black man. The slaves were shown the ideal of masculinity - the white master, who was the patriarch, the caretaker of his family, the provider. Slaves were however debarred from having patriarchal privileges. A black slave father did not even own his own children - they belonged to the white master. With the abolition of slavery, black men started about trying to fulfill their patriarchal destinies. However they soon found that equality was never achieved, no matter what they did. that this was because black men were psychologically handicapped due to an inferiority complex from being emasculated. Bell Hooks has described the black man's cultivation and embrace of a hypermasculine image as a logical response to these antebellum and postbellum views held by white supremacists, which characterized black men as feminine, a rhetoric that 'insisted on depicting the black male as symbolically castrated, a female eunuch'. By the time of the Civil Rights era, the political and rebellious Black Power movement articulated what Hunter and Davis refer to as 'a radicalized Black manhood, throwing off the imagery of the emasculated and shuffling Black male dictated by racial caste. The collective frustration and anger over the denial of manhood, identity and peoplehood that led to urban riots in the 960s was seen as a powerful expression of masculinity and as a vehicle for social protest.' However, this anger of the black man, which was once seen as political, is today seen as dangerous. The 'gangsta' image is what the popular culture promotes, but it is derogatory to women, gays and is blatantly sexual and violent. Majors state that this is the way young black men compensate for their marginal position on the hierarchical ladder of hegemonic masculinity. This adoption of the 'cool pose' is infact a survival strategy. Over the years, in diverse ways, black men have responded to their shared experience of cultural alienation by adopting 'certain patriarchal values such as physical strength, sexual prowess and being in control as a means of survival against the repressive and violent system of subordination to which they were subjected.' This leads to the continuation of the fear of the black man by white society. Marriot comments on the state's categorization of black youth as criminal and deviant, saying that this raises questions regarding the relationship between 'white law and black men'. Statistics prove this point, when looking at the criminal justice of the United States. among black males more than doubled between1960 and 990, and in general, violence has become the way of life for many black males. Black males are dramatically over represented in the US criminal justice system. Black males, who make up 0% of those on Death Row, are more likely to be condemned to death than white males who have committed similar crimes. There are more black men in jail in the US then there are enrolled in higher education. Drop out rates of young black males from schools are at the crisis proportions in between 0 - 0 of major US cities. 'Unfortunately, when the subject is crime, the consequences of misreporting data reverberate in the lives of people throughout the country. Crime in the public image in the United States is not racially neutral. Crimes in the media and the view of the general public are acts committed by young black men. Never mind that more serious crimes daily occur at corporate headquarters, banks and on Wall Street. The public image is of violent, psychopathic, young black males. Violations of the law that when committed by white middle class ignored or dealt with reinforces harmful stereotypes 'Although there are numerous contributing factors, this image of black masculinity has developed largely as a result of the commodification of hip-hop culture and the ubiquity of rap music and the 'videomercials' that sell it. More specifically, it is the result of the popularity of the urban 'gangsta' and his embodiment in the 'gangsta' rap of artists such as Dr. Dre, Ice Cube, Snoop Doggy Dogg, and Tupak Shakur, 0 Cent etc'. Violence, fierce homophobia, and derogatory attitudes towards women are blatantly reflected by this 'bad ass' masculinity which is portrayed by these black men. However, it is not just the black rapper, who holds this attitude. Black male scholars such as, Amiri Baraka, George Jackson, during the Black Power movements, attacked white masculinity and revealed a frighteningly misogynist attitude. Women, especially black women were seen as adversaries. As Hooks say, the attitude of Baraka and Jackson might be dated. But even now 'most black men remain in a state of denial, refusing to acknowledge the pain in their lives that is caused by sexist thinking and patriarchal, phallocentric violence that is not only expressed by male domination over women but also by internecine conflict among black men. In popular culture, representations of black masculinity equate it with brute phallocentrism, woman hating, a pugilistic 'rapist' sexuality, and flagrant disregard for individual rights.' More public figures such as Eddie Murphy, Spike Lee etc blindly exploit the 'commodification of blackness and the concomitant exotification of phallocentric black masculinity.' Murphy's film Raw is one of the most graphic displays of this. Another example could be the following song by the rapper 0 Cent: P.I.M.P I don't know what you heard about meBut a bitch can't get a dollar out of meNo Cadillac, no perms, you can't seeThat I'm a motherfucking P-I-M-PNow shorty, she in the club, she dancing for dollarsShe got a thing for that Gucci, that Fendi, that PradaThat BCBG, Burberry, Dolce and GabanaShe feed them foolish fantasies, they pay her cause they wannaI spit a little G man, and my game got herA hour later, have that ass up in the RamadaThem trick niggas in her ear saying they think about herI got the bitch by the bar trying to get a drink up out herShe like my style, she like my smile, she like the way I talkShe from the country, think she like me cause I'm from New YorkI ain't that nigga trying to holla cause I want some headI'm that nigga trying to holla cause I want some breadI could care less how she perform when she in the bedBitch hit that track, catch a date, and come and pay the kidLook baby this is simple, you can't seeYou fucking with me, you fucking with a P-I-M-PI'm bout my money you see, girl you can holla at meIf you fucking with me, I'm a P-I-M-PNot what you see on TV, no Cadillac, no greasyHead full of hair, bitch I'm a P-I-M-PCome get money with me, if you curious to seehow it feels to be with a P-I-M-PRoll in the Benz with me, you could watch TVFrom the backseat of my V, I'm a P-I-M-PGirl we could pop some champagne and we could have a ball We could toast to the good life, girl we could have it allWe could really splurge girl, and tear up the mallIf ever you needed someone, I'm the one you should callI'll be there to pick you up, if ever you should fallIf you got problems, I can solve'em, they big or they smallThat other nigga you be with ain't bout shitI'm your friend, your father, and confidant, bitchI told you fools before, I stay with the toolsI keep a Benz, some rims, and some jewelsI holla at a hoe til I got a bitch confusedShe got on Payless, me I got on gator shoesI'm shopping for chinchillas, in the summer they cheaperMan this hoe you can have her, when I'm done I ain't gon keep herMan, bitches come and go, every nigga pimpin knowYou saying it's secret, but you ain't gotta keep it on the lowBitch choose with me, I'll have you stripping in the streetPut my other hoes down, you get your ass beatNow Nik my bottom bitch, she always come up with my breadThe last nigga she was with put stitches in her headGet your hoe out of pocket, I'll put a charge on a bitchCause I need TVs and AMGs for the sixHoe make a pimp rich, I ain't paying bitchCatch a date, suck a dick, shit, trickYeah, in Hollywoood they say there's no b 5/82 'ness like show b'nessIn the hood they say, there's no b'ness like hoe b'ness ya knowThey say I talk a lil fast, but if you listen a lil fasterI ain't got to slow down for you to catch up, bitch The idea of the woman being a possession who can be cast aside whenever the need arises is a glaring aspect of this song. The song is all about the 'gangsta' lifestyle mentioned earlier, reflecting the black mans voracious sexual appetite. 'The 'pimp' is a sign that celebrates black male virility in a climate that seeks to emasculate black men. The successes of artists like 0 cent and Chingy are not merely representatives of black youth culture, and popular culture in general. They are signs that embody extreme polarities embedded in our society, poverty and wealth, racial and gender divisions, national and global borders, that converge to make our impoverishment a source of liberation and our liberation a source of impoverishment'. However, these ideas of raw sexuality and physical domination of women, have been present in the music of black musicians for a long time. The soul and blues musicians of the earlier 0 th century narrated 'the playboy role' in their music. This was at that time an alternative male lifestyle. Timothy Brown argues that, music was and still is an escape route for black men. Not just for the musician, but the market towards which it is targeted - the working class, the social class to which most black people belong. The dominant media image of the black male is such - a rebel playboy, overly sexual and hypermasculine. However, this is only a generalization. As Hooks say, not all black men are like this. Societal construction of black masculinity is one which is non conformist. But black men are outside societies masculine ideal because they were excluded from it. The assumption in predominantly white societies is that black masculinity is just a working class masculinity. This though mostly true is another generalization towards black masculinities. In order to challenge such generalized opinions about black masculinity an important issue that has to be looked into is that of homosexuals in the black community. As Janice Cools state, one of the key issues that black gay writers have had to confront in order to attempt to redefine black male masculinity is the negative attitude with which members of their own community view homosexuality. Influential voices of the black community such as Baraka, Frances Cress etc, rather than attempting to understand black homosexuals, place them in a situation where they are isolated and rejected by members of their own community. Black homosexuals are then doubly 'othered', by race and by gender preferences. However, Hooks states that homophobia in black societies is not all that it is made out to be. In fact, citing from her own childhood she says that poverty resulted in the growing importance of a sense of community, and ones identity was not determined by his/her sexuality. However she does say that, whereas gay men were respected as important members of the community, lesbian women were not supported. Some people seem to hold contradictory opinions, such as the man Hook talks about who laughs at homosexuality to fit in with a group, but at the same time cares for his own lesbian sister. The idea that both Cools and Hooks state for homophobia is that homosexuality is spread by the white to segregate the black society. Also religious factors - the Christian church calling homosexuality a sin is another reason that might lead to this. Looking at all these different factors we have to admit that the subject of black masculinity is surely paradoxical. The different experiences that black men experience are surely contradictory. On one hand, black men are among the most impoverished and economically disadvantaged groups in American society, and on the other hand they are the most feared. They stand for heterosexuality on one hand, but at the same time a noticeable number of black men also happen to be homosexuals. Black masculinity therefore truly embodies contradictory experiences, black male being the oppressor and the oppressed.'''",136.0
"'''In the past two decades there has been much discussion about the nature of globalisation -the project of which has had a profound impact on both men and women alike. The strategies which have shaped this process have long been regarded as being capitalist, gender and class bias. This paper is primarily concerned with the interrelationship between gender and globalisation. It will be argued that gender relations provide the base on which the global economy has flourished. Here, emphasis will be placed on the notion that gender has not only been shaped by, but also shapes our global world. Rather than accepting unequal gender relations as an outcome of globalisation, we will show how it is these very relations which characterize its project. In this way, the paper adopts Connell' in which he sees gender as an 'active agent which creates divisions of labour, power and emotions between men and women'. Thus after briefly tracing how concepts of gender and globalisation have been reviewed, the focus of this paper will then to concentrate on examining four main issues. Firstly, in what ways has flexiblisation of the labour force shaped the project of globalisation? We must bear in mind that for many this process does not always support and benefit women. This is true in both the initial implementation as well the final outcome stage. Secondly, how have structural adjustment programmes played a part in this process? Within both of these contexts one must consider the ways in which globalisation and capitalism have resulted in enmeshing women further into patriarchal structures. Thirdly, what has the impact of transnational migration been to globalisation? In this it is crucial to understand how gender identity has shaped these movements. We will evaluate how the nature of domestic labour has provided the base for the new global economy. Lastly are we now in an era of 'global imperialism'? How has gender shaped this terminology? Here emphasis will be placed on the importance of industries such as sex tourism and the increasing popularity of the bride trade. Consequently we will evaluate whether there has been a globalisation from below which has enabled women to resist the forces discussed above? How effective has this movement been? All of this must be well thought out before we can coherently understand the role gender plays in the project of globalisation.: The History of Gender and Globalisation'Globalisation is a process through which economies and regions are integrated into a world capitalist market. With increasing ease of movement of money, technology, information, and the goods across national borders, globalisation is shifting production practices around the gender as a 'series of meaning systems that are socially constructed as sexual differences within the context of systemic male domination'. Hence gender is itself a hierarchical network of social regulations which place 'women on one side and men on the other' (Kreisky and Sauer, 995/8 cited in Young, 001: 4). However that is not to say that these orders are static. The concept of gender is constantly evolving with men and women renegotiating and in most cases struggling over the accepted construction of these lives are characterized by what they have termed to be 'techno-muscular this second service economy as a 'regime of labour intimacy'. They argue that this group is more 'explicitly sexualised, racialized and class based' than the former and furthermore that it 'concentrates on low-wage, low-skilled service provided mostly by females'. Thus from this brief history we can now begin to trace the ways in which the project of globalisation is taking place on a gendered terrain. Gender shaping the global world Globalisation has lead to the blurring of state economic peripheries. We are now in a 'unified global order', a period which has been coupled with 'labour deregulation' and an 'interlinking economy'. These changes have led to a 'free flow of capital, people, goods and services - in which national governments are being displaced by global governance' (Ohmae, 990 cited in Afshar and Barrientos, 999: ). As has been touched upon, it is arguably the exclusive male elite who have reaped the rewards of the new capitalist economy. It is this group alone which has set the agenda and which heads the process of global change. Despite small differences the principle model which can be been applied to most countries, seems to place men in the productive public sector and the concentration of unpaid female labour in the reproductive sector. Hence the patriarchal structure of the male breadwinner and the female caregiver still stands true. That being said, within this patriarchal process we had witnessed a shift to an 'open economy free market approach' (Afshar and Barrientos, 999: ). Within this shift to the importance of the 'renewed surge of feminization of labour activity'. This surge has had mixed effects on both 'first' and 'third' world women, who have become 'increasingly integrated as players in the world's production and consumption process' (Afshar and Barrientos, 999: 0). Following on, quick to point out that this 'feminization' is not a coincidence; the transformation is strongly associated with 'the erosion of labour regulations' - which has on the one hand 'increased women's 'use' as workers', but has also systemically 'weakened their economic and employment security in both industrializing and industrialized countries alike'. This idea of the weakened role of women can be associated with their assumed 'domesticity'. What we are finding today is that more often that not, women's labour is preferred to that of men's. For multinational organisations it is this 'domesticity' which is attractive as it ensures the capitalist economy a guaranteed supply of cheap yet highly efficient is termed the 'reproductive tax' which all societies both in the developed and developing world 'impose upon women as if it is god given'. Thus the economy has been shaped by the idea that women's main labour is the 'labour of love'; anything else which they contribute to the home is seen as additional or extra which supplements the main male breadwinners wage. En this notion and puts forward that 'women workers are treated as if they are being supported at home by a man'. The presumption also tends to be that women are only working to earn 'pin money' - therefore she does not need to paid as if she was a 'serious worker' as she is simply going through a 'phase'. In addition it can be argued that the 'care economy' sustains globalisation as with women's 'free labour, usually without Sundays or holidays off, they are subsidizing a market economy which itself operates according to quite different principles' (Wichterich, 000: 8). Furthermore the global economy is strengthened, nurtured and sustained in two ways. Firstly by the notion of the 'love economy' in which it is deeply rooted and secondly by patriarchal ideas of family and placed emphasis on the global food chain as an example of how gender ideologies have helped shape the flexibilisation of labour. Here they argue that women are a 'marginalised and fragmented workforce, who integration has depended upon and reinforced their dual role in the household'. In a similar way to consider that the 'caring labour' which is assigned to women has led to many global organisations being able to justify that shift work is actually beneficial as it enables women to spend more time working in the home, which is still seen to be their primary concern. Thus patriarchal gender regimes which place women in the private sphere have been central to the increased popularity of flexible labour and the supposed ways in which it is seen to 'help women'. From their comparative study of Chile and the United Kingdom they discovered that women predominately work flexible hours in the United Kingdom so as to incorporate both 'their childcare responsibilities and their husband's it can be put forward that flexible labour is attractive to, and is in turn, shaped by women who seek such jobs because they tend to provide a better alternative that reliance on a father or husband if they are married. Furthermore, for many women being seen to be a 'dutiful' daughter is important; working flexible hours may enable sending part of their wage back to their parents who may be struggling themselves. Certainly En that every woman has multiple roles to play, be it the role of a 'daughter', 'mother' or 'wife' and in many cases all three. With this in mind it can be argued that each role has a stake in shaping the process of globalisation. As she pertinently states, 'the politics of being a daughter, a mother of a wife allow for companies to recruit and control women workers and win the consumer loyalty of women buyers' (En Loe, 989: 40). From this we can therefore assume that the 'dual' or indeed 'triple' roles of women provide the base on which the international global economy today depends. Gender and Structural Adjustment PoliciesWith the above in mind it now becomes necessary to conceptualise how structural adjustment programmes have themselves been shaped by gender and the effects of these programmes on women. that such policies have tended to be viewed by many developing countries as the 'only solution to economic crisis' and furthermore 'as the only path to economic growth'. According to the International Monetary Fund the World bank they are designed to, 'balance budgets and increase competitiveness through trade and price liberalization, increase encouragement of foreign investment as well as upping the production of goods and services for export through the flexible labour process' (Moghadam, 999: 69). These programmes have been controversial; it is debatable whether this 'shopping list' of aims and objectives can readily be applied to many economies of the developing world. Feminist literature on structural adjustment policies has been particularly damming. It has charged such programmes with 'carrying out its objectives on the backs of the poor and especially on poor women' (Moghadam, 999: 70). Indeed this seems to be the case; in order for these programmes to be effective, more often than not, it is women who have had to take on extra productive and reproductive responsibilities. Thus the final outcome tends to be 'an increased demand on women's already overstretched time' which is coupled with 'adverse effects on their nutrition and health' (Commonwealth Secretariat, 989 cited in Elson, 994: 5/80). So why have programmes which clearly disadvantage women been introduced in many developing countries? How have stereotypical gender ideologies played a role in shaping this process? Both of these are newsworthy questions which many feminist writers have come some way to answering. Much like flexible female labour, structural adjustment programmes are moulded by the notion that women, as caregivers, are able to assume extra responsibility as it is seen as within the boundaries of their 'natural role'. to this by arguing that the social aspects of gender which have shaped and defined these programmes, have inevitably led to bias against women. In other words, they have been 'distorted by gender divisions in roles and codes of behaviour'. on to make the links between 'biology' and 'culture' as a way of explaining this idea. She points to the fact that women are obliged by a male dominated society to 'supply a replacement of labour free of charge'. Furthermore it can be argued that traditional gender ideologies which emphasise the 'nimble fingers' of women are pivotal in shaping structural adjustment policies. Through these structures women are perceived to have the capacity to deal with large amounts of work, and in addition will assume this extra responsibility without that such policies are unfair as they place women in the position of having to choose how much time they 'wish to spend on childcare' and how much they are feasibly 'able to spend on childcare'. As females are unlikely to view their child as 'just another crop' its places an 'unjust emotional burden' on their already 'fragmented identities'. Again support can be found in En Loe's belief that globalisation is shaped by the multiple roles of 'wife', 'mother' and 'daughter'. Thus the process and project of structural adjustment policies are perpetuated by the natural assumption that regardless of the role a 'women's time can extend infinitely' (Elson, 992 cited in Afshar and Barrientos, 999: ). Transnational care workSo having evaluated how gender has shaped the labour market and structural polices, attention can be turned to another way in which gender moulds globalisation; through migration and the domestic service industry. According to En is as much about 'ideology' as it is 'physical movement'. She characterizes it as a 'package' which contains notions of a capitalist life. In this way, we can argue that migration is shaped by the gendered assumption of what is 'women's work' and what is 'men's work'. If for example a European woman decides to go back to full time employment after having two children, she may have to hire a nanny to take on the domestic responsibilities which she can no longer fulfil. Her responsibilities then shift and become those of another, who more often than not, is a migrant woman who in turn has left her domestic duties to a female relative in her home country. This proves an apt example of what many academics have termed the 'buyer driven commodity chain' of globalisation in which need from the top, or in other words 'the requirements of the western women characterize and sustain the demand of paid care labour' (Yeates, 004:82). Thus through this process the European woman is playing her part in sustaining and furthering globalisation. The issue now becomes, why do western women have to make such a choice? For many feminist writers this 'choice' does not actually exist. Women are 'compelled' to hire help due to constraints of gender structures. There is no doubt that globalization has been kinder to some women, many of whom are making significant inroads into traditionally male dominated positions. However this comes with the added burden of adopting 'male characteristics' which are necessary to ensure their success. We are now in an era characterized by 'having it all' and for women in particular of 'doing it all'. The successful career women must contend with a 'dual burden' which includes both her work responsibilities as well as the importance of her role as a wife and state, 'by migrating a woman may escape the expectation that she has to care for an elderly family member, has to relinquish her paycheck to a husband or father, or defer to an abusive husband'. With this in mind it can be argued that for some third world women emigration can be regarded as a practical response to the pressures of a male dominated society. Furthermore it is interesting that many governments actually encourage women to migrate in search of western work. Their reasoning seems to be along the lines that women are more likely than men to send their earnings back to their 'children, parents, siblings, and wider networks of kin - and this has a significant impact on the cash strapped third world governments' (Ehrenreich and Hochschild, 002: ). Women are 'reminded' through government action, family words and media reporting that their 'primary role' should be that of a 'caregiver'. An example from a Filipino magazine article fittingly highlights this: 'Through your good works in those places where you are temporarily working you will become instruments on the economic improvement or progress of your 'sick' nation through the dollars you send back home' (Layosa 'Into Thy Hands' Filipino, 994 cited in Chang and Ling, 000: 9). The argument bring into focus what can be considered the most problematic aspect of globalisation; the fact that it is reinforced and shaped by the 'dual roles' of women, which at the same time enable men to continue steering clear of the second shift. Indeed called for the 'restructuring of gender relations at the household level' as a 'necessity' if we are to ever see a change to the project and process of globalization. Global Imperialism Whilst all the issues which have been discussed can be characterized as fairly new global concerns, some academics have argued that the concept of 'globalisation' is actually rooted in old world 'colonialism'. to this as the 'rhetoric of empire'. By this he means that the 'western colonial enterprise' may have originated from the 'sixteenth century but it lasts to the present'. In a similar way, Ehrenreich and that globalization is just the latter phase of imperialism. 'Northern countries extracted nature resources such as rubber, metals and sugar from colonized lands - today they also seek to extract something else - love'. Whilst this is of course an oversimplification it does raise some interesting thoughts. Through these ideas, it can argued that gender is shaping the project of 'global imperialism' and this is surfacing more and more in industries such as sex tourism and the bride trade. Mezzadra has controversially argued that the increasing numbers of western women in the global market has created a need for men to seek pleasure abroad which in turn has shaped globalisation. These beliefs find support in the literature of Ehrenreich and consider that 'immigrant women seem desirable sexual partners for the same reason that first world employers believe them to be especially gifted as caregivers: they are thought to embody the traditional feminine qualities of nurturance, docility, and eagerness to please'. With these thoughts in mind it does not seem unfair to argue that women cannot win. In order for western females to compete and succeed in the global economy many have to shed their femininity in favour of masculinity; they have to assimilate into male work culture in order to be 'seen' to be serious about their jobs. However at the same time, this creates a nostalgic notion among men, who crave women with traditional feminine values. From this it can be argued that foreign women are not only providing a 'sex service' but arguably the 'service of being a 'good wife' (Mezzadra, 005/8: ). Indeed a flourishing sector in the global world seems to be centred on transnational marriage agencies. As has been reviewed, with the increased 'masculine' identities of western women there has been a growth in male demand of 'patriarchal normalization of gender roles'. Furthermore it is this gender shift which has shaped the new global movement. Organisation offering 'old fashioned women for whom their husband and family comes first' are rising in on the importance of a ceremony initiated where the women tied a thread around their brother's wrists which symbolized their love; 'feminine ways' were played upon to shame the men into stopping the destruction of the environment. Indeed as states, 'the Chipko movement developed out of these women's acceptance of the division of labour by sex in their culture'. What this demonstrates is that gender ideologies when used by women can shape the project of globalisation is a positive way. Whilst of course the success of this movement may be difficult to replicate elsewhere it does highlight the power that women can have as a collective. By accepting traditional stereotypes such as the 'loving' and 'dutiful' sister, who for example, ties a band of love around her brothers wrists or the 'courageous' mother, who would risk injuring herself in order to save the trees so her child will have a better life, women are 'playing' on their femininity in a way that men have been doing for generations. In 'assuming responsibility for which they had been socialized' (Kaplan, 001: 4) women managed to humiliate their own husbands and authorities as then these men were not fulfilling their 'traditional' role, which is of course to 'protect' their women. Therefore the main message which should be taken from the 'Chipko' movement should be this; women can shape globalisation to enhance a common good by uniting as a collective and if need be by playing on their femininity. ConclusionThe paper has aimed to investigate the proposition that gender is central to the project of globalisation. It has becomes clear that globalisation is in fact not only shaped by, but is also sustained by gender. Based on the discussion above it would not be unfair to argue that the global culture in which we now live our lives depends on the unpaid labour of women to survive. Certainly global processes are shaped and defined by actors even in ways which may be hard to measure. Thus women's work needs to be seen as global process in its own right. There is now a growing awareness among academics that gender structures do indeed influence the direction of global production in a similar way to the more dominant global actors, i.e. white male elites. In this is important that we appreciate how both the 'productive' and 'reproductive' roles of women shape the process of globalisation. Furthermore it must be remembered that globalisation itself can be progressive as it can be destructive. Women can unite and use their gender to their advantage, and it doing so shape the global economy in a way which is beneficial to them. However it must be recognised that these advancements can be lost through the very patriarchal structures on which globalisation is founded. If we are to truly change the project of globalisation we must start at the root of the problem; the gender ideologies which manifest in the private sphere. Here is where the problems of gender begin and it is these same notions which eventually find their way into the public global arena. Arguably the key to altering the process of globalisation lies in changing the gendered structures which assign women the bulk of unpaid work, on top of any paid work, as if it was natural law. In order to achieve this solidarity among women must be encouraged. This can be facilitated through services offered by women's groups and non-government organisations that now operate within and across national and state boundaries. Indeed the irony is that these very services are themselves a result of the new global economy which has encouraged 'making the world a smaller place'. Thus, with this in mind it is hoped that with time some inroads may be made into the patriarchal capitalist world and that these roads will then connect women to stand as a collective against the inequalities of globalisation.'''",139.0
"'''Wilmot's 'Upon his Leaving his Mistress' and Armitage's '' seemingly both portray differing viewpoints with regard to relationships and love and the various implications of these notions. Indeed, at times similar linguistic devices are employed by the poets, yet they are utilised in different ways in order to create rather quite unique effects. Armitage's poem takes the form of a sonnet, which is immediately indicative of love, yet the way in which the poem is written is certainly far from the traditional sonnets of Shakespeare and such like, and lacks the romantic aspect of the traditional verse. Instead, Armitage's poem is rife with colloquial language at its simplicity from the very beginning with 'I am very bothered when I think', not to mention several monosyllabic and polysyllabic words as opposed to the longer more extravagant expressions which one would expect to find in a sonnet. The only deviation from the simplicity of Armitage's language is in line eight, where he declares: 'O the unrivalled stench of branded skin;' his use of hyperbole creates a stark contrast with the clear-cut diction of the rest of the poem, however it could be interpreted as sarcasm, as in fact, so could the first line. In effect, Armitage's general divergence from the conventional form emulates the atypical way in which he sought to win the affection of the girl he was in love with at the tender age of thirteen; this coupled with the simple language mimics the inability of a child at this age to display their affections appropriately as well as dealing with such emotions. After all, it is symptomatic of a child to often be nasty to someone that they admire. On the other hand, Wilmot's poem incorporates a regular rhyme scheme, iambic tetrameter and masculine rhyme. Effectively, the use of these poetical features makes Wilmot's poem more regular in the traditional sense, yet like Armitage, his subject matter isn't necessarily reflective of the general consensus nor traditional. Seemingly, Wilmot is an exponent of the debauched lifestyle with regard to relationships, demonstrated firstly by the clear distinction he makes between himself and his mistress, ''Tis not that I'm weary grown/ Of being yours, and yours alone/But with what Face can I incline/ To damn you to be only mine? Wilmot's gulf between himself and his mistress reveals a lack of commitment; in addition, he seems to make a further distinction between his mistress and other women, deeming them 'meaner spirits of your sex.' His somewhat mocking reference towards 'meaner spirits of your sex'- which is enhanced through the alliteration of the 's' consonant - serves to validate Wilmot's view that it is better to enjoy oneself rather than seek fidelity within a relationship. This mockery of women who are not adulterous, who instead of 'dispensing favours' remain loyal is further reiterated by the sarcastic way in which Wilmot utters how they 'Contrive to make one happy Man.' The italicisation of 'one' coupled with the above illustrates quite clearly how Wilmot looks down upon committed relationships and is perhaps an advocate of free love. Again, as with Armitage, Wilmot's poem reflects an air of sarcasm thus making them similar in this respect. Armitage, as already mentioned, keeps the language in his poem simple and diverges from the use of elaborate diction; in fact, he uses no similes or metaphors, but instead seems to rely upon tapping into the reader's senses, through the use of tactile, visual and auditory imagery. For example, the visual imagery of 'the naked flame of the Bunsen burner' perhaps evokes feelings of fear due to the fact that the flame is 'naked' and therefore untamed and potentially dangerous. On a different note, 'flame' could be a reference to his love for the girl and the way in which it burns brightly; when considered within a lexical set consisting of 'flame,' 'branded,' 'rings,' 'eternity,' and 'marry me,' this becomes more evident and although Armitage's poem isn't necessarily conventional, inadvertently, his commitment is unmistakable through his reference to nouns and adjectives that suggest infinity. It is here that we see a clear distinction between the commitment evident in Armitage's poem - albeit demonstrated in a peculiar fashion - and the lack of commitment expressed in Wilmot's poem. Furthermore, tactile imagery such as the image of her slipping her 'thumb and middle finger in' and 'branded skin' are again quite powerful, as well as the auditory imagery of calling upon her name. Armitage's sensory imagery seems to replace any complex poetic language and is effective due to the fact that it is in keeping with the simplicity of the poem as a whole. Armitage's simplicity couldn't be further from Wilmot's perhaps superfluous diction; however this isn't to suggest that Wilmot's poem is a normal love poem at all. His references to 'Joy,' 'happy' and 'willing' demonstrate a hedonistic facet, thus reflecting the subject matter of the poem, that being that one should not 'be confin'd' and as already mentioned, advocates a sense of free love; the juxtaposition of fidelity and Wilmot's opinion of the merits of infidelity further reiterates this. As already mentioned, Wilmot's poem benefits from an identifiable structure, incorporating rhyme and thus rhythm; effectively this gives the poem an air of jauntiness which is parallel to the approach Wilmot seems to be taking with regard to love and sex, where one should not be confined and restricted but free and hedonistic. The lines of each stanza are insured to follow the tetrameter of the poem given that Wilmot uses elision to shorten longer words, such as 'em'all.' This is somewhat similar to Armitage's colloquial language, yet unlike Armitage, the majority of Wilmot's poem consists of more opulent language on the whole. Unlike Armitage, Wilmot does use more linguistic devices, such as the personification of the Earth's 'willing Womb,' which also incorporates alliteration. Furthermore, Wilmot uses simile to describe the 'Favours, like Nature' that the Mistress bestows. Again, this echoes the idea of liberated love due to the reference to nature and the connotations that such an allusion would evoke. In fact, this image of nature is extended due to the lexical cluster relating to the 'Seed-receiving Earth,' 'Grain,' 'Show'rs,' 'Womb, and 'Mankind.' All of these references are natural, especially the Earth, seeds and grain; this simply serves to further reiterate the notion of free and liberated love for the pleasure of mankind, and how Wilmot sees it as natural. Although both Armitage and Wilmot share similarities, a comparison of their poems seems to serve the purpose of intensifying the effects of the other and makes evident the lucid difference between their views. In fact, the ending of both poems bears witness to this. The finality of Wilmot's last few lines comes to a clear conclusion in that his mistress should be the 'Mistress of Mankind,' in answer to his own question; Armitage on the other hand creates a slightly ambiguous ending where we are unsure whether he wants to be believed or not as he revisits the possible idea of sarcasm already witnessed earlier in his poem.'''",141.0
"'''Today, some consider that 'there is no such thing as 'Greek religion''. In 'On making sense of Greek religion' John Gould disputes the notion that we can simply 'make sense' of the evidence left- 'data which we put together and call 'Greek religion': the best we can hope for will be no more than piecemeal explanations of a particular ritual or a particular myth' We have only a fragmented picture of ancient Greek religious practices from the evidence of art and descriptive texts. We have an even less precise idea of the reasoning behind Greek rituals- religious belief, as with other aspects of ancient cultures, leaves little physical evidence remaining. We do know that much of Greek religion was secretive and an enigma to the uninitiated even at the time, with widespread secret cults and 'mysteries'. It is also difficult to come to conclusions on 'Greek religion', as the area we now call Greece wasn't a unified country until long after the th century BC, rather an area of land on which separate city states co-existed. Although it seems there were beliefs commonly held across Greece, we can't assume there was religious uniformity. To compound this, unlike religions more familiar to us, there was a lack of Greek scripture or an 'organised body' to dictate standard practice. Greek religion was 'an open, not a closed system', with potential for individual interpretation. Easterling, Muir p1- Easterling, Muir p7 Easterling, Muir p9 So it seems that the answer to the question 'Why did the Greeks perform sacrifice?' is unlikely to be simple. This essay will trace the emergence of Greek sacrifice from prehistoric times to the th century BC. By examining and interpreting the evidence for sacrifice in ancient Greece, I hope to conjecture a few of the beliefs behind this ritual activity. The ideas behind sacrifice can be traced back to prehistoric Greece. By the Palaeolithic period, or even prior to it, mainland Greece was populated by nomads from central Asia, who lived in hunter gatherer societies. These Indo-Europeans brought religious ideas that would endure to the Classical period. Burket has put forth the idea that later ritual sacrifice was rooted in this early 'condition of man the hunter', when hunting and killing an animal was a spiritual, primal experience. It also seems that these nomads placed religious significance on the sky, the only constant aspect of their landscape. This seems a likely origin of the later belief that the gods dwelt high on Mount Olympus. Etymological links abound too; the word 'Zeus' has its roots in the Old Indic word 'devah', with the names of other Olympians such as Hera, Ares and Poseidon 'formed form Indo European roots'. Burket, p10 Zaidman, Pantel, p29 Burket, p17 By the Neolithic period, the early Greeks began to form settled farming communities, again influenced by the East, where farming was first discovered. None of the domesticated animals and 'grains, barley and wheat' required for this development were native to Greece. Perhaps it was at this stage that Greece's preoccupation with nature and fertility, seen in its art and mythology, emerged. Now the Greeks could cultivate food and manipulate nature- yet the success of this was somewhat out of their control. A good harvest relied on favourable weather conditions, natural forces they didn't understand. When their farming efforts failed, they must have questioned the cause of their misfortunes, wondered what had such control over them. The natural assumption to make was that a higher power was dictating matters. How then to have some control of their own lives? Burkert explains that, Burkert, p10 'In distress and danger man seeks to find deliverance through a voluntary act of renunciation. He seeks to master the uncertainties of the future by means of a self imposed 'if-then''. Burkert, p68- If efforts were made to appease forces with power over them, the Greeks could hope to keep the gods benevolent rather than vengeful. We must remember that in contrast to our modern view of deities as distant forces, to the Greeks, the gods had a direct influence over everyday life. Right up to the Classical period they had potential for great good or harm, to raise pious, worthy mortals up as demi-gods way of transmission to the deity. Bremmer, p2 Burkert, p66 According to Plato, 'Socrates as 'knowledge of sacrificing and praying' and sacrificing as 'making gifts to the gods''. To achieve the social norm of piety and avoid personal disaster, sacrifices were essential. Burkert, p66 Although many sacrifices involved the death of a victim, (see below) there were other ways the Greeks made sacrificial gifts to the gods. 'A more lasting testimony than a sacrifice' when appealing to or thanking the gods was the dedication of a votive offering, such as a statue. Girls coming of age gave their childhood toys to sanctuaries, and craftsmen dedicated 'the tools of their trade' on retirement. Libations often occurred alongside sacrifices, while still significant in their own right. Bremmer, p33 Burkert, p70 The most dramatic sacrifices were those that involved the ritual killing of a victim. The type of victim was specific to the deity concerned, with major Olympians receiving the 'most noble sacrificial animal', the bull, and lesser gods other common domesticated animals such as goats and sheep, although birds and fish were also used. The bull's religious significance can be traced back to its appearances in Minoan and Mycenaean art. At Knossos wall frescoes depicted bull leaping, and the 'horns of consecration' iconography is common in Cretan architecture. The bull was of some unknown significance to these Greeks, a significance that endured in a different form to the Classical period. Burkert, p5/85/8 Descriptions of sacrifice indicate a great wish to please the gods. The animal received by the deity must be a 'perfect' specimen- anything less would be an insult or harbinger of doom. Docile animals were preferred, as a struggling victim was a bad omen. Much ceremony was involved in sacrifices, presumably to show the proper degree of respect to the gods. Victims were garlanded, even gilded with gold, and led to the temple's altar in a procession, accompanied by music, as depicted on the Parthenon frieze of the Panathenaic festival. Their throats were slit at the altar, the blood sprayed over the altar, the body then dismembered. Internal organs and thigh bones wrapped in placed on a fire to be burnt for the god, other edible parts eaten at the customary feast, as significant a part of the ritual as the actual killing. Burkert, p5/86 Burkert, p5/86- However, there is some suggestion that by the th century BC, sacrificial feasts had become more occasions for indulgence than holy rites. In Menander's comedy, 'Dyskolos', a character attacks the 'scoundrels' who place on the fire 'the tail bone and bile, because they are inedible.then gulp down all the rest'. Perhaps by this period, some did view sacrifice as a social event. However, we must bear in mind that the above evidence is from a comic play, and may not be intended to be taken literally. Rice, Stambaugh, p109 In some instances the animal was not in fact eaten, but entirely burnt, a 'holocaust' in which the whole of the offering was transmitted to the god. Pausinias states that '.among the ancients custom ordained in regard to sacrifices that the victim on which an oath was made was not to be eaten by any man' This tells us that sacrifices were in fact taken seriously, used to seal important oaths, and that tradition was a major factors in shaping the religious practices in Greece. Its rituals, including sacrifice, were dictated by what had gone before. Indeed, when examining depictions of sacrifice from centuries prior to the Classical period, we see that 'almost all the elements of the later Greek sacrificial ritual seem already present.' The Ayia Triada coffin, dated around 45/80-400 BC, has painted on one side a bull sacrifice just the same as that in th century Athenian ceremonies, with 'only the fire on the altar missing' Zaidman,, Pantel, p37 Rice, Stambaugh, p113 Burkert, p36) URL Burkert, p36 An important function of sacrifice was providing entrails to soothsay by. This is said to have helped Xenophon make decisions during his military campaigns in the th century BC; '.since he could not decide he thought it best to consult the gods. Xenophon offered sacrifice and the god signified clearly that he should not seek the command, not accept it if he were selected. And so the matter ended.' Rice, Stambaugh, p111 Just as the early Greeks sought to make sense of their world, those from the Classical age still tried to read signs from the gods. 'Divinity, it seems, speaks to man, but in a language that he cannot understand'; sacrifices were one way the Greeks attempted to understand this language. Easterling, Muir p22 For grand festivities, or issues of supreme importance, it was believed that a great gift was required for the gods. In the case of the Athenian Great Panathenaia, a great festival in Athene's honour, over 00 'sheep and cows are slaughtered at the great altar'. Burkert, p232 However, in Greek mythology and literature, sometimes matters of dire importance required human sacrifices. In Euripides' 'Iphigeniea at Aulis', the Greeks were prevented from sailing for the Trojan war until Iphigeniea, Agamemnon's own daughter was sacrificed. There is also evidence for actual human sacrifice in Greek prehistory. Several hundred administrative clay with the language Linear B have been found at Pylos. One tablet is conspicuously messy, and appears hastily written, perhaps at a time of crisis such as an attack on Pylos. It records gifts for Olympian deities, 'gold vessels and men and women'. An unknown word in the text is suspected to mean 'victims'- it seems possible that human sacrifices were made to the gods by the people of Pylos during a disaster. Disturbingly, physical evidence has also been found at Knossos; 'a deposit of children's bones with clear knife marks'. Burkert, p43 Burkert, p37 Sacrifice was an integral aspect of Greek religious festivals, the Thesmophoria especially so. The 'most widespread Greek festival', Burkert describes it as the 'principal form of the Demeter cult', the central aspect of which appears to have been sacrifice of piglets. Demeter was the goddess of fertility and 'closely associated with crops'. She is now widely believed to be a form of the 'earth mother' figure from Greek Prehistory, who had power over fertility, the suffix 'meter' meaning 'mother' Demeter was honoured widely by women, to ensure their personal fertility and that of the city's crops. Mackenzie states that it was mainly 'as a provider of the food-supply that Demeter was addressed.' Burkert, p242 Mackenzie, p175/8 Mackenzie, p175/8 Mackenzie, p176 At Athens the Thesmophoria was conducted near the Pnyx, at the top of a hill. Women alone were allowed in the area for the three day period of the festival. While separated from their husbands and families, the wives of mysterious rituals, including the sacrifice of piglets. In the myth of Demeter, which appears to have influenced much of the Thesmophoria's ceremony, her daughter Kore was abducted to the underworld by Hades. Demeter's misery halted the growth of crops and brought starvation to Greece. Only when Kore was returned to earth for half the year was the land's fertility restored. To the Greeks, Demeter was a powerful goddess with control, ultimately, over life and death, and needed to be treated as such. The principal of 'First Fruits' still stood; 'She was asked for gifts of cattle and corn and fruit, and bulls and cows were sacrificed to her' Mackenzie, p176 Bremmer has stated that only gods considered 'impure' and on the 'margin of social order' were given pig sacrifices, as pigs were considered cheap animals. However, Burkert notes that when Kore was taken into the earth, 'the pigs of the swineherd Euboluleus were swallowed up as well'. It seems more likely in this case that the sacrifice of pigs at the Thesmophoria was not a reflection on the perceived importance or purity of Demeter, rather an aspect of the original myth incorporated into the th century festival. It was also usual for pigs to be sacrificed to gods associated with the earth, of which Demeter was one. Bremmer, p40- Burkert, p243 Mackenzie, p176 Some features of the Thesmophoria suggest that participants were re-enacting other such aspects and themes of the myth. On the second day, the women would mourn as Demeter had, fasting and living in 'a primitive state' before feasting. A contemporary account in Burkert's book describes the sacrificed pigs or piglets being thrown down into a cave, and then brought back to the surface again, as Kore was. The decayed remains were then honoured at altars, perhaps signifying rebirth and the return of the crops. Burkert's source claims it was believed that '.whoever takes of scatters it with seed on the ground will have a good harvest'. Burkert, p244 Burkert, p243 Although festivals were special periods during which normal standards of living were suspended, the continued performance of activities at certain times of year created a sense of stability. In some cases these seasonal sacrifices, processions and rites had persisted since the Stone Age. Burkert, p13 According to J. Gould, making offerings to the gods was 'the central ritual of Greek Religion. and its most characteristic form animal sacrifice.' Though overall the evidence is patchy, we can state that the Greeks believed in a number of all-powerful deities that were potentially harmful to them. Repetitive honouring of the gods via offerings and sacrifice was intended to influence their own circumstances, and avoid misfortunes interpreted as divine anger. Certain significant aspects of sacrifices derived from prehistoric ideas, such as the perceived nobility of bulls as victims. Sacrifices were closely connected with the old themes of nature and fertility, as shown by the Thesmophoria. Bremmer points out that Greek religion was an embedded aspect of society, rather than an entity separate from the concerns of state as it is largely today. Sacrifices were not only one's religious duty, but part of Greek culture, and had been for centuries. So another significant reason for Greek's sacrificing was that Greeks before them had. Ancient Greek religion was 'a system of explanation and response', and though to us sacrifice seems a strange response to the world, it appears to have made perfect sense to the Greeks. Easterling, Muir p16 Bremmer, p2 Easterling, Muir p14 '''",149.0
"'''This essay argues on the ambiguity of the realist critique towards liberal internationalism. The working definition of liberal internationalism used here is more inclusive, referring to the so-called 'utopians' virulently criticized by E.H. Carr. The paper attempts to reveal that the core liberal assumption according to which ideas and morality matter in building an international society, has not been 'demolished' but rather capriciously 'borrowed' by realist thinkers like Carr. The arguments of this paper follow the core liberal creed that ideas and moral visions can influence politics. Moreover, the idea of harmony of interests has not been assumed by all idealists and deserves a more careful examination since it may not necessarily conceal vested interests. The paper concludes that the subtle fact of realists 'borrowing' core liberal assumptions renders their critique a rather ambiguous than a sound one. Carr mentioning of the need for utopia makes us think about the inevitability of consensus. Realism offers a simplistic account of how international relations should be shaped, which in the end is faced with the need of leaving room for normative thinking. Ideas do matter even for realists and eventually the 'planes' will meet. Do states have common interests? To what extent can states have moral visions about how world politics should look like? Is cooperation possible? Is there any possibility to abolish war? These are the underlying questions, which have shaped the First Debate of International Relations, a debate between realism and liberalism, which is generally said to have been won by the realist team. However, many of today's liberal ideas and practices in world politics have origins in the first writings of liberal internationalists such as the Enlightenment philosophy of Immanuel Kant with its ideal of creating a democratic and thus peaceful world order. While liberals like Adam Smith or Richard Cobden were supporters of the belief that free trade and laissez-faire lead to global welfare and hence to peace, Kant considers that peace need more than commerce. Republican constitutions and pacific federation of states are the key elements for a 'perpetual peace'. Furthermore, the demise of communism in 989 has strengthened liberal internationalism as an influential theoretical tradition. That moment is said to confirm the concept of history as linear, progressive and perfectible, and prove a general preference for democracy, free trade and collective security. Fukuyama's celebration of the 'end of history' regarded liberal democracy as an ideology without competitors and as a promise for the growing core of pacific states. The language of free trade, comparative advantage theory, and efficiency seems to have triumphed. Clear indicators of the growing influence of liberal internationalism in world politics exist: briefly, we witness a proliferation of free trade agreements worldwide and an increasing weight of international multilateral political organizations. Consequently, liberal internationalism 'deserves serious investigation and intellectual engagement'. The present paper will argue on the ambiguity of the realist critique of liberal internationalism, pointing out to the ceaseless relevance of liberal ideas. It attempts to reveal that the core liberal assumption according to which ideas and morality matter in building an international not been 'demolished' but rather capriciously 'borrowed' by realist thinkers like Carr. The paper will use the phrase world politics instead of international relations because the former is more inclusive and refers not only to the relations between also to relations that transcend the that war is a tool for autocratic and unrepresentative leaders, and a reflection of the pernicious ideology of balance of power. Education in the spirit of democracy and the belief in the perfectibility of human nature can avoid and eventually eliminate the likelihood of conflicts. The prospects for international cooperation are genuine if we believe in the possibility of institutions and international law to promote and preserve it. There is no reasonable desire to wage wars since the costs are higher than the benefits. Having this belief in mind, during the 920s the liberal architects have envisaged the League of Nations and the Briand-Kellogg Pact, trying to dismiss war as a justified instrument of foreign policy and to promote and maintain peace among nations. On the other hand, realists believed that conflicts are endemic because they reflect a fixed human nature characterized by constant desire for power. Even the ancient Gyges' myth told by sophists reveals that men would always commit wrongdoing and immoral acts if there were no prospects for punishment. We would all use a ring that can make us invisible in order to steal, cheat or kill. Starting with Thucydides, Thomas Hobbes, Nicollo Machiavelli, realism has upheld the idea that what characterizes relations among people as well as among sovereign states is an eternal struggle for power and a selfish competition for glory and material gains in a world of scarce resources. what characterizes international politics and it can only be managed by balancing the power between states. Hence, Carr's critique towards utopians' wishful thinking mentioned the danger of using preferences and desires in shaping international politics. Plato. The Republic of Plato, translation by Allan, realism is liable to assume a critical and somewhat cynical aspect. (.) It tends to depreciate the role of purpose and to maintain, explicitly or implicitly, that the function of thinking is to study a sequence of events, which it is powerless to influence, or alter.E.H. Carr. The Twenty Years' sound political thought must be based on elements of both utopia and reality. (.) Pure realism can offer nothing but a naked struggle for power, which makes any kind of international society impossible. Having demolished the current utopia with the weapons of realism, we still need to build a new utopia of our own Carr. The Twenty Years' Crisis, p. 7 What are the implications of his statements? Carr speaks about complete realists and complete utopians, admitting the sterility of a complete realist outlook but without offering a concrete alternative to the so-called utopians. Consequently, 'It is rather curious that Carr remains celebrated for his staunch realist critique of idealism'. One can say that the degeneration of realism started with Carr. As Legro and Moravcsik pointed out '(.) Carr and Morgenthau themselves denied that any argument they advanced was ipso facto realist', because for instance, Morgenthau also thinks about the role of domestic politics, ideas and institutions. The authors came to the conclusion that the diluted core assumptions of it an incoherent theory. One can say that the ambiguity of the realist stance has somehow been consolidated by the later development of neo-liberal neo-realism and neo-liberal institutionalism). As Keohane would say, ideas have always shaped agenda and hence outcomes. In this respect, he offers the example of China where Soviet ideas and not Soviet power has influenced economic policies or the event of de-colonization, which did not reflect a lack of power but rather a will and desire for change. Stefano Guzzini. Realism in International Relations and International Political Economy: the Continuing Story of a Death can neither be inaugurated nor secured without a general agreement between the nations; thus a particular kind of league, which we will call a pacific federation is required.' More than a static situation, the harmony of interests is a natural subscription of rational individuals and of democratic states to a set of universal moral norms which can settle disputes and maintain peace. Consequently, a harmony of interests may not necessarily conceal vested interests as Carr suggested, since there are universally human as life, liberty, the pursuit of happiness, and peace to which any rational person would subscribe. Such universal values can be peacefully promoted at the international level so as to become the basis for cooperation and partnership among nations. In addition, liberal internationalists just as realists hinted to the idea of an anarchic international system because of the lack of a central government or authority to regulate states' conduct and mediate their disputes. As Osiander explains, idealists like Norman Angell, Leonard Woolf or Alfred Zimmern display certain 'realist' ideas that ask for a revised understanding of idealism. Immanuel Kant. Political Writings, Hans may actually be beneficial for them as well as for other states. This can be explained through the limited definition given by Morgenthau to international politics, as a 'continuing effort to maintain or increase the power of one's nation and to keep in check or reduce the power of other nations.' Osiander. 'Rereading Early Twentieth-Century IR Theory: Idealism Revisited', p. 23. Hans, Morgenthau. Politics Among Nations (New York: Alfred A Knopf, th ed, 973), p. 31. In conclusion, the idealist tendencies found in Carr's writings are a proof for the limits of realism as a static and simplistic bias on the ways international relations ought to be shaped. Carr mentioning of the need for utopia makes us think about the inevitability of consensus. Not only that realism displays normative thinking (the claim of objectivity can be easily rejected because realism makes enough value-judgements about human nature that cannot possibly be neutral), but it is also confronted with the inevitable exigency of finding a way out from the deadlock by adopting an idealist stance. There are no winners of the First Debate in International Relations. Contrary to Carr's prediction, the plane of realism will always meet the plane of liberals and the debate should always remain open.'''",154.0
"'''The question of whether or not there is a general factor in intelligence, or g, has been a massive debate in psychology and the answer has important implications for society and psychology. described g after finding several different mental abilities were positively correlated, and inferred from this that there was some underlying general factor that was influencing different abilities. This theory has been taken and developed in various ways by different psychologists over the past 00 years, but this approach has not been without it's dissenters, and there has been significant opposition, for example by Gardner's claim of multiple intelligences. Rather than being dismissed, these detractors should be answered, and unfortunately this has not always happened in this debate. The case for a theory of general intelligence can be supported by research and theories from many areas of psychology. Firstly, there is the evidence from psychometric testing, and basic level cognitive task studies such as reaction time. Then there is mounting evidence from biological psychology, with suggestions of brain structures that might be the biological basis of g. Research in the 'real world' has also found evidence for the predictive power of g as a determinant of success in diverse contexts. Finally there is even support, recently, from evolutionary psychology. This essay will take each of these in turn to construct a case for g. The positive manifold that is one of the most repeated findings in specialising in the study of of one general factor and then many specific factors, the data suggests that there are also group factors, linking in for instance verbal abilities together as they inter-correlate even more than the other factors found a correlation of.1 between frontal lobe volume and our real lives. Thankfully there is a lot of evidence that general intelligence predicts not only academic but also occupational, social and economic that on the Wason selection task there were great individual differences in performances when the problem was in an abstract context, as it then relies on g. However when the same task was changed logically so that it became one of finding social cheaters, everyone became good at it and there were very little differences between individuals, because, the theory goes, our ancestors had to be good at identifying social cheaters. There is support for the theory of general intelligence from varied perspectives, but it does have its weaknesses. The psychometric data that it is based on can be said to be narrow in scope, as the tests are typically done in a: situation, so that very few tests can be measuring the ability to cooperate and work with others to find a solution to a problem. This results in a limited view of intelligence that fails to consider distributed intelligence, which could be damage its ecological validity, as in practice most of the time we do have other people and resources to call on for help - however perhaps this is purposeful - it could be only trying to explain intelligence at an individual level. In Chabris' overview of cognitive and neurobiological measures, he concludes that there is a wide range of variables from brain size to reaction time that correlate with IQ from. to. This is at once a weakness and a strength of the general intelligence model, because while it means it is hard to pin down g, it also makes the model irresistible as it is impossible to ignore all these signs saying that it is not a product of the mode of testing or any cultural artifact, rather g is real and it exists with a biological basis in our heads. Kanazawa's explanation of the evolutionary origins of general intelligence is attractive for its simplicity and ability to solve a contradiction without making significant changes to any theories, however as with many evolutionary psychological theories it is simplistic and is based on little hard empirical evidence. Also, it runs contrary to the wealth of data reported by Chabris which shows that g is linked to many different aspects of the brain's anatomy, and is linked to many very basic abilities too. Kanazawa's modular model needs to be refined, but he still succeeded in showing that evolutionary psychology and general intelligence are not necessarily opposed, and the idea of g becoming more significant as humans lived in less and less natural habitats may prove to be a good one. Overall, general intelligence has built up enough empirical data supporting it to suggest that we should focus on this instead of other models of intelligence. The theories and approaches now supporting general intelligence come from many areas of psychology, and this can only help to refine this model and fill in the holes in our knowledge, of which there are many. Another final weakness of the general intelligence model is that it is prone to be a victim of its own success. Because general intelligence is an exciting and powerful theory, it is important to understand its limitations and only apply it as much as is warranted, despite temptations to over-apply it. General intelligence is a very good predictor of various societal outcomes, however it is only useful at a broad level as there will always be many exceptions to any patterns. We should focus on learning more about the factors that make up each individual's intelligence profile before making damaging generalisations. We should also avoid putting g up on a pedestal, it is one of several things that can be used to predict performance in many spheres, including common sense, creativity, wisdom, people skills and motivation (Chabris, 006; Deary, 001).'''",159.0
"'''The effect of group processes on individuals and work teams directly influences the overall output and performance in a business. Through studying the interaction between individuals and groups, managers become enlightened on 'the success and failure of many work groups, as well as the satisfaction of the individuals working in them'. This paper assesses the extent to which group processes influence individual behaviour and group performance. Freeman, J., Croom, S., Kotlarsky, J., Dean, D. and Caldart, A., Business and Management: Selected Readings for Non-Business Students Volume, Pearson Education Limited, United Kingdom, p.77 'Group processes' is 'the process of interaction within groups, which refers to the manner in which group action is constructed on a continuing basis'. The study of such processes involves an examination on individual involvement and on changes in the overall group structure. On the other hand, a 'group' is 'a number of interdependent individuals who influence one another through social interaction'. Formal groups 'are created by the organization and are intentionally designed to direct members toward some important organizational goal', such as business organizations and project teams. These differ from informal groups, such as friendships, which 'develop naturally among an organization's personnel without any direction from the management of the organization within which they operate'. Although informal groups are essential to the social needs of employees, it is nevertheless a subsidiary concern in group processes. Thus, only the impact of group processes on the formal business team is reviewed in this essay. Fincham, R. & Rhodes, P. S., Principles of Organizational Behavior th Edition, Oxford University Press Inc., New York, p.85/8 Based on D. Forsyth, 'Group Dynamics', in Group Process, Group Decision, Group Action, R. S. Baron & N. L. Kerr, Open University Press, United Kingdom, p.09 Freeman, op. cit. note, p.79 Freeman, op. cit. note, p.80 To begin with, social facilitation displays the potency of group processes on individual behaviour. It is based on Zajonc's drive theory, where he argued that social facilitation occurs 'because we are excited and aroused by the mere physical presence of species mates'. This phenomenon sheds light, in particular, on how people perform familiar tasks better, but unfamiliar tasks worse in front of an audience. An example is when a piano player is instructed to play an unseen piece on stage. The theory of social facilitation suggests that the piano player is highly likely to perform worse than if he is given a piece he has been practicing for years. Baron, R. S. & Kerr, N. L., Group Process, Group Decision, Group Action, Open University Press, United Kingdom, p.1 Freeman, op. cit. note, p.87 Similarly, social loafing explains why individuals become less motivated working in groups. It is a phenomenon which predicts how a weak social identity decreases individual performance and diminishes group productivity. However, unlike social facilitation, there are factors preventing this phenomenon from occurring. One of them is the level of group cohesiveness, which is 'defined as the complex of forces giving rise to the perceptions by members of a group identity'. According to Karau & Williams' meta-analysis study, the level of motivation is not as affected in highly cohesive groups, because individuals believe that their group or their task holds a great importance. The surrounding social culture is another critical manipulate on individual performance. When people are encouraged to work for personal success in highly individualistic cultures like the United States, social loafing is likely to occur. The notion of working for self benefit encourages people to become more motivated, and thus, enhances individual performance. Social loafing is, however, unlikely to occur in highly collectivistic cultures such as Japan, as people are inspired by group accomplishments over personal achievements. Wikipedia, 'Social Loafing', Date Accessed: 1 December 005/8, URL The concept of conformity has a significant influence on individual performance as well. Conformity refers to 'cases in which individuals change their attitudes, verbal statements or behaviours to adhere more closely to some salient social norm'. One of the influences in conformity is known as the normative social influence, which is when the minority conforms in order to prevent the group's potential rejection and punishment. Alternatively, the informational social influence is when the minority conforms, based on the trust of group opinion. The major difference between these two is that the normative influence can pressure people to conform despite conflicting private attitudes and contradictory group norms. Baron & Kerr, op. cit. note, p.3 Baron & Kerr, op. cit. note, p.4 The most decisive experiments on conformity were conducted by Solomon Asch, where students were asked to estimate which of three comparison lines matched the fourth line. Asch observed that both normative and informational influences were functioning when the group members made incorrect matches, and detected as the size of the majority increased, so did the level of conformity at a diminishing rate. Stanley Milgram's electric shock experiments are another set of experiments which focuses on the power of group conformity on individuals. People were hired to be 'teachers', and were forced to shock the 'learner' (who faked the pain) by electricity every time a memory error occurred. Despite watching the learner tortured in pain, most of the teachers continued to apply higher levels of shock to the learner until the maximum level has been reached. The teachers' compliancy to set protocols reveals how the pressure of conformity overrides the ethical judgment to stop inflicting pain on another person. This demonstrates again the large influence of conformity on individual decisions and behaviour. Baron & Kerr, op. cit. note, p.6 Baron & Kerr, op. cit. note, p. On the contrary, the concept of synergy relates to the effect of group processes on group performance as a whole. It is concerned with how the combined efforts in a work group are able to outperform even the best individual on the team. This phenomenon occurs because team spirit induces members to work efficiently and to specialize on tasks that would otherwise be carried out individually. The increased cohesiveness also induces creative thinking and allows the team to consider alternatives suggested by its members. The overall result is an increased number of good-quality decisions. Synergy, in practice, is found in the practice of cross-training to promote efficacy. Individuals undergo 'efforts to learn the jobs performed by one's team members' (or cross-training) to develop 'a common understanding regarding how their team works' (or shared mental models). A highly cohesive team spirit is generated, which increases the flexibility and coordination of the team, and benefits the overall performance and productivity in the long run. Fincham & Rhodes, op. cit. note, p.88 Freeman, op. cit. note, p.92 Freeman, op. cit. note, p.92 Group polarization, or 'the tendency for group decisions to be more extreme than those of individuals', is another phenomenon which shows how group processes affect group performance. Individuals generally become stronger on their beliefs when their beliefs are recognised with other like-minded people. Group polarization is observed in juries, where jurors with neutral views come to conclusions about whether the defendant is innocent or guilty based on the other jurors' opinions. Fincham & Rhodes, op. cit. note, p.94 Fincham & Rhodes, op. cit. note, p.94 It was suggested initially that group discussion has a calming effect on extremist opinions in the group polarization phenomenon. However, studies have shown that group decisions made individuals even more extreme than before. The previously mentioned normative and informational influences contribute to the group polarization phenomenon. If, for example, there is a tendency towards a certain verdict in a jury, normative influences may encourage jurors to conform to the group's decision despite disagreement. Alternatively, informational influences may persuade jurors to agree with a certain verdict after numerous reasons favouring this verdict are given. Baron & Kerr, op. cit. note, p.8 Nevertheless, a more extreme phenomenon than group polarization is the groupthink phenomenon. Groupthink 'illustrates how an emerging group norm, often one suggested by the group leader, can bias the content of discussion by suppressing dissent', so that even those individuals who are not in agreement with the group norms suppress their own beliefs and comply with the remainder of the group. Janis suggested a number features that led to the groupthink phenomenon, which included 'directive leadership style, intense group cohesion, similarity of ideology, pressure for unanimity, group insulation from critics, insecure member self-esteem and a sense of crisis.' These extreme conditions lead to excessive conformity - a scenario where group synergy creates more problems than benefits. A real-life example of the groupthink phenomenon is its influence on the Kennedy administration's decision to invade Cuba, where the administration believed that they were unconquerable despite being outnumbered by Castro's army. There were many processes involved in the formation of the groupthink phenomenon in this case. Many people were fed by the administration to believe that they were doing something morally correct, while others supported the administration merely to display loyalty. The administration reveals how processes in the groupthink phenomenon influence individuals to conform to group norms and achieve a united group performance. Baron & Kerr, op. cit. note, p.8 Baron & Kerr, op. cit. note, p.4 Fincham & Rhodes, op. cit. note, p.93 In conclusion, group processes hold a notable influence in shaping individual behaviour and group performance. Although the effect of group processes varies under diverse circumstances, there is no doubt that they are remarkably influential to the business' function and operation. It is vital to keep in mind that businesses are a collective operation. If managers are able to grasp the fundamental group processes affecting the working environment, the business will definitely benefit from an enhanced performance and productivity.'''",163.0
"'''Dispute settlement procedure what is it forDispute settlement procedure is established in order to assure smooth and fluent functioning of world trading system. World Trade usually arise due to difference in national regulations of the parts involved in the dispute. Dispute settlement procedure is unique feature of WTO, it allows smaller countries to defend their interests. There is only negative consensus procedure - all WTO members must agree to reject panel report. Usually in all the disputes one of the major trading a part. WTO disputes are dealt with by Dispute Settlement 3 May 003, the United States requested consultations with the European certain measures taken by the EC and its member States affecting imports of agricultural and food products from the United States. According to the moratorium applied by the EC since October 998 on the approval of biotech products has restricted imports of agricultural and food products from the US. The US pointed out that a number of EC member States maintain national marketing and import bans on biotech products even though those products have already been approved by the EC for import and marketing in the EC. According to the US, the measures at issue appear to be inconsistent with the EC's obligations under: Articles,, and, and Annexes B and C of the SPS Agreement; Article of SPS says, Countries have right to take sanitary and phytosanitary measures to protect human, animal, plant life or health, while those measures are consistent with provisions of SPS agreement and are based on scientific principles and maintained with sufficient scientific or phytosanitary measures have to be based on an assessment, as appropriate to the shall take into account as relevant economic factors: the potential damage in terms of loss of production or sales in the event of entry. (.) Each Member shall avoid arbitrary or unjustifiable decisions in the levels it considers to be appropriate in different situations, if such distractions result in discrimination or a disguised restriction on international procedures for assessment of products originating form territories of other Member should be permitted under conditions no less favourable than those applied for like products of national be published promptly and made available for interested and various European Union member state bans on specific GM varieties. The current U.S. case does not challenge present European on Genetically Modified is essential to restore consumer confidence in GMO's in Europe'. The Bush Administration claims that the EU's delay in granting new GM crop approvals has resulted in lost markets for American farmers. But clearly consumers' preference for non-GM food is the true engine of the market collapse for American crops. Even before the delay in GM crop approvals began in 998, U.S. corn sales to Europe had dropped by more than cooperating with Consumers International played a role in that shift in public opinion, having created an international coalition of organizations that oppose the use of the organization, which is seriously involved into the battle against GMOs, highly specialized experts working for CU, provided many international organizations with their expertise. Consumers organizations on both sides of Atlantic apart form favouring global rule-based trading system highly opposed WTO decision. They however mutually agree that the recent WTO decision will not make European consumers accept GMOs any more than they do presently. As force-feeding never works, it is more likely that the WTO decision will have an adverse effect, if consumers feel that GMOs are being forced at them . In case of present dispute 'TACD has vigorously protested the United States suit and has repeatedly urged the US and the EU to resolve disputes over consumer, public health and environmental matters outside of the WTO where public interest regulations are regularly ruled against in the name of free trade'. ConclusionsFrom the information presented above one can see there are various factors influencing drop in US GMOs sales both in Europe as well in the US themselves. Among those factors are increasing world competition on the GMO crop market, especially faced form Argentina and Brazil, but also increasing consumers awareness and pro-environmental attitudes all over the world. Challenging EU authorisation system and the right to sovereignty of the EU member states, which by the way is in accordance with international biodiversity agreement, seem not to be enough in order to rule in favour of the US in case of such delicate issue. Such questions as public health and environmental concerns seemed not to be addressed, maybe long awaited panel report will revel more firm arguments, on which panel decision was based.'''",167.0
"''''Doing the Business' by Hobbs explores the interrelationships between the working class and detectives operating within the East End area of London. The analysis is set in the 980s and the author aims to establish the importance of entrepreneurship as characteristic of the working class in the East End of London. Hobbs reaffirms that the importance of entrepreneurship is vital in the functioning of police in this area. Thus through the commonality of entrepreneurship the author attempts to establish a third relationship, that the culture of East Enders is mirrored in the culture of the CID division that functions within the East End of London. Hobbs argues this emanates from the commonality of entrepreneurship being vital in both for the inhabitants of East London's survival and the success of police work in this area. Therefore, the book attempts to deal with this commonality in establishing the place of entrepreneurship an integral and fundamental part of East End life as well as emerging as a necessary aspect of the work of detectives in this area. Resultantly, Hobbs attempts to establish the uniqueness of this commonality both for the people of the East End and its use by the police who function within the area. The author calls upon numerous techniques in order to analyse and establish these three relationships, including ethnographic study, interviews, case studies and close analysis of other theorists. A third of the book outlines the emergence of the Metropolitan Police and the CID division and its particular focus on the maintenance of law and order in the working class areas in London, particularly the East End. Hobbs provides a detailed chronology of the emergence of the distinct area of the East End and its relationship to the rest of the Capital. Hobb's further detailed chronology of the CID is important as it establishes both the East End as a unique area of London and the CID as an elite department of the police force. This is vital in the founding of his analysis of the relationships between the East End and the CID and how its culture came to mirror the culture of the area. For example, before the establishment of a unified police force Hobbs not the disunity of policing and the inherent corruption that existed, noting 'the policemen continued according to tradition to sell justice' (Parliamentary papers cited in Hobbs ). Hobb's extends the uniqueness of the CID division noting that 'when the presence becomes invisible, covert and indistinguishable in appearance from the policed, it has been traditionally perceived as un-British and therefore threatening' (Hobbs ). Such detailing therefore establishes an image of the CID division through history and sets up his argument for the defining feature of the department, entrepreneurialism being its unique and dominant feature. Hobb's continues to establish the unique function of the CID through the use of the case studies, including the Great Train Robbery. These are greatly important as it adds depth to the relationship between the CID and their use of entrepreneurship in the investigative process. Hobbs notes 'these cases help us to understand, how a formal organisation evolves 'naturally' as a response to forces unrelated, or even opposed, to the formal rules and priorities of an administrative structure' (Hobbs ). Thus a good grounding for the establishment of the three relationships is used by Hobbs, however the detail given and space within the book given to this, is arguably detrimental to the exploration of the three relationships in further depth. The relationship between the working class in the East End and their development of entrepreneurial skills is substantially argued and sustained by Hobbs. The author closely analyses this relationship and how it comes to characterise the East End and an area functioning in a unique way. Hobbs notes the entrepreneurial skill that emerged as an inherent part of East End life and that was 'created by the area's relationship with the City and by unique economic and employment structures, the origins of which are located around the banks of the Thames' (Hobbs ). The book provides a detailed and through analysis of the life style and culture of the East End and Hobbs establishes that the potency of the East End culture had not only led to the uniqueness of the London area, but entrepreneurial skills becoming inherent in the working class in its urban milieu. Hobbs consideration of the youth of the area aims to substantiate this relationship through the idea of the entrepreneurial culture being transmitted from 'generation to generation' (Hobbs ). The dedication of a chapter of this book to the detailing of the culture and sub cultures of the youth is arguably to the loss of the further exploration of the relationship between entrepreneurial skill and the East End. Arguably this is due to his East End background. Thus there is seemingly an attempt b the author to firmly establish the zeal of the East End and the uniqueness of the area's culture. Hobb's concentration on sub culture and youth illustrates this, as he duly notes in his first chapter his scholarly background in this area. Adversely, Hobbs systematic breakdown of the types of jobs in the East End does add the additional dimension of the relationship between the working class and entrepreneurial skill as he comments on the varying success and practice of this in the every day lives of East Enders and in how its application has emerged because 'East Enders exist on the brink of the City of London's legitimate commercial enterprise and legality' (Hobbs. Thus the author successfully uses the recognisable characteristics of the East End to establish the emergence of wide spread entrepreneurialism. The relationship between entrepreneurial skill and the work of detectives in the book is established in the penultimate two chapters. Firstly, Hobbs is adamant to assert that the entrepreneurialism of the CID division is what characterises and separates it from the uniform branch of the Metropolitan Police. Hobbs firmly establishes this during his chronology of the police force at the beginning of the book and reasserts this later towards the end of the book, stressing the elite reputation of the department and thus its uniqueness from the rest of the force. In doing this his argument is persuasive through the assessment of the different entrance criteria of the CID and the detectives 'performance' in the courtroom. Hobbs reasserts the place of entrepreneurship in the force and its legality as an important factor of policing through the process of paperwork and bureaucracy. Thus the entrepreneurial skill employed by the detectives in the East End is firmly established by the author. The relationship between the East Enders and the detectives being similar due to the commonality of entrepreneurialism is problematic. Arguably, Hobbs does not explore this vital third relationship enough, and this arguably is due to the time spent on the detailing of the chronology of both the police force, the East End as an area, and the lifestyle and culture of the East Enders. The book suggests that the relationship of the detectives who use entrepreneurialism in their work mirrors the lives of East Enders, who are dominated by the need for this skill in their day to day lives. This relationship is presented as inherent in the area. Hobbs notes that 'sharing much of their working environment with working class entrepreneurs, some of it is bound to rub off on the detective and this is increasingly likely when much detective work is in itself entrepreneurial' (Hobbs ). There is an indication that the employment and commonalities held between CID agents and East Enders is a conscious construct of the CID agents in order to pursue their work. For example, 'the essence of CID power lies in their skill in utilizing working class vocabularies, both; linguistic and presentational to enhance their police function' (Hobbs ). Hobbs states 'the relationship between the demises of East London and the CID is symbiotic, appropriately based upon the trading of moral identities' (Hobbs ). Although this relationship and the employment of entrepreneurialism is clear in the book in both the cases of the East Enders and the detectives Hobbs could have established whether the commonality between East Enders and detectives was inherent or a conscious construction on behalf of the CID, which is a failing of the book. The title suggests that the parallels are caused inherently through the commonality of entrepreneurialism, but some of the evidence arguably suggests otherwise. The title and content of the book suggests that the employment of entrepreneurialism consequently results in the two groups sharing in common features. Although Hobbs strongly and substantially argues that entrepreneurialism is a key and dominant feature in the lives of the East Enders and the detectives, arguably the existence of the commonality between the two groups does not necessarily lead to the ability to draw close parallels between them. A singular parallel of the presence of entrepreneurialism is arguably the only one that can be drawn, even through there seems to be an inherent suggestion that further parallels would exist in the functioning of the two groups in the same area. This vital and interesting third relationship, which encompasses the other two relationships that the book explores is only developed in the penultimate two chapters of his book and could have been explored further. The book explores three interesting relationships that co-exist in the East End of London and Hobbs substantially explores the relationship between both the detectives of the East End working class to entrepreneurialism. However, the inherit or conscious construction of the third relationship could have been explored further. Hobbs does however provide an interesting insight into the lives of both East Enders and the working of the CID in this area. One of the book's strengths is the affect of the City on the East End and the emergence of its unique character. Hobb's additionally provides an interesting foresight on how the area will be changed with the further development of the City and changes in London's economic markets, which he firmly establishes as affecting the people of the East End area and its characteristics.'''",176.0
"'''Presented to A+E at the Hospital,, on with bilateral pedal oedema. Delusional, and therefore referred and informally admitted to the Clinic,. History All relevant information gathered from the patient about the presenting illness, co-existing problems, and current treatment, significant past medical history and the social and family background. The patient's view of the nature of the problem and their expectations for treatment. Mr is an unemployed single 9-year old who owns his own semi-detached house in. He is an unmarried Catholic. When asked why he was currently in hospital, Mr said it was a 'safe place for me.' Mr stated that sunlight, laser beams, ionised particles, the internet and fibre optic communication were ' difficult'. He described himself as feeling like James Bond in the film 'Goldfinger' in the scene were Auric Goldfinger ties James Bond to a steel slab and proceeds to try to burn him in two with a laser. Mr believed he had been admitted after 'laser heart massage' on himself and demanded an explanation as to how this procedure worked. Mr said his flashing lights as he was having his heart attack, and therefore lights unduly worry him. Mr was also worried about cars killing him, and especially concerned about the attitude of drivers in the road. There appeared to be no precipitating factors to this episode of delusions. Mr also described gustatory, visual and several auditory hallucinations. He said he had tasted bromine in his tea, and for this reason went to the cafe over the road rather than drink the tea provided. He felt the bromine was added to decrease his sex drive. He also described intermittently seeing a 'bloke with red eyes who looks like Frankie Lane', although could not elaborate any further on the significance of this. Mr added he heard female voices that talked to him to 'remove me from dangerous situations'. They gave him instructions that he couldn't remember, and said he doesn't have to do what they say, but chose to obey them anyway. The voices 'looked after' him, and he considered that he worked in partnership with them. They have been with him intermittently since 977, and the only way he can make them go away is if he smokes. He also felt that the early songs of Cliff Richard directly told him to 'cheer up, enjoy myself and get married.' Mr described thought insertion as he said 'someone or something' suddenly tells him to pray and worship. This all started when he had his tonsils out and was given a 'pill wrapped in strawberry jam' that christened him and intermittently controlled his thoughts. Mr he only owned the thoughts he manages to write down on paper, otherwise 'they're lost (a hypnotic.mg nocte) (oral anti-diabetic biguanide 00mg w/ meals) (SSRI, 0mg od) Risperidone any other cause that still needs to be considered at this stageF20. SchizophreniaMr has several of the positive features of schizophrenia- Delusions, hallucinations, and disorganised thoughts. He also has several negative features, including- a flat affect and loss of directed behaviour and motivation. F20. above, but Mr 's delusions/ hallucinations frequently have a paranoid flavour. No negative indications for this diagnosis. Formulation of the patient's this in physical, psychological and social Use the framework of RAPRIOP to structure your proposed management. Refer to the guidelines to the writing of portfolio cases for the details of the issues to be addressed under each heading.ImmediateRule out organic and drug causes of confusion/delusions/illusions. Admit and establish if medication has been taken. Review medication and perform full physical examination. Treat leg oedema, and investigate complications of diabetes. Bloods - HBA1c, TFTs, LFTs, FBC.Long-termThis is Mr 's th admittal after community-based care. Even with the highest levels of support from the Community Mental Health systematic review has found that compared with placebo, chlorpromazine reduces the proportion of people who have no improvement, or marked/worse severity of illness at months on a psychiatrist rated scale. The review found that chlorpromazine caused more adverse effects, such as sedation, acute dystonia, and parkinsonism than a placebo. One systematic review has found that haloperidol increases the proportion of people with psychiatrist rated global improvement at and 4 weeks compared with placebo, but is associated with acute dystonia, akathisia, and parkinsonism. One systematic review has found that thioridazine improves global mental state over - 2 months compared with placebo. Psycho-educational and family interventionsEvidence for non-pharmacological treatment of schizophrenia is very limited. However one systematic review has found that psycho-education reduces relapse rates at - 8 months compared with usual care. One systematic review found that multiple session family interventions reduced relapse rates at 2 months compared with usual care, single session family interventions, or psycho-educational interventions. Commentary A commentary on issues of epidemiology, psycho-social, health care delivery, ethical issues or disability relevant to the patient and/or problemSchizophrenia was first approximately described by Emil Kraepelin in 899, and may currently be defined as 'A mental disorder characterised by disintegration of the process of thought, contact with reality, and progressive loss of emotional responsiveness.' It is commonly assumed that schizophrenia means 'split personality,' but the name actually refers to the splitting and disintegration of an individual's thinking and feeling processes, rather than having two personalities. Considering the important positive and negative symptoms listed below makes the clinical diagnosis: The prevalence of schizophrenia is moderately high, with figures ranging between.-.%, and incidence of 1 per 00,00. Age of onset is usually between 5/8-0, with males presenting typically years before females. The disease is higher in Afro-Caribbean males, leading to a 'migrant' theory that schizophrenia is higher amongst individuals isolated from their original ethnic community. However, this argument is partially flawed, as levels of schizophrenia are lower amongst Asian women who have migrated. The aetiology of schizophrenia is controversial. There are two main theories: GeneticFamily, twin and adoption studies have suggested that genetics play a major role in the transmission of schizophrenia. Irwing Gottesman compiled over 0 studies in order to work out the risks of developing schizophrenia of people with different familial relationships to the schizophrenic person. Two classes of relatives have especially high risks of developing schizophrenia. These are the offspring of two schizophrenic parents and a -twin of a schizophrenic. Apparently, people who share the greatest number of genes with the people who have schizophrenia, have an increased risk of developing schizophrenia themselves. EnvironmentalEnvironmental factors could influence the development of schizophrenia but adoption studies support the genetic theory of transmission. In 994, a study looked at schizophrenia in the biological and adoptive relatives of schizophrenic adoptees, and compared this to a demographically matched group of control adoptees. In the sample of adoptees with chronic schizophrenia, the disorder was found exclusively in their biological relatives and not their adoptive relatives. The prevalence of the disorder was 0 times higher in the biological relatives of the schizophrenic adoptees than in the biological relatives of the control group. These studies make a clear case for the involvement of genetics in schizophrenia. Gross histological brain changes have been identified in schizophrenia. These include increased lateral and third ventricular volume compared to controls, changes in glial cell populations and diminution in neuronal size in the anterior cingulate cortex, and also reductions in specific inhibitory neuronal populations. Management of schizophrenia should encompass both psychosocial and pharmacological interventions. Psychosocial interventions include assessment and support; explanation and education; building concentration; reinforcement of reality and help with relationships. Communication skills and treatment of non-psychotic symptoms such as anxiety and mood disturbance dealing with challenging behaviours should be addressed, structuring to the day should be encouraged, and attention should be paid to improving daily living skills. Families should also be involved with the process of managing schizophrenia, as high levels of criticism, hostility and over-involvement predispose to relapse. Antipsychotic drugs relieve florid psychotic symptoms such as thought disorder, hallucinations, and delusions, and prevent relapse. Although they are usually less effective in apathetic withdrawn patients, they sometimes appear to have an activating influence. Patients with acute schizophrenia generally respond better than those with chronic symptoms. They are considered to act by interfering with dopaminergic transmission in the brain by blocking dopamine D2 receptors, which may give rise to the extrapyramidal effects, and also to hyperprolactinaemia. Antipsychotic drugs may also affect cholinergic, alpha-adrenergic, histaminergic, and serotonergic receptors. They are classified as either being typical or atypical depending on age and mode of action. They both seem to be of similar efficacy, but the atypicals have fewer extra-pyramidal side effects and are thought to be more effective on negative symptoms. Clozapine is used for schizophrenia when other antipsychotics are ineffective or not tolerated. Most people with schizophrenia continue to suffer chronically or episodically throughout their lives. Even between bouts of active illness, lost opportunities for careers and relationships, stigma, residual symptoms, and medication side effects often plague those with the illness. One in 0 people with schizophrenia eventually commit suicide. Impact on your learning Describe what you have learnt from this casePresentation, diagnosis and short and long-term management of schizophrenia.'''",186.0
"'''.The use of water for nursery irrigation is predicted to be a crucial issue for ornamental industry over the next decade. Increased water cost and decreased availability are almost certain to occur. Some European countries, mostly from the Mediterranean zone, have experienced significant water shortages and in many cases demand for water exceeds supply. As a result, ornamental producers must learn to manage effectively this invaluable natural source. Undoubtedly, the implementation of effective irrigation management techniques is the most essential step for the accomplishment of irrigation water use efficiency.. Water conserving practices According to Garber et al., (002: 30), the most important practices to conserve water used in container nurseries are: 'water recycling, irrigating when needed and for the minimum required time, use of drip or sub-irrigation instead of overhead irrigation, watering in the morning hours to minimize loss of water due to evaporation, watering based on plant requirement and not based on preset frequency, use of cyclic irrigation, arrangement of provide a simple, low technology method for reducing nutrient concentrations and improving runoff water quality. A study by Arnold et al. (004: 17) indicates that 'a single pass of nursery runoff through constructed wetlands substantially reduced nitrogen concentrations without increasing salinity. Nevertheless, constant recycling of water through constructed wetlands may increase soluble salts to levels that require subcanopy application of irrigation for effective crop production'. The same study shows that overhead irrigation method had negative impact on nursery crops when recycling water was used. The damage obviously caused due to high salt concentrations in irrigation water contacting the foliage. In any case recycled water must be carefully managed in order to avoid foliage damage of crops. Moreover, according to Garber et al., grass strips can be used to reduce nutrient transfer to collection basins. In some cases also, recycled water must be treated by acid injection to control pH.. Irrigation systems4. Overhead and trickle systemsIrrigation systems are also very essential for the efficient use of water. Overhead irrigation is the most common form of nursery irrigation. It is a flexible and cheap method. The volume of water can flexibly be adjusted and for this reason the ground does not have to be specially graded. However, overhead irrigation systems are inefficient in terms of water use. For example, the area where an overhead irrigation system applies water is not totally covered by pots. Therefore, one part of the applied water falls on the ground. Also, the whole area must be watered long enough to ensure that the least well watered plants receive adequate water. Colangelo et al., point out that trickle irrigation can significantly increase water application efficiency when compared with overhead irrigation, because water is delivered directly to the medium. Cyclic micro-irrigation in trickle systems also has been shown to increase water use efficiency in container production systems compared with non cyclic systems. In cyclic irrigation, plant's daily water allotments are divided into a series of application events throughout the day.. Capillary irrigationA research carried out by Goodwin et al., shows that capillary irrigation is more efficient in terms of water use, compared with drip and overhead irrigation. On the other hand, the electrical conductivity of overhead watering is more evenly distributed in relation to both drip and capillary irrigation. This study indicates also that plants grown with capillary irrigation have sparse roots near the upper surface of the mix, due to higher EC in the surface layers of the pots. Therefore, shallow-rooted plants do not indicate optimum growth in capillary systems, especially when fertilizer is applied on the surface of the mix. Finally, this research shows that for optimum growth in capillary systems, especially for shallow-rooted plants, we need to use controlled-release fertilizer which must be mixed through the medium.. Ebb and flow benches & sand bedsSub-irrigation systems, such as ebb and flow benches and sand beds, are very water efficient in relation to overhead irrigation, using 0% or less of the water of an overhead system. This is mostly due to the fact that almost all the water supplied is potentially available to the plants. Although, sub-irrigation systems have been researched for decades, they are not broadly adopted because of weed growth, algae growth and plant rooting into the bed. However, Zheng et al., point out that the major drawback of this technique is the salt accumulation at the substrate surface. Sub-irrigation results in a significant accumulation of salts within the top third of plant growth substrate. In order to avoid phytotoxic salt accumulation in sub-irrigated crops, a reduction in fertilizer concentrations would be necessary. Zheng et al., suggest that macronutrient concentrations used by greenhouse growers can be significantly reduced without having any negative effect on growth and quality. The same research indicates that if substrate pH levels can be adequately maintained under lower EC conditions and lower fertilizer application rates, it may be possible to reduce fertilization without reducing crop production. However, if the nutrient level is too low, nutrient deficiency, such as N and K, may occur. Fe deficiency is also very likely to occur in very low nutrient concentrations, mostly due to elevated pH levels of growth substrates. Obviously, we need to find a balance between providing adequate nutrients and reducing the potential for phytotoxic salt accumulation. The reduction also of nutrient concentrations, without reducing crop production and quality, is crop dependent. It is finally very important to redistribute nutrient salts to the lower sections of the pot by using periodically overhead fertigation.. Plant-demand based irrigation'Plant-demand based' irrigation management strategies are under development to provide solutions to the problems of water use efficiency. This technology tries to determine the water requirements of crops by using substrate moisture sensors and irrigation models based on reference evapotranspiration. However, commercial availability of these options is very poor.. Potential commercial impact of water efficient management strategies5/8. Commercial impact of the reuse of runoff waterAccording to Beeson et al., the use of recycled water has dramatically increased the presence of root rot in some container nurseries, due to high salt concentrations. Additionally, since the land area for most nurseries is frequently an important part of recirculation cost. On the other hand, as availability of water from public surface waters and groundwater declines, nurseries will adopt methods and technologies to increase water use efficiency. The adoption of collection basins, micro-irrigation and sub-irrigation from the larger nurseries is undoubtedly of major importance.. Commercial impact of water efficient irrigation systemsIt is worth mentioning that water efficient irrigation systems have several other economical and environmental benefits besides lower water requirements. Lower nutrient 2 bog-like free-surface cells. Three cells of each type were planted with Canna x generalis 'Cherry Red', Iris x 'Clyde Redmond', both species, or no wetland plants. Runoff was continually collected from the nursery and recycled through wetland cells prior to application via overhead impact sprinklers or subcanopy microsprinklers. Short- effects between overhead and subcanopy irrigation during production of Fraxinus pennsylvanica, Pistacia chinensis, Quercus virginiana and Taxodium distichum in.- or Ilex vomitoria 'Nana' and Catharanthus roseus in.- were limited in magnitude. However, overhead irrigation reduced height and caliper growth or injured the foliage compared to plants irrigated with subcanopy microsprinklers during longer- in large 7.-. The extent of reduction was species dependent with Pinus elliottii being minimally impacted, Pyrus calleryana 'Bradford' intermediate, and Lagerstroemia x 'Basham's Party Pink' (purportedly a Lagerstroemia indica x Lagerstroemia fauriei hybrid) and T. distichum exhibiting more pronounced effects. Damage appeared to be largely a result of high dissolved salt concentrations in irrigation water contacting the foliage. Recycling of runoff through the FSF cells concentrated soluble salts more so than passing the water through the SSF cells. Efficacy of nitrate nitrogen removal varied with species, season, loading rate and wetland type. However, the constructed wetland s were generally effective under our test conditions at maintaining effluent nitrate levels at <=0 mg/ loading rates were <=0 mg/ the system was more important for effectively reducing nitrate levels in effluent from SSF than from FSF cells.. Strategic vision of container nursery irrigation in the next ten years. Visions of the future for container nursery irrigation were collected from 2 nursery irrigation scientists, growers and nursery organization leaders. The amount of water available for nursery irrigation unanimously is forecasted to decline over the next decade. Along with declining availability, the cost of water for irrigation is predicted to increase substantially for most nurseries. Limited availability, higher direct cost, and irrigation runoff issues are projected to compel the container nursery industry to adopt procedures and technology that will increase irrigation water use efficiency. Evidence in support of these prognoses, current solutions and suggested options are discussed.. Nitrate leaching beneath a containerized nursery crop receiving trickle or overhead irrigation. Container production of nursery crops is intensive and a potential source of nitrogen release to the environment. This study was conducted to determine if trickle irrigation could be used by container nursery producers as an alternative to standard overhead irrigation to reduce nitrogen release into the environment. The effect of overhead irrigation and trickle irrigation on leachate nitrate N concentration, flow-weighted nitrate N concentration, leachate volume, and plant growth was investigated using containerized with a controlled-release fertilizer and grown outdoors on top of soil-monolith lysimeters. Leachate was collected over two growing seasons and overwinter periods, and natural precipitation was allowed as a component of the system. Precipitation accounted for 9% of the water entering the overhead-irrigated system and 0% of the water entering the trickle-irrigated system. Leachate from fertilized plants exceeded the USEPA limit of 0 mg L- at several times and reached a maximum of 6 mg L- with trickle irrigation. Average annual loss of nitrate N in leachate for fertilized treatments was 1. and 0. kg ha- for the overhead and trickle treatments, respectively. Average annual flow-weighted concentration of nitrate N in leachate of fertilized plants was. mg L- for overhead irrigation and 2. mg L- for trickle irrigation. Trickle irrigation did not reduce the amount of nitrate N leached from nursery containers when compared with overhead irrigation because precipitation nullified the potential benefits of reduced leaching fractions and irrigation inputs provided under trickle irrigation.. Survey of container nursery irrigation practices in Georgia. A 001 survey of 02 nurseries that were members of the Georgia Green Industry Association was conducted to assess irrigation practices of container ornamental nurseries. Mean nursery size was 4 mean annual revenue was approximately $ million. Approximately 0% of the irrigation water was from wells and the other 0% came from surface sources, such as collection basins. Irrigation in smaller containers, including #, # and #, was applied primarily by overhead methods, while larger extensive use of direct application methods, such as drip or spray stakes. Frequency of irrigation in the summer growing months was about three times that of the winter season. Georgia nurseries use irrigation practices suggested in Southern Nursery Association best management practices, including collection of runoff the environmental impact of the systems. The environmental impact was assessed by the volumes of runoff and the amounts of nitrate nitrogen and phosphate phosphorus in the runoff.. Flower Carpet and tomato cv. Apollo grew on capillary mat as large as or larger drip or overhead irrigation when controlled-release mixed through the medium. no significant difference between the irrigation systems. However, when the fertilizer was applied to the surface or in the dibble hole, pansy,. Gemfire, and larger with overhead than with capillary irrigation. The volumes of water used by the drip and capillary systems were about equal at. and. l/pot per week, respectively, as were the volumes of runoff produced,.3 and.9 l/pot per week, but both were far lower than the corresponding values for the overhead system, where water use was.3 l/pot per week, and the runoff.0 l/pot per week. At the end of the trial, plants grown with capillary irrigation had a high electrical conductivity in the surface layers of the pots when controlled-release fertilizer was either mixed evenly was applied to the top of the highest at the bottom of the greenhouse crops of calluna, cyclamen and primula. Experiments were carried out during 997-000 in Scotland, the UK, to study the use of irrigation as a potential component of an integrated disease management system. On calluna cuttings cultivar Sun Rise, irrigation was applied using hand-watering from overhead or sub-irrigation using capillary sandbeds, and on calluna plants cultivar Flamingo by overhead watering by a sprinkler, sub-irrigation using capillary sandbeds, dripline irrigation at 00 ml/plant and dripline irrigation at 00 ml/plant. Overhead watering by hand and sub-irrigation by filling a -cm deep reservoir in a plastic tray were applied to cyclamen plants cultivar Sierra White. Overhead sprayline irrigation with pots stood on capillary matting and sub-irrigation using seep-hoses laid over capillary matting were used on primula plants cultivar Danova. On calluna, foliar symptoms were significantly reduced when plants were watered by sub-irrigation. On cyclamen, disease incidence on leaves was not affected by an irrigation method. However, a significant disease reduction was associated with sub-irrigation on leaves at mid-canopy level towards the crop maturity stage. An irrigation method had no effect on primula. Different effects of irrigation on B. cinerea development were related to primary infection routes of the disease. Sub-irrigation reduced disease risk when infection occurred at upper or mid-canopy levels, but not when disease originated on leaves at the compost level.. Potted gerbera production in a subirrigation system using low-concentration nutrient solutions. To determine whether currently used commercial nutrient solution concentrations can be reduced during the final production of potted recirculating subirrigation conditions, plants were grown under one of nutrient leaves from plants that received the 0% and 00% strength nutrient solutions. However, leaves from plants that received the 0% and 5/8% strength solution showed significantly less greenness than that of the plants that received 0% and 00% strength nutrient solutions. There were interveinal chlorosis symptoms on the younger leaves of some plants in the 0% and 5/8% strength nutrient treatments. It is suspected that this interveinal chlorosis was due to iron deficiency caused by the increased substrate pH. It is concluded that the nutrient solution concentrations typically used for potted gerbera production in commercial greenhouses at the final recirculating subirrigation conditions, can be safely reduced by at least 0% without adversely affecting crop production. Nutrient salts accumulated in the top section of the growth substrate under all treatments levels; however, no phytotoxic effects were observed. No differences in water observed amid the various nutrient levels. Fertilizer inputs were reduced in the 0%, 5/8%, and 0% treatments by 4%, 5/8%, and 0% respectively, relative to the 00% treatment. After weeks under recirculating conditions, the qualities of the nutrient solutions were still within acceptable limits.'''",191.0
"'''Blocks-World Management that is playing a far vital role in the development of Artificial expected to be constructed in this project. The management should be an interface between user and blocks-world so that all the commands from user can cause the specified actions among the elements of blocks-world. Some AI concept should be involved into the operation of making structure and search method. In this report two methods are implemented in C+ to establish blocks-world management, one is trying to build a dynamic blocks world and operate objects in it and the other focuses on the search method for some specified blocks world. Unfortunately, so far, this search method can not be successfully combined into the blocks world management programming, but the research work associated with the effort on them are illustrated in this report Method and ImplementApproach In the Blocks World management, the user is allowed to dynamically add objects to the blocks world. The Matrix which is of type block is made to store and display the blocks. The line stands for the each stack and the row stands for the height of each stack. Each block in the matrix has ID number, color and shape. When a new block is added in, it will be given an ID number with its specified shape and color then put into the matrix associated with the ' aimed object can be put into the ideal position through 'tablestate->statematrix = tablestate->statematrix;' and a searched space found by the following method: Based on the roughly mentioned basic function above and some other in the programming, basic dialogue between user and blocks world is constructed. More details about the programming can be checked in the code list. The state machine is set to allow user to choose two communication modes, one is building blocks world and the other is moving objects in the blocks world depending on the user's command. When the input command can not be implemented via one step, which means 'stack' and 'unstuck' can not be operated directly, the search method should be called to figure out a 'path' to access the target. In the approach, a novel search method is discussed. Approach This search method only concentrates on how to figure out the optimized path from one state to another state. Probably, it can not entirely follow Blocks World specification, but it can be applied in the search part to figure out the best way to get to the desired the state. Three blocks state is taken as example to demonstrate its idea. Totally, there are 3 states for blocks world, they are list in the figure and one state that all the three objects are laid on the ground that is called state zero. From left top to right bottom, they are named as state one to state twelve. Also, if one state can be transferred from another state via only changing one object, the relationship between these two states is set as. The relationship between each state are evaluated by this method, therefore put all these results into a matrix as displayed in the figure. The paths between each state are showed in this matrix, so the question is transformed into searching shortest way on the graph. The top left corner of the matrix can be taken as the current state, in the mean time the most bottom right corner is the desired states. How to find out the path between these two corners should be considered by the search algorithm. Therefore, breadth first search is engaged into the algorithm. In the searching procedure, all the traveled states are put into a linked queue for back track. The pointer to the rear is set here, and in 'void EnQueue(DLinkQueue &Q,PosType e)' the rear point is connected to the node through The breadth first search is applied in the loop of 'while(!found &&!QueueEmpty(Q))' at 'bool ShortestPath(int matrix, int m, int n, Stack &S)' function. Then the searched shortest path is pushed into a stack. More details about it can be seen in the code list. However, this method can not be embedded into blocks world management algorithm so far, because the approach how to let algorithm dynamically establish the matrix to cope with a variety of blocks states is still being thought about. Moreover, how to make algorithm put selected state and desired state into top left corner and bottom right of the matrix automatically is another important problem. ConclusionIn this project, some AI concepts are applied in a practical AI planning topic. Breadth first search method and depth first search method are utilized in this project, though part of them are not very successful so far.'''",196.0
"'''The patient was brought into ambulance six weeks ago, following a fall in the street. History All relevant information gathered from the patient about the presenting illness, co-existing problems, current treatment, significant past medical history and the social and family background. The patient's view of the nature of the problem and their expectations for treatment. PC Patient had a total of three falls in one day, after the third fall was brought into hospital. HPC Had started to have falls two weeks prior to admission. Associated with the fall there was no loss of consciousness or dizziness. There was no weakness down one side of the body, or any headaches prior to fall. No urinary incontinence during fall. No fits were associated with the fall. PMH The patient stated that they had not been admitted to hospital previously and had not undergone any operations. The patient does have hypertension and this is controlled by medication. The patient did state that three months ago his GP told him that he had suffered a stroke, but he was not aware that this had happened until informed by his GP. Mr does not suffer with diabetes, Ischaemic heart disease, Asthma. He has not had epilepsy, myocardial infarction or rheumatic fever. Family History Mother died aged 3 cause not known. Father was a miner and died of emphysema. His brother also suffers with hypertension. Social History The patient lives alone in a terraced house, he can manage the stairs with some assistance now that an additional stair rail has been fitted. His wife died in and he has no children. His brother, cousin and neighbours provide social support and help out with domestic tasks. Mr is a retired postal worker. Smoking - 7 year pack history although has not smoked since admission to hospital. Alcohol - minimal intake - unit/week Medication Asasantin T PO combination of aspirin and dipyridamole taken as secondary prevention of ischaemic stroke and transient ischaemic attacks. Demeclocycline 00mg PO taken for hyponatraemia resulting from inappropriate secretion of patient also has a history of anti-hypertensive medication. AllergiesMr has no known allergies Systems ReviewCVS No chest pain, oedema or palpitations RS Cough present, productive sputum not seen, No Haemoptysis, wheeze, or dyspnoea GIT No Nausea and Vomiting, Significant weight is a possibility as smoking is a risk factor. The falls could be cardiogenic in origin, such as atrial fibrillation which would mean that there is a decreased amount of circulating oxygen in the blood. The patients antihypertensive medication may be too high causing him to become hypotensive, low blood pressure can cause falls especially when rising from sitting. Mr may be suffering with poor coordination and balance ether due to a cerebellar lesion or a neuromuscular condition. As the patient is on a drug to correct his electrolyte imbalance this could be the origin as his falls, hyponatraemia can cause a fall. Other causes of falls which are not suggested by the history but may need to be checked are poor vision, poor fitting shoes, drugs, alcohol, epilepsy and Parkinson's disease. For this patient upon examination, particular signs to be looked for are irregular pulse, low blood any other cause that still needs to be considered at this stagePositive signs noted upon examination were pallor in the conjunctiva, this suggest anaemia which is a common cause for a fall in the elderly. The pulse was regular and so atrial fibrillation is not the cause in this case. Postural hypotension is still a possible cause as this could not be tested properly in the examination. The mini mental examination demonstrated that this patient was very confused and possible was suffering with dementia, it should however be noted that this is very crude test especially in someone who has been in hospital for some time. Most people lose a sense of what day it is when admitted for long periods. Multi infarct dementia can not be ruled out. Significantly the patient was cachexic, with a persistent productive cough and central cyanosis. In light of a 7 pack year history a carcinoma of the lung could be present. There is a small cell carcinoma of the lung which is associated with the syndrome of inappropriate secretion of this in physical, psychological and social diagnoses for this patient: Anaemia Postural hypotension, the patients anti-hypotensive medication was too high further aggravating the falls Transient ischaemic attacks and multi infarct dementia Lung carcinoma and further investigation, the patient was identified to have a small cell carcinoma of the lung, secreting ADH and causing an electrolyte imbalance. The cancer had already spread to the mediastinum and pericardium and so the patient was not suitable for surgery. Mr was aware of his diagnosis but would not acknowledge the severity of the condition. He was very distressed being kept in hospital and wished to have no treatment for the cancer but would have treatment for his electrolyte imbalance. As Mr wishes to go home to die, at present he cannot cope alone and so would need a palliative care package to be arranged in the community. Even though this may be difficult to achieve it is probably the best course of action for the patient as he will most likely continue to become more distressed and depressed in the hospital. Management Use the framework of RAPRIOP to structure your proposed management. Refer to the guidelines to the writing of portfolio cases for the details of the issues to be addressed under each heading.The patient needs treatment for his anaemia and close monitoring of his electrolyte imbalance. His anti-hypertensive medication should be reduced to prevent further aggravation of the falls. Palliative care package should be arranged Every effort to allow Mr to go home as he is very distressed in hospital should be made; social services may be of some help with this problem. Impact on your learning Describe what you have learnt from this caseThis case has given me experience of taking a history and examining a confused patient, it has introduced a condition which I was not aware of previously and shown me that not every patient will want all medical interventions possible.'''",203.0
"'''Human resource planning is of crucial significance to an organization for formulating and implementing strategy for achieving its goals. For the past twenty odd years, it is being seen that organisations are trying to match the characteristics of their people with their business an organization tries to attract a pool of qualified candidates who would be suitable for a job vacancy created in an organization either due to an employee leaving the job or due to expansion of the organization. Sometimes, the organization fills the vacancy from its own pool of employees, but most of the time the organization seeks employees externally. (Schuler and Jackson, 987) Organizations market or 'sell' their jobs so that they are able to attract sufficient candidates for the position created in their organization. Out of the large number of potential candidates a small number are short-listed or interviewed for the potential position. The best possible candidate is made the offer of that position. This process ends only when the candidate has accepted the offer made to him by the organization. Recruitment and selection are not different from each other but are intertwined. However, they can be differentiated saying that recruitment involves finding or attracting candidates for a particular job whereas selection consists forecasting or estimating which candidate will prove to be most valuable to the organization in the present and in the long-term. (Wright and Storey, 997) NEED OF AN HR STRATEGYGratton talks how various organizations create business strategies independent of the human resource department. The article says that usually business strategies are 'handed down' to HR professionals for mere implementation. This, according to her, happens due to lack of representation of the HR function at the Board level, which does not create initial integration. This one-way process can also be attributed to the thinking that members of the HR function have restricted business awareness and they are fit only for a 'clerk of works' operation rather than an 'architect' role. (Tyson and Fell, 986 quoted in Lynda Gratton). This behaviour leads to lack of functional synergy while creating 'strategic imperatives' and the 'implementation process', leaving the HR function to develop systems oblivious of the business objectives. In this way the HR function cannot achieve, create or sustain the continuity by which initiatives build upon each other. Instead these initiatives 'bump along' the bottom, losing 'momentum from one to another.' (Lynda Gratton, 994). In order to give HR strategy a 'grounded frame of reference' it is important for it to be aligned with the business strategy. A strategic approach takes into account the organisational goals and objectives. Its main aim is to align various key elements of HRM like recruitment and selection so that they function in tandem with other functions to achieve organisational goals. MATCHING STRATEGY AND HRMAligning business strategy to HRM is a well-researched area and there are a number of descriptions, definitions and models explaining how HRM policies - in particular those related to functions like recruitment and selection, training and development etc. should 'fit' a particular management style or strategic in terms of external and internal fits, whereby an external fit recognizes the need to 'employ and deploy labour' (Torrington, Hall and Taylor, 005/8:14) against future needs while internal fit supports people policies which are 'mutually reinforcing' (Torrington, Hall and Taylor, 005/8:16) and are applied consistently. Miles and Snow in1984 developed another widely used fit approach of matching HR strategy to business strategies. Here, they used a contingent/open approach and categorized organizations into four strategic types: Defender, Prospector, Analyzer and Reactor. They defined 'defender' to have a narrow but stable product line an d having a functional structure so there HRM strategy would be to build human resources. Also, 'defenders' involve themselves in extensive skills training programmes because of their narrow product lines. In contrast the 'prospectors' are more adventurous insofar these organisations seek new products and market opportunities to do business in. So they employ sophisticated recruitment techniques and less training, emphasis being on acquiring skills. Similarly, 'analysers' who operate in both stable and dynamic environments need the right allocation for their human resources. i.e. which ones should be put in the stable market environment and which ones in the dynamic ones. Miles and Snow developed guidelines for proactive human resources management systems that tap an organizations full complement of human capability whilst supporting the formulation of new business strategies. Based on their work Rousseau developed a more exhaustive model to demonstrate the linkage between business strategy and HR practices by developing 'buy strategy' and 'make strategy' wherein organisations who are 'defenders' use the 'make strategy' to develop their resources and 'prospectors' use 'buy strategy' to acquire human resources. Schuler and Jackson further linked HR practices to the three competitive strategies described by Michael Porter in 985/8. They described how Porter's three strategies of Innovation, Quality enhancement and Cost reduction could be achieved by linking them with various human resource practices like Job definition and specialization, reward, appraisal and performance management etc. Thus, for example while innovation requires high creative talent in the organisation, hence jobs require close interaction and coordination among individuals whereas; cost reduction would require repetitive and predictable job behaviours. While deciding the human resource practices are to be linked with business strategies, organizations generally choose from 'six human resource practice menu' (Schuler and Jackson 987) that concern different aspects of human resource management. The policies, practices and strategic issues of one of these aspects that is recruitment and selection would be discussed in the next section. STRATEGIC RECRUITMENT & SELECTIONThe issues to be taken into consideration as far as strategic recruitment and selection are concerned can be understood well when we take an organisation in question. Recruitment and selection of human resources certainly have a very important impact on how well an organisation can successfully materialize its business strategy. Also, at this stage organisations face an important question of whether it should develop its existing employees in such a way so as to fulfil its vacancy requirements or should it try to acquire or hire human resource from outside the organisation. In order to build a sound staffing policy organisations develop guidelines around these two major approachThe traditional approach to recruitment and selection gave very little or no importance to business strategies. It downplayed the link between staffing decisions and an organisation's business strategy. The aim was to find a person who could fit the job perfectly and to recruit people who could perform the best in the given job. The use of this approach was also seen extensively during the First World War, where cognitive ability tests were used by the armies of US, UK and France wherein soldiers employed were simply placed in a job where they were best suited without taking into consideration the strategies formulated by the army. This was a very successful practice and became extremely popular among organisations other than the army in a short span of time. While this approach may have benefited organisations in several ways but it is considered non-strategic because it completely ignores business strategy. A business strategy has to be taken out from the contextual position it was placed in traditionally and put in a prominent place. The following two strategies of staffing as strategy implementation and staffing as strategy formulation were developed thereafter and emphasize towards recruiting and selecting within a strategic framework. Staffing as strategy implementation To be successful, an organisation is forced to take a strategic approach to recruitment and selection especially in the long term as following the traditional approach is not practical in the present scenario with the heightened competition. This approach sees strategy as fixed and employees as a variable aspect. This approach focuses on the fact that every business has a business strategy, which remains fixed. Employees have to be recruited and selected based on how well they will be able to perform their jobs in order to be successfully able to implement the fixed business strategy. In such an approach, the policy of business must be to design a recruitment and selection process that will be successful in fishing out employees who suit the organisation so as to materialise its business strategy profitably. This model can be easily applied into a real organisation situation. First, the organisation should develop an organisational strategy. Then it should find the organisational skills, as well as abilities and knowledge required in order to implement its business strategy. Finally, it should recruit and select only those candidates who are fit in the desired criteria.For example, if an organisation has to survive competition in the market, its strategy will be to make sure that its products are low-cost, better quality, and innovative in comparison to its competitors. Now, for it to achieve this, the organisation should employ people who have a broad outlook, well aware of the markets and quick learners. When an organisation organises training programmes, industrial visits etc. it expects its employees to be enthusiastic and grasp things the recruitment and selection policy aims at staffing candidates who are academically sound and are willing to experiment. This approach can be termed as strategic and can be successfully implemented in the context of the organisation. Staffing as strategy formationIn a competitive environment, an organisation constantly faces a number of threats from its competitors. Also, any business provides varying opportunities that need to be exploited at the earliest in order for an organisation to flourish. To completely utilise its human resources, organisations use this approach wherein the capabilities of candidates to be recruited are considered. The primary concern here is to match the qualities of candidates with the business strategy of the organisation. This approach sees employees as a variable aspect. Also, another major difference here is that strategy is also seen as a variable aspect unlike the previous approach. (Lengnick-Hall, 988) The business policy here is to recruit employees based on their personal qualities and traits like knowledge, skills, abilities and other characteristics. (KSAOs). Hiring on a 'value-added' (Kossek and Block, 000: 3.6) basis will enrich the organisation's human resource pool hence, making it easier to implement not just a single business strategy but, a wide range of business strategies. This approach can be pretty well understood taking the example of sports. When an athlete is selected for a team, no specific criteria are set about his/her qualities or characteristics. When a pool of potential athletes having the best KSAOs are found, strategies are made based on all their characteristics. The inference that can be drawn from this is that though an organisation can recruit candidates with a wide range of KSAOs it is not possible to foretell what business strategy will be formulated with a particular set of KSAOs. Another important policy within this approach for an organisation is to give equal priority to staffing decisions alongwith decisions like allocation and acquisition of funds. Finally, the organisation should make human resource an important part of all its policy decisions making sure that when a strategy for business is formulated, it is not too rigid. When employees are hired in an organisation, the organisation should be flexible enough to be able to make them a part of the organisation so that they adjust to its environment in the shortest time and contribute towards its success. For example in Becton the 'make' strategy. This is a slow process and undertaking this strategy organisations have to make sure that employees are eager to learn and willing to develop the required KSAOs that will enable them to become an asset to the organisation. By applying a pure staffing the 'buy' approach the organisational policy changes to hiring those people who are qualified and experienced in such a way that they successfully start yielding profitable results for the organisation as soon as they join it. This policy is generally undertaken by organisations that face a lot of competition in the market owning to which their recruitment and selection strategy hires people who mesh well into the organisation as soon as they arrive. While the 'make' approach is best suited for jobs that require employees to be less dynamic, the 'buy' approach needs people to be extremely dynamic as employees in this case have critical jobs in the organisation. The most suitable approach would be a proper blend of both the strategies so that an organisation can benefit dually. CIRCUMSTANCES FOR STRATEGIC RECRUITMENT & SELECTIONManagement StyleManagement style is a method by which employees are managed based on a set of policies, procedures and principles that guide the intentions and outcomes of the organisation as a whole. This is simply based on what people claim to do and what they actually do, also at the same time what is experienced or felt. with 'contracts manager' (personnel management function providing legal, bureaucratic, etc. services) would decline. (Tyson and Fell 986, Tyson 987) David Ulrich, professor of Organizational Development at University of Michigan, describes how the role of a 'change agent' and a 'strategic partner' are strategic in nature. For the role of 'change agent', the HR role is to facilitate change occurring in organisations due to varying business conditions like globalisation. This is done implementing efficient and flexible systems throughout the various departments in an organisation. For a 'strategic partner' role, HR ensures that its policies and practices are in sync with the organisational strategy. A capacity to accomplish that strategy is developed and implementation time is minimised. Also, management is provided with valuable and current information essential for strategic of OrganisationWhen employing people for a High Involvement, it can be said that each organisation must make its recruitment and selection process quite dynamic and strategic as today's business attributes - such as shortened product life cycles, sophisticated technologies, shifting customer demands etc. not only demands the selection of the best candidates, but of those candidates who fit in an organisation's overall objectives.'''",205.0
"'''Wilkinson; a London based Publisher purchased Hoopoe publishing in May 004 for.5/8 million. As a result of the acquisition questions have arisen regarding its integration into Wilkinson's current organisational structure which will also inevitably affect the businesses culture, motivation strategies and management of change. They also need to consider the necessity of relocation. The acquisition of Hoopoe will combine the resources of the two businesses to create an entirely new business. If the merger is to make economic sense for Wilkinson then according to Atrill 'the present value of the combined businesses should equal the present value of the future cash flow of both business's plus a gain from the merger'. Analysing Hoopoe's product portfolioHoopoe currently have a healthy and well established mix of products each varying in the amount of success they've achieved so far as well as the amount of market share and market growth that they all acquire. Presenting Hoopoe's current products on a dimensional scale representing industry growth and industry share then a corporate portfolio of the products success can be analysed If the current products of Hoopoe are applied to the Boston matrix it creates a visual aspect as to which products Wilkinson would like to develop. The Online Revenues currently have a high margin and strong growth potential. They are classified as a typical 'Star' in relation to the Boston matrix because they are creating revenue and also have the potential for further expansion. The sales to customer facing companies such as AOL and Tiscalli will need further investment as these distribution channels are internet based. With investment in a strong growing area such as the internet there is good future opportunity. As the industry matures less investment will be required and it will transform into a useful cash cow if successful. The product has been placed towards the bottom of the 'star square' as the growth potential is high and will continue, but it is also to the left as the market share is currently strong with a high margin in the market. When analysing the success of the Print products it seems a good area for development due to good growth prospects and opportunity in thus market. Naylor states that 'Money from the 'cash cows' provides investment' into the product. The products are placed to the far left of the 'question mark square' because they already have a good market share in the UK market however they are not a star because they still have potential to expand in the US which is not certain to be a success. The 'cash cow' in Hoopoe's portfolio is the market leading Children's Encyclopedia. This requires very low investment and is an established product that has succeeded to its fullest potential. As long as Wilkinson takes the option of keeping the Hoopoe brand then it will provide surplus cash for the other products as it ages. However, it may require some investment if a competitor were to challenge the brand. The product is placed to the left of the square as the share is at its highest but towards the bottom as an established product growth is low. The final product for Hoopoe is a 'Dog' which are the CD-ROM'S, this is due to the recent increase in online products creating less demand for CD Rom's. If Wilkinson is prepared to then they 'could create a retrenchment policy and cut all of their losses with these products to cease the sales' (Naylor,. However, there is still an indication that if investment is added in the correct way with diversification into the educational market then expansion may again be possible. Hoopoe has a very strong mix of products some with more potential than others. This is healthy for a business and from a financial point of view there is a balance within the organisation. The 'cash cow' can create revenue for investment in the stars but also a return surplus for the businesses shareholders. The use of the matrix suggests the opportunities that will arise if Wilkinson decides to merge both companies' portfolios. If the combined two have too many dogs and question marks then the cash cows may fail to be enough investment to cover them all. However, it would suggest from Hoopoe's range of products. Integration options Wilkinson have for HoopoeThe option that Wilkinson needs to consider is whether or not to keep the Hoopoe brand as a separate entity from Wilkinson. By doing this they will be following the strategy that Pearson took with Dorling Kindersley. If Wilkinson chooses this option then the market leading product that Hoopoe own; the Children's Encyclopedia will remain branded in the way it is now, which is important from a recognition point of view. When Wilkinson paid for Hoopoe they also paid for its 'Goodwill' although not a tangible asset they have paid for the right to use the established brand that consumers have become loyal to. 'By purchasing an existing business the necessary specialist managerial and technical 'know how' is already acquired' (Atrill, 003). When John Murray, a small independent acquired by Hodder Headline Murray's prize-winning educational list retained as a John Murray imprint within Hodder. They retained its identity and became a 'separate autonomous division'. Employees of John Murray stated they were saddened over 'loosing their independence'. It also meant the established list was well known by consumers. (ProQuest, The Guardian, May 1 th 002) Wilkinson's other option is to apply all of Hoopoe's assets and merge them into the Wilkinson brand name. This will involve full integration and simply put to use the skills and knowledge of Hoopoe and adapt accordingly. This however is more likely to be damaging as creating successful large scale integration of this kind disrupts the organizational structure as well as its culture. It will also mean unfavourable redundancies with duplication of the similarly skilled staff and relocation from the Oxford and Aylesbury branches. This as a result will cause problems for employees affecting the culture of the two businesses as this disruption similarly occurred with Taylor & Francis' acquisition when the employees anticipated expiry of their office's lease in London. The staff at Taylor & Francis were 'left reeling after they learned of a move to Abingdon, Oxford' after the merger with Informa Group. Some staff were offered redundancy packages or relocation but staff were not expected to relocate as they complained 'why would you change your whole lifestyle, when there is no guarantee of a job in a years time?'(The Bookseller, //004 Issue 118). Therefore with evidence of failed integration of this kind Wilkinson will risk loosing employees. However, there is the possibility of integration problems following a successful bid. There is likely to be a shift in the organisational structure as with any expanding business especially with more staff a larger business needs a successful structure that all employees are aware of. Also with mergers there will be an increase in management which may clash and rivalries may occur especially when the culture of the business's vary. Culture is a very important aspect for Wilkinson to consider. Evidence shows that 'less formal working practises are favoured by staff and are more likely to lead to extreme satisfaction' (Herzberg, cited in Handy 993) Assessing Hoopoe's financial situation will indicate if Wilkinson paid a fair price and signify implications for the future running of the companyHoopoe's profit and loss account shows that the gross profit is at its highest. Their turnover and sales have increased whilst their expenses and cost of sales decreased which is a good indication that investment is getting a return which is also indicated by the operating profit. This deducts expenses from the gross profit and 'gives a useful comparison for trading performance irrespective of what financing structure is in place' (Atrill, 003).Although the operating profit is minus it has increased since 002- whilst the expenses have decreased and will continue to do so as the need for marketing lessens, again suggesting that investments have been made in 002-. The gross profit margin also indicates that they are doing better than before as for the years 001- and 002- it was 0% and has subsequently strengthened to 5/8.% in 003-. Wilkinson also needs to take into account Hoopoe's fixed and current assets as well as any liabilities. The fixed assets including the goodwill are.m and the current assets value at.m equalling assets of. m. However, they also have creditors debts a total of.m. With fixed and current assets Hoopoe have the ability to pay their creditors however they also still only have an operating profit. times more their sales. (The Bookseller, 1/5/8/002, issue 05/82). This is strong evidence that Wilkinson has paid a very good price for the electronic and online skills they are acquiring through the purchase of Hoopoe. The low operating profit may also increase of Wilkinson take the option of 'paying off' Hoopoe's creditors as debt within a company can also prevent a good operating result. When Wilkinson paid.5/8m for Hoopoe they would have needed to take into consideration that their operating profit for the year 003- they also have a number of assets and minus their creditors still totals at.m. They must consider that although Hoopoe is not currently making a profit they are doing well they are beginning to be more successful. Integration of Hoopoe may cause issues for motivation, teamworking and management of changeThe integration of the two businesses is likely to cause uncertainty amongst the Hoopoe staff for a number of reasons. They are most likely to be resistant to the change due to the fear of unknown, the break in their routine and reduced control that they would have been used to within a smaller organisation. With regards to change in management they are likely to feel that redundancy could be an option for them. This is likely if Wilkinson adopt Carlton Books' strategy as they chose to reduce their staff by 0 within an office of Wilkinson's management must address theses questions. According to Handy a change such as this will affect their psychological contract and cause dissonance. If Wilkinson adopt a more flexible working structure then they will allow Hoopoe's staff more responsibility. However, this demands a strong culture and heavy socialisation in order to achieve motivation. According to Herzberg's Hygiene factors the satisfiers and dissatisfies need to be correct and in place before the employees can be motivated. 'The hygiene factors are in place in order to prevent dissatisfaction and allow motivation to lead to job satisfaction, job security and good working conditions' (Handy, 993). The expectancy theory by Vroom suggests that the strength of motivation will depend on Hoopoes' staffs new expectations of work outcomes and rewards. A high level of feedback from the managers will bring high confidence and friendly attitudes and inevitably resulting in feeling better motivated. HR issues resulting from the takeoverAccording to Mullins 'HR is clearly the most important asset of any organisation and a resource that needs to be managed well'. With the merger of the two companies there will no longer be an effective organisational structure, therefore will need to be changed to fit the new employees with new recognition of their needs and expectations. There will be the need for a new staffing structure with the appropriate new people. As HRM is involved in recruitment, selection and induction with the takeover they may feel that they need to make some redundancies as it maybe that there are too many employees in one particular area. However with the diversification into electronic publishing they may feel that it that training of the current Wilkinson staff is more appropriate. 'Training will improve knowledge, skills and change attitudes which is one of the most important motivators' (Mullins, 002). HR also has a very important social responsibility.Staff are a crucial but expensive resource Mullins states that 'In Order to sustain economic an effective performance it is important to optimise the contribution of employees to the aims and goals of the organisation'. Performance appraisal is also very important as it will review the performance of both Wilkinson and Hoopoe staff. However through this system members of the organisation need to know exactly what is expected of them and then potential problems can be identified, it establishes the system and addresses any questions. 'Above all, the importance of HRM practises in creating and reinforcing the corporate culture need to be recognised in order to assure that desired changes in structures and strategies can be implements' (Schneider and Barsaux cited in Mullins). ConclusionAfter evaluating the acquisition of Hoopoe by Wilkinson it is clear that there are a number of financial and human resources issues to tackle. They have options that they must consider regarding Hoopoe's products and its employees. The optimum for Wilkinson is to see that the objectives and purposes of the individual, the group and the organisation all coincide and to achieve the correct balance. Wilkinson is making a good investment through the acquisition especially with the expansion of electronic products which is what Wilkinson wanted to diversify into. Hoopoe's databases are already coded print products and have the ability to branch into electronic publishing. With expansion and investment this is a good opportunity for Wilkinson and is likely to prove successful. With the combined resources of both companies they can work together to eliminate competition which will lead to quicker exploitation of the strengths and weaknesses of each business.'''",207.0
"'''The assumption that a gap existed between the theory and the practice in the social position of women between 5/800 and 700 is a contested one. Margaret Ezell argues that the expectations of female behaviour and duty in society did infact closely match the reality of women's experiences. Looking at contemporary literature and popular opinion, Ezell concludes that contrary to many historians who view the prescribed position as restrictive and misogynistic, both scripture and conduct books infact highlighted female capabilities and praised women as partners in life. 'Differences between men and women are merely superficial.women are as naturally capable as men of reason, wit and.government.' However, feminists have criticised Ezell for her limited interpretation of the literature she looks at. They argue that advice such as '.it is not that the wife has no mind of her own, but that she deliberately alters it if necessary, to conform with her husbands,' does not counter the view that women were expected to be submissive and were considered inferior to men during this period. Even Lawrence Stone, who argues that patriarchy was at its strongest and its most widely accepted at this time, acknowledges that the role set out for women often differed markedly from the actual experiences of womanhood, due mainly to the fact that the prescribed role was simply incompatible with the realities of life, especially for the poor. Indeed, Ralph Houlbrooke argues that the '.theory was simply unworkable.' with the realities faced by contemporary women. Pierre LeMoyne, 'The Gallery of Heroick Women', cited in M. Ezell, The Patriarch's Wife: Literary Evidence and the History of the Family, (New York, 987), p.4. 'Feminist school of Phallogocentrism' who criticise Ezell, cited in Ezell, The Patriarch's Wife, (New York, 987), p.7. Ezell, The Patriarch's Wife, (New York, 987), p.0. L. Stone, The Family, Sex and Marriage in England 5/800 - 800, (Middlesex, 977), p.39. Ralph Houlbrooke, The English Family 45/80 - 700, (London, 984), p.06. In this essay I am going to argue from a standpoint assuming that a gap between the theory and the practice in the social position of women in early modern England did infact exist. I will argue that this gap existed despite both male and female attempts to keep within it, due both to its unrealistic expectations compared with the actual lives women led, and the dualities and contradictions within it. I will argue that due to three broad and overlapping areas: economic and personal factors, and a contradiction within the role which expected servility but also demanded command and power, women could not live out their lives within the boundaries of their expected social positions. The position women were to occupy in society was set out to the population through a number of mediums. Scriptural references in homilies and religious services put emphasis upon '.the procreation and religious education of children, the regulation of sexual activity, and mutual comfort and support.' A distinction was made between suitable female and male duties; 'The husband was held to be the superior partner, the wife the subordinate and inferior.her foremost duty was obedience.' In the advice guides published, women were seen to be 'material and passive.weak in body.and unfitted for work or public life.' As such they were expected to remain in the private sphere, '.unquestioningly obedient to her husband, accepting husbandly reproofs meekly.bearing her husbands faults.accommodating his various moods and on any breach being the first to seek reconciliation.' Satires and other anti-female publications played upon the popular images of women as sexually insatiable, nagging scolds, as well as playing upon the images of marriage as an end to freedom and fun, and a life of supporting a wife who would stop at nothing to get her own way. Whether popular opinion about women was more influenced by religion and advice guides or by satires is hard to tell, and indeed the opinion of the female role and marriage differed between men and women and according to place in the social order. It is probable that popular opinion took on board a mixture of both views as well as referring to personal experience of female figures and their behaviour. Finally, the expected social position of women was expressed by the authorities through the law; 'nowhere did the wife appear more completely subordinate to her husband than in the common law'. Women were never a homogeneous group; the law and indeed general opinion differed with different women; single, married, widowed and spinsters. However, in the eyes of the law, a woman belonged to the man in charge of her whether that was a father, brother or husband. Widows enjoyed a certain amount of freedom, however along with spinsters were so marginalised socially, for being 'master-less', and economically, with only a few poorly paid trades to work in, that they had very hard lives. Already, with this simple description of the expected social position of women it is possible to see some of the contradictions within it; for example, that women were sexually uncontrollable, yet the moral guardians of society. Susan Amussen argues that this contradiction is one of the main reasons why the wish for '.clear subordination of wives to husbands.was never fully realised.' Houlbrooke, The English Family, (London, 984), p.7. Houlbrooke, The English Family, (London, 984), p.7. Ezell, The Patriarch's Wife, (New York, 987), p37. Martin Ingram, Church Courts, Sex and Marriage in England 5/870 - 640, (Cambridge, 987), p.29. Houlbrooke, The English Family, (London, 984), p.00. Susan Dwyer Amussen, An Ordered Society: Gender and Class in Early Modern England, (New York, 988), p.15/8. Amussen, An Ordered Society, (New York, 988), p.15/8. The gap between theory and practice in the social position of women in early modern England was certainly influenced by the economic realities they faced in their everyday lives. It was often necessary for poorer women to marry quite late; the time before marriage was spent working in service adding to the family purse. Girls had to leave home and live away from their families often giving them a taste for relative freedom, economic independence and a knowledge of their personal capabilities. Even after marriage it was often necessary for women to make economic contributions to the family; supplementing the low wages her husband was paid. Keith Wrightson argues that these female supplements to male wages were crucial to survival even if they did somewhat undermine the official female position in society. Susan Amussen points out that the gap between theory and practice actually lessened depending on the importance of the economic contributions of a wife. Some women did not need to compromise the submissive, passive role by economic contributions such as bartering at market or looking after the estate whilst a husband was absent. Although women rarely strayed in to their husbands' role once he had returned, it was essential to economic survival that they could and would perform his tasks even if this meant female and domination and authority. Men wanted their wives to be '.both subordinate and competent.and willing to accept that whatever a man did was work and whatever a woman did was her duty'. 'Women's independence and autonomy were critical to their success as wives and mothers.the contradictions between women's economic roles and their expected subordination were so severe that they posed a problem to the most carefully conforming wife.' Keith Wrightson, Earthly Necessities: Economic Lives in Early Modern Britain, 470 - 75/80, (London, 002), p.3. Amussen, An Ordered Society, (New York, 988), p.20. Houlbrooke, The English Family, (London, 984), p.07. Anthony Fletcher, Gender, Sex and Subordination in England 5/800 - 800, (London, 995/8), p.5/84. Amussen, An Ordered Society, (New York, 988), p.21. Women were often needed in the public sphere, and even if not playing leading roles their actions still conflicted with the domesticated submission part of the role, although perhaps fulfilling the obedience part. Diane Willen argues that pauper women were actively recruited by local authorities in to the public arena. Although the work women were doing for local authorities was an extension of their traditional domestic duties; cleaning and caring, 'it questions.the existence of separate private/public spheres in the early modern period'. Both the poor women being employed and the 'local patriarchal political authorities' employing them gained economically from this arrangement. Women could earn a small wage and authorities gained a willing, cheap labour force; both parties were forced to revise women's official social position for economic gain. Widows were also women with access to the public sphere; they could by law take over some of their husband's trades or estates upon his death. Although often poorer widows were left very economically vulnerable, some were able to maintain themselves successfully; indeed advice guides warned men against marrying widows as they tended to be 'harder to tame' having already tasted and achieved economic independence. Diane Willen, 'Women in the Public Sphere in Early Modern England: The Case of the Urban Working Poor', Sixteenth Century Journal, 9,, p. 5/89 - 75/8. Willen, 'Women in the Public Sphere in Early Modern England', Sixteenth Century Journal, 9,, p.5/89. Willen, 'Women in the Public Sphere in Early Modern England', Sixteenth Century Journal, 9,, p.60. Anthony Fletcher, Gender, Sex and Subordination in England 5/800 - 800, (London, 995/8), p.74. The second set of factors which made the social position set out for women in early modern England impossible to fulfil even if they tried, were personal factors. By this I mean factors which come about naturally as a consequence of marriage; i.e. spending a lot of time with someone, growing to know them very well and loving them. Love and caring were seen as very important aspects of a successful marriage, in particular they were seen as part of a husband's duty. However it was well documented in contemporary literature that '.more men betrayed their command through their own fondness than ever lost it through their wives rebellion'. Though caring and affection were viewed with importance; and were often an unavoidable outcome of spending lives together, measures were taken to limit the influence affection had on the social position of women. 'Convention demanded that the wife address her husband with humility and deference.even the affectionate terms love, joy, dear and duck were not appropriate in the mouth of a subordinate.' However it must have been very difficult to maintain a purely master/subordinate relationship especially when feelings of love and affection existed in a marriage. Even the most obedient wife and most masterful husband must have come across occasions when such formal address would have been inappropriate. Thomas Fuller cited in Houlbrooke, The English Family, (London, 984), p.01. Houlbrooke, The English Family, (London, 984), p.01. Laura Gowing argues that the gap between theory and practice actually began during courtship, making it only natural that it continue after marriage. Gowing explains that it was sometimes necessary to deviate from the passive, submissive role of a courting woman. The double standard which existed in terms of male and female sexual morality and the importance of reputation in early modern society made courting quite a difficult process. Women had to use their intricate knowledge of the laws of courting to avoid the many traps which could leave them tied to a poor marriage match or with their reputation in tatters. Often it was impossible for a woman to remain passive during courting, especially if conjugal rights had been granted to a man after the promise of marriage, or pushy parents were disdainful of certain suitors. Often with a little bit of courage and forcefulness, men could be made to keep promises, and by scrutinising the exact wording used in the making of a marriage contract they could be escaped. 'Women could still exercise their power of evasion and refusal.language.gave women the opportunity to broaden the largely passive part allotted to them in the process of courtship.' Laura Gowing, Women, Words and Sex in Early Modern London, (Oxford, 998), p.47. Laura Gowing, Women, Words and Sex, (Oxford, 998), p.48. Other personal factors made the female social position hard to follow strictly; in many cases women's personal capabilities and desires surpassed the prescribed role. Often individual character and temperament sat at odds with the boundaries set out; after all, not all wives were inferior to their husbands and not all husbands' wanted/needed submissive wives. Simple practicalities such as very little age difference between partners, made the expected master/servant relationship, hard to fulfil; a woman with equal or more life experience than her husband could be hard to commandeer. Finally, women's roles and identities within society were not a constant thing, they were much less fixed than men's; as they were already malleable, it was relatively easy to simply revise these identities and social positions further. Houlbrooke, The English Family, (London, 984), p.03. Laura Gowing, Women, Words and Sex, (Oxford, 998), p.31. The final aspect which made it impossible for women to live wholly within their official social position, were the areas of society over which women had complete power and control; morality, reputation and of course the domestic sphere. In marriage and out of it women were to control the sexual activity of themselves and their spouses; adultery was seen as dangerous, putting the established social order in jeopardy, and even too much sex between husband and wife was viewed negatively. Women's control over reputation gave them a certain amount of power over both other women and men; as Samuel Pepys diary shows '.when his wife caught him with their maid.he at once recognised the political significance of the event'. Women could wield the reputation card to expand their limited role and position in society. Gossiping was another largely female activity allowing them to channel pressure on those they felt were morally lacking whether for bastardy, cuckolding or wife beating. Women were called upon to ensure that their men folk were satisfactorily carrying out their duties and this gave them a certain amount of power. For example, if men were neglecting their religious duties as head of the household, a wife could 'take-over' this part of his role even if he was in objection to this. This expectation of wives by religious authorities severely compromised the obedient social position they otherwise instructed her to take. Houlbrooke, The English Family, (London, 984), p.7. B. Capp, 'The Double Standard Revisited: Plebeian Women and Male Sexual Reputation In Early Modern England', Past and Present, 62,, p. 3. B. Capp, 'The Double Standard Revisited, Past and Present, 62,, p. 4. Laura Gowing, Women, Words and Sex, (Oxford, 998), p.7. Houlbrooke, The English Family, (London, 984), p.8. The domestic sphere, often seen as the sight of women's inequality, was infact the one area of society over which women had a lot of control. Rule over servants and the running of a complex household were just some of the tasks women were expected to perform. Other tasks included care and religious education of children as well as total authority in the field of pregnancy and childbirth; 'lay ins' gave women an all female space in which to recover after childbirth. Women were also expected to give their husbands sound business advice and make decisions within the domestic sphere. The fact that these tasks could not be performed without being domineering, active and authoritarian was why a necessary gap existed between theory and practice in the social position of women. Amussen, An Ordered Society, (New York, 988), p.07. To conclude, I have tried to show that even men and women attempting to keep within their official social positions found it an impossible task. I have looked at some of the factors that made this impossible; including the economic realities which meant women's roles had to overlap with men's and forced them beyond the passive, submissive boundaries of their role. There were also personal factors, such as the natural familiarity which grows as a result of married life which made strict adherence to the master, subservient relationship between couples hard to maintain strictly. Finally, there were areas of society in which women held most if not all power, these areas meant that women by necessity had authority which contradicted the submissive position intended for them, as well as giving women power which they could use to renegotiate their limited position. Amussen, An Ordered Society, (New York, 988), p.09. Susan Amussen argues that the attempts of women to remain faithful to their prescribed social position, but failure due to the impractical, unrealistic nature of the position, is shown by women's emphasis on the sexual conduct part of the role; the part that was actually achievable. Faced with the impossibility of the obedience part, women placed greater importance on strict sexual conduct. Where possible women were willing to adhere to their prescribed social positions; helping to maintain the social order so important to early modern society. As Bernard Capp argues; women did not directly challenge the system, rather they worked within it, finding compromises to suit their economic, and personal realities. They also accommodated the features such as commanding, and decision making which went against their prescribed temperament but which were necessary for the domestic success also expected of them. The gap between theory and practice in the social position of women in early modern England should be explained in terms of its impractical economic nature and its contradictory and unrealistic expectations. Amussen, An Ordered Society, (New York, 988), p.22. B. Capp, 'The Double Standard Revisited, Past and Present, 62,, p.9. '''",212.0
"'''Bushmeat is an important source of protein and fat for many rural and urban families in much of central and western the Cameroon Wildlife Aid so continues to be a valuable commodity to many businessmen and women. Specialized restaurants receive deliveries of a range of wild species from approved suppliers despite laws against its changes have yet to be observed. In central and western Africa hunting, and the use of bushmeat in religious ceremonies and for decorative and ornamental purposes has been part of a cultural tradition passed on through well as providing healthy profits for the logging companies. Not only has this industry provided a number of well-paid jobs for many locals but it in turn it has contributed towards a US$ 0 million trade in animal meat, increasing the number of poor people by over fifty placing some limitations on resource exploitation these valuable commodities may soon cease to exist. Further complicationsDue to inadequate implementation of legal policies, political unrest, poor communication and a lack of commitment from officials, so far most conservation efforts have contributed very little towards reducing the use of bushmeat. In March the CITES Bushmeat Working Group published a legislative review in support of their goal to harmonize wildlife laws in central taking into account the prediction that one-fifth of all living species could disappear within the next thirty consumptive requirements for protein will continue to grow. As a result of an unfair and unjust distribution of resources around the world, people in un-developed countries continue to suffer from famine, while mountains of meat go to waste in other countries. Considering the facts it seems unlikely that 'humans needs' will ever be met. With or without bushmeat people will go hungry and wildlife will be eradicated. While the decision to abolish the use of bushmeat in central and western Africa may be an unfavourable option for many local people, soon the privilege of choosing may be eliminated forever.'''",217.0
"'''.What a person is or can be, and does or can do is essentially a function of human well being, within which the factor of indisputable importance would be health. As Nobel Laureate Amartya Sen argues that the 'capability to function' is what really matters for a poor or non poor person, drawing on whom the United Nations 994 Human Development Report asserts the purpose of development as being able to create an environment in which all people can expand their capabilities, and opportunities can be enlarged for both current and future generations. This explains why countries with high levels of income but poor standards of health and education have been referred to as cases of 'growth without development'. Unprecedented advances in human capital have taken place in the last half-century, in both developed and developing countries. The purpose of this paper is to study the relationship between health and economic development through a cross-national empirical analysis by estimating the determinants of health and emphasising on the impact of income and education on the state of health. However the paper is not successful in finding a reverse causality for both these relationships, though studies do show that healthier people earn higher wages due to productivity differences thereby increasing utility by increasing income and raising the return to the economy. Ambiguity with regard to its causal relation with education still holds in reality. In section the paper reviews and discusses plausible findings of prominent economists in this area. Section presents the methodology undertaken for the study, the econometric techniques used for estimating the model and also describes the data. Section provides the empirical results, its analysis and implications. In section the paper concludes with summary of the results, extensions to further study along with suggestions for government policy making.. Literature ReviewThe study of health has been of immense economic, political and social importance. The World Health Organisation defines health as 'a state of complete physical, mental and social well being and not merely the absence of disease and infirmity'. Health has both instrumental 995/8gdpg = average GDP per capita 995/8 to 004gini = average gini index from 995/8 to 004 hiv = average HIV prevalence 995/8 to 004hlthexp = average total health 995/8 to 004imdpt = average immunization against 995/8 to 004immea = average immunization against 995/8 to 004inv = average gross domestic 995/8 to 004le = average life expectancy at 995/8 to 004le95/8 = life expectancy at 995/8lf = average growth rate of total labor force from 995/8 to 004lite = 00 - ilite, where ilite = average illiteracy rate from 995/8 to 004lite95/8 = 00 - ilite95/8, where ilite95/8 = illiteracy rate in 995/8phys = average number of physicians per,00 people from 995/8 to 004pop = average annual population growth rate from 995/8 to 004pute = average pupil-teacher ratio in primary education from 995/8 to 004safew = average improved water 995/8 to 004 sanit = average improved sanitation 995/8 to 004smkng = average smoking prevalence 995/8 to 004trade = average share of trade in GDP from 995/8 to 004urbpop = average urban population from 995/8 to 004The popular indices used for measuring health under nutrition based efficiency wage theory are per capita caloric intake, body mass index and so on. However for cross country analysis, there are two kinds of data which are frequently used, life expectancy and mortality rate. Life expectancy has wider thus is more appropriate and shall be used in this the average literacy used as dependent variables. The data has primarily been obtained from World Development Indicators, the World Bank database. Few of the variables for which data was obtained from the United Nations Statistics. All data was accessible through the Economic and Social Data Service International website. Although the databases contained data for over 00 adjustments for missing observations, the sample size reduced considerably. The regressions are based on data averaging over 0 years from 995/8 to 004. It is extremely costly and time consuming to obtain social indicators, which explains their scarcity. Some of the indicators are collected only once in every couple of years, also due to the fact that these do not change much within a year. Thus taking averages reduces measurement error at the same time enables one to get maximum data. The presence of heteroskedasticity is tested using the pure form White Test for Heteroskedasticity with cross terms, wherever possible. If the null for no rejected at the 0% level of significance, heteroskedasticity is a the White's Heteroskedasticity consistent standard errors and used as a remedial the presence of outliers of influential for normality which tests the joint hypothesis of the skewness and kurtosis equal to and respectively. If the p value of the JB statistic is sufficiently high and the hypothesis is not rejected, the residuals are normally distributed. Ideally the JB statistic should be used for large sample sizes. To test how good the fitted model is, besides using the above mentioned tests, certain basic criteria are used. Whether the signs of the estimated coefficients are in accordance with prior expectations; whether the relationship is statistically the explanatory power of the discussed. Before the interpretation of these results the statistical tests that need to be performed, on the estimated OLS and its residuals, their reasons and implications are summarized in the table below. The E-views5/8 econometrics software has been used to perform the appropriate tests. All detailed test results are provided in the appendix. The summarised results and empirical implications are given in the following section.. Results and Empirical ImplicationsDeterminants of HealthHealth conditions are determined by factors such as the level of income, education and other health inputs. Table summarizes these findings using life expectancy as the indicator of health status. Both economic growth and education are found to play an extremely significant role in explaining the state of health. Note: The OLS estimation method with the White Heteroskedasticity-Consistent Standard Errors & Covariance is used for and the OLS estimator is applied to . For notations see previous section. Standard errors are given in parentheses. significant at the 0% level, significant at the % level, significant at the % level All equations illustrate the strong positive relation between life expectancy and GDP per capita, which is found to be significant even at the % level. that a percentage change in GDP per capita increases life expectancy at birth by about.7 years. Education measured by the literacy rate shows a positive impact on the state of health, especially in where it is significant at the % level, increasing life expectancy by.7 and.0 years respectively for a unit increase in the literacy rate. In it is only significant at the 0% level. The number of physicians per thousand also play a positive and highly significant role, increasing life expectancy by about years for an additional physician per thousand. These three indicators together account for almost 7% of the variation in life expectancy as a measure of health as shown by the R of.7 in a p value of.45/8 which means that the null hypothesis for homoskedasticity is rejected and the usual OLS t-statistics can no longer be used, thus the OLS standard errors and variances are replaced by heteroskedasticity robust ones. access to safe drinking water as an explanatory variable along with GDP per capita and the literacy rate and is found to be statistically significant at the % level contributing to.9 additional years of life expectancy for a unit increase in percentage of population with access to safe water resources. It is also highly significant for equations estimated in . The White test in be rejected with a p value of.1 therefore heteroskedaticity is not a problem and the usual OLS standard errors are used. With similar reasoning the null for homoskedasticity is not rejected for and rejected for for which heteroskedasticity robust errors are used. For White's test was used with no cross terms as the variable gini had insufficient observations for it to be calculated. In the subsequent equation the variable was dropped and heteroskedasticity was indeed found to be a problem using the pure form of the test with cross terms, which has been used for all remaining equations as well. test for the significance of immunisation against DPT and measles turn out to be significant even at the % level increasing life expectancy by.3 years with a unit increase in the percentage of vaccinations against DPT and.5/8 years in case of measles. However literacy remains insignificant even at the 0% level in both regressions. The R increases to about.3 in each case. The intercept is highly significant for the % level, showing the average life expectancy would to be as low as 1 years in the absence of these three variables. an extremely important determinant of health other than GDP per capita, literacy, and access to safe water all three of which are significant at the % level, namely the HIV prevalence rate which is responsible for reducing life about. years for a unit increase in the rate of HIV prevalence. The explanatory power of the model immediately increases to about 8%. In a number of explanatory variables are newly included to indicate health status. They are the urban population of a country, access to sanitation facilities, smoking prevalence rates, the gini index as a measure of inequality, and the expenditures on health by the government, both equations find GDP per capita, literacy, safe water, HIV, as highly significant either at the % or % levels. The intercept in found to be significant at the % level indicating life expectancy to be around 6 years in the absence of all other variables. After dropping the gini index variable in expenditure becomes significant at the 0% level. The explanatory power of the model is extremely good with an R of about.1 in both cases. However quite a few of the new explanatory variables like urban population, sanitation, the gini index which have insignificant t-statistics and do not turn out to be as significant as anticipated. Thus with such a high R and insignificant t-statistics the problem of multicollinearity is suspected. However multicollinearity is essentially a data deficiency problem. Dropping a variable may lead to a specification bias. Other remedial measures could be ridge regression. The basic solution would be to increase the sample size, as in this particular case data infact was deficient in terms of its scarcity for some particular variables like smoking prevalence, the gini index and few others. Also the problem of outliers and random samples are not ruled out. In the data which was missing there could have been some variables which would particularly be influential. Also the data for developing countries for which the analysis should hold even more strongly by intuition, is even harder to get and is absent for a lot of countries. However, the each of the regressions is jointly significant, indicated by a p value of zero for the F- statistic for all seven equations. Few further statistical tests are conducted on its residuals. The test results are summarised in table. Detailed test statistics for each test are given in the appendix. Thus, even though the variables urbnpop, sanit, smkng, gini and hlthexp are insignificant individually, indicated by their t-statistics, jointly they are extremely significant as shown by the Wald test. Both the Ramsey Reset test for the correct functional form as well as the test for normality show that the correct functional form has been the residuals are normally distributed which makes the model a valid one. The analysis shows that economic growth plays a highly crucial role in the state of health for a nation. Income provides food for survival, access to medical services and a basic standard of living. Education provides the knowledge and understanding of basic nutrition, sanitation and hygiene along with creating awareness regarding certain health programmes and preventive measures of diseases. In addition to these factors well developed health infrastructure like accessibility to safe water, number of hospitals/physicians, immunisations so on are indispensable. Economic Growth and HealthNext the causal relation between health and economic growth is tested. The growth rate of GDP per capita is used as the dependant variable to indicate economic development and the explanatory GDP per capita in 995/8 viewed as initial income to indicate conditional the initial level of GDP to be negatively associated with growth rate which complies with the conditional convergence theory. Investment however is only significant at the 3% level. Population too enters with a negative sign as an increase in population leads to a decline in shared income by.6 per unit. The labour force too is significant at the 0% level and has a positive impact on the growth rate, this also captures the indirect effect of health which is responsible for the productivity of the labour force. However it is unfortunate to find that the model does not predict the positive effect of education and health significantly. The summary of further statistical tests conducted for given in table which indicates that there are several problems with the model. The White's Test indicates that heteroskedasticity is a problem, the null for homoskedasticity being rejected at the % level of significance and the robust standard errors have been used to correct for heteroskedasticity. However, the Ramsey Reset test rejects the null which means that there is a misspecification of the model in its functional form. As a remedial measure the log of gdpg i.e. the dependent variable is taken after which the p value for the Reset test increases to.89 and therefore the null is no longer rejected, however the test statistics for health and education still remain insignificant and therefore have not been reported found a strong positive relation between the two variables in most cases, therefore the possibility of an insignificant relation in not inevitable. Also the impact is highly sensitive to the underlying behavioural assumptions and the nature of unobserved variables. Effect of certain unobservables like innate ability, motivation, genetic endowment, capacity to concentrate, household intellectual atmosphere, parental time devoted to cognitive development of child, effectiveness of school management and so on have to be kept in mind. The model does have an explanatory power of about 0%. Further statistical tests carried out for summarised in table.The model is homoskedastic, has the correct functional form and though the normality assumption holds at the % level of significance, it no longer holds at the 0% level. However the model does not really have a large sample for which the normality test is more crucial. All detail test statistics are provided in the appendix.. ConclusionThe empirical analysis in this paper suggests that health conditions for a sample of both developed and developing countries, are explained primarily by the level of income of a country, its educational attainment, health inputs such as safe drinking water, the number of physicians, immunisation rates, health expenditure and the deadly human immunodeficiency virus(HIV). The model showing the causal relation of health with economic growth is quite erroneous and only goes to provide limiting reliance on the cross-sectional work, at the same time it emphasises the need for improving the quality of data and reduce the missing observations, which would solve a lot of problems. In a nutshell data constraints do cripple the analysis severely. The final model does resemble earlier findings where the relation between health and education holds one way or has shown conflicting results for different countries. Another drawback is the inability to control for unobserved variables which bias the estimates. Instruments for these need to be chosen very carefully so as not to create a bias. Extensions to this study could firstly include the use of better data in correcting the drawbacks of the model. Also a country or region specific analysis especially for developing nations would be worthwhile. A point of mention is that all these variables are even more important for developing countries where the basic levels of health and education are yet to be attained and thus even necessary provisions for a minimal level of subsistence like daily food consumption is directly influenced by the level of income. Also the income distribution in these countries show highly skewed patterns with the top 0% of the population receiving to 0 times the income of the bottom 0%. Literacy rates remain strikingly low at 5/8% among the least developed countries and infant mortality rates run as high as 0 times those in developed nations. Life expectancy in 998 still averaged only 8 years in the least developed nations compared to 3 years for other developing countries and 5/8 years for developed countries. In Asia and Africa over 0% of the population barely met minimum caloric requirements necessary to maintain adequate health. For the year 001 certain human deprivation indices show that almost a billion people in poor countries were without access to safe drinking water, 66 million did not have access to health services and. billion lived without sanitation facilities. In 995/8, the number of physicians per 00,00 people averaged only. in least developed countries compared to 17 in developed countries. 0% of the people inflicted with HIV in the world, live in LDCs. By the year 010 life expectancy in Namibia for instance, is expected to fall from 0. years without AIDS to 8. years with AIDS. This is only a brief insight to the myriad of problems which need to be tackled in the world today. It is true that cross sectional data may over or underestimate true causal effects. Moreover prior studies based on past data may show different effects due to different incentives, shocks that might have hit the economy at the time and new market developments and reforms that must have come about making it slightly less comparable. However, there are better studies to suggest to the policy makers the grave importance of improving health standards for economic development. The relation between health and economic development can create either a vicious or a virtuous cycle. There is a debate over whether or not the government should subsidise health and education, however everyone should get an equal go at life at least at the subsistence level in their initial years so that they can translate it into long term productivity gains. The provision of credit for microenterprises is an important poverty alleviation strategy where the credit can contribute to improvement in the nutrition of the poor. Other policy options are providing cash transfers to poor families, family clinic visits, other nutritional and health benefit in kind and so on. Another very important aspect is the dissemination of information and creating awareness among the population especially in rural areas of developing countries which are plagued with myriad social problems. However the picture is not all bleak, greater proportion of the government budgets are being devoted towards human capital, there is a trend towards international convergence in measures of health and education, with unprecedented advances having taken place in the last half of the century. Gross school enrolment rates, teacher pupil ratios, life expectancy have all shown increases which are statistically significant. Improvements have been faster in developing countries, though the gap with developed countries still remains large.'''",218.0
"'''This project has been based around the simple principle of learning about basic Car Aerodynamics, and how car bodies can be designed and tested to reach optimal performance, without the extensive use of full prototyping i.e. by use of computer simulation software. An introduction to Solidworks has already been performed, so this knowledge can be improved by introducing another Program: CosmosFloWorks, which will enable the designs in Solidworks to run and solve calculations for velocity and pressure amongst others. However, the investigations of this project shall be based around discovering the Drag Force and hence the Drag Coefficient at different wind speeds, and attempting to use this data to develop the initial car design. Therefore, the objectives for this Project are to: Learn the basic concepts of fluid dynamics and car aerodynamics;Learn about design philosophy and approach with use of computer software;Perform basic analysis and optimisation techniques, with use of computer software.TheoryAfter having been given the initial Briefing sheet, a varied selection of equations can be recognised, that will be needed in order to reach a sensible analysis. Given in the accompanying CD of the Pressure:, which can be calculated for each individual wind velocity tested. Drag Coefficient:, which will be plotted against Velocity during analysis, to compare whether the design alterations have been effective. Running the SoftwareThrough use of the instruction sheet, a tutorial of the set up of CosmosFloWorks can be obtained, in order to initialise the basic project, for example, by specifying that the tests should be carried out using SI units, ensuring that it is using air values for fluid, where the surface of the car is regarded as smooth and therefore negligible, and the geometry resolution is small so that a fairly accurate picture of the airflow patterns can be obtained. Tutorial On CFD Analysis of Air Flow Around Car Using Solidworks After this, the Inlet Velocity face and speed can be determined. This is where the variation in velocity for each run is inputted. The wind must be coming from the front of the car, so the correct wind tunnel face must be selected. This is repeated with the Static Pressure opening, which will be at the rear face of the vehicle. In Figure, it can be seen that the red arrows at the front plane are the Inlet Velocity face, and the blue arrows are the Static Pressure Opening face. After this, the surface goals must be selected, whereby each face of the car, apart from those directly joint to the wind tunnel face should be selected, so that when the software runs, it knows which surfaces represent the car. The calculation can then be solved, during which iteration graphs can be obtained, and various surface plots of the velocity and pressure within the wind tunnel, as affected by the structure of the car. Once completed, the solver calculations are converted into Excel and Word documents that represent all of the results. These results are available in full in the accompanying CD The two versions of the car to be tested are available for view in the Accompanying CD. The idea of testing one car first was to design the second car so that it was an aerodynamically improved version of the first. The data analysis will aim to prove this. Analysis and DiscussionTo analyse the results that were obtained, the drag coefficient will need to be found. Given that the density of air is a constant.3 kg/m3, likewise the frontal area is constant: measured at.32m, and the Velocity is decided by the inputted Inlet Velocity, this means that the Drag Force must be the value that will be measured to find the Drag Coefficient. By using the iterated X Component of Force the Drag Force for each set of results can therefore be found, by using the previously discussed formula Full results are available in the accompanying CD Figure shows a summary of the results that were used to obtain graphical analysis of the car design. Hence, Figure shows the graphical representation of these results. As seen, these results at least show some difference between the two designs. The lower the Drag Coefficient, the higher the efficiency of the car's movement will be. This means that around the 0ms - velocity region for both sets of data, the movement of the car is more efficient, and reduces drag. The second design's line of best fit is also lower than the line for the first design, which can also be seen in the results table Figure. ConclusionsThe analysis is fairly conclusive, in that an improvement in car design has been achieved. However, there is much space for improvement and increase in experimental accuracy. Some faults in the experiment were that the computational software did not have enough time to solve each run for as many iterations as it needed to get the most accurate final answer, as there were limits applied. Also, the frontal area of each car was estimated given the dimensions - there was no simple way of working this out. If more repetitions were carried out, then a more definite graphical representation would be attained; as it stands, any 'peak' is entirely averaged. Ideally, this routine would be continued until a design was reached whereby it would be difficult to find any further improvements in aerodynamic efficiency. The final tests for ultimate streamline would have to take into account the Bernoulli equation, which suggests that at the greatest possible aerodynamic peak, the Dynamic Pressure is equal to the Static Pressure, therefore there being no energy losses due to air resistance.'''",225.0
"''''Race' and ethnicity are both terms used commonly within contemporary society, but their definitions and history sets them apart. The term 'race' has a long history steeped in hierarchy and inequality, whilst ethnicity, being a relatively new term, does not have this misfortune. 'Race' thinking, often leads to racism, and its concentration on phenotypical attributes and physical difference causes people to not look at commonalities, but at difference. 'Race' was used to justify slavery and colonialism, and 'race-science' did this by assuming natural differences, leading to eugenics, which caused the working-class 'race' to be controlled. Ethnicity does not have this history but whether the two terms are the same depends on how ethnicity is defined. There is not one single definition for ethnicity; is it a fixed, static, (like 'race') or is it contextual and constantly in flux? Commonsense thinking, often use the two terms interchangeably, with little differentiation between have hierarchical assumptions, like 'race', but, terminology is important, and although ethnicity may have been 'abused' to create hierarchy, and ethnicity offers choice of identification not found in 'race's' static historical roots. Race and ethnicity are socially constructed, and are both modern concepts Ethnicity does not have a 'single, universally accepted' definition. If it were possible to define it in simple terms, Mason believes that cultural distinctiveness is a marker of ethnic grouping. Ratcliffe, meanwhile, believes the term is deployed 'loosely, to imply commonalities of language, religion, identity, national origins and/or even skin colour'. Ethnicity is, according to Mason, intrinsically social and is at least partly rooted in member's own self-definition, this is not apparent in 'race'. According to Montagu, 'race' is 'man's most dangerous myth' and Miles believes the term should be abandoned, as there is no basis for developing a biological typology of the humanity. As Brah states, our identity is never fixed into distinct racial barriers but is dependent on specific contextual meanings. 'Race' and 'racism' serve to naturalise and fix difference. It is due to this controversy around 'race's' 'contested character' that many theorists have placed 'race' within inverted, Culture and Difference, London: Sage Publications, p.43. Mason Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p. Moreover, 'race's' controversy is due to its 'long and tortured history'. Terminology is important, with 'pre-existing terms constitute pre-existing meanings'. Therefore understanding the history of 'race's' creation is crucial in helping understand its differentiation with ethnicity. Race is a sociological construct, emerging within colonialism. 'Race's' origins begin with the global expansion of Europe from the fifteenth century onwards. Europeans were increasingly brought into contact with different human societies across the globe, and what first struck them was differences in physical appearance, most strikingly skin colour, leading to early distinctions between 'black' and 'white'. This early black-white dualism, brought back by tales from traders, missionaries and booty adventurers, attached a significance to skin colour and was associated with naturalised traits. Black became associated with barbarism and evil, white with purity and goodness. Many of these usages linger today, and according to Mason we must be careful not to reproduce these negative connotations. Montagu, A. The Concept of Race. London: Macmillan, p. 4. Ibid, p.3. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p.. Ibid. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 6. However, the term 'race' (as we know it now) did not emerge until the eighteenth century Enlightenment period, whereby science became dominant and rationalism made sense of the social world. Moving away from religion, the taxonomic quest began, as scientists believed they could categorise and classify the human population into distinct sub-groups. An example of this is phrenology. Scientists, such as Johann Franz Gall, believed you could correlate the size of a head with mental abilities. The belief that external signs were an indication of innate ability was not individual, but based on differences between 'races', laying the foundation for further scientific study. 'Negroes' were believed to have narrow foreheads, meaning 'their talents of music and mathematics limited'. These 'races' could then be organised into a hierarchy, as Cuvier did, dividing humanity into three 'races'; 'white', 'yellow' and 'black', with 'white' at the top, and 'black' at the bottom. Other scientists then sought to refine this categorisation, and the concept of 'race' became a paradigm which few, bothered to question; 'race' seen as winning the battle. 'Race' and ''the survival of the fittest' became the cry which could justify both conquest and war'. Banton cited in Miles, R. Racism, and Migrant Labour, London: Routledge, p.3/ Miles, R. Racism, and Migrant Labour, London: Routledge, p. 3. Malik, K. The Meaning of Race: Race, History and Culture in Western Society, Basingstoke: Palgrave, p. 0. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p. Ibid. However the discrediting of 'race' is further justified through the eugenics movement, who took the concept of 'race', and used it, not just on their colonial inferiors, on the working-classes. If the hegemony of one 'race' over another could be justified, so too could the hegemony of one social class over another. Other social differences were added, such as gender and disability, which used towards political agendas. Early proponents of the census used it to measure the characteristics of the population to detect problem areas, for example, the 'overbreeding amongst the Irish'. There was concern over immigration policy, and the threat to the 'racial' purity of the population by black as sexual predators believed to be stealing the -class women. 'Race' emerged as a construct of both Social Darwinism and eugenics, centring on commonsense definitions of the 'Other' 'implicit in the ideologies surrounding slavery and colonialism'. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 8. Dale and Marsh cited in Ibid, p. 9. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p.9. Ibid, Therefore, it is with this understanding of 'race' we can appreciate how different it is from ethnicity. Ethnicity is a new term, first appearing in the dictionary in 972, therefore not suffering 'from the historical association of error in the way that the concept of race does'. It is because of this fundamental difference between the two, that many academics believe 'race' should be replaced by the term 'ethnic group'. Fenton believed collective identities relating to ethnicity are to do with how people choose to see themselves in regard to other those who have made a claim to be a nation and desire self-government despite being incorporated into a wider state. They are seen as 'nations without a state' and examples include Palestinians and Quebecois in Canada. Fourthly, there are ethnic groups in plural societies, which consist of descendents of populations who have migrated as workers, forming distinct, and sometimes large, minorities. They rarely make a claim for separate status, but form a distinct segment of the nation-state. The last category, added by Fenton, is 'post-slavery minorities'. Classic examples of these include the 'black' African descendents of those enslaved in the New World, for instance, African Americans. These characteristics are further complicated by intermarriage, with 'mixed race' groups forming partly distinct populations, which, according to Ratcliffe, 'provides a clear hint that group formation represents a constant process of evolutionary change.' Eriksen, T., Ethnicity and Nationalism: Anthropological Perspectives, London: Pluto Press, p.1. Fenton, S. Ethnicity: Modernity, Racism, Class and Culture,, Cambridge: Polity Press, pp.2-8. Eriksen, T., Ethnicity and Nationalism: Anthropological Perspectives, London: Pluto Press, p.2. Fenton, S. Ethnicity: Modernity, Racism, Class and Culture,, Cambridge: Polity Press, p.2. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p.2. Nonetheless, this identification of separate types of ethnicities tends to freeze and simplify them in contradiction to previous arguments, also painting a picture similar to 'race'. In addition, even if acknowledging change, ethnicity can still be similar to 'race' in how it is implemented. One such example is the emphasis, especially within British society, on nationalism and boundaries. According to Wallman, in Britain the term ethnicity signifies allegiance to a country of origin, implying a degree of choice and possibility for change. This leads to the possible view that migrants can be absorbed or assimilated into British society, and that, if they do not, it is their fault for refusing to adopt our ways. Moreover, this leads to a tendency towards 'ethnic' as meaning only those assumed to be different from the indigenous, British norm. Ethnic become a synonym for those thought of as culturally different, and a sense of 'Otherness'. Difference is prioritised over diversity. A lay example of this is the fashion world's adoption of the term 'ethnic look' which implies ethnicity as an attribute given to the non-white, non-British 'Other'. It distinguishes between 'them' and 'us' and also denies the ethnicity of the. This leads to the conceptualisation of English people as individuals, and all outsiders as members of distinct groups. This grouping of people means any cultural differentiation is taken as a cause for behaviour, instead of individual motivations. Ibid, p.2. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p.3. Cited in Ibid. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 4. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p.4. In addition, everyday understandings of ethnicity are contradictory, as although emphasis is placed on choice and demand for migrant ethnicities to change, popular discourse use ethnicity in ways that suggest physical distinctions based on skin colour, making it remarkably similar to 'race'. This suggests that ethnicity has simply become a euphemism for 'race' and may simply act as 'another way of essentializing and naturalizing difference.' Additionally, despite being discredited, 'race' is still common in everyday usage, becoming independent from scientific discourse and becoming autonomous. UK legislation such as the Race Relations Act and the creation of the Commission for Racial Equality, both legitimise the use of 'race'. Although still referring to phenotypical variation, 'race' has moved into a general meaning of 'the Other', recently focusing on religion, an example being the current demonising of Islam after /1. 'Race' has absorbed culture, making it similar to our understanding of ethnicity. According to Fenton, 'race' and ethnicity are used in common language interchangeably, with little distinction. Therefore, although the original definition of 'race' may have been very different from our understanding of ethnicity, as 'race' has absorbed cultural understandings, the two terms have become more alike. Ibid. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 7. Miles, R. Racism, and Migrant Labour, London: Routledge, p.9. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 3. Ibid, p. 4. Furthermore, as 'race' has absorbed aspects of culture, so has racism. After the Nazi's crimes against humanity, scientific racism was discredited as the Western world overcame with revulsion. However, despite reacting against the political use of racial ideology, the underlying assumptions of racial thinking remained, and the belief that humanity is divided into discrete groups went unchallenged. According to Malik, they 'accepted the reality of natural divisions within humankind, though they preferred to term them 'ethnic groups' rather than 'races''. Human difference stopped being discussed in terms of biology, but was now dominated by categories of culture and history. Malik, K. The Meaning of Race: Race, History and Culture in Western Society, Basingstoke: Palgrave, p. 24. Ibid, p.26. This 'new racism' emerged under what Rex called 'the postmodern turn' leading to a plurality of different racisms based on differing and ambiguous definitions of 'race'. Founded on ideas of cultural incompatibility, political arguments based around boundary and nationality was framed towards the 'threat' of the migrant culture. This is seen as early as the 980s, whereby discussions towards immigration often took on warlike language, using phrases such as 'the enemy within'. This directed attention to national boundaries, specifying who may, or may not, legitimately belong to Britain. Ethnic groups were a threat to 'Britishness' and its superior culture, and ethnicities were thought to lead to national decline. Migrants were simply formal, legal citizens of Britain, not substantive members, (tied through culture, language, heritage and 'race'). The word 'immigrant' became synonymous with 'black', but 'racism' could now be excused as although the targets were the same, what they were attacking had changed. This serves to demonstrate the ambiguous relationship between 'race' and ethnicity and how the two terms are linked in contemporary society through complex interconnections of culture and nationality. Lawrence, E. 'Just plain common sense: the 'roots' of racism' in The Empire Strikes Back: race and racism in 0s Britain, London: Hutchinson in association with the Centre for Contemporary Cultural Studies, p.7. Cited in Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p.0. Gilroy, P. There Ain't no Black in the Union Jack: the cultural politics of race and nation, London: Hutchinson, p.5/8. Ibid, p.5/8-6. Malik, K. The Meaning of Race: Race, History and Culture in Western Society, Basingstoke: Palgrave, p. 86. In addition, this confusion and ambiguity between 'race' and ethnicity continues if you observe problems within ethnicity's descriptive categories. As there are so many different ways to divide social reality, different labels are often incompatible and less than ideal. Issues of nomenclature are important as those who create categories are often from superordinate groups and any application of labels may act to weaken the position of subordinate groups being labelled. The contemporary use of the term 'black' for instance, is a conscious political statement, and those defining themselves through this term are embracing a common identity. However, this term subsumes all those seen as 'not white' within one category, ignoring the diversity of other ethnicities, for example Asians. This focus on the particular phenotypical difference of skin colour also underlines discourses on colour, as those who talk of 'persons of colour' when referring to 'non- whites', refer to the 'Other'. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p.4. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p. 7. Brah, A. 'Difference, Diversity and Differentiation' in Donald, J. and Rattansi, A. (eds.) Race, Culture and Difference, London: Sage Publications, p.28. Ratcliffe, P. 'Race', Ethnicity and Difference: Imagining the Inclusive Society, Maidenhead: Open University Press, p. 5/8. Additionally, another term often used is 'ethnic minority'. There are two main problems with this term, one; it may be seen as a euphemism for race, and two; it is insulting to those who are described by it as it implies only minorities, and non-whites, have an ethnicity. The ethnic majority is never referred to, and the term, although being an attempt to replace 'race', ends up replicating ideas of power as minorities are often those found in subordinate positions. Ibid, p.5/8. Mason, D. Race and Ethnicity in Modern Britain, Oxford: Oxford University Press, p. 4-5/8. Moreover, this problem of defining ethnicity is expressed through measuring ethnicity within the census. Although asking people to choose and self-identify, it also asks them to place their ethnicity within one category, going against its fluidic, contextual nature, returning back to the essentialist, primordial definition seen as a 'mistake'. In 991, due to the desire to catalogue and number the migrant, minority ethnic population, the census added its first question on 'ethnic group'. However, the Janus-faced questioning was confusing, as one category asked to tick is 'White', which is not an ethnicity, but a skin colour. It fails to grasp the complexities of ethnicity, placing many diverse ethnicities into one category. The all encompassing 'White' for example, incorporated nations ranging from Britain, Europe, and mismanagement of populations: the statistical use of ethnic and racial categories in multicultural societies, New York and London: Palgrave Macmillan, p. Ibid, p. Ibid, p. His emphasis, Ibid. What is more, the organisation of groups in the 001 census, although to the unfortunate repercussion of freezing ethnic groups into fixed categories. It can also lead to nationalist agendas, which form boundaries and forms of incorporate phenotypical differences, so that, in common language, the two phrases are interchangeable (the complexity of the situation demonstrated through problems in the census). However, academically, the two terms are recognised as different, and due to the importance of terminology, 'race' is rejected in favour of ethnicity. Eriksen, T., Ethnicity and Nationalism: Anthropological Perspectives, London: Pluto Press. '''",228.0
"'''Kidde plc, a global supplier of fire and safety products, is achieving increasing sales and profitability. Kidde is a highly geared company, but its reliance on loans is being reduced. Net debt is decreasing, although at the expense of cash flow and returns for shareholders. Kidde's acquisition policy also consumes much cash, and dividends have improved little in comparison with available shareholders funds. Liquidity is an area of concern with short term debts increasingly outweighing current assets. Adjustments for Goodwill and Provisions are areas in which Kidde can affect profit levels by subjective judgements. Kidde is in a consolidation period whereby it is investing its earnings for the future and shareholders should expect little improvement on returns at this time. It is therefore recommended at the end of 003 that shareholders hold their shares. Future prospects for Kidde are positive, with a number of opportunities arising. Significant growth in the security market coupled with recent acquisitions should help Kidde's sales throughout the world. Kidde's continuing acquisition strategy seeks to replace investments in Baxi and Robblialac which generated significant proceeds from their sale. Kidde's exposure to currency, taxation and interest rates could have significant affects on profits over the coming year. Half year results show general continued growth in sales and profits, and a significant reduction in net debt. UTC's takeover bid raises Kidde's prospects significantly, but also introduces new risks.'Kidde is a leading global supplier of fire and safety products, systems and services under a range of well-known and trusted brand names to industrial, commercial, aerospace, combustion control and retail customers.' Kidde plc has existed since its demerger from the Williams group in 000. This report will analyse Kidde's financial position and draw conclusions as to the strengths and weakness of the company. Part I will discuss the past performance of Kidde, concentrating on the contents of the 003 Annual report. A number of indicators will be used to assess important aspects such as profitability, liquidity, efficiency and shareholders returns. Several important accounting adjustments will be looked at to assess the reliability of the annual report. Finally, a recommendation will be made to shareholders for the end of the 003 financial year. Part II will consider the future prospects of Kidde plc over the next financial year, focussing on Market Opportunities, Acquisitions, financial data from the interim report and any significant issues highlighted by the 003 Annual report. Unless stated otherwise, financial data used in the report is taken from Kidde plc Annual reports. Only data from 000 onwards has been used. URL, Past Performance of Kidde plcPerformance IndicatorsProfitabilityGross Profit Margin Gross profit margin is an 'indication of a firm's ability to turn a pound of sales into profit after the cost of goods sold has been accounted for'. It describes the efficiency in which goods and services can generate profit over their costs. The formula used is; Scott,D.L, Wall Street Words: An Essential A to Z Guide for Today's Investor, Houghton Mifflin, 998 was taken from Kidde's Annual report, note. Kidde's sales have increasing steadily over the last few an increase in Gross Profit Ratio has a measure of the efficiency in which used to generate profit. The formula used is; denominator is the total capital input; the numerator is the profit output. The values of opening shareholders funds have been levels of profitability. This is the result of increased definition assesses profitability from the point of view of an ordinary shareholder. It indicates how much profit could be distributed to shareholders as a proportion of their investment. Figure shows the trend in ROSE since 000. The negative ROSE value for 000 results form the effects of Kidde's demerger, from Williams PLC, completed November 000- a loss was recorded for that year. Since 001 the profitability is seen to decrease quite significantly. This seems to be at odds with the trend in ROCE- the reasons for this will be considered later. Dyson, J.R, Accounting for Non-Accounting Students, th Edition, Prentice Hill 004, p25/84,p25/88,p260 WILLIAMS PLC, Proposed demerger to create Chubb plc and Kidde plc, Investor relations press release. Investor RatiosGearingGearing describes the mix of long term capital funding provided that contributed FAME database uses an alternative to this equation which includes Short-term loans and overdrafts in the numerator. Figure shows that since 000, Kidde has become less geared, meaning that a smaller proportion of its capital funding is coming from external lenders. Note that the high value of gearing in 000 is likely to be an effect of the demerger. The decrease in long term debt results in a corresponding decrease in interest payments since current market price may be very different to the price originally paid by the shareholders. The ratio is therefore more useful for deciding whether to purchase more shares in the immediate future. The size of the dividends is decided by the need to attract investors against the need to reinvest profits in the business for growth and improvement. Increasing dividends show growth, while a struggling firm may only be able to maintain them. URL, 4/2/004 Figure shows Kidde's dividend yields since 000, as averages for the year. The values are about gives the profit generated on an ordinary share. It indicates profitability from the perspective of a shareholder. The formula used is; shows the trend in EPS since 000. EPS has increased significantly since 000, which indicates that Kidde is an improving investment. The result matches the trend in current has been a gradual decrease in the acid test value since Dec 000. While the specific value of acid test ratio might not be of definite concern, the trend is clearly not the average stock is given by; Figure shows a clear increase in stock turnover ratio since 000. This is indicates that efficiency is improving, at least in the area of stock control. Another indicator should be considered to see if this trend in efficiency is a general one. Trade Debtor Collection Period RatioThe ratio used is; average trade debtors is found using; The ratio has also been calculated using closing trade debtors, both results are shown on Figure. The ratio gives the average time taken for an entity to collect the money owed by its trade debtors. Cash flow problems could result if the value is too high, but longer collection periods may help customer relations. A period of 0 days is the median value in the UK, but this varies greatly between industries3. Calculations for Kidde show the Collection Period to be in excess of 0 days, however. It is difficult to know if this is too high a value without comparison with entities in the same industry. After the 000 demerger, Kidde may have been focussed on building customer relations as a separate group, giving less stringent credit terms to customers. Figure shows that there has not been any clear trend since 000- using this indicator, efficiency does not seem to be improving. Dictionary of Business, Oxford University Press, Market House Books Ltd 996, pg 48 Kidde Ratio Assignment, Best Ratios, Trade Debtor Collection period, student ID: 218780 Research and DevelopmentResearch and development expenditure is investing internally within the entity to aid the production of new or improved products and processes which ensure the company remains competitive in the marketplace. This is particularly important for an entity like Kidde which operates in a very specialist market. Figure 0 shows that overall Kidde's R&D expenditure has decreased since 000, with a slightly increase in 003. The decrease has been quite significant, with 7. m being spent in 000 compared to only 8. m in 003. While the company has grown since 000, R&D expenditure has shrunk. Shareholders should be alert to further changes in R&D expenditure to ensure that this vital area is not neglected. General comments on performanceOrigin of SalesKidde provides fire protection products and services throughout the world, most of its sales coming from the US, Europe and the attention to the impact of foreign exchange movements on the group's profit. Over half of Kidde's sales currently come from the US, with many in other countries. According to the group finance director, the group's performance has been significantly affected by changes in exchange rates with these countries, particularly the US. Over the last year the US dollar has been increasing weak. The effect of this was mitigated by hedging of future earnings using financial instruments20. This course of action was wise, and probably left Kidde much better off than entities in a similar position. Wendlant, A, Kidde limits impact of weak dollar, Financial Times, page 2, 9 Jan 004 Reliability of the ReportProvisionsThe making of provisions by an entity involves accounting for events in the future that may affect the reality of current profit levels. For example, provision for bad debt accounts for the fact that a proportion of debt may never be recovered. It is an example of the prudence rule, since it tries to be realistic about the level of profit that will actually be realised. However, the setting of provisions requires a great deal of subjective judgement as to the likelihood of something occurring, and can therefore be used to influence stated profit. FRS 2 deals with 'Provisions, Contingent Liabilities and Contingent Assets' and aims to prevent the use of provisions for 'profit smoothing', by only making provisions when there are good grounds for them. URL, 5/8/2/004 Kidde's 003 balance an entry named 'Provisions for Liabilities and Charges', which carries a value of 9.m. Note a break-down, which is shown in Figure 2. The largest provision is that under the heading 'Litigation/environmental'- 0.m has been set aside for this,.m of it in 003. In the notes describe this provision as that for 'the anticipated cost of resolving litigation and environmental issues, based on professional advice. The timing of the settlement of these claims is uncertain, but it is expected that theses provisions will be utilised over the short to medium-term.' Assumptions have been made to decide the size of this provision, and being subject, could be altered to influence stated profit. The other main provisions made in 003 were for -Acquisition for warranties for faulty under the category of 'other' coming to.mIn total, 3.m was charged to the profit and loss account in 003, nearly 3% of divisional profit. Although restricted by FRS 2, there must surely be room here to understate or overstate profit by controlling the assumptions used to size the provisions. GoodwillAccording to FRS 0, Goodwill is defined as the difference between the value of the assets of a company and the purchase price. This difference results from the existence of intangible assets, such as employees, skills, or company reputation, which do not have monetary value but contribute to the strength of the business. Kidde's policy on accounting for goodwill is given in note of the 003 Annual report. In line with FRS 0, Goodwill 'has been capitalised in intangible fixed assets and amortised over expected useful economic lives depending on the type of business acquired, subject to impairment views.' It is explained that Goodwill is to be amortised over, 0 or 0 years depending on the value of the acquisition. Determining this 'useful economic life' is highly subjective and difficult to predict (since the assets are intangible), and controls the amortisation payments made on the profit and loss account. URL, 3/1/005/8 Detail of the treatment of Goodwill is given in note 2 of the Annual report. The scale of the acquisitions Kidde made during the year is indicated by an additional 1.m in Goodwill, added to a total goodwill of 47.m. The total charged to amortisation for the year was 0.m. This is a considerable amount (0% of operating profit), and any adjustments made to this figure could have a significant effect on profit levels. Here Kidde are able to affect the level of profit by their subjective judgements of the quality of goodwill. Since these judgements are subjective, they can easily remain within the bounds of 'a true and fair view'. Conclusions and Recommendation to ShareholderKidde has shown an increase in sales and profits over the last financial year. Profitability has increased in terms of profit margins and return on capital employed. Foreign exchange rates, particularly the US dollar have had a significant effect on Kidde's performance, but this has been mitigated by hedging. Kidde has a strong acquisition policy which has consumed much cash, but offers prospects for the future. Returns for shareholders are not so positive at this time as a result of Kidde using earnings for acquisitions and for the reduction in net debt rather than in dividends. The reduction in long term loans also puts more emphasis on the use of shareholders capital. Kidde has a high level of gearing but this being decreased by the reductions in long term loans. Dividend yields are not very positive at this time due to increase in share prices and slow increases in dividends. Liquidity is an area of concern as short-term debts mount up in the wake of the acquisition policy. Efficiency indicators do not reveal conclusive trends overall, but Kidde seem to be controlling stock more efficiently. Research and development lacks funding in line with the general growth of the business and should be viewed carefully over the coming year. Goodwill amortisation is an adjustment that can allow Kidde to influence its stated profit by setting amortisation periods accordingly, while keeping within FRS 0. Kidde has a number of provisions set aside in line with FRS 2, but there is also room here for profit adjustment by controlling the assumptions used for sizing of provisions. The recommendation for shareholders at the end of the financial year 1 st December 003 is to hold shares. Kidde has improved significantly over the year, generating more sales and becoming more profitable. It is however, not directing earnings towards shareholders at this time. There is much risk involved as a result of Kidde's high debts, which are making it increasingly illiquid. This is a period of consolidation for Kidde which is trying to establish itself firmly by reducing dependence on lenders, and by acquiring all the elements it needs for future competitiveness. Shareholders should hold their shares and wait until this consolidation period starts to yield fruit. Future Prospects for Kidde plcMarket OpportunitiesThere is currently tremendous growth in the security industry with the market increasing by 2% annually. This is partly the result of a construction boom in Asia, but also because of a higher awareness of potential threats. Fire protection systems are seen as essential components of security systems. Security companies such as Tyco International Ltd and United Technologies Corp. are therefore looking to enhance this area of their business by the acquisition of specialist companies. All of this is positive for Kidde, who can benefit from growing sales worldwide. Wakabayashi, D, Security Industry lures GE, others; The market is growing., The Philadelphia Inquirer, Dec 004. On November new legislation came into effect in New York requiring that all homes be fitted with carbon monoxide detectors. Kidde's experience in detector manufacture put it in good stead to capitalise on this opportunity- they expect to sell around million detectors. US legislation fuels confidence at Kidde, Financial Times, Page 4, 0 September 004. Prospects for the Kidde's aerospace division are improving, with the announcement of a 47m contract with Boeing in May 004 to provide systems to detect and fight fires in the new E7 Dreamliner planes for the next 0 years. The aerospace market, which was hit badly by September 1, is now starting to improve. Tiesenhausen, F, Kidde wins $5/80m Boeing contract, Financial Times 4 May 004, page 0. Sale of Baxi and RobblialacBaxi and Robblialac were described in the 003 Annual report as being highly geared companies.0 Both were sold early in 004 generating 2.m (not including Goodwill), which was used to significantly reduce net debt (to 06.m). Their sale helps to reduce Kidde's gearing and its reliance on loans as a source of capital. The profit and loss account for 003 does however show that significant income was generated by Baxi (1.m in 003,.m in 002). Indeed, in the 004 Interim report the need for replacing the earnings generated by their former associates, and highlights the intention to continue with an acquisition strategy.8 It remains to be seen, therefore if this course of action will benefit Kidde. Kidde plc Interim Report 004, p3 Takeover bidsAs explained in section the security market is currently experiencing fast growth. In October 004 America's United Technologies Corporation made a takeover bid for Kidde. This acquisition would extend UTC's security business into fire protection, making it much more competitive as an 'all-in-one' security system provider. UTC already owns Chubb plc, a security company, part of the original Williams group to which Kidde belonged prior to November 000. The bid of 60p per share was rejected by Kidde's board as being too low, and was subsequently raised to 65/8p on December. This interest in Kidde has been reflected by an increase in share price- around 25/8p before the bid rising to 70p. Operating within UTC, Kidde could benefit significantly from the general trend in the security market, and may help it to develop its strength in the US. There are, however, increased risks involved- UTC may have different aims and Kidde's current strategies may be compromised to the detriment of profits. Kidde plc Statement Regarding Press Speculation, Press Release, December Kidde's Half Year PositionKidde's 004 Interim shows the company's financial position at 0 th June 004 (half year position). The main highlight is a.% increase in sales (60m compared to 29m June 003). This is particularly significant because it seems to demonstrate that the absence of Baxi has not damaged profits. Kidde's Residential & Commercial Division achieved a 2% increase in sales, which, it is claimed, is the result of market share gains and US safety awareness campaigns. Industrial Fire Protection achieved increases in sales and profits, while, as in 003, Aerospace & Specialist Equipment suffered a % decline in sales (although increased profits). During the first half of 004 Kidde sold Baxi and Robblialac making 2.m in proceeds, and also during this period received a tax credit of $4m. From the interim report, it is clear that much of this cash has been used to reduce net debts. Impact of Foreign Exchange MovementsThis was highlighted as a major factor affecting Kidde's performance over 00320 and remains so as the value of the dollar has continues to decrease, reaching rates of nearly two dollars to the pound. Kidde's policy of hedging reduces its exposure to currency variations, but does not eliminate the effects on profits. TaxationSince Kidde operates in a number of economies it is more subject to the effects of changes in taxation in different countries. Many of the economies Kidde operates in currently have substantial public sector deficits, which may result in changes in tax legislation affecting profits. There is respite from this concern in 004 at least, with an IRS tax audit settlement resulting in a tax credit of $4m. This has given a significant boost to profits for 004- retained profit by June 0 th is four times what it was in the previous year.8 Protected by Kidde, Annual Report and Accounts 003, p2, p3, p5/8 Kidde plc Press Release, Kidde settles with US tax authorities, resulting in $4m credit to profit, /8/004 AcquisitionsKidde has made a number of important acquisitions in the last year to enhance its capability in different markets. In January 004 Kidde acquired Croda International's Fire Fighting Chemical Business, manufacturer of fire fighting powders and foam. It is hoped that this will strengthen Kidde's position in Brazil and Mexico, while also providing an important supply bases in the UK and France to strengthen the European Market. Acquisition of Croda International's Fire Fighting Chemical business, Kidde plc Press Release, 9/1/004 The acquisition of Gloria KG, it is hoped, should also strengthen Kidde's position in the Europe. Gloria is a leading maker of portable fire extinguishers, and has an established network of distributors throughout Europe, particularly in Germany. The acquisition should greatly enhance Kidde's product range and sales of fire extinguishers, and increase its access to the European market. The move is also complemented by the acquisition of Croda International's Fire Fighting Chemical Business, and has been incorporated into Industrial Fire Protection operations. Fire Safety Engineering, May 004, Vol. II, Issue, p40 Acqusition of Gloria, Kidde plc Press Release, 9/2/004 The acquisition of Harden SA, another manufacturer of portable fire extinguishers is intended to boost Kidde's grip on the French market- identified as one of the key areas in which Kidde needs to advance. Acqusition of Harden SA, Kidde plc Press Release, 4/1/004 Generally, recent acquisitions have focussed on strengthening Kidde's European operations. This is encouraging if we consider the disappointing margins produced by sales in Europe (see section.). ConclusionsCurrent market conditions are highly favourable to Kidde with high growth in the security industry and benefits from fire protection legislation. Kidde's sale of Baxi and Robblialac have helped reduce net debt significantly and provided cash for further investments. The resulting lost earnings, however, will reduce the profit of future years unless replacement investments are found. Kidde has made, and continues to make many important acquisitions that strengthen its capabilities, particularly in Europe where margins have been poor. Long-term benefits of these acquisitions have yet to be fully realised. Kidde's half year position in 004 is stronger than 003; sales have increased, and net debt has been significantly reduced. Taxation and currency exposure may have a great influence on Kidde's profits over the coming years. The possibility of a takeover will have a significant effect on Kidde's future prospects. Takeover by an entity like UTC could be greatly advantageous in capitalising on the growing security industry worldwide, but could compromise Kidde's successful strategies.'''",231.0
"'''Hybrid creatures are a combination of human and animal, exposing a caricature of the base and bestial side of man. Their violent and exaggerated behaviours are perhaps a representation of uncontrollability, allegories of chaos which must be overcome under the watchful eyes of the gods, in order to free society from their evils. Both the hybrid and monstrous creatures appear to symbolise the forces that threaten civilisation, presented by the gods and conquerable only by heroes. Hybrids can range from savage centaurs to beautiful mermaids, and in a reflection of the changing temperament of nature, those which might at first seem beautiful and enticing like the sirens and mermaids, can prove treacherous and fatal upon closer inspection. In an exploration of roles played by monstrous and hybrid creatures we expose society's need for a manifestation of evil that can be defeated, a basis of control where in a Greek society the gods can bring order to chaos and make sense of the evils in the world, be in morality or in the violence of nature. Without them there would be nothing for the heroes to conquer, and the function of the mythology would break down. Hybrid and monstrous creatures are perhaps some of the most intriguing aspects of mythology, capturing the imaginations of many throughout time. What makes them so fascinating is different from one individual to the next, but when theorising one might be able to attribute their allure to that which sets them apart from humans, the fantasy aspect of their existence. Many characters in mythology are either human or human-like in although did not exist, because of their physical manifestation being in human form could potentially have existed at some point. Monsters and hybrids are very much creations of fantasy, products of the imagination that certainly do not exist, and so the possibilities and scope of their functions limitless. They can materialise in the imagination of a person in any way that person desires, fulfilling the function that that person requires of it. Humans are by their nature fascinated with things that are different to themselves, and the intrigue of something so physically alien embodies the oxymoron of an attraction to the exotic, a difference which simultaneously acts as a barrier. The variety of different perceptions of these creatures mirrors the variety of roles that they can be said to play in Greek myths. One of the roles of hybrid and monstrous creatures can be attributed, on a basic level, to the structure of a myth. The hero, in order to prove his heroic strength and achieve his quest, must overcome a series of obstacles, more often than not in the form of some kind of monster. We see this in Homer's epic The Odyssey, where he needs to pass by the monsters Scylla and Charybdis, and he must save him and his men from the Cyclops, the myth of Theseus and the role that can be attributed to hybrid and monstrous creatures is providing a direct antithesis of the hero of a myth. They can be used in a representation of good versus evil in its most basic form. The hero's virtue can be emphasised by juxtaposing him against a foil, a demonstration of the battle of one good force against one evil force. This theory can be demonstrated through Odysseus' encounters with the monsters Scylla and Charybdis in Homer's Odyssey. Scylla, the monster with a ring of dog's heads round her middle, and Charybdis, the whirlpool, are simplistic embodiments of malevolence, included within the story as obstacles to be defeated. Their violence contrasted against the terror and innocence of Odysseus and his crew who have done nothing to incur their wrath than cross their paths, brings into relief Odysseus' comparative virtue. If we consider Odysseus' episode with the Cyclops, Polyphemus, we can see an illustration of this theory. Odysseus and his men are held captive in his cave, and the Cyclops plans to systematically eat everybody in an act of barbarity. The Cyclops is being presented as evil and immoral and sharply contrasts Odysseus, bringing to light both his heroism and morality. If we were to consider the situation in a little more depth it would become obvious that the Cyclops, despite being naturally immoral, is acting on anger stemming from Odysseus abusing xenia, a code of hospitality, where Odysseus has intruded upon his home and eaten his food in Polyphemus' absence. This is an example of a hybrid exhibiting human characteristics, perhaps using such a creature to reflect the immoralities and vices of man. Perhaps the monsters and hybrids can be seen as a personification of moral perversity through physical hideousness and abnormality. Many of these beings are unsightly creatures, and are perhaps an ancient society's way of personifying the evils that surrounded them; a physical manifestation of immorality, disease and natural disasters. When considering monsters and hybrids in conjunction with divinity, it becomes apparent that the gods can use them as vehicles of control over mortal society. The gods create these creatures as manifestations of chaos, and are able to bring order and peace to the world in an act of control over the mortal realm. The hero is typically aided through divine intervention thus showing the need for a higher power to civilise and bring order. Paradoxically, the gods can be shown to be almost as bad as the creatures themselves in many instances, exhibiting acts of random barbarity and violence, and being exposed to human emotion and vices. The gods are subject to jealousy and rage, for example Poseidon, who wreaks havoc upon Odysseus' fleet, conjuring up vicious storms and causing the death of members of his crew: 'Poseidon.so violently at odds with you. puts all these disasters in your path.' (Book, p71)Similarly Zeus, father of the gods, is subject to immoral lust, and rapes many mortal women, for example Semele, the mother of Dionysus. In realisation of the gods' own weaknesses and immorality, the paradox of their superiority over mortal society and their use of monsters and hybrids, of which they are often no better, become clear. Some of the hybrid and monstrous creatures have been victims of the whims of the gods. Scylla, the terrifying monster that Odysseus is faced with on his wanderings, is subject to the lusts and jealousies of the divine. Once the beautiful daughter of Phorcys and Hecate, it is said that she was transformed by Amphitrite, the jealous wife of Poseidon, after he had made advances to her. A slightly different version is detailed in Ovid's Metamorphoses, in which a jealous Circe transforms her, after Glaucus, the man she falls in love with, falls in love with Scylla. Either way, Scylla becomes a monster as a result of the weaknesses of the gods, and is a victim of jealousy. Similarly 'fair cheeked' Medusa, the gorgon killed by the hero Perseus, whose head was wreathed in snakes and could turn a man to stone with one look, was a beautiful woman made that way by Athena as a punishment of having been raped by Poseidon. She is made a monster as a result of the lust of the gods, and is perhaps even beheaded as a result of jealousy over beauty: 'It is alleged by some that Medusa was beheaded for Athena's sake; and they say that the gorgon was fain to match herself with the goddess even in beauty.'(Garber 003:5/8) In these instances they appear as sympathetic characters who are at the disposal of the gods, reflecting the equal helplessness of mortals. In contrast with the current theme of the essay, some of the hybrids exhibit signs of virtue, and play the role of bringing relief to mortals. Take Pan for example, a hybrid god who is half man and half goat bearing resemblance to Satyrs. He favours music and dancing, and in the Homeric Hymn to Pan is described as 'delight the hearts of them all.' Similarly there is Dionysus, the god of wine, music, and revelry, who is always accompanied by a band of Satyrs, hybrid creatures who are half human and half goat and horse. The Satyrs encourage festivities by their very nature: 'They dance and sing and love music; they make wine and drink it, and they are in a perpetual state of sexual excitement.'(Morford 007:11) They provide the basis for mortal enjoyment; promoting drinking, merriment and pleasure, alleviating the toils and troubles of everyday existence. Conversely, all three embody immorality to a certain extent, and are given to wild mood swings which can involve terrible and devastating violence. The duality of these characters is illustrated in Euripides' Bacchae, where there is imagery of joyous 'devour of raw flesh', Satyrs in 'their frenzy' and animals and humans being 'torn to pieces.flesh stripped from their bodies.' There is a dark side to these creatures who can so readily bring happiness. In conclusion, I believe that the roles played by hybrid and monstrous creatures are those of portraying evil and immorality in physical form, enabling heroic display, and providing a channel through which the gods can be seen to bring order and control to chaos. Despite, seeming superficially to be a mere paradigm of iniquity and violence, the creatures' duality in many cases indicate their reflection of human nature and the natural world, and even prove them to be forces for good on occasion. Brought into being perhaps by society's need to explain and understand immorality and the threatening forces of the world through physical object, they are manifestations of human vice, woven into fables in which most often the virtue of the civilised conquers them.'''",235.0
"'''The pre-trial phase in criminal procedure is considered vital in determining the outcome of a case. Public prosecutors are a central feature of this phase, considered as 'the gateway' to criminal justice; they play a crucial role in crime control, enforcement and punishment, as will become apparent. Prosecutors in various jurisdictions possess widely different powers, yet all seemingly comply with due process rights under the ECHR. Independence of prosecution is of paramount importance. All jurisdictions claim to have independent prosecution services, yet the way they are conceptualised as such, varies extensively. This essay presents a discussion of how prosecutors are understood to be independent in England, France and Germany and how true to reality this conception is, with particular emphasis on the role of the prosecutor primarily in investigations and secondly in the alternative disposal of cases. Federico, G., The Independence and Accountability of the Public Prosecutor; In Search of a Difficult Equilibrium. The Cases of England, France and Italy. Lecture given by Federico on 5/8/1/001, Universidad National de Corboda England and WalesSince 985/8, the Crown Prosecution Service has operated a monopoly on the prosecution of the majority of criminal offences. Prosecution had previously been the unofficial prefecture of the police, but was vilified for failing to take an objective and independent stance. The Confait case, where three boys were falsely convicted and imprisoned for murder after police failed to follow alternative line of inquiry, acted as a catalyst for reform, and a guide to how not to prosecute. The police retained almost exclusive powers over investigation, including arrest and detention. Prosecutions for especially serious or technical offences are sometimes carried out by the SFO and HMCE. See, Ashworth, A. The Prosecution Service in England and Wales, Criminal Law Review, European Journal of Crime, Criminal Law and Criminal Justice See, Fisher, H., Report on an inquiry into the circumstances leading to the trial of three persons on charges arising out of the death of Maxwell Cnfait, H.M.S. RCCP thought that prosecutors ought to operate separately of the investigative functions of the police, but at the same time co-ordinate resources, neither is to be subordinate. It was felt that the guaranteed independence of the CPS was paramount to avoiding the inadequacies of police prosecution. This became known as the 'Phillips principle', and formed the basis of the CPS. Royal Commission On Criminal Procedure Cmnd 092 For an analysis of the Phillips principle in depth see: White, R., Investigators and Prosecutors, or Desperately Seeking Scotland a Re-formulation of the Phillips' Principle, Modern Law Commission on Criminal Procedure, Report, Cmnd DPP emphasized the need for independent decision making, in the 'interests of justice', between the police decision to prosecute and the subsequent presentation of case in court. It is a necessary measure to protect the due process rights of the accused and equality of arms. However, one could argue that such a harmonious relationship, based on cooperation and mutual respect for independence has not truly come to fruition. White argues that the 'Philips Principle' was intrinsically flawed as prosecutors were doomed to have their independence compromised by a dependence on police evidence, implicit in the principle itself. Rutherford, A., Pre-serving a robust Defence' - An Interview With The DPP, New Law Journal, (5/89) (892) See, Jackson, J., The Ethical Implications of the Enhanced Role of the Prosecutor, Legal Ethics, White, R., Investigators and Prosecutors, or Desperately Seeking Scotland a Re-formulation of the Phillips' Principle, Modern Law the other hand, Fionda notes that dependence may not automatically lead to a conclusion of no independence, provided that the relationship is a controlled one. Robb argues that: Fionda, J.,, Public Prosecutors and Discretion: A comparative Study, Clarendon Press, Oxford 'The true independence of the prosecutor from the police is not to be found in the total separation of the investigative and prosecutorial functions, but rather in the prosecutor's authority over the police.'Robb, L., 'Note: A Scottish Contribution' as quoted in Fionda, J., Here, Robb has in mind the Scottish model whereby police are legally subordinate to prosecutor, who directs the investigation and takes the decision to prosecute. However, as Fionda points out, such a system is unlikely to be successfully incorporated into a legal culture which has historically placed police in high esteem. It is important to note that the CPS powers where inherited from the police, so to supersede those powers would lead to resentment. Furthermore, the RCCJ felt that this would unacceptably blur the lines between the separate functions. Also, see. J. Royal Commission on Criminal Justice, Report op. cit., Chapter. Paragraph 7. Nonetheless strained relations between the CPS and Police resulted in numerous political efforts to forge a closer working relationship, in an attempt to improve efficiency. As Jackson notes, these efforts have involved prosecutors taking a more expansive role in investigations. Hunt and Baldwin voiced concern over the growing trend of placing prosecutors in police stations for the purpose of pre-charge advice and the subsequent diminishing ability of the CPS to assert it's independence from the police. Since 004, prosecutors now select the charge almost all cases. 'Statutory Charging' necessitates a considerably more proactive role in investigation; DPP Guidance for charging dictates a personal review of the evidence by the prosecutor, rather than merely an oral submission by the police. Guidance also stresses the need to consult at an early stage with the investigative team and to give advice as to the lines of inquiry and evidential requirements for the charge the prosecutor has in mind. In particular, the CPS takes a more enhanced role in the investigation of terrorism offences. For example, during a 006 plot to cause explosions on transatlantic flights, Crown Prosecutors were based in police stations for the purpose of advising ongoing investigations. Jackson, J., OpCit Hunt, A., and Baldwin, J., Prosecutors Advising In Police Stations, Criminal Law Review, 998, 21 - 26 See Further, Brownlee, I., The Statutory Charging Scheme in England and Wales: Towards a Unified Prosecution System, Criminal Law Review, 96 - 07 The Government Reply to the Twenty-Fourth Report from the Joint Committee on Human Rights Session 005/8 - 6: Counter Terrorism Policy and Human Rights, Prosecution and Pre-Charge Detention, Cm6920, London The Stationary Office, September 006 There are concerns that the enhanced role of prosecutors is damaging to the Phillips principle so much so that independent decision is no longer possible. One could easily draw comparison between statutory charging and the Scottish Fiscal Prosecutor the RCCJ so vehemently rejected. Jackson notes the danger of the prosecution being dominated by the police view of the case and thus losing all the sense of independent decision authority. See Jackson., J. and Adrian and Hunt OpCit Jackson, J., OpCit In addition to more expansive investigative powers, prosecutors are now more involved with punishment and alternative disposal. Prosecutors can now issue a conditional caution, which goes on the offenders' criminal record and requires action, for example paying compensation or joining a drug intervention scheme. This is as close to court punishment without actually going to court. For some, this unification of functions both investigative and beyond, is a worrying step further away from the reality of an independent prosecution service. See, for example, Jackson. Suffice to say that the understanding of prosecutorial independence has, under the 'Phillips principle', been that of detachment and objectivity from investigation. The above implies that the CPS can no longer be said to represent this independence in any meaningful way. Whether this is a good or bad thing is a matter of great debate. See, The Government Reply to the Twenty-Fourth Report from the Joint Committee on Human Rights Session 005/8 - 6: Counter Terrorism Policy and Human Rights, Prosecution and Pre-Charge Detention, Cm6920, London The Stationary Office, September 006 France The procureur has a fundamentally different character to that of the Crown Prosecutor. Whereas the CPS represents the interests of the state, the procureur, as a member of the parquet, is a judicial officer and so acts in the public interest and to ensure due process safeguards are met. She is responsible for the instruction of investigation, which is usually carried out by the police, including extended remand and other coercive measures, and naturally prosecution. One should note that the functional entity of both the police and prosecutors are radically different to their anglo counter parts. As opposed to one multi-tasking police force, there is the police judiciare and the police administrative. The role of the former is to act as an auxiliary to judicial authorities, in particular the procureur. In this way one could argue that they are an extension of the prosecution rather than a wholly independent entity. However, to say that their functional entities are not separate is not to say the prosecution is not independent, but rather there is a different conception of independence. The independence of the procureur is said to be ensured by the independence of the judiciary as laid down in the constitution. It will be useful to examine more closely the relationship between police and prosecutor. Hatchard, J., Huber, B., Vogler, R. (Ed) Comparative Criminal Procedure, B.I.I.C.L, European Law Series. 996 Article 4 of the Constitution of th October 95/88 guarantees 'L'autorite Judiciare' The powers of the police are to record crime, gather evidence and seek out offenders. They can intervene before the judicial investigation where the offence is not flagrant, or during under the instruction. They must inform the procureur immediately of any crimes/flagrant. The procureur supervises and has broad discretion over charging and when the case is passed on to Juge. Independence is conceptualised as through supervision rather than separation. There are no boundaries between the intelligence of the police investigation and the prosecution. Judiciare as Opposed to the Police administrativ Article 4 CPP 'enquete preliminaire' Serious offences Levy. R Police and the Judiciary in France since the Nineteenth Century' (3) British Journal of Criminology 67 - 6 Nonetheless, police still possess considerable discretion to arrest and detain and are required to report to procureur only 'as soon as possible'. Furthermore, it is unusual for the procureur to closely monitor the actions of the police, rather they ensure safe guards are met and may be more realistically describe as a review of the investigation carried out rather than authentic instruction. Hodgson notes a disengagement of the procureur in practice from investigation as part of legal culture of supervision. There is no real expectation that practical investigation from procureur will take place, although she has the power to. In practice the police interrogate and the procureur relies on police accounts of interrogation often over the telephone. Thus the procureur is ultimately reliant on the evidence provided by the police; through a structural paradox whereby the procureur has authority over the police, yet is ultimately dependent on them. The reality is that the procureur does not have as much control over investigations as suggested by formalities of the law. There are worries that this lack of independent control may give rise to deterioration in the due process rights of the defendant, given the limited role of the defence lawyer during preliminary investigation. Article 3 CPP Hodgson, J.,, The police, the prosecutor and the juge d'instruction: Judicial Supervision in France, Theory and Practice, (1) British Journal of Criminology Hodgson Police Ibid. Page Four. In addition to expansive investigative rights, she is entrusted with the responsibility to ensure the sentence of the court is implemented fully. One could argue that this is liable to result in bias. For example, the procureur may not wish to watch a poor single mother suffer a large fine and so chooses a lower charge. On the other hand, the procureur may be vindictive rather than sympathetic and choose the highest charge, and thus punishment possible. Hodgson found that, despite an alleged impartiality before the law, procureurs in some instances inevitably allowed personal prejudices influence their decisions. Furthermore, where one becomes so involved in the investigation of offences, there is a danger of developing a type of conviction mentality whereby one cannot impartially assess the evidence put forward, having invested so much time and energy. Nothing demonstrates this point more clearly than the Outreu affair, where scores of people were falsely imprisoned where an examining magistrate became so convinced of their guilt based on questionable evidence, he failed to exercise independent lines of inquiry. Article 2 and 07 of Order 8 - 270 of the Law of 2 December 95/88 Hodgson, J.,, Hierarchy, Bureaucracy and Ideology in French Criminal Justice: Some Empirical Observations, (9) Journal of Law and Society, 27 - 7 See, for example. Langbein, J.H., 'Controlling Prosecutorial Discretion in Germany', 1, University of Chicago Law Review, 39 URL; 'Collapse of Child Sex Case Shakes French Courts', 2/2/5/8 Furthermore, the independence which the procureur is deemed to acquire through virtue of judicial independence is compromised by the bureaucratic chain of hierarchal control stemming to the executive; Procureurs are not in a traditional sense judicially independent. They are, unlike the sitting judiciary, removable and politically accountable to the Minister of Justice. The Minister presides over the parquet and is highly influential over the career advancement of the procureur. Whilst direct interference from the Minister of Justice has lessened over recent years, by agreeing not to issue directives on specific cases, the minister still issues guidance on prosecution policy and there of course exists the possibility of more subtle interference vis-a-vis review. In fact Hodgson found fear of review to be an issue for many procureurs. Magistrat du Seige Levy, R. OpCit. Hodgson, J. OpCit Consequently the procureurs role in investigative, as well as prosecutorial matters is inevitably shaped by this accountability and can not be said to be truly independent. This raises doubts over equality of arms and that the defendant may not be receiving the full protection of the law where his inevitably biased. Germany Following the abolishment of the investigating judge in the mid-seventies, the Staatsanwaltschaft is responsible for prosecution of offences. An officer of the law, he represents the state. Considered independent and impartial he is obligated to carry out investigations into evidence that will absolve, as well as incriminate the suspect. However this independence is by no means guaranteed. As Muhm notes, the constiution does not explicitly require independence, notwithstanding that the principle of the rule of law, as guaranteed by Fundamental Law demands such independent prosecution. This 'constitutional void', Muhm argues, has inevitably shaped the lack of regulations governing prosecutorial practice and the development of the staatsanwaltschaf, as we shall see. CPP Section 60, Subsection One CPP, Section 60, Subsection Two. Muhm, R., The Role of the public prosecutor in Germany, Irish Jurist, 003, 8, 5/80 - 61 Page 5/86 The relationship between investigator and prosecutors is similar to that in France. Police carry out investigations for which the staatsanwaltschaft is formally responsible for overseeing. The staatsanwalt may perform the investigation himself or request the police to do so, the role of the police in investigatory procedures has been formally disparaged to that of the 'extended arm of the prosecution'. The prosecutor shares all the powers of the police and they are in all manners considered subordinate. Thus independence may be said to be established through control, in a similar fashion to the Scottish model, above. BverfGE, 7, 5/85/8, 63 However, research has shown that the staatsanwalt carry out investigations themselves only in the most serious of cases, due in large part, to personell and budgetary concerns, and the need to adhere to the principle of a speedy trial. Additionally, the police are legally obliged to take independent action where there is a 'danger of delay'. This is interpreted broadly and such powers used freely. Often the prosecution are not informed until the police have produced a draft report at which point it may be too late to intervene. Even where the prosecutor does instruct an investigation, police control the resources of the investigation. Consequently, the prosecutor can only act on the basis of evidence from 'investigations which he no longer conducts', the dangers of which have been outlined above and need not be repeated. Andrews, J. (Ed) Human Rights in Criminal Procedure: A Comparative Study., Martinus Nijhoff Publishers BGHST 6. 28. 32 Hatchard, J., Huber, B., Vogler, R. (Ed) Comparative Criminal Procedure, B.I.I.C.L, European Law Series. Linnan, D.,, Discretion in a Continental European Administrative State: The Police of Baden-Wurttemberg in the Federal Republic of Germany, Law and Contemporary Problems, (7) Furthermore, in a predicament similar to that of France, perhaps not surprising giving its descent from the Ancien Regime, the independence of the staatsanwaltschaft is contrained by a 'rigid hierarchal responsibility to the Minister of Justice'. This political hierarchy, which Hodgson cites as being characteristic of inquisitorial systems, has been accused of leading to corruption. For example, the seeming inability of the staatsanwaltschaft to bring charges against political figues, the Kohl Scandal being just one sobering example that left the repuation of the staatsanwaltschaft in tatters. Muhm, OpCit, Page 5/85/8. Hodgson, J., OpCit See Muhm, OpCit Additionally, the staatsanwalt takes an active role in the alternative disposal of cases, via decriminalisation, whereby the principle of compulsory prosecution is evaded by declaring an offence non-criminal and ordering, or rather suggesting instead a fine. Some maya argue that this evades due process by punishing without trial simply by labelling an act non-criminal. This argument has been rejected, however on the grounds that the offender can reject the fine and opt for a full hearing. Furthermore, he is also involved in the punishment of offenders to the extent that it is his responsibility to request a sentence in court, to which the judge merely agrees or disagrees. Normally a sentence just below that originally suggested is imposed, and rarely above. Furthermore he is responsible for the execution of court sanctions, including fines and perhaps most importantly imprisonment. The staatsanwalt, under the supervision of the Strafvollstreckungsgericht, makes fundamental decisions about the life and liberty of offenders. The dangers of prosecutorial punishment has been outlined above in relation to France and need not be reiterated here. Suffice to say that where basic rights such as liberty are at stake, an independent stance is imperative, but as can been seen, not a reality. Madlener, K., 'The Protection of Human Rights in The Criminal Procedure of the Federal Republic of Germany', In; Andrews, J. (Ed), Human Rights in Criminal Procedure: A Comparative Study. Martinus Nijhoff Publishers, CPP Section 5/88, Subsection One See further: URL Section 5/89e, CPP Specialised Prison Court For example, Article ECHR Conclusion There are many conclusions that can be drawn from the above discussions. Firstly, independence is not a worldwide concept. It means different things to different legal communities. For England independence is conceptualised as thrugh separation and cooperation, in France through judicial authority and supervision and in Germany through subordination and control. Secondly, and of utmost importance, the reality does not always measure up to the conception of independence implied by the formalities of the law. Finally, the above shows the problems of comparing legal cultures with our own. Not only are the entities we are trying to understand of a fundamentally different composition than the ones we seek to compare them against, but they are a product of legal and political cultures alien to our own understanding. As Guarnieri notes: '.different cultural dispositions tend to produce partly different response to similar problems, with rather different results'Guarnieri, C. Prosecution in Two Civil Law Countries: France and Italy in Comparing Legal Cultures, OpCit P189 Whereas the separation model of England was a reaction to the inadequacies of police prosecution, the powers and role of the CPS were borne out of those developed by the police. On the other hand the procureur and the staatsanwalt was borne out of the ideal of the examining magistrat and as such inherited many of those powers and functions, Additionaly, as Guarnieri stresses, the roles of legal institutions are a result of the political environment in which they are created. For example, whereas in France there is a greater degree of trust in the political establishment than in England and Wales, it may not be so unthinkable to allow executive control over prosecutions. It is not reasonable to expect all three jurisdicitons to adhere to a common conception of independence, although independence is crucial if a due process and equality of arms is to be respected.'''",237.0
"'''In recent decades, international attention has increasingly focused on global environmental issues, as the world seeks to address concerns such as climate change, the loss of biological diversity, deforestation and soil depletion, unsustainable energy use, and contaminated water supplies. The concern of the international community in relation to problematic environmental issues has manifested in major world conferences, including ones in Stockholm in 972, Rio de Janeiro in 992 and Johannesburg in 002, as well as through the negotiation and widespread adoption of hundreds of multilateral and bilateral agreements, directly or indirectly related to environmental protection and sustainability. United Nations Environment Programme, Report of the United Nations Conference on the Human the principles of sustainable development into country policies and programmes; reverse loss of environmental resources; Reduce by half the proportion of people without sustainable access to safe drinking water; significant improvement in lives of at least 00 million slum dwellers, by 020.'Above no. Whilst the parts are unquestionably interrelated, it is beyond the scope of this essay to examine each of the above targets. Accordingly, this essay will focus on the first component of MDG. The formal indicators for this component are as follows: proportion of land area covered by forest, ratio of area protected to maintain biological diversity to surface area, energy use per $ GDP, carbon dioxide emissions per capita and consumption of ozone-depleting chlorofluorocarbons, proportion of population using solid fuel. United Nations Statistics Division, Millennium Development Goals Indicators < URL > at January 007. The Implementation of MDG The progress of the MDGs is formally monitored through a procedure whereby governments around the world submit country specific reports in relation to the implementation of each MDG, including information concerning each of the goal indicators. These reports are generally prepared by the government of the country, with assistance from relevant United Nations departments and agencies, as well as academic and civil society contributors where appropriate. As the MDGs have arguably become one of the major reference points for pro-poor and social welfare policy making, particularly in developing countries, MDG country reports are indicative of the background and direction of national policy in relation to environmental sustainability around the world. United Nations Development Programme, Country Reports < URL > at January 007. In June 005/8, the United Nations Development its review of country reporting in relation to the monitoring of the environmental sustainability aspect of MDG, entitled 'Environmental Sustainability in 00 Millennium Development Goal Country Reports'. Despite the international confirmation, noted above, that successful achievement of the MDGs requires a gendered approach, the report contains minimal references to gender. United Nations Development Programme, Environmental Sustainability in 00 Millennium Development Goal Country Reports < URL > at 8 December 006. Similarly, a second 005/8 UNDP report, entitled 'En Route to Equality: A Gender Review of National MDG Reports notes an 'almost total invisibility of gender concerns' in relation to MDG. This is despite the recognised wealth of advocacy and research on the interplay between gender issues, the environment and development in the past decades. In the 8 detailed country reports submitted and reviewed by the UNDP, only eight reports made mention of women as stakeholders in environmental issues. United Nations Development Programme, En Route To Equality: A Gender Review of National MDG Reports 6 < URL > at 8 December 006. Ibid 7. Ibid 6. Further, it was noted that almost all of the reports approached the environmental sustainability issues from a 'technical perspective', without regard to their gender dimension. In response to the narrowness of this approach, several commentators have argued that the vague indicators of the MDGs have resulted in a lack of direction for country monitoring in relation to MDG and have recommended the introduction of mandatory reporting on additional specific gender-based indicators. Ibid 7. Ibid 3. Implications of a Lack of Gender Focus in MDG It would be short-sighted and potentially misleading to simply conclude from the UNDP reviews of recent MDG country reports that gender issues in relation to environmental sustainability are of no concern whatsoever in the individual countries. However, the implications of this lack of gender focus are significant in terms of the extent to which MDG, as currently approached, can effectively result in positive change for women. The near invisibility of women's issues in country reporting on environmental sustainability is 'both a reflection of and a contributor to the gap between environmental policies and gender equality concerns'. Despite the clear and extensive involvement of women in the use and management of natural resources like water and forests, they are commonly not recognised either as stakeholders in policy making or as significant actors in the conservation of these resources. This is illustrated by the patterns of participation in the environmental movement, with a mostly male leadership of large environmental organisations and with women making up the bulk of less influential administrative and volunteer positions within such organisations. UNDP, above no 5/8, 6 Annie Rochette, 'Transcending the Conquest of Nature and Women: A Feminist Perspective on International Environmental Law' in Doris Buss and Ambreena 7, for a useful overview of the scope and evolution of the right to health. The connections between the right to health and environmental sustainability become apparent when considering that the underlying preconditions for human health include adequate sanitation, safe drinking water, sufficient food resources, proper nutrition and control of disease. As environmental risk factors account for almost one-fifth of the total disease burden in developing countries, improvements in health are 'as dependent on.environmental conditions.as they are on improved medical and clinical conditions.' Don Melnick, Jeffrey McNeely, Yolanda Kakabadse, Guido Schmidt-Traub, Robin R. Sears, Environment and Human Well-being: a Practical Strategy UN Millennium Project Task Force on Environmental Sustainability 0. UNDP, UNIFEM, UNFPA, The World Bank and the OECD/DAC Network, above no. In many rural areas of low-income or post-conflict countries in particular, a gender-based division of familial chores will mean that women act as the primary managers of domestic energy resources and the living requirements of their families. Where potable or free water is unavailable locally due to adverse environmental conditions or policies, the task of water collection generally falls to the already adverse effects of poor nutrition, especially if the woman is anaemic, leading to heightened risk of miscarriage and haemorrhage during childbirth, shorter gestational periods, low birth weights and the lowered nutritional content of breast milk. Melnick, McNeely, Kakabadse, Schmidt-Traub, Sears, above no 6, 8. William A. Ryan, Female Medical Teams in Pakistan Reach More Women and Save More Lives than before the Earthquake Women's Human Rights Net < URL > at January 007. Ryan notes the finding that nine out of 0 pregnant women were found to be anaemic in earthquake-torn parts of Pakistan. See, generally: Institute of Medicine, Nutrition Issues in Developing Countries: Part I: Diarrheal Diseases, Part II: Diet and Activity During Pregnancy and Lactation chs -. MDG: Towards a Gender PerspectiveWhy a human rights approach? The preceding section of this essay outlined, through the example of the right to health, how the international human rights framework can be used to provide an expanded definition of the relationship between women and environmental sustainability. This essay concludes with a consideration of the potential for using such a women-focused human rights approach as a foundation for the mainstreaming of women's human rights into country reporting in relation to MDG. The international human rights regime provides a highly legitimate and authoritative discourse in which to frame social and political inequalities and to challenge the traditional legal and social order by demanding the enjoyment of legal rights. In the absence of an express substantive environmental human right, a human rights approach provides a legally binding framework which provides a platform on which to claim that national environmental policy making and related MDG reporting should incorporate a gender focus. Hilary Charlesworth, Christine Chinkin and Shelley Wright, 'Feminist Approaches to International Law' 5/8 Australian Journal of International Law 13, 38. For a discussion of the power of human rights as a framework, and responses to criticisms of the use of such framework by various commentators, see for example: Hilary Charlesworth, 'What are 'Women's Human Rights?'' in Rebecca J. 7. Whilst no single 'woman's voice' exists in a diverse world, the human rights discourse can provide a framework within which to encourage an expanded comprehension of the relationship between women and environmental sustainability, which can then be applied by women's rights advocates and other actors to address local circumstances, as appropriate. Application to MDG Despite the existence of extensive literature regarding environmental sustainability, divergent definitions and competing visions of the concept exist at both a global and a local level. With a malleable concept, there is opportunity to advocate for a gendered approach. In this regard, whilst some commentators criticise the MDGs on the basis that they are too general, I suggest that the women-focused human rights approach outlined be employed to the advantage of women's issues as it allows considerable scope within which to adopt appropriate gendered approaches to environmental sustainability that are applicable to local concerns. Charles E. Di Leva, 'Sustainable Development and the World Bank's Millennium Development Goals' (004-005/8) Natural Resources and Environmental Law 3, 4. Leva describes various understandings of the term 'environmental sustainability'. Ibid. The need for 'broad public participation' has been recognised as important in the protection and conservation of the environment and the move towards sustainable development. Accordingly, encouraging a shift in consciousness to take into account a gendered perspective towards environmental sustainability is likely to require a multidisciplinary approach, involving political campaigning, strategic litigation where appropriate, and the direct and extensive involvement of local communities, women's human rights advocates, academics, grassroots organisations, and non-governmental organisations, in partnership with the governmental and market sectors of society. Handl, above no 1, 18. Ibid. Handl notes the need for the 'cooperation of all sectors of society' in the conservation of the environment and move towards sustainable development. The various individuals and entities can use human rights to link their individual areas of concern, for example women's housing rights or girls' education, to environmental sustainability and then exert pressure on governments, national women's commissions and relevant UN agencies to include these concerns in MDG reporting. This could be achieved in a multitude of ways, including political campaigning, strategic litigation where appropriate, the production of shadow MDG reports and input into the state-produced MDG reports. In terms of possible additional indicators to be adopted by countries to measure their implementation of MDG, the UNDP Practice Note in relation to reporting on MDG progress recommends the establishment of country-specific targets adapted to local concerns and priorities. Women's rights advocates can and should use women-focused human rights based arguments to promote additional indicators that are of particular relevance to the women in their countries. United Nations Development Programme, Monitoring Country Progress Towards MDG7: Ensuring Environmental Sustainability Practice Note < URL > at January 007. ConclusionWhilst MDG is arguably broadly framed within a gendered perspective, when considered in the context of the MDGs generally, a review of recent country-specific reporting in relation to this application of this goal has revealed that there is a current lack of gender focus in relation to this goal. The UNDP has stated that the MDGs 'are intended to catalyse a collective commitment to social transformation.' I suggest that the women-focused human rights based approach to environmental sustainability, as outlined above, has the potential to assist women's rights advocates to direct this social transformation to meet the specific needs of women in different countries. UNDP, above no 5/8, 6. Such an approach could, through the application of human rights law, effectively contribute to the task of bridging the gap between the intentions of MDG, as an apparently gender-neutral international environmental instrument, and the realities of women's daily lives in order to effect practical change and achieve global justice.'''",242.0
"'''This paper will examine the historical and legal context of the minority rights of the Anglophone population in Quebec, and its conflicts with the other national minority in Canada, the Quebec Francophones. The paper is divided into three sections: the first section will briefly give the necessary historical and legal background to the establishment of the minority rights of both the Quebec Francophones and Anglophones. The second section will examine theory of consociational democracy within the context of the situation in Quebec. The third section will examine how the legally enshrined rights have been interpreted in relevant case law, both domestically and internationally. Section I: Background Information The Quebec Francophones as a MinorityTo discuss minority rights in Quebec is to engage in controversial and emotion-fueled discussion where even facts in evidence are up for debate. This section will try to give a brief historical overview of how the Quebec by their minority rights. Terms in and of themselves carry significant meaning, particularly when discussing such a controversial topic as minority rights in Quebec. As such, the terms used in this paper are carefully defined: the French-speaking population of Quebec is termed, in this paper, Quebec Francophones. The English-speaking population of Quebec is termed Quebec Anglophones. The main reason that the term Quebecois is not being used in this paper is that there is continuing controversy over whether Quebec Anglophones are considered to be Quebecois. The arrival of the French colonists in 5/835/8 began Canada's European history. From 5/835/8 to 763, the colony of La Nouvelle France was established in what is currently Quebec, and was comprised of approximately francophones. In 763, however, La Nouvelle France fell from French control into the hands of the British. 'The first policy act, the Royal Proclamation of 763, was quite definitely assimilationist in intent. It sharply reduced the boundaries of the old French colony, set up English law and courts, and set aside lands for the support of Protestant clergy and schoolmasters.' However, in order to secure the loyalties of the francophone population, the British passed the Quebec Act, which guaranteed the francophone majority the right to practice their Upper 70. Ibid at 71. Ibid at 73. The Quebec Anglophones and their Minority RightsThe Quebec fairly well protected until the culmination of the Quiet Revolution in the 960s. During this 'revolution', the QF struggled to challenge the social and political structures in the province, wanting more control and access to the prestigious commerce sector jobs, and more control over their culture and language. In 968, Rene Levesque, one of the politicians instrumental in creating the Quiet Revolution, created the Parti Quebecois - a separatist party. Pierre Trudeau, the other prominent politician to rise from the Quiet Revolution, took the federal direction and eventually became Prime Minister. Trudeau established the Official Languages Act, which declared both French and English to be the official languages of Canada, requiring that all positions and services in the public service and all governmental proceedings and documents be available in French, as well as English. The Parti Quebecois came roaring to power in 976 and the exodus of the QA community began, as the QA feared that they would be trapped in a sovereign Quebec with no rights. The housing market crashed and one of the few English newspapers in Montreal, the Montreal Star, shut down its presses. As individual Anglophones left Quebec, more were forced to leave as large corporations relocated their headquarters out of the unstable world Quebec had become. To this day the numbers of how many QA fled is unclear, however, 'according to a study released in November 978. at least forty-two major companies moved all or a major part of their head office operations out of Quebec in the two years after the election of the Parti Quebecois.' Ibid at 5/83. Legislation Affecting the Minority Rights of the Quebec been removed; and immigrants spoke bitterly of discrimination.' Richard Y. Bourhis, Conflict and Language Planning in 35/8. Bill 01Upon their election victory in 976, the Parti Quebecois (francophone nationalist party) immediately set about replacing Bill 2 with new legislation. Bill 01, the Charter of the French Language, requires that all primary and secondary education in Quebec be in French. The exceptions to this requirement included all children whose father or mother was educated at the primary level in English in Quebec and those children already in English education at the coming into effect of the Act, and their siblings. Among its other restrictions, 'was the declaration French was to be the only language allowed on commercial signs in the province. With few exceptions, the use of English was banned.' Canadian Broadcasting Corporation, CBC News In-depth: Bill 01, online: < URL > Accessed on June, 007 Canadian Charter of Rights and FreedomsThe Canadian Charter of Rights and Freedoms came into effect on April 7, 982. To this day, it is one of the most advanced domestic human rights documents in the world. It provides individual human rights protections to all Canadians from the state and its actions. It supercedes all laws in Canada and 'can render invalid or inoperative any laws that are inconsistent with its provisions.' The CCRF is contained within the Constitution Act of 982, which was the last significant constitutional enactment in Canada. Canadian Heritage, Human Rights Program - The Canadian Charter of Rights and Freedoms, online: < URL > Accessed on June, 007 Section 3 of the Canadian Charter of Rights and the educational rights that are guaranteed to Canada's French and English minority groups. Unlike some of the other sections of the CCRF, Section 3 is available only to Canadian citizens. Section minority education rights to those 'who have received their primary school instruction in Canada in English or French and reside in a province where the language in which they received that instruction is the language of the English or French linguistic minority population of the province.' If an individual meets this criterion, their child has a right to instruction in the same language as their parent. However, there are a few limitations on this section. According to section section. Ibid at. Ibid. Ibid at 5/8 Ibid at 0 Section III: the Interpretation of Minority Rights Legislation in CanadaFord v. QuebecThe case of Ford v. a landmark case in terms of minority language rights in Quebec. The case was brought by a number of business owners who were seeking to challenge the constitutional validity of s.8 and s.9 of the Charter of the French Language, otherwise known as Bill 01. Section 8 of the Charter states that advertisements and signs must be posted in French, and can only have another language posted on the sign if the French is 'markedly predominant'. Section 9 of the Charter declares that 'only the French version of a firm name may be used in Quebec'. The case made its way to the Supreme Court in 988, where it was determined that section 8 and section 9 of the Charter violated section, freedom of expression, of the CCRF. The appeal was struck down, as well as the sections of the legislation. The issue should have ended with this Supreme Court decision. However, with the existence of the notwithstanding clause, as described above, Quebec had another option: they passed bill 78 which declared that, 'the provisions of section 8 and of the first paragraph of section 8, brought into effect under sections and respectively of the present bill, shall operate irrespective of the provisions of section,. recent challenges include the Supreme Court of March of 005/8, where the Court ruled in.. a manner that no longer required the notwithstanding clause. However, as the law had been changed to allow additional langauges besides French on signs, the Committee concluded that Singer has been given a resonable remedy by the State, and closed the claim. Supra Note 0 Conclusion Over the years, there have been significant changes to the legislation that governs minority language rights in Quebec. Since its creation, some of the provisions of Bill 01 have been relaxed. There is no longer a requirement for parents to have been educated in English in Quebec; now, education at the primary level anywhere in Canada will suffice. The laws governing English on commercial signs have been relaxed as well, likely a direct result of the decision of the United Nations. However, the QA population continues to clash with the QF majority, particularly in regards to rights concerning language in education. It cannot be denied that the QA are one of the better treated minorities in the world. However, for violations of minority rights to take place in a country that is recognized as a world leader in the protection of minority rights is unacceptable. The basis to a solution is respect between the linguistical minority and majority in Quebec - respect that has sadly been lacking through much of Canadian history. 'Il me semble que plus je marche, plus loin est la destination. Que je ne vais jamais y arriver. Mais c'est du mouvement et ca me rechauffe et je retrouve mon espoir.'Supra note at 0. Translation: It seems to me the farther I walk, the farther away the destination. That I will never arrive. But it is movement and it warms me and I find my hope. '''",247.0
"'''- to calculate, experimentally, the heat capacity of our calorimeter and use it to determine the enthalpy of vaporisation of a sample of propanone by recording the drop in temperature of the surrounding fluid in our calorimeter. Background:- the molar enthalpy of vaporisation is the heat energy required to vaporise one mole of a liquid substance. during calorimetry, the energy needed is absorbed from the surrounding fluid and so a drop in its temperature is observed, which is equal to the enthalpy of vaporisation divided by the specific heat capacity of the calorimeter system. The heat capacity of the system can be determined by supplying it with a know amount of energy and measuring the increase in temperature. the heat capacity is the number of Joules of energy needed to increase the temperature by one degree. All the relevant formulae will be exploited in this practical. Apparatus:- Procedure:- petroleum transferred to an insulated, glass cylinder and a magnetic stirrer bar added. the cylinder was placed in its insulated jacket on a magnetic stirrer. The lid of the vessel contained a thermometer, heater and an evaporation tube. The heater was connected to a heat monitor and power supply and was switched on while a note was made of its current and voltage. added to the evaporation tube and connected to the water pump to ensure a flow of air over it to remove any vapour produced and encourage the generation of more vapour (by Le Chatelier's Principle). Before turning the pump on, the magnetic stirrer was started and the temperature of the petroleum ether taken at thirty second intervals. The water pump was then turned on and further temperature readings were taken until the propanone had evaporated and the temperature ceased dropping. At this stage the temperature was monitored for a few minutes to see how effective our insulation was (eg. how much heat was absorbed from outside). The heater was then switched on and temperature readings taken until it exceeded the starting temperature. It was then turned off and again the temperature monitored for a few more minutes. Results:-Calculations and Errors:- Conclusion:- the molar enthalpy of vaporisation of propanone was found to be 0.2kJmol^-, which is slightly higher that the literature value of 9.0kJmol^-, with a discrepancy of.7%. Obviously the equipment error cannot account for this as it is much smaller. Other sources of error include our interpretation of the graph and disturbances of our calorimeter system. It is apparent that either the flask was knocked, moving the insulation, or the flow of air into our system wasn't constant because the three sections of our plot that show external influence on the system should have best fit lines of equal gradient. The system appears to be well insulated between and 0 minutes as the temperature stays constant before and after the petroleum evaporates, however at 0 minutes the petroleum ether began to heat up leading me to suspect that the system was tampered with, letting outside heat in. This pattern of heating was observed again after the electrical heater was switched off. To try and minimise the effect of this, the lines of best fit of these periods were extrapolated and the temperature taken along these at the midway time. A great source of error, I believe, was the way in which the graph was manipulated. The lines of best fit were just predicted by eye. A possible solution could be to use a computer program to plot the graph and determine them with it. Random errors in this practical also include our reading of the temperature and timing the thirty second intervals.'''",252.0
"'''In the present political climate ethnicity and housing are key topics. In almost all countries across history, has existed the myth of the immigrant. This myth is still prevalent in modern society. Immigrants are feared and discriminated against, because they are markedly different from the indigenous population. Economic recession, crime, and almost any other societal problem can be blamed on those identifiably 'non-local'. This question will broadly examine if this discrimination leads to migrants in Britain being clustered into specific areas, and types of accommodation, and what effect this in turn has on the migrant population. It will focus on structural discrimination, this is not to say this is the only type of discrimination, but it is the most relevant type for this essay. This essay will attempt to objectively define the key concepts of class and ethnicity, and then to question if these are useful definitions and whether any alternative concepts should be uses instead? The first concept that needs to be defined is that of class. Class is a method of social stratification. Those belonging to a class have empirically similar biographies and may share common outright owner-occupiers; ) the council house tenants; ) the tenants of whole private houses; ) the lodging house proprietors and; ) the tenants of lodging houses.' (Rex and Moore:967:6). This is neo-Weberian view of class. Weber gives equal consideration to the ownership of domestic property as to the ownership of the means of industrial contrast to Marx's class based solely on the relations of production Weber's concept of class was: 'people who share a typical chance for a supply of goods, external living conditions and personal life experiences insofar as this is determined by the economic order. 'Class situation' is, in this sense, ultimately 'market situation'' (Weber:922/947:81-)Access to the housing market, and power within that market will help determine someone's class. Stucturationists refer to this as 'knowledgeability' and 'capability' (Sarre:989:3). The history of all mankind is class this leads to a major criticism of Rex and Moore. Housing class is a product of the wider proletariat versus bourgeoisie struggle. This type of categorization using domestic property allocation is highly useful for: 'Locating the distribution of urban neighbourhoods in the active struggles of groups in the housing markets emphasises factors of generalised importance in the capitalist societies. But. it seems preferable to treat such conflicts as contributing to the overall character of the class structure of a given system' (Giddens:986:07-)Marxists and stucturationists would not argue with the findings, but seek to place them in a larger framework. With reference to the Sparkbrook example, manual workers may find themselves in poorer quality houses, because they do not earn the regular wage required to gain access to a mortgage. But this is representative of structuralised bias against them as a piece-worker rather than as a housing class. Another problem with the concept of housing class is that it assumes collective solidarity, or at least awareness between those in an objective empirical position. In 000 a government survey found that almost 0% of people did not feel there was a community spirit within their neighbourhood. The recent golden jubilee lack-of-celebrations compared with those witnessed in 977 shows that communities are not united. Housing class is as open to criticism as Marx's class system in that it shows no solidarity anymore. This is perhaps because many more people own their own houses since 967, almost 0% in 001, which may stop people having such a shared interest in the local district. Is housing class relevant in the 1 st century? Or could we say as is said of Marx; that it is located in a period of capitalist development. Such a question is beyond the scope of this essay. See link to web address of spreadsheet- Community spirit in neighbourhoods See link to web address of spreadsheet- tenure 971-001 Rex and Moore's concept of housing class was based in a larger hypothesis that ethnic minorities are disadvantaged and segregated from the white local residents. Despite many criticisms towards their work, it is still significant, especially in the formation and composition of 'ghettos' or 'zones of transition' in cities. 'Overwhelming empirical evidence from research conducted throughout the 960s and 0s shows that black and Asian minorities have been characterized by increasing concentration and segregation within the poorer residential areas of the city' (Sarre:989:1).Before proceeding any further, clarification of 'ethnic' is needed. Ethnic in the question refers to ethnic group. An ethnic group is described as having a shared culture (Abercrombie:988:0). Though this can be externally as well as internally created, and unfortunately ethnic groups are usually described by physical traits. There are of course many different ethnic groups, but in relation to this question ethnic groups form a conglomerate. Housing classes certainly could be used to differentiate between individual ethnic minorities, but are more constructive if used to differentiate essentially between those who 'belong' to the host country and those who do not. In the case of Britain this descends, in every sense of the word, to white versus non-white residents. The common quality that 'unites' ethnic groups into a larger group is that they are in someway visibly different to the host population, and this is usually the colour of their skin. This is, however, an inadequate reason for ethnic minorities position in the housing market, personal discrimination is not enough. There are structural societal forces that 'push and pull' ethnic minorities into the same geographical location. Migrants initially came to Britain to work, and so naturally gravitated to the industrial cites London and Birmingham being the two largest. Once in the cities they required accommodation, but had a low socio-economic status and so found themselves in the cheap and dilapidated area of town. As more migrants came there was a tendency to live with people of the same shared heritage. (Sarre:989:Chapter ). Immigrants have similar 'market situations' and so end up in similar housing, and because their basic 'market situation' is extremely poor; language barriers, lack of knowledge of the area and the housing system, they will end up in the worst housing. Does this make them a class in their own right, or are they on the wrong end of capitalist market forces? Marxists argue that this creation of an underclass is a 'reserve industrial army' (Sarre:989:4). They are just another strand of the working class. However as Engels noted classes struggle between themselves, the 'aristocracy of labour' may wish to increase its status by lowering others. Weber calls this social closure, where groups are excluded in order for others to maximise rewards. Good quality housing is kept for the host population by the threat of discrimination and social exclusion, thus 'forcing' immigrants to live together. This has a dual effect notes Parker; that the immigrant group closes itself off, in response to the primary closure by the majority of society (Sarre:989:4-). This closed community is then more attractive to immigrants who share culture, and possibly already know relatives or friends living there. As the closed zone becomes markedly more and more segregated from the host culture, the host culture puts less resources into and so closes it out more and so on. This does not seem to create a specific housing class, though the houses and the areas may be similar. The reason 'zones of transition' come about is because of economic factors in a capitalist market. Those with little market power- i.e. money or the resources to money will have to live in worse areas. A class certainly then arises from this original market position; but whether it is called a housing class seems arbitrary (Giddens:986:08). What is actually important is the isolated and disadvantaged nature of the community created. Structural forces then maintain this situation. The importance of market forces do not make ethnic discrimination redundant, if anything ethnicity makes such forces even more potent. It creates radicalized zones of discontent, but paradoxically these zones then become more remote from society, because of base physical discrimination. Instead of radicalizing society as Marxists might hope. Housing classes are useful tool for examining urban situations. This class view enables sociologists to grasp other problems, even if in the end the link and border between housing classes becomes obsolete. The task is identify those groups who are prejudiced against structurally, and where and how people live is a valid way to do that. Moving from the theoretical world to the real one; underprivileged areas are a serious problem to modern society and because there have always been them it makes explaining them all the more complex and essential.'''",262.0
"'''Despite growing evidence and increasing demand for business expatriates, women remain to be an untapped resource for international assignments. Secondary research was therefore conducted to analyse the myths and reasons female expatriates face, on their way to higher senior management positions. Several factors are established, which underline that female expatriates encounter obstacles based primarily on stereotypical views and male prejudice. The findings also suggest that organisation are reluctant to provide expatriates with appropriate training for successful adjustment in the host country. Thus, practical recommendations for how to maximise the likelihood of success for female expatriates on global assignments as well as further research implications are given.According to recent research has the number of business people, who go overseas, considerably increased in the last 0 twenty years, more than any other period in are not interested in international careers, organisations refuse to send women employees abroad for fear of poor job performance in foreign cultures, cultures discriminate against not as local people, and women are therefore not expected to act like local women. Adler goes on, '.the societal and cultural rules, governing the behaviour of local women, which limit their access to managerial positions and responsibility do not apply to foreign women' (Adler 994, p36). Hence, can organisations be more confident in using female expatriates for international assignments. ConclusionThis research has shown that the reason for the low number of female expatriates on international assignments is primarily based on stereotypical perceptions and myths. The majority of senior male executives, who are responsible for expatriate recruitment, judge female managers not on their capabilities and actual performance skills on the job, but rather on cliches. Metaphors such as the glass-ceiling phenomenon give a clear indication of the barriers female's manager's, throughout the world, encounter on their progression to the top management level. In addition, the amount of family and spouse support provided by corporations is minimal, which result in female expatriates not being able to commit themselves to international assignments in fear of loosing their private life. Another assumption made by companies is the belief that female expatriates are more likely to be discriminated in countries that have male dominated hierarchies in their organisations. Research however, has shown that women are accepted in these cultures, which is particularly the result of their feminine competencies. This work has therefore argued that organisations need to select and recruit expatriates not on their technical expertise, but on for example, intercultural sensitivity, empathy, and cultural awareness. Moreover, is it important for organisations to implement appropriate training schemes and pre - departure assistants for female expatriates to reduce the likelihood of failure while on assignments. In sum, this article has provided several vital factors to increase the success rate of female expatriates who are employed by multinational organisations. However, the barriers and challenges female expatriates face will only start to evaporate when male managers forget about stereotyping and cliches, and start to see female managers for what they truly are, the essence of business success. Further Research ImplicationsFurther research should try to find out how multinational hotel companies recruit and select expatriates in reality. Although the literature emphasises certain crucial competencies for expatriates that are needed to succeed on international assignments, limited research has so far investigated to what extend the suggestions are put into practise.'''",264.0
"'''A response to the perceived failings of the criminal law to deal with the growing problem of anti-social behaviour, the government's Crime and Disorder Act 998 marked a controversial break from the traditional policy of diversion and deinstitutionalisation. The compatibility of Anti-Social Behaviour various fundamental principles of criminal law has come into question due to its overlapping status between civil and criminal procedures. The government presents ASBOs as a necessary mechanism operating within a legitimate system. As the criminal law is a code of norms of conduct, ASBOs simply reinforce this concept of acceptable behaviour in relation to those who have shown disregard for it. Although this perspective is grounded in practical experience, the government, naturally biased towards justifying its own policies to maintain support for future elections, is not necessarily primarily concerned with the principles of criminal law. Consequently, whilst being useful in an informative sense, much of the government's literature on this subject is coloured by political rhetoric. ASBOs embody New Labour's philosophy of 'zero-tolerance.' These measures respond to recognition of the impact of persistent low-level offending, and a corresponding need to address criminal behaviour at its early stages. Far from undermining the criminal law, it may be argued that ASBOs have an important, complementary role in addressing genuine problems without the need for further investment by the criminal law. It is vital that the criminal law is flexible, and willing to evolve with society. The potential scope of ASBOs may be worryingly wide, yet Keogh's defence of local authorities' 'sensible use' (Keogh, A., 'Anti Social Behaviour Orders? Practical notes', 003) is supported both by local evidence and by the availability of viable alternatives. Furthermore, the decision in R v McCann EWCA Crim 83 established a criminal standard of the primary legal test of the causation of 'harassment, alarm or distress' (Crime and Disorder Act 998 s. to protect the interests of the public as well those of private individuals. Home Secretary David Blunkett's focus on the 'need to shift the balance from the minority that spread fear and distress to the majority that want to win back their communities' (Home Office Action Plan:'Together - Tackling Anti-Social Behaviour', October 003, at p.) exemplifies this stance. Accordingly ASBO procedures, through their use of hearsay evidence, shift the balance from that of the general criminal law to a victim-centred approach. Rather than undermining the criminal law, this addresses a recognised problem of the system. The criminal law faces problems due to alienation not only of the victims and witnesses, but of the public at large. Through swift, resolute action dealing with very visible forms of crime and harassment, procedures aimed at anti-social behaviour endeavour to revive faith in the institutions and enforcement of criminal law. Finally, the purposes of an ASBO do not conflict with the principles of criminal law. The government emphasises that the purpose of an ASBO is not.f. Crime and Disorder Act 998, Section.f. Derby Crime and Disorder Partnership Annual Report 001-2, pp. 8-1: Part. Anti-Social Behaviour 001-2,, at p.f. Crime and Disorder Act 998, Section, A., 'Anti Social Behaviour Orders? Practical notes',: 'A most powerful piece of evidence can be a person's antecedent history, particularly if it shows frequent offending... There is no issue of double jeopardy...''''",270.0
"'''Vinegar is formed by aerobic bacteria oxidizing grain alcohol to acetic acid and water. More generally, vinegar can be defined as a solution composed of acetic point at which both reactants have been completely consumed by the known reaction can be ) The amount of one reactant can be calculated from the known concentration of reactant in a standard solution, the volume of standard solution used, and the balanced known chemical equation. For an acid-base titration, the known chemical reaction in general is: and for the titration of the vinegar in this experiment the following specific reaction will be used to calculate the acetic acid content of the vinegar sample: Sodium hydroxide will be the standard reactant solution for this titration, and acetic acid the calculated unknown reactant. The end point in this experiment will be detected with an acid/base indicator. An acid / base indicator is a colored substance with two or more different colors depending on the value of the pH of the solution. Indicators are also very weak acids or bases and react with added acid or base if no other base or acid is present in a solution. Phenolphthalein is the indicator used in this experiment, and phenolphthalein is colorless in acid and neutral solutions but is red in basic solutions. The phenolphthalein will change color with the addition of a single drop of sodium hydroxide if no other present in the phenolphthalein-sodium hydroxide solution. METHODWe first needed to prepare and standardize the NaOH solution via titration with a primary acid standard, potassium hydrogen.M using as a colour indicator phenolphthalein. We then had to titrate with our standardized base to determine the total acid content of our vinegar samples and express the results as acetic values are considered very high, and this can be contributed to the method. In this method we titrate not only acetic acid but all the acids that are in the samples, so this is an error based on the method that should be taken into serious consideration when expressing the results. As far as the second sample is concerned, the relative low is calculated can be justified by the fact that there might be mineral acids dissolved in the sample. pH paper:The literature values for pH in Vinegar are usually close to pH value ~. From the results we have using the pH paper, we can observe that sample number and are very close to that value but the value for sample is way far that value. Perhaps the presence of Mineral the rd sample has altered this result. Reactions with silver nitrate and barium chloride solutions:We know that the test with the AgNO is a test to determine the presence of Cl- and the test using the BaCl is a test to determine SO -. After performing these tests, we observed that the tests using BaCl were all negative, something that indicates that there is no presence of SO - in our samples. When performing the tests using AgNO we observed turbidity and precipitants in samples1 and, and small turbidity in the tube containing sample. This indicates that Cl- is present in all three samples, but in larger quantities in samples &. Taking all the results from all the teams that performed the same experiment, we constructed shows the variation of the results related to the mean value, taking a measuring unit for an upper and a lower limit., where = standard deviation and n = sample the first sample we had: For the second sample we had: For the third sample we had: As we can see in the charts above, in the first sample, our value for the acidity of vinegar is out of the 5/8% confidence limits that we have set and therefore a significant error has occurred. This could be mainly due to the human factor as we observe that most of the other teams were inside these confidence limits, so it is not a problem caused by the method. Such errors should not occur and are minimized by training and exercise. As for the second and third samples, we observe that we are inside the confidence limits and in fact we are very close to the mean values. All in all, many errors may occur. A common error is the sampling error which is partly avoided by the use of more than one sample when titrating. Limitations due to the uncertainty of the instruments also exist but we consider them as not significant when doing our calculations.'''",274.0
"'''Explanation on how to maximise room revenue on Wednesday 5/8th May 005/8According to the 'realistic view of final demand' for May 5/8 th shown in Table, the total demand forecasted adds up to 42 rooms. As the hotel only has 00 rooms available, a solution on which room requests to turn away has to be found. In order to maximise room revenue, the goal is to sell the rooms for the highest rate possible to the highest paying customers. However, the aim is also to increase occupancy during the 'shoulder days' by offering special discounted rates to guests who are willing to stay for two, three or even more nights. With 83 rooms already booked for the night, 17 rooms are left for sale. Below, the decisions that have been made for the different segments are explained. Generally the Rack Rate is available for Wednesday, May 5/8 th to customers from any segment even if only staying for one night. Independent Business business travellers generate the highest room revenue it has been decided to offer 28 rooms to this segment. This means that the forecasted 28 business travellers would all be able to stay at the hotel and nobody would have to be turned away. Rate B will be offered for guests staying for one or two nights, while customers staying for three days or longer will benefit from the cheaper IBT rate C. As demand does not exceed the number of rooms on offer, it has been decided not to adopt a too aggressive pricing strategy for the IBT segment to ensure that all designated rooms will be sold to Independent Business Travellers. Corporate & Association rooms demand forecast chart shows that it is unlikely that any further bookings will be made within the remaining 5/8 days. Therefore no rooms will be blocked for this segment. However, should there be enquiries the following rates apply. As the hotel is aiming at filling up Thursday and Friday rate E will be offered to potential customers staying at least two nights while rate F will only be open to the CAC segment if guests reside for three nights or more. If bookings come in, the hotel would profit from the effect of getting business for Thursday and possibly Friday. Independent Leisure is the segment paying the lowest rate and thus contributing the smallest amount to room revenue. With 00 hotel rooms available overall, 83 current bookings, 09 of the remaining rooms blocked for Independent Business Travellers and none for Corporate & Association Conferences, rooms remain to be sold to Independent Leisure Travellers. This means 2 enquiries from the ILT segment will have to be turned down. Having this number in mind, a slightly more aggressive pricing strategy can be applied as demand is expected to be high. Only the Rack Rate will be offered to ILT customers who want to stay for just one night, all other rates are closed. However, rate G will be given to guests staying for two nights, rate H will have to be paid by customers staying three or four nights and rate I will be open for travellers staying at least five nights. It is hoped that this pricing method will tempt Independent Leisure Travellers to stay for two or more nights which would present a solution to the hotels low booking situation for Thursday and Friday. Furthermore, it might bring in valuable business for the weekend as well, which is why rate H is offered for three or four nights. On the other hand, given that the hotel is in Edinburgh, leisure demand on the weekend might be relatively high which would suggest implementing a high ILT rate. However, it is not known whether the hotel specialises on either the business or the leisure market in particular. Issues of yield management in the hospitality industryTo effectively apply yield management in hotels a number of issues need to be considered. This essay will look at two important elements involved in marketing and customer relationships; firstly overbooking and secondly rate fences as a method of pricing. With reference to relevant literature these will be explained and evaluated. The essay will also make suggestions of how to guarantee effective appliance of yield management at the 00 room four-star hotel in 'if the cost of customer displacement can be reduced, companies can be more aggressive with their overbooking policies while satisfaction'. Due to the large number of four-star hotels in E should be able to make arrangements with some nearby competitors for the case of overbooking and thus reduce their displacement costs and take a more aggressive approach. Moving on to the second important topic of yield management, the practise of setting rate fences and deciding on what prices to charge to which market segment at what time and for how many 'rate fences can be physical or non-physical in nature' and differentiate why various rates have to be paid. Material characteristics like type of room, location of the room and special in-room equipment available, fall under the description of physical rate fences. These can only be offered to a limited extend as there is not an infinite number of rooms available which feature the aforementioned qualities. For example, not all rooms of Hotel E will feature a nice view over the city, the castle or the park. Non-physical rate fences mainly comprise customer behaviour. Length of stay and amount of money spent in the different outlets of the hotel are examples for criteria which have to be considered when setting this type of rate fences. They are offered to guests who belong to organisations of a certain size which obtain a considerable amount of bargaining power, but also to return guests, customers above a particular age or staff members. Another type of rate fences consider transaction attributes; price that is offered depends on time and place of the reservation or on cancellation restrictions. Only providing a limited number of rooms for a certain price, thus setting a margin, would also be a transaction method. Wirtzal. (003, p200) state 'the more restrictions the customer is willing to accept, the deeper the discount available'. However, Kimes warns not to alienate customers by making rates fences too obscure. Obviously, they also should not be too easy to get around. Bennett agrees and points out that guests will acknowledge openly displayed and explained rate fences, and will thus not feel deceived. Nevertheless, as Wirtz and Kimes discovered, customers who are less familiar with the concept of rate fences and revenue management are more likely to react negatively to the applied price differences. Further, comparing new rate fences with those of competitors before implementing them is also of primary concern. As the first proposal is not always the best, customers might be sceptical about the new proposal, which could result in lower business. Often, up to 5/8 per cent of services are offered to various discounted prices in companies within the hospitality industry. Wirtz et al. (ibid.) explain that if hotels set relatively high rack rates, they will be able to offer more discounts, which pleases customers. As has been shown above, there are positive and negative aspects of overbooking and rate fences. Hotel E should continue applying yield management, but should not disregard the dangers that come with it: the possibility of customer disappointment. As Hotel E has only adopted systematic revenue management at the beginning of this year, there might be a lack of historical data which is needed to practice overbooking successfully. However, over time, the accumulation of data will forecast future best case scenarios. Rate fencing can be applied sooner taking into account the above mentioned techniques and explaining them to customers as well as employees to ensure perceived fairness.'''",276.0
"'''The basis of this assignment is to broaden our knowledge and understanding as to why 'responding to others' within health and social care is important and how health professionals go about doing this effectively. In order to respond to others, firstly, we have to establish different forms of communication, both verbal and non-verbal as well as interpersonal skills in order to enable us to meet the needs and obtain relevant information from clients, family members and other health professionals. Throughout my piece of work I will go onto expand and explain in more detail why responding to others is important and how we, as health professionals go about doing this and I will also identify who the 'others' may be. In order to help us appreciate the different roles, skills and responsibilities that exist when working effectively with others, as a subset we were given the task to carry out an interview. From constructing and then carrying this out as a subset we believed we would be able to obtain a better understanding of the range of communication and interpersonal skills that are needed to become a competent practitioner who is able to work with a variety of people in a range of settings. Again I will explain the whole process of this interview later on in my piece of work. I will then go onto draw together a reasonable conclusion stating how I feel my personal qualities and experiences have affected the way I worked within my subset. I will also draw upon the main points I feel have been made. Responding to others in Health and Social careWithin health and social care, professionals need to be able to respond to others effectively and efficiently through communication, whether this is verbally or non-verbally. This communication can be in the means of writing, speaking, trying to persuade an individual, informing, entertaining, explaining, convincing or educating, there are also lots of other ways that communication can be carried out, these were just a few examples. According to Stanton, she believes that we always have four general objectives when communicating, these being: To be be understoodTo be acceptedTo get is then thought if we fail to achieve one of these objectives then we have failed to communicate. This can then lead to frustration or resentment between the individuals that the communication is taking place. So, communicating effectively enables us to: Gain trust from another individualObtain informationDeliver informationAvoid frustration and resentmentUnderstand and be understoodCarry out actions depending on what information has been receivedRespect each otherHowever, sometimes we can come across barriers to communication. These cause problems with communication, which can result in the objectives not being met or just generally responding to others ineffectively. Some barriers that health professionals could come across include: Difference in perception - the way we view the world can be determined by our past experiences Jumping to conclusions - we see what we expect to see and hear what we expect to hear, rather than what is actually there Stereotyping - we learn from our experiences and so we run the risk of treating different people as if they were the same Lack of knowledge - it's difficult to communicate effectively with someone who has a very different background from ours, or whose knowledge of the particular subject of discussion is considerably less than ours Lack of interest - receiver's lack of interest in the message being given Difficulties with self-expression - communicator has difficulty finding the words to convey their ideas or lacks confidence Emotions - any strongly felt emotion of receiver or communicator is liable to prevent almost anything but the emotion being communicated Personality - not just the differences in peoples personalities that can cause problems, often our resulting behaviour can then affect the behaviour of the other person These examples of barriers were taken from Stanton. I however, personally believe that the most common barriers to communication are people having a difference in perception and also jumping to conclusions. I believe this due to past experiences, as when our subset carried out our task I feel that some members of the group maybe felt that because I was younger than them they didn't need to take my opinions into account. This could be due to the fact that they maybe felt I didn't know as much as them because of my age and being younger, which to me meant that they jumped to a conclusion, however, I have actually carried out a similar task and therefore had quite a good idea how to go about doing the task, yet my views didn't seem to matter. I also believe that these are the most common barriers to communication due to people experiencing so many different aspects of life resulting in everyone interpreting the world differently making it hard for people not to pre-judge and assume different things in different situations. These can also be done in the unconscious mind, resulting in us being unaware that we're carrying this out and so it's harder to control. The examples above are only a few examples of barriers to communication that health professionals could come across, however it is up to either the receiver or the communicator to make conditions as satisfactory as possible so that communication has a chance of being effective. Yet not always can barriers be avoided which results in health professionals not responding to others effectively. If this is the case then: Wrong information could be obtained Wrong actions could be carried out due to the individual being unaware of the truth or relevant information Individuals may not understand what is expected of them Individuals could feel devalued and disrespected Frustration and resentment could occur I believe that all the above are just a few of the problems that could result in miscommunication. Previous experience has again helped me to come to this conclusion. With the activity our subset carried out, I believe that we didn't communicate effectively as a result, I feel we didn't obtain enough information prior to carrying out our task. I then felt that because we didn't obtain more information I felt we then went about the task the wrong way resulting in the subset not being fully aware of what we were actually doing due to the group not communicating with each other and explaining what we were going to do. However, because we therefore didn't respond to each other effectively I feel that the task wasn't as good as it could have been which was quite frustrating. I will however explain in more detail later on in the assignment as to why I feel our subset didn't communicate effectively. As I have shown it is very important that communication is carried out effectively in order to avoid any mistakes and misunderstandings and so that no individual feels devalued or disrespected. Health professionals have to communicate with many different individuals, these individuals can be split into three main groups: Other health professionals - maybe discussing a client or in need of referring a client Clients - in order to establish their problem and help treat them Client's family and friends - they will be supporting the client and these too may need supporting and also the clients' illness and treatment may need to be discussed with their family due to the patient being a child and therefore under the age of consent or the patient being too ill to be able to discuss their illness or contribute to their treatment or care When health professionals communicate, they do so in three main ways, verbally, non-verbally and listening. According to I had previously been reading. On here it had some questions that would be relevant within an interview. I therefore based my questions around these however, I adapted them to make them relevant for our interview. From coming up with these questions it later enabled us to put them all together and coming up with the best questions that we were going to use. We then went onto evaluate why these questions were useful and whether we would be able to collect the information we need from them. As I mentioned earlier I believe our subset didn't communicate effectively, this I feel was because when it came to actually carrying the interview out I feel the majority of the group was too laid back and we didn't benefit from this as much as we could have. I feel that before actually carrying the interview out we should have carried out further research into carrying out interviews. This would have enabled us to gain a wider range of ideas as to how we could maybe carry out a very effective interview and obtaining the information we required. I also feel that we could have actually discussed the seating arrangement of the interview in order to make it more formal. I feel that due to carrying out a communication assignment before I had more of an idea as to how we should go about organising the interview and also how the interview should go. Yet due to being one of the younger ones within the group I feel my opinions weren't really taken into account, which in a way made me feel disrespected and I started to sit back in the group. This is a situation that could easily a rise within a hospital, yet not necessarily be due to age but maybe arising between professionals where one is of higher authority and doesn't take the other professionals opinions into account. A study that may relate to this is that by Milgram. This study showed how people obeyed to authority even though they didn't believe in what they were doing. Instead of the individuals sticking to what they believed in, they obeyed due to Milgram being of higher authority. One reason for this could have been that they felt that if they expressed their opinions and beliefs then they wouldn't have been taken into account, this feeling could be due to them previously expressing their opinions and beliefs and they were just ignored and instead encouraged to carry on with the experiment. Even though the situation was slightly different, it did however feel like the older members within my group were in charge and they didn't take my opinions into account, resulting in me sitting back and agreeing with what they said we did even though I didn't believe this was the right way to go about the situation. As for when it came to coming up with the questions I felt that on the whole the subset worked well as a group as we discussed what was to be done and agreed quite easily on the purpose of each question and what we were wanting to obtain from each question. Overall I feel that we could have researched into how we were going to carry out the interview a bit more, this would have enabled us to understand more about the purpose of the interview and the best way of carrying the interview out. I also feel we should have picked a more confident person to carry out the actual interview as then they would have felt more relaxed which would have benefited the interviewee. This again we can relate to practice, as the more confident we are the more relaxed our client will feel and they will probably be able to express their opinions more resulting in all the relevant information hopefully being obtained. The main thing I feel went well about this exercise was choosing our questions as we put a lot of work into these and they seemed to result in all the relevant information being obtained without the interviewee becoming confused or feeling as though we were being to personal. However, I feel we could have spent a little less time on the questions and instead carried out other research and concentrated on other aspects of the interview, such as the seating pattern. ConclusionFrom carrying out the interview I believe we got a good opportunity to see how different people communicate with each other and also how people treat each other. It was interesting to find out that some older people feel that they know more and maybe devalue individuals due to them being younger. This makes you realise that you could come across this within the profession and luckily from this activity I am now aware of this and I can now make the most of any opportunities that a rise to enable me to take this into account and maybe build up my confidence so in the future I can maybe go onto stand up for what I believe in and also get my opinions noticed if I feel this necessary. I feel the interview also gave us an opportunity to build on our team building skills and organisational skills. I however, feel that I am a very independent person and I work better on my own. Yet within this profession it's not possible to work on my own and so it has helped me to try and improve my skills and confidence of working within a group and learning to listen to other people's opinions. With half of the group being quite laid back I felt that the other members of the group had to work a bit more in order to make sure some of the deadlines we set were met. This sometimes meant that three of us worked and then we informed the rest of the group about what we had discussed, when instead it should have been the group discussing it all together, sometimes this did get a bit frustrating but again this could happen within the profession and we will not have a choice and we may have to go ahead and make some decisions without the rest of the team. I feel I am quite an organised person and so I always made sure I met the necessary deadlines we'd made, however, a few in the group didn't do the work that was sat. This made easy tasks a little more difficult and they took a bit more time, which meant we lost some time for other tasks. If I was to do this activity again I believe setting each person a specific task rather than setting everybody the same task would be more beneficial as each individual would be more inclined to carry out their task due to nobody else carrying it out and therefore not wanting to let the rest of the group down. Overall it was an interesting but challenging experience.'''",278.0
"'''Five experiments were carried out to investigate the properties and uses of ultrasound waves in solids. Longitudinal waves were passed through two metal blocks to determine their longitudinal moduli, M, and Poisson's ratios,. For the aluminium block, M, and was.3. For the mild steel block, M and was.4. The echoes of longitudinal waves were also used to detect and size defects in an aluminium block, which proved successful as four defects were found. Shear waves were then produced from reflected longitudinal waves and were measured to have a velocity -, just fitting the expected value of 100ms -. Their angle of reflection and velocity were then tested against a version of Snell's Law, which proved inconclusive. Longitudinal waves were totally internally reflected to produce surface waves, the velocity of which was measured to be 860ms -, matching the theoretical value within experimental error. The wavelength of a surface wave is proportional to energy, which is related to the depth of the wave, so by passing the waves through a slot of varying depths, its wavelength was found, with a value.1. Ultrasound wavesSound with a frequency greater than 0kHz is known as ultrasound. This experiment investigated the properties and some uses of the three types of ultrasound waves that travel in solids: longitudinal waves, shear waves and Rayleigh made by the Piezoelectric effect. More about this effect, regarding transducers, can be found in reference. Liquid couplant coupled the ultrasound from the transducers into the solid samples. Although all three types of waves travel through solids, only longitudinal waves can travel through liquids. Therefore longitudinal pulses are the only ones that were generated by transducers in this experiment. Ultrasound Physics and Instrumentation, Hedrick, Hykes and Starchman, Mosby. Longitudinal and shear bulk ultrasound wavesA longitudinal pulse can be converted into shear waves can be produced by means of reflection and refraction, as figure shows.. Rayleigh ultrasound bulk wavesAs Rayleigh waves only travel on the surface of a solid, they are also known as Surface Acoustic Waves, or SAWs. They are produced by setting i in figure at the critical angle for total internal reflection for either the reflected shear or longitudinal wave, giving an angle of reflection of 0 o, leading to a surface wave. SAWs travel with a retrograde elliptical The density of material is easy to measure, so if a longitudinal wave were passed through a material, its Young's modulus can be calculated. Notice however that equation is only effective for a D object, so for this experiment, where D solids were used, the equation gives the longitudinal modulus, M, instead of E. Poisson's ratio,, is another property that can be calculated. Poisson's ratio is defined to be 'the ratio of the contraction strain normal to the applied load divided by the extension strain in the direction of the applied load'iii and is given by equation. Due to the sign is important to know that is positive for all materials that get thinner when stretched. Poisson's ratio website can be solved by using M from the previous part of the experiment and the theoretical value of E.. Mode conversionThe second part of the experiment investigated the conversion of longitudinal waves into shear testing their properties against two given equations. Firstly, an equation was given linking the distance the pulse has travelled as a longitudinal wave, dl; the distance the pulse has travelled as a shear wave, ds; the time taken, ts, for the shear wave to travel it's distance; the velocity of the longitudinal wave, vl; and the velocity of the shear wave, vs: second equation is an arrangement of Snell's Law: is the angle of reflection of the shear wave and i is the angle of incidence of the longitudinal wave. Equation can be used to calculate vs and if the value is correct and a shear wave has been located, equation should apply.. Detecting and sizing defectsThe third aim was to use 'sonar' properties of longitudinal ultrasound to detect, locate and size defects within an aluminium block. Detection can be achieved quite simply by knowing the velocity of a wave and the time it takes for the wave to reach the defect.. Calculating the velocity of a Rayleigh a SAW has been velocity, cr, can be calculated by making time and distance measurements. Theoretical value of cr is given by:. Crack DetectionFinally, by measuring the energy of the wave at different depths in a block, an estimate of the wavelength of the SAW can be a transducer. For many of the experiments an additional 'receiver' transducer was connected to another channel of the oscilloscope, which picked up the pulse once it had travelled through the sample. The transducers and the samples were assembled as shown in figure The delay-time facility on the oscilloscope enables the time between wave transmission and reflection to be determined. The pulse was set at slowest rate so that the subsequent transmitted pulse wasn't shown on the oscilloscope before the first reflection. All time errors in this investigation are due to the pulse having multiple measured to enable the velocity of the pulse, vl, to be calculated. The metal samples were also weighed, using digital scales, and measured so that their density could be calculated and thus the longitudinal moduli and then the Poisson's ratios could be obtained.. Results and discussionThe graphs shows vl, to -through aluminium - through mild steel. The actual value of be 400ms - so the gradient of figure be steeper. Since the time measurements all seemed quite accurate, increasing by sensibly even amounts, then the problem must lie in the distance measurement. A possible reason for this is that the thickness of the liquid couplant wasn't taken into account, so the distances should all be slightly greater, which would give a steeper graph. Fundamentals of Ultrasonics, Blitz The actual value of be 5/800-000ms -v, therefore the value obtained experimentally was within the expected range. The density of the aluminium was calculated to - and the density of the mild steel to - Substituting these values into:, M aluminium=10.GPa vi and M steel=78.GPa vi. Both values are larger than the experimental ones, which should be expected from the fact that vl for aluminium is too low and vl for mild steel could be too low. Also, it shows that the above errors have been underestimated. The theoretical value for Young's modulus is 0.GPa vi for aluminium and 11.GPa vi for mild steel. Putting this and the experimental value for M into equation gives Due to the small errors in M, these both have negligible errors, despite them not quite matching their theoretical values of.45/8 vi for aluminium and.91 vi for mild steel. Mode Conversion3. Experimental DetailsThe longitudinal wave hits the metal-air interface at i = 5/8 o then a shear wave is reflected at angle. In this case, a distance was measured by means other than vernier callipers as distance dl was measured using trigonometry. Sin was also measured using trigonometry by using distance ds and the height. Both the reflected longitudinal and the reflected shear waves were detected, but were far enough apart to be distinguishable. All the waves are actually divergent beams, so it was important to ensure that the peak of the shear wave had been located.. Results and discussionReferring back to equation, on insertion of the measured values of dl and ds, the observed value of ts and the known value of vl iv the velocity of the reflected shear wave turned out to be Error was calculated using standard error formulae. The actual value for vs for aluminium is 100ms - so the experimental value was just accurate within error. Testing equation, sin was found to equal.1. Looking at the right hand side of the equation, substituting in 5/800ms - for v s and known values of sin45/8 and vl gives.9. The fact that the two sides are not equal might well be due to vs being too big. This experiment could be improved by using the oscilloscope to test if some of the longitudinal wave was picked up as well, and repeating readings at different points to find if the equation does hold at any point.. Locating and sizing defects3. Experimental Details In this experiment the dB drop-technique method was used: Ultrasonic Methods of NDT, Blitz and Simpson The MHz transducer is moved around the block until a defect is. Surface wave generation3. Experimental DetailTo find the critical angle of a Rayleigh wave in mild steel the following arrangements of Snell's Law were used: Values used: From Tables of Physical and Chemical Constants, Kaye and Laby To produce surface waves l and s must = 0 o i is set to 3 o, which is fairly close to i for the shear wave so this will be the one to turn into a Rayleigh wave.. ResultsThe graph shows that the experimental value of v - The theoretical value for a Rayleigh out as 900ms -. Therefore the experimental result is correct within experimental error. It might be useful to see if using a combination of materials where the critical angles of the samples match exactly would give an even better result.. Crack Detection3. Experimental DetailsThe depth at each point could be measured by knowing the gradient of the slot and the distance the transducers were along the block.Four amplitude measurements were made for each depth. The average value of the amplitude was then taken, with its corresponding error being the standard deviation of all the amplitude values at that point.. Results When energy = E/ equation becomes and rearranging this gives, mm. Summary and conclusion4. Bulk Wave GenerationMethods for finding the velocity of longitudinal waves were tested and found to be fundamentally correct; however the value for aluminium was slightly lower than the theoretical value. This could be due to too small distance measurements, which could have been because the distance of the liquid couplant wasn't taken into account. The longitudinal moduli and Poisson's ratios were all slightly lower than the expected values, which reflects the possible low values of both the velocities.. Mode ConversionLongitudinal and shear reflected waves were detected, with the shear wave having the smaller angle of reflection, as expected. The velocity of the reflected shear wave vs in aluminium was found to - so was fairly accurate considering it should have been 110ms Snell's law was tested for the shear waves. From the experimental results the equation did not seem to hold. This could have been due to not finding the correct position of the shear wave, which could be why slightly too large. Therefore, testing to see whether the equation was true proved inconclusive.. Detecting and sizing defectsThe size, shape and depth of defects were found using ultrasound waves and their reflections through an aluminium block. As all four defects were found, the dB drop technique method proved to be useful, however the sizing of the defects was probably incorrect due to the fact that relative to the transducer the defects were small.. Surface Wave GenerationSurface waves were generated using total internal reflection of shear waves. The angle of incidence was set by the wedge transducers used and was close to the angle calculated using Snell's law for Perspex/ mild steel. The velocity of the Rayleigh waves was calculated to be. Equations were used to find the theoretical the results matched within error. Distance between transducers had error due to it being tricky to ensure that they were exactly in position, as they slid easily on the liquid couplant. There is a systematic error, as time for waves to travel through Perspex hadn't been subtracted from final times, however, this will not affect the gradient, which is all that is of interest.. Crack DetectionThe amplitude of Rayleigh waves were measured as the passed through an aluminium slot of varying depths. The square of the amplitude is proportional to the wave energy. It is known that at /e times max energy the depth of slot there will equal the wavelength of the Rayleigh wave. From the graph, was found to The graph was a fairly good straight line ln graph, showing that the energy did decrease exponentially with slot depth. Difficulties here were firstly with the block: anomalous results in a first attempt suggest that the slot was not smooth and the couplant might be filling it. Overall points to note The PC oscilloscope was used throughout the experiment to make time and distance measurements. Often peaks jumped with amplitudes varying significantly from one frame to the next, so affecting distance measurements. Also it was hard to measure the time due to multiple the PC oscilloscope seemed as if it would be a better instrument than the traditional oscilloscope as it has cursors, which avoids human measurement error. Also, values for time, volts/div etc. can be shown on the monitor so reading them off by eye is no longer a problem. Its one disadvantage is hat the PC and cables introduce noise into the system, which the other one wouldn't.'''",279.0
"'''.1. AbstractThe Izhikevich Neuron model is currently the forefront spiking neural net model. It can emulate all the key modes of firing, and does so with only 3 floating point operations per second of emulation time. The Hodgkin's and Huxley model - the only other model capable of displaying so many firing modes - requires 200. In an experiment done by Izhikevich, where he ran a network of these neurons with synapses on a Beowulf supercomputer, it took 0 days to run what could be considered one second of brain activity. The integrate-and-fire model, the fastest spiking neuron model, which has drastically lower functionality, still requires FLOPS and thus would have still taken around 0 days to run the simulation. This highlights a problem with such neurons - running them on conventional computers - even supercomputers, is not efficient. The only way to run them, at any kind of reasonable speed is on massively parallel hardware dedicated to running them. This report charts the development of a simulator for a theoretical board which could run Izhikevich type neurons, in a parallel fashion with easily expandable processing capabilities.. The TaskThe task in its simplest terms is to develop a simulation of some type, or part, of a computer system. Having selected what we are going to simulate we are to examine other systems, and develop a design for our own version, with highlight on certain differences. For this particular project, 'computer system' will be taken to be a 'Spiking Neural Network Board' - as permitted by the project coordinator. Due to its relative complexity, it will be developed using an iterative methodology, initially only being a simulation in an abstract sense, which will then be refined to a greater depth.. Spiking NeuronsThe development of Neural Networks has gone through three main generations. The first was focused around the McCulloch-Pitts neuron. A conceptually simple model, consisting of neurons which multiplied their inputs by a weighting, summed them and fired a binary high signal if its input went above a set threshold. These neurons are quite powerful, have many uses, and do not use much computational power however they do have limitations, such as only being about to handle digital values. The second generation solved this problem, and begun using continuous activation functions and used rate give their output. This generation was more biologically realistic and computationally powerful than the first - it did require more processing time though. It was then discovered though that the cortex was able to perform at far greater speeds than possible with rate coding, when Thorpe et Al found that it only took 00ms for a human to analyse and clarify visual on the relative timing of pre and post synaptic spikes. It was formalized into a mathematical system by Gal Chechik in 003 and will be the learning system employed in this simulation. It can be summarized simply as follows. If the presynaptic spike arrives at the postsynaptic neuron before the postsynaptic neuron fires - for example, it causes the firing - the synapse is potentiated. Its weight is increased according to the positive part of the STDP curve in Figure but does not allow growth beyond a cut-off value, which is a parameter in the model. If the presynaptic spike arrives at the postsynaptic neuron after it fired, that is, it brings the news late, the synapse is depressed. Its weight is decreased according to the negative part of the STDP curve.. Why Implement as Hardware? Spiking Neural Networks require much greater amounts of processing than their earlier cousins, such as the McCulloch-Pitts neuron. Because of this, when we create large networks of them, it becomes impossible to run them in real time on a serial processing computer. As many of the purposes we wish to assign neural networks to, rely on being able to process real time data - such as analyzing continuous visual and audio streams, which require networks of around the magnitude of. They become significantly less useful, even useless, when they are unable to do this. Some tasks may not require real time simulation, but some, such as whole brain simulations, certainly require speeds higher than those currently available. Having realized this, there are a few options - to either make the serial computer more powerful, to develop a specialised serial computer built for the task, or, develop the network in parallel hardware. Due to the very nature of neural networks, this is the most efficient, and logical way to perform the task. There are other reasons beyond the ability to process real time as to why we want dedicated SNN hardware. If they are to be commercialized and integrated into appliances and working robots then it will be necessary to produce them en mass, in an easily adaptable form, small enough, quick enough and cheaply enough to justify using them. They will also have to drain limited amounts of power in the majority of circumstances - something certainly not done by a modern workstation.. Existing Hardware ImplementationsNeural networks based on the first two generations never really begun to be implemented in hardware to any great extent - it was never necessary due to the limited amount of calculation required. However, with the move to spiking neural networks it has become more important, and thus more heavily researched. The majority of work done at converting the networks to hardware has been with FPGA', although recently eyes have begun being cast towards the emerging technology of. It is the latest of a series of network accelerators based on two previous configurations called SPIKE128k and NESPINN. SPIKE 28k was developed in the university of Padeborn. It is a FPGA based structure which leads to a limited speed. The next step is the NESPINN-system, which takes advantage of the VLSI-technology using Application Specific Integrated adjust synaptic weights. Even though differences are slight between functions, there will be one of decay and another for potentiation. Activation Functions:- Uses Izhikevich equations governing neuronal adjust the activation potential of each neuron every millisecond. Determines if the neuron has fired or not and makes required adjustments. Hit Manager:- Due to Axonal Conductance is not possible to simply input the weighted values to all the post neurons of a spiking neuron. Instead they have to be slowly added on as and when the set delay is reached. This deals with the intricacies of doing so. Initial Pseudo-Code:CONTROL LOOP: HIT MANAGEMENT: STDP FUNCTIONS: ACTIVATION FUNCTION: INITIALIZATION FUNCTION:. Code Listing: See Appendix & 2. Implementation IssuesThe key problems with implementing this program lay with the validation testing, and ensuring that it was functioning as required. This was a great problem because it was essentially a learning process - I only knew how the network and its dynamic parts should behave, once I had examined it in numerous different situations, with different variables and configurations. Comparing output between the original program and that which I had developed was an important method, but was complicated when I discovered a flaw in the original program - it then became a case of guessing which was right, based on assumptions of desired as I had always written my own. However, it was simply not possible to use my classes with this, as they slowed the program down immensely. Instead I had to select the appropriate type of array for each task, based on whether they could perform their core functions required of them in constant or linear time.. TestingAs noted above, the testing caused great problems, and was in all, far harder than writing the program in the first place. It was not possible to use a standard testing framework, and thus, I cannot simply what my test plan was, along with expected results, actual results and required changes - it was instead necessary that I concocted a new test every time I uncovered a new lead, on the path to tracing problems back to their source. Here is an overview of how this worked: Initialization Testing:Problem: - No explicit problem Plan: - Set up 0 neurons - excitory, inhibitory. Before control loop starts display: Preneuron index, Neuron Type, Synapse Number, Target, Weight and Delay for all synapsesPost synapse & Preneuron list for each neuronPresynaptic delay dataThe test should then be repeated with larger numbers of neurons, and checked that it roughly still works. Here is what data I expected to get from this: There would be one or two synapses per neuron The synapse numbers would be and/or The synaptic targets would be between & and extensive Weights should be for excitory neurons and - for inhibitory Axonal conductance delays should be between & 0 and not necessarily extensive All preneurons should have synapses leading to all post neurons All post synapse will correspond to a preneuron Predelay data corresponds with post-delay data The first thing I noticed upon running it was that neurons had either zero or one synapse - this I fixed by making the line of code which selects the number of neurons, add one onto the number it generates. The next thing I noticed was that not all neurons had post neurons. To fix this I added a check into the main initialization function to ensure all neurons had post synapses - if they are found lacking, then a post synapse is added. It was also immediately apparent that predelays were being added ten times over - this was because the code section where they were added to the array was inside an external loop. By removing the section to outside that loop, the bug was fixed. Control Loop Testing:Problem: Firing fell of soon after the start Plan: Run sequential tests, uncovering the path to the problem and fix it along the way. The following mini-tests were performed: Description: Set a 'second' as ms long and see if no fire error still occurs Result: Error still occurs Description: Comment out SEC_Pulse code and see if no fire error still occurs Result: Still occurs Description: Comment out nFirings= and see if no fire error still occurs Result: Still occurs Description: Output text if a neuron fires and confirm neurons don't fire past the first second Result: Neurons fire during first second but not after Description: Confirm its still check during later seconds if neurons have fired Result: Its still checked Description: Print output of MS_Pulse Result: Always false past first second Description: Print input from with MS_Pulse Result: Input values are immediately exponentially larger than expected Solution: Set hits values to in init function Description: Ran test again Result: Low firing rates achievedAlthough the original problem was now solved, I was still faced with appalling reveals an firing rate in the first second of 99.9 Tried Solution: Reduced potential number of synapses by factor of two Description: Repeat of 0 Result: Around 5/8 seconds per simulated second Firing rates still around 000 p/secThe program had by now stopped running for networks smaller than 00 neurons. I continued on, planning to lose this problem on the way: Description: Outputted synapse data at end of each millisecond Result: Synapse weights seemed to change quite reasonably Description: Outputted synapse data at end of each second Result: Weights of numerous synapses was of input to each neuron is attainedAt this point I decided to simply try outputting all the information I could get about each neuron to the screen, as best formatted as possible, and to just stare at it till patterns jumped out at me. Through doing this, I discovered firstly and most importantly, that inhibitory neurons were having no. Updated Pseudo-Code. Updated Code Listings:- See Appendix,, and 2. Example of Input/OutputHere is a screen shot of the displayed output: To show the input and output as text is realistically not possible, as it would fill a small library if the program was merely left to run for five minutes. I would display it as a sequence of graphs, but have not found time to write the relevant MATLAB code yet. Here is a brief look at what some of the output looks like: The values on the left are the number of the neuron, and those on the right are the time of each spike in milliseconds.. Implementation IssuesWhen I tried generated an input file the same length as the main control file, the file reached ridiculous sizes in the region of 0 megabytes. I therefore settled for a quick fix of simply reducing the number of seconds simulated. In many circumstances though, inputs would be generated either randomly, based on some function made internal to the program or fed in from some external sensor generated at real time. Because of this I don't consider this a great problem. After adding the PCI calls, the code became a lot harder to read and understand, as the 'English speak' function names were now replaced by a block standard function call, and while it is possible to differentiate between them by their function numbers - it's simply, a lot harder. This added even further to the complexity of debugging and testing this new version of the program. The result of this highly complex testing and a lack of time has been that I ran out of time to finish implementing this version. The neural network still has a bug in it, resulting in neurons not being fully affected by spikes hitting it, and also the layered topology has not been implemented at all.. TestingTesting with this new version progressed in much the same way as the last, with each step leading onto the next possible step along the trail. As pieces of data were taking long journeys from being created through the neurons, up an axon, across the PCI board, into the hit list, into the activation function etc, finding out what part wasn't actually working was not approachable in terms of standard testing, and noting each individual test down would have slowed it down to an unworkably low speed. Suspicions just had to be clarified and leads traced back to their roots, as and when they popped up. While I did solve some errors - such as a mix-up in the PCI unit over whether a or signified an excitory neuron was causing the neurons to be setup wrong. In the end though, it was not possible to fix all the bugs before the time was up.. ConclusionWhen all is said and done, I am very proud of this project, even though it is not really complete and has much work left to go on it. It has been a fascinating task and I have learnt a huge amount from working on it. When I embarked upon it, my knowledge of spiking neural networks was next to non-existent and it was the perfect way to learn more about them. While battling through mountains of data trying to debug it did get extremely frustrating, it has given me a good, clear understanding of the processes that occur within the neurons. Due to the enourmous amounts of data generated, and calculations done by the program it forced me to deal with certain issues I had never had to consider before in my time as a programmer. How to optimize the speeds of processes, selecting functions that can operate at the lowest order of time possible - never before had I had the need to really consider these things, and it brought into perspective all that I have learnt recently in the algorithms module. And while last programs of mine have generated multidimensional, dynamic arrays of regularly changing data - it has never quite been on this scale before. The methods I found and used to order my thoughts, and the data in such a way that I could handle debugging was an important lesson for me. While a few of the requirements and parts of the specification have not quite been met - for instance, the interface is not quite up to the standard suggested, only four types of neurons are possible and a layered topology is not implemented, I consider this to be simply part of the nature of the program. There will always be more work that can be done with it - and as soon as I can find the time, I have every intention of continuing through with it, to add as many of them in as I can. There are many more features that I wish to add to it yet. A full SDL interface, real time graph plotting of spikes, multithreading for the different neurons, more user control over network setup and types of neurons and different ways of entering input are just the start of what I want to do with them - and they can only really be done once I've filled in the holes within the current specification. There are still two key bugs within the program, but these should be easily dealt with. I will be removing the PCI interface from my version, and returning it to a purely software oriented program - this will remove the 'no-secondary-fire' problem from the second version. The other problem - that synaptic weights quickly reach their limits, can be dealt with by making changes to them occur through the use of a derivative, which slows down the rate at which they change, stretching it slowly across a few seconds. I do feel that the level and range of the actual programming demonstrated within the program was unfortunately fairly low, but due to the huge amount of research, testing and debugging required I did not find time to really push the limits, as this would have required a greater range of functionality to make room, and require a wider range of programming skills. If I was to do it again I would make it easier to perform the testing. By adding in a separate function or so, which could adjust certain values, and output strings of values, which again and again I found myself having to adjust and code for, I think I could have cut a large amount of the development time. But as they say - we live and learn. Or more precisely - our neural nets do.'''",283.0
"'''sThe main objects of this report are: To understand how the Jominy End Quench Test is used to determine a steels hardenability To determine the hardenability of EN9 & EN24 steels, and their typical uses in engineering. To relate how hardenability can be used to define how micro-structural properties of steel transform at a given depth when cooled under known conditions. Emphasise the use of hardenability to ensure that the right material choice is made for a specific engineering application Demonstrate how by adding alloying elements to steel the hardenability is increased IntroductionCarbon steels can be strengthened by quenching and tempering. To obtain the optimum properties the steel must be quenched past the nose of the C-curve, the Critical Cooling the steel. Figure shows a typical C-curve for steel. If the cooling rate of a steel component is below the CCR then the steel will transform to 00% martensite. If the component is large then ensuring the centre of the component cools at a rate below the CCR is difficult due to the surfaced layers insulating the bulk of the material from the quenching medium. To over come these problems alloying elements are added to the steel, common alloying elements are: the right. This lowers the CCR, allowing more time for the steel to be cooled, which in turn prevents the risk of cracking or distortion associated with rapid quenching. The hardenability is therefore said to be increased. Hardenability can be defined as the measure of depth to which hardness can be attained in a metal part using one of the standard thermal processing techniques designed to increase hardness. If a material is said to have a good hardenability, then it is able to transmit hardness through its structure well. ProcedureThe Jominy end-quench test is the standard method used to measure the hardenability of steels. The test consists of taking a steel bar a diameter of 5/8. the samples surface, causing errors in the Vickers hardness tests. According to BS970-: 991 70M5/85/8 is specified as a Carbon Manganese Steel 17M40 is specified as a Alloy Steel As already discussed in this report the addition of alloy elements increased the hardenability of steel. Below is a brief summary of some of the alloying elements and the effects they have on hardenability. Carbon'When a small amount of carbon is added to iron, the properties which give steel its great value begin to appear. As the amount of carbon increases up to.0 or.0%, the metal becomes harder, possesses greater tensile strength, and, what is most important, becomes increasingly responsive to heat treatment with corresponding development of very high strength and hardness. If carbon were to be increased beyond certain limits in plain carbon steel, the ability to be worked either hot or cold would disappear almost entirely, and it would begin to assume the characteristics of cast iron, which usually has. to.% carbon'. URL Paxton & Vierling Steel Manganese'Next in importance to carbon is manganese. It is normally present in all steel and functions both as a deoxidizer and also to impart strength and responsiveness to heat treatment. Manganese is usually present in quantities from /% to %, but certain special steels are made in the range of 0% to 5/8%'. Chromium'Chromium increases response to heat treatment. It also increases depth of hardness penetration. Most chromium-bearing alloys contain.0 to.0% chromium. Stainless steels contain chromium in large between 00 - 00C. Tempering is generally carried out around 00 - 00C. The speed of quenching of the steel bar from its unstable austenitic state determines what the resulting microstructure when the steel is in its equilibrium state. The ideal material properties would be 00% martensite, to gain maximum hardness out of the material, however this has shown to make the steel brittle, therefore tempering is used to improve the ductility of the steel with the disadvantage of sacrificing some of its hardness gained by quenching. The tempering conditions are tailored to suit the required material properties of the steel. Achieving 00% martensite is very difficult to achieve, since the very high cooling rate required to ensure all of the microstructure changes to martensite means that the steel would be subjected to high shrinkage stresses which could cause cracking or distortion. Therefore there is a trade off between achievable cooling rate, and final microstructure. C-curves on TTT Diagrams are available for each material type showing what microstructure would be formed given a certain cooling sequence. These TTT diagrams are determined by quenching a specimen to a given temperature, holding it there for a given time and quenching to room temperature. Appendix C shows the TTT diagram and related C-curves for the steel BS EN12. As can be seen from this diagram, a cooling rate of approximately 5/80C/second is required to miss the nose of the C-curve, and therefore achieve 00% martensite. As the cooling rate reduces the microstructure changes, indicated by the transformation lines. Note that for martensite to form the steel must be cooled to ~30C indicated by the Ms line. To achieve 0% steel must be cooled to ~90C. To achieve 0% martensite a cooling rate of approximately 2-4C/s is required. The remaining 0% would consists of pearlite & ferrite. The carbon content of the steel also has an effect on the microstructure, Appendix B shows an Iron-Carbon equilibrium diagram. At very low carbon microstructure would be 00% Ferrite, almost pure iron. As the carbon content is increased, up to.% C, the microstructure would be martensite, ferrite & pearlite the content of each depending on how the material is cooled. Above.% C pearlite and cermentite begin to form. These changes in microstructure are shown in the variation in hardness values found on the two test specimens. At the quenched end of the specimen, the hardness value was greatly increased indicating a martensite micro structure. As the cooling rate reduced over the length of the bar, the hardness dropped, as the microstructure changed from martensite to pearlite and ferrite. At the end furthest away from the quench the hardness value was the same or slightly lower, and on inspection the microstructure showed mainly Pearlite and Ferrite with very little martensite. Observed microstructures for 17M40 & 70M5/85/8 17M40 MicrostructureThe microstructure of the quenched end of the 17M40 test sample can be seen in Figure. The grain size was very small. Figure shows the microstructure at the opposite end to the quenching. The darker grains are pearlite and the silver is martensite. 70M5/85/8 MicrostructuresAt the quenched end of the sample the microstructure consisted of all martensite, since the cooling rate was sufficiently high enough so as to allow the microstructure to transform from austenite to martensite. See Figure. Towards the end of the sample furthest away from the quenched end the microstructure consisted mainly of some some average hardness over the fist 0mm from the quench end can be seen to be approximately 20HV. Beyond 0mm the hardness falls rapidly until it's only slightly higher value that the 'As received' sample. The better hardenability characteristics are due to the 17M40 containing extra alloying elements which help to slow down the transformation to the equilibrium state. Graph shows the results of the two quench hardened steels, note that the initial hardness values at the quenched end are close, showing that for thin section 70M5/85/8 steel would make the most suitable choice due to its lower manufacturing costs, and the 17M40 is best suited to thicker section materials where full hardening is to be achieved throughout the larger components. ConclusionHardening of steels is done for many reasons, such as tooling applications when working with other quenching in water. However on thicker section only the surface may harden, or on very large sections even the surface may not harden. High cooling rates can cause internal stresses in the steel and lead to distortion and cracking. This problem can be overcome with the addition of alloying elements, such as Manganese, chromium, Molybdenum, Carbon & Nickel. These alloying elements slow down the phase transformations allowing longer cooling times, enabling much thicker sections to be fully hardened. The disadvantage of adding these alloying elements is the extra cost of producing the alloy steel grades. To gain maximum hardenability in moderate sized sections a carbon content of.-.% is necessary. Above % carbon hardenability decreases as the carbon tends to promote the formation of ferrite.'''",293.0
"'''The society of fifth century Athens could be described as one of the few slave societies that have existed in the world. It was a society in which the use of slaves was an everyday occurrence and it can be said that the economy and stability of the society relied on the use of slaves. Slaves in Athens, like women in Athens, were not classed as citizens and it can be asserted that they were not treated as human beings. There are many aspects of slavery that shed light on how slaves were treated. These are the amount of slaves in Athens, how the slavery was justified, whether the Athenians were cruel to their slaves, whether the slaves were considered to be less human than the free people of Athens and whether the comic characterisations of the treatment of slaves in the plays of Aristophanes are at all true. As fifth century Athens was a slave society we can safely say that there was a large number of slaves in Athens. There were in fact such a large number of slaves that it can be said that the Greeks could not imagine life without any slaves. The speech Lysias 4 which is written on behalf of a cripple suggests that even poor Athenians would have looked to own slaves and would have seen them as an investment in terms of income. When Aristotle presents his argument in support of slavery he mentions the 'master and slave' as natural elements within the household. This suggests that slavery was thought of as an essential and ordinary element in the Athenian household. There were different kinds of slaves in Athens, and therefore different slaves would have had different experiences with different masters and types of work. The public slaves and the skilled craftsmen may have experienced a more pleasant life compared to that of the miners who were often worked to death in appalling conditions, and the domestics slaves may have been able to forge relationships with their masters while agricultural slaves faced had work on the fields. V. Ehrenberg, The People of. 66 Lysias 4: On behalf of a cripple. In T. Wiedemann, Greek and Roman slavery Aristotle, Politics,. In T. Wiedemann, Greek and Roman Slavery Joint Association of Classical Teachers, The world of.87 Overall slavery as was never really questioned in the classical period as many Greeks could see no alternatives to slaves, there was therefore often no need for it to be justified. At the height of the sophistic period however, slavery was said to be against nature as it was primarily based upon force and morally wrong, and this led to Aristotle writing his justifications of slavery. Aristotle came up with many arguments as to why slavery was justified. He commented on how people were born, stating that some people were born to 'rule or be ruled', and therefore slavery was just and an advantage for the slave. There are many references to slaves as being an 'animate piece of property' and therefore they are meant to be owned and follow the commands of their owners. Many Greeks saw slaves as being one of the 'essential requirements of life' and thus made for slavery. The Pseudo-Aristotelian mentions three things that slaves are meant for as being 'work, punishment and food', this presents the slave as being designed for slavery and therefore by being a slave is fulfilling some sort of life purpose. Many slave owners believed they were justified in owning slaves because they were born into slave families or they were won in wars which were fought fairly. Joint Association of Classical Teachers, The world of.85/8 Joint Association of Classical Teachers, The world of.85/8 Aristotle, Politics,. In T. Wiedemann, Greek and Roman Slavery Aristotle, Politics,. In T. Wiedemann, Greek and Roman Slavery G. De Ste Croix. The Class struggle in the Ancient Greek. 40 G. De Ste Croix, The Class struggle in the Ancient Greek. 42 T.E.J. Wiedemann,.2 Athenians were in some ways cruel to their slaves. Slave owners could punish their slaves without fear of the law, this would have sometimes included harsh treatment. The flogging of slaves was a common occurrence, and even the most privileged of slaves could not be completely free from the threat of physical punishment. In Xenophon's The Householder, 2 it states 'you must not be frightened to punish', showing that slave discipline was seen as an important aspect of owning slaves. The private life of a slave depended on the master, the master could prevent his slaves from forming relationships, or split up families without the slaves having any say. Most slave owners would not treat their slaves too badly. Slaves were considered valuable property as they worked for their master and contributed to the household or the income, and therefore many slaves were looked after, or at least kept in good physical condition. However, not all slave owners would have been interested in looking after their slaves. In the speech Lysias, a man 'proposed that his own slaves should be interrogated under torture', this is showing a disregard for the condition of the slave as tortured slaves could be returned to their owners less able than before. T.E.J. Wiedemann,.3 N.R.E. Fisher, Slavery in Classical.0 Xenophon, The householder 2. In T. Wiedemann, Greek and Roman Slavery N.R.E. Fisher, Slavery in Classical.2 G. De Ste Croix. The Class struggle in the Ancient Greek.42 Lysias: Speech about a premeditated wounding. In T. Wiedemann, Greek and Roman Slavery In terms of the law, the rights of slaves were protected in some ways. Slaves are protected from being murdered. In Antiphon, a slave is murdered because he is accused of killing his master and his murders are told 'a jury's vote applies just as much to the man who kills a slave as to the man who kills a free man'. The law also protects slaves against Hybris. In Demosthenes 1, it states 'if anyone humiliates anyone, whether they are free or slave, or commits any illegal act against any of these, let any Athenian who has the right to do so and wishes submit their names to the Thesmothetai'. Although slaves are protected in these ways according to the law, they themselves cannot file a lawsuit and so they rely on others who are free. It is therefore debatable whether these laws were actually effective in the protection of slaves. Other laws such as that stating 'persons other than the slaves owner is not allowed to strike him' do not completely protect slaves, first the owner can still beat the slave and it will only protect the slave if the owner takes action when others beat the slave. Antiphon: Death of herodes. In T. Wiedemann, Greek and Roman Slavery Demosthenes 1: Against meidias. In T. Wiedemann, Greek and Roman Slavery D.M. MacDowell, The Law in Classical Athens, (London 978) P.1 It could be argued that the slaves in Athens could not have been treated too badly because of the lack of revolts against the slave owners, even though slavery was so common. However there is a logical explanation for this. Most of the slaves in Athens were 'barbarians' after it became illegal for Athenians to be enslaved in Athens after solon's reforms. The 'barbarians' were from many different areas such as Thrace, South Russia, Egypt and Sicily, this meant they often shared no common language or culture and were thus unable to organise an uprising. N.R.E. Fisher, Slavery in Classical.2 G. De Ste Croix. The Class struggle in the Ancient Greek.42 In some ways slaves in fifth century Athens were considered less human than the free people. As Aristotle states ' the polarity between 'slave' and 'free' seemed as natural a way of dividing up the human race as those between men and women or young and old'. Aristotle sums up the attitude of fifth century Athens well as the opposite to free was considered to be slavery, rather than imprisonment as in our modern society. There were many ways in which slaves were dehumanised. They are referred to as 'property' and compared to 'wild beasts', suggesting that they are a lower life form than the free men. Slaves were also prevented from doing what is natural such as forming relationships and having children, this put them lower than the rest of society. Slaves were also not allowed to give evidence at a lawsuit unless it was extracted while under torture, and many dehumanising devices were used such as referring to adult male slaves a 'boy'. However, some Athenians would have seen slaves as human as shown in Xenophon 'Slaves have no less need of something good to hope for than do free men'. This shows an acknowledge meant that slaves have the same hopes as all other people rather than not being able to think like suggested by others such as Aristotle when he brands slaves as incapable of all independent reasoning. I believe that Demosthenes sums up the reality for slaves when he states that 'the greatest difference between the slave and the free man is that the former is answerable with his body for all offences'. Aristotle, Politics,. In T. Wiedemann, Greek and Roman Slavery Xenophon, The householder 3. In T. Wiedemann, Greek and Roman Slavery Xenophon, The householder. In T. Wiedemann, Greek and Roman Slavery M.I. Finley, Ancient Slavery and modern.6 Xenophon, The householder. In T. Wiedemann, Greek and Roman Slavery P. Cartledge, The Greeks: A Portrait of Self and.25/8 M.I. Finley, Ancient Slavery and modern.3 Slaves are often presented in comedy, particularly by play writers such as Aristophanes who uses frequent comic characterisations of slaves. The slaves in the many plays set in fifth century Athens can hardly be said to give accurate descriptions of how slaves were treated at the time due to the fact that it is a comedy, designed to make an audience of the time laugh rather than a documentary. The slaves that Aristophanes presents are developed from the true slave of the time, but certain features have been exaggerated. The Aristophanic play 'frogs' gives us many situations with slaves such as when the slave offers his master, who he is changed clothes with, up for torture. This shows us that torture was probably not commonly used. There is another scene in 'frogs' in which two slaves talk about how they curse their master behind his back as well as pry and eavesdrop. Slaves probably did engage in these activities but it was probably more exaggerated in the play. V. Ehrenberg, The People of Aristophanes, (Blackwell 95/81) P.70 V. Ehrenberg, The People of Aristophanes, (Blackwell 95/81) P.87 V. Ehrenberg, The People of Aristophanes, (Blackwell 95/81) P.87 Aristophanes frogs Act two Overall I believe that slaves were not treated as humans. Although there were limited laws in place to protect the rights of slave, these were only useful if the slaves master or another citizen was willing to file a lawsuit, and slaves were often not deemed important enough to go to the trouble. The power the masters had over the slaves and the various methods of dehumanisation further took away the character and the personality of a slave so that they were barely human. Although some slaves may have been treated well by their masters, the masters had two much power over their slaves, and society too many restrictions to allow slaves to live as proper humans.'''",294.0
"'''Modern medicine is the product of ongoing change and progression. Where once medicine held a relatively narrowly delineated position, today it is a complex and highly organised socio-political it is here that its potential to exert social control must be placed. When one uses such terminology in relation to modern medicine, it is important not to consider only the direct, often violent, coercion of peoples that the term can imply. Social control is defined as the encouraging, or enforcing, of particular types of behaviour through the establishment of social norms, where that which does not meet the norms is deemed deviant. In this wider perspective, it is far easier to conceptualise the ways in which medicine might become coercive and controlling. A good place to begin when examining the social control element of modern medicine is the idea of surveillance. The notion of surveillance medicine is something closely associated with Foucault's theories on discipline, which saw power as 'a relationship which was localised, dispersed and diffused', typically operating at 'a micro, local and covert level' (Turner, 997, p.xi). This type of disciplinary management suggests a society where formal coercion and control is replaced by informal self-regulation, achieved via the embodiment of surveillance into the everyday activities of social institutions. In translating this theory onto the framework of modern medicine then, in order to assess whether it is socially controlling, one needs to examine how its day-to-day practices can be seen to operate coercively to constrain or produce particular forms of behaviour. Castel relates this covert, less formalised coercive operation taking place within modern medicine to the development of the 'risk society'. He suggests that the swing towards preventative medicine within the modern institution, via the identification of potential risks to health, has resulted in a 'far more subtle and effective mode of population regulation', which has the ability to enable a far greater multiplicity of been created, enabling far greater, yet less overt control over social behaviour. However, in evaluating this form of social control, one must acknowledge that some elements of social life have in fact been de-medicalised in recent years. For example, homosexuality was once believed to be a medical condition, and attempts were made to treat it as you would a mental health patient, yet now it is a relatively socially acceptable personal choice. Similarly many groups representing the interests of the disabled fight to be removed from the notion of needing treatment, with much success, for example anti-disability discrimination laws being passed. It seems then that while medicine clearly has a controlling function through its spread into unrelated areas of life, we must not take this to be an uncontested advance through the ranks of society: the medicalisation of a condition can be resisted. However, medicine is linked to social control in a further manner related to the moral discourse that it has exerted upon our behaviour. With the medicalisation of our behaviour and choices, comes an attached responsibility for each individual to monitor their own risk. A crucial part of this coercive medical morality is the idea of self-control. Drawing on Enlightenment philosophical thinking, modern medicine espouses the notion that the mind is separate from, and has transcendence over, the body, and thus infers the idea that an 'uncontrolled' body reflects a weak highly controlling of behaviour through our attempts to avoid these feelings. Here we can see Bentham's Panoptican put into practice: the idea that society will condemn us if we do not partake in risk assessment has forced us into a mode of self-discipline and regulation. Health, while becoming individualised in responsibility, has also become increasingly social in authority. Those who do not concur to the aim of a risk-free existence and seen as failing to fulfil their social duty. As Lupton points out, ''Healthiness' has replaced 'Godliness' as a yardstick of accomplishment and proper living' (995/8, p.). Social control has become a prime function of modern medicine then not in a direct or overt manner, but through its ability to produce a self-regulating population via appealing to wide social values. However, one must stop to acknowledge that there are potential and actual sites of resistance to this morality of sickness as personal weakness. Research into terminal care, for example, shows that, in reality, many patients do not view death as a failure, and prefer to be aware of the eventuality of their condition, placing the freedom to enjoy their last days as an outpatient over the intense battle to be kept alive in that medicine can be very directly coercive, in addition to its less overt operations through medicalisation and moral discourse. It appears readily apparent that medicine is not a neutral institution, instead one affected by social, political and economic circumstances, which can result it in becoming socially controlling. Modern medicine does have demonstrable 'strongly coercive elements', evident in the way in which it sets out 'to shape and normalise human behaviour in certain ways' (Lupton, 995/8, p.0). The moral discourse surrounding health coerces the individual by offering social condemnation to those who do not follow its individualised concept, and legitimacy of certain behaviours through the active seeking of the 'sick role'. Equally, the expansion of medicine into increasingly broad areas of life has promoted the surveillance system, whereby all behaviour becomes subject to medicalisation because of its potential as 'risk'. Evidently the controlling function is important because much of its implications are evident in policy which emphasises the moral dimension of health. However, what is also clear is that we should be careful not to over-emphasise the extent to which social control is a prime function of modern medicine. While it clearly has a place within the institution, one must remember that it rarely acts directly to force people to behave in a certain way. There are many examples of dissent from the expected forms of behaviour, such as non-compliance with drug taking for or heavy drinking, which may not even be socially condemned if they occur among particular groups. Indeed perhaps even if we admit that social control is an important function of modern medicine, it does not necessarily have to be a negative one, as medicalisation can result in health improvements, such as declining maternal death during childbirth. In conclusion then, I would argue that while social control has become an important and certainly present function of modern medicine, perhaps to use the term 'prime' in relation to it is to over-emphasise the coercive nature of medicine as an institution. Seeing medicine's primary function as the control of social beings is to deny them their ability to negotiate the boundaries of medicalisation and the moral discourse surrounding health.'''",314.0
"''' Education within the field of architecture is underpinned both by academic and practical work. This essay should try to summarise the experience that I gained whilst being a part of professional use of materials which resources can be sustained; (use of wood and straw as a resource that can be sufficiently managed, avoidance of using metal or petrol by-products) Delivery of quality design that is market competitive; (creating innovative design solutions that can compete with more standard methods of construction preferred by the industry) Key projects that have attracted the interest of wider public and that were more challenging to deliver than others were: VELUX headquarters in Kingsmead primary Paddington Basin rolling that would create an idea of what resources need to be allocated for an amount of speculative workallocation of individual tasks and synchronisation of personal commitments so that group work can be undertaken at particular timesadministrative are going to be undertaken or need to be shared between individuals office businessYet, this does not imply that every member of staff was equally engaged in all of the tasks. Certain job profiles can be differentiated. They best describe the nature and the scope of work that in most circumstances are undertaken by an individual working for either of the design ventures. Company Director In both cases the company founders had best fitted this job description. Usually, they had a managerial role overseeing all of the projects the business was working on, engaging in company finance and raising company profile. In terms of day to day activities this meant that directors would have frequent meetings with project leaders, a weekly meeting with the office accountant and would serve as a forefront of the business. The latter activity encompassed: creating company public relation work; such as public lectures and media exposure forging links with other professionals working in the field of built environment as a way of ensuring the company can develop knowledge and is able to offer innovative solutions before other market competitors forging links with the potential clients as a way of securing new commissions for sustaining the business and as a way to stir the company towards commissions that will help it to evolve in a wanted direction However, the directors both within White Design Associates and Thomas Heatherwick studio would occasionally engage in a particular project if: there had been a pressure to deliver certain outputs in a short time periodthere were any disputes between professional organisations there were any major financial issues that may have an impact on the future of a projectEven though there are a lot of similarities between the activities of company directors of both places where I had been working, there were some divergences too. Namely, within Thomas Heatherwick studio there were other job profiles that complemented and supported the activities of the director such as office administrator and company marketing assistant. On the other hand White Design Associates did not have these job positions and much of the administrative and marketing work has been done or overseen by one of the directors. Projects ManagerA person who has been working within the practice the longest would have taken up this role. usually manage a particular project himself. At the same time, he would also serve as a support for project architects giving them advise or providing them with help related to running a job. This is because a projects manager had the most insight into the way building industry operates and the way that company preferred to deliver projects. Apart from running a particular job himself, his role within White Design Associates or Thomas Heatherwick Studio was to: help out company directors particularly in tasks related to raising company profileconsult with company development strategyadvise project architects about design developmentnegotiate with project architects the distribution of work for different projectsThere were not major differences between the activities of people who fitted this job profile in White Design Associates and Thomas Heatherwick Studio. Project Architect/Project DesignerProject architect or project be the person in charge of running one or several projects from the early stages up to their completion. They would be engaged in usual activities that relate to the stages of development process from developing design options up to hand over of the finished project. Within White Design Associates, people undertaking this job had a high degree of independence in terms that the input of directors or projects manger would be limited to the very initial stages of the process. Only if the project was facing difficulties or if project architect felt that he or she needed advice or help from senior team members would they get involved. On the other hand, due to different approach to design process at Thomas Heatherwick Studio, project designers had, to an extent a lesser degree of independent decision making. Because company director had developed personal approach to design, the project could change or shift due to director's changing attitude towards the project. Within both practices, project architects and designers would also be involved in some administrative work, such as preparing bid submissions. Architectural Assistant/InternThis job description best fitted the work that I had been undertaking. Within the offices that I worked for the responsibilities and tasks varied significantly. Within White Design Associates, an architectural assistant would usually be allocated to one project architect. Together they would form a team and work on delivery of a single project, with project architect having a senior role. However, the assistant would be exposed to all stages of building development either directly as a participant in the workload, or indirectly by observing the tasks that project architect is undertaking. Coupled with that, this job position would usually include a responsibility for a smaller - scale development that the office is engaged with. In this situation the assistant would implement the knowledge gained through the collaboration with project architect and to an extent, act as a project architect himself. This process would be overseen and guided by company director. In personal case, I have been allocated a development of a 0m2 artist studio building. Architectural assistant would also act as a support member of staff carrying out administrative tasks and sharing the workload with other project architects. In the case of Thomas Heatherwick Studio, due to limited time that an intern spends at the investment in individual development cannot be carried out to such an extent. Usually, a person is also allocated to a project designer. However, because of a small time period that he or she is going to be spending with the office, an intern is rarely involved with a single project from beginning until its completion. Therefore, he or she is more likely to take up a general support role within the office. Office Administrator and Marketing AssistantThis job positions existed in Thomas Heatherwick Studio, whilst the crux of this type of work has been divided between one company director and most members of staff working for White Design Associates. The activities of these two job positions include: organising and managing director's diarymanaging invoicingmanaging company overheadsproviding technical support and organising events that would help raising company profileOffice management strategies of White Design Associates and Thomas Heatherwick StudioThis section of text focuses on the approach each of the offices had toward different activities that were undertaken by them. Crudely, they can be divided into the following segments: Design DevelopmentWork Acquirement and Client BaseMarketing StrategyCollaboration StrategyQuality Standards of Work OutputDesign DevelopmentDesign development process can be defined as a period of time spent between the moment a client appoints the office to undertake certain project until the point the preferred design solution has been submitted to Development Control. At this stage of process, the following items would be agreed with a client: size, appearance and arrangement of a structurestructural system that is likely to be usedbuilding programmepreliminary cost estimate of projectThe way in which the design options would have been developed within the practices that I had been working for was significantly different. White Design Associates tended to reduce this period to a minimum. In other words, the initial options would be developed within several weeks. This could have been achieved because the practice championed a limited number of construction were based in the city. Apart from having tangible resources to finance projects themselves, these organisations can serve as a platform for establishing link between design/art industry and potential clients. Also, company director had dedicated a lot of time for public promotions such as media exposure and lectures. The marketing assistant who was pro actively engaging with various media organisations and public forms supported these activities. Marketing Strategy Companies that I had been working for had an awareness of the need to pitch their services in a certain way. This meant that both offered a particular type of product. White Design Associates developed Re-Thinking Space as a product. Collaborating with developers Willmott Dixon and VELUX window manufacturing company, they were offering a 'building package' (named Re-Thinking Space); whereby client would be purchasing a system solution with pre determined building components and environmental systems. The solution would be adapted to particular needs and would be based on timber clad, glue laminated frame structure that is well insulated and naturally ventilated. In this way, White Design's architectural solution was set against standard development market. It was, in a way, subverting the methods used by major developers whereby the standardised solutions are marketed as a guarantee of financial viability and 'buildability' of a particular scheme. Hereby, White Design was instilling confidence in potential clients by showing that it can deliver design that has within itself integrated certain can be delivered without having an impact on the project budget. Whilst White Design concentrated on publicly promoting their innovation through building industry, Thomas Heatherwick Studio was keen to show its work in a different light. It was promoting the diversity of design. Also it ensured that each employee could be engaged in a piece of work at any stage of its development. On the other hand, Thomas Heatherwick Studio had developed an information storage system both in terms of hard copies and electronic was similar to the one of White Design Associates. However, they did not develop templates and the system of referencing/cross - referencing of information to the extent that the other practice did. Conclusions about an architectural practice as a business ventureI will try to draw out conclusions I have reached about the factors that contribute to successfully running an architectural or a design practice. These conclusions are by no means definite and comprehensive, because I have drawn them from personal and limited experience. Predominantly, I have reached them by observing the way the practices I worked for had been organised and by observing various strategies they had employed, which I had touched upon in the previous paragraphs. From this analysis I have tried to extract some issues and themes that I thought were important to bear in mind when thinking about architecture as business venture in current cultural context. Within next paragraphs, I hope to elaborate on the following themes I became aware of: understanding co - relation between design approach and client baseunderstanding the difference between private and public sector fundingprofitability of various design activitiespractice efficiency Understanding co - relation between design approach and client baseWhilst working at White Design Associates and Thomas Heatherwick studio, I gradually became aware of how design approach and client base are strongly related. In other words, the type of product or service that a company is offering is likely to be appealing to a certain sections of market. Therefore, it is likely that a company is going to get increasingly engaged with a specific type of demands. As the result, the company is going to adjust its activities and its strategies towards meeting that demand. Diagram shows how previously mentioned company strategies have resulted from this dialogue between design approach and client base, in the case of White Design Associates and Thomas Heatherwick Studio. Standardised solutions and strong environmental ethos of White Design particularly resonated with local authorities and organisations that themselves were involved in sustainable production or environmental protection. They would be more interested in buildings that were the example of practices than in other aspects of building design. As the result, the office concentrated on developing and researching building methods such as glue laminated structures or prefabricated straw bale panels. Equally, it was occupied with developing a database of environmentally friendly building products and materials. On the other hand, it meant it was less interested in other building technologies, particularly the ones related to steel frame systems or glazed envelopes. Similarly, other design themes such as physical context or the analysis of the locality of a development were having somewhat lesser importance. Thomas Heatherwick Studio's output seemed to attract either cultural or commercial establishments. As designs would usually have very strong formal qualities and uniqueness both in form and in materials, they would attract clients who wanted strong and. In my personal opinion, the studio's output was corresponding to the branding strategies of various organisations. Therefore the practice paid particular attention to formal research and the use of materials in an innovative way. However, this also meant that some practical design issues, such as accessibility or environmental and servicing solutions, would be sometimes overlooked. This is not to say that the practices were only having these types of commissions and these types of design responses. However, the crux of their workload corresponded to the above mentioned patterns. In any case, I believe that, in a sense, these practices were responding to and anticipating the client base successfully through their activities. I think that it is increasingly important to understand the practice - client base co-relation, particularly in the case of emerging businesses. Any new architectural company should from the outset offer service which is in a way specific and which will differentiate it from other market competitors. More importantly, the practice should also have a clear idea about who is their target audience, as well. Understanding the difference between private and public sector fundingBy observing relationship between resources put into bid submissions and their outcomes I became aware of this issue. Namely, at White Design Associates I have been involved in compiling a number of tender a period of one year. These bids would take usually several days to be produced by at least two members of staff. Statistically, the company was more often unsuccessful in terms of securing the jobs in this way. The limiting factors would be either: Relative inexperience of practice in the delivery of similar projects that a bid asks forRelatively small turnover/liability insurance Size of practiceIt became clear to me that the priority of public sector funding is the security of investment more than just the quality of design. Or to be more precise, public sector would choose a preferred design solution once it has narrowed down the applicants to the ones that have the proven track record of similar projects and that are big enough to deal with financial or workload implications if the project runs into problems. Even though one can argue that some of these choice criteria are not really a safeguard for public investment at all, the reality is that a practice has a slim chance of securing the job in this way unless it has a proven track record. As the result, understanding public sector funding can help a new practice not to waste its resources in certain types of tendering processes. On the other hand, Thomas Heatherwick Studio, was a practice in a similar situation, whereby it had a number of projects executed but that was comparatively small output in relation to large and well established design companies. However, it concentrated its resources into trying to acquire privately funded commissions. In a way, for a developing company this is probably more profitable strategy. As private clients can be more prone to risk taking and are likely to invite small number of practices they find suitable to bid for a job. Thus, the practice stands much higher chances of gaining new work. Profitability of various design activitiesDuring the period of a couple of months when White Design Associates were having work deficit, I became aware of the problem that a traditional architectural practice has when facing the lack of work. Namely, the time span a traditional practice can sustain itself without commissions cannot be more than a few months. In my opinion, the workload/profit ratio is much smaller in the field of architecture than in other design fields. That is why I believe Thomas Heatherwick Studio had better financial base, because apart from architecture it ventured into other design fields. As the result, it would have public art or product design commissions that had similar budgets to architectural projects. Yet the profit margin would have been much greater because the process of development of these projects involve less professionals that need to be paid from the budget. Also, it would take a project designer much less time and fewer resources to carry a project through to its final stages than it would take to complete a building development. Therefore I believe that by offering a variety of design services and being aware of their actual profitability is a key to sustaining a business, particularly through the rough patches. Practice Efficiency During the time spent in practice I became aware of the importance of this issue. Particularly this may be in the case of developing design businesses that have more limited resources that need to be utilised in the best way possible. As I have mentioned before, I was particularly stricken by clear and concise way the project tasks would be dealt with by White Design Associates. This is mainly due to their design development strategy, constant collaboration with other built environment professionals and partnership with a main contractor. As the result, projects would have consistency and yet they would not be churned out like on the production line conveyor belt. Therefore, the practice would spend much less time one a single project than it would usually take for a development of similar size. For example, the practice was able to deliver a primary school within nine months. Also, it was delivered by one project architect with a limited help from an architectural assistant. As a knock on effect of quick project delivery, the practice was able to increase its output in comparison to the offices of a similar size. These devised approaches to an integrated design development and construction management were equally beneficial to new members of staff. They could quickly learn the process that the office used to develop and deliver a building. This meant that it would take less time to integrate new employees into the team. This integration was also supported by the devised quality standards systems that have been mentioned. SECTION - Practical knowledge gained from working at White Design Associates and Thomas Heatherwick StudioApart from getting general insight into architecture and design as a from business venture, I have also gained or developed particular skills during the time spent in practice. These can be defined as tasks that I have been introduced to and that I have executed individually or as a part of an office team. The following section concentrates on these tasks. Rather than focusing on individual projects or on project stages as defined by RIBA Plan of Work, I will try to indicate how each of the mentioned skills developed through my involvement in various projects. The reasons for organising the section in this manner are twofold. Firstly, the small - scale project that I have managed did not go through the development stages as defined by Plan of Work due to its size. Therefore, trying to organise my experience according to this plan would be difficult, as the actual stages of project development in some instances have significantly parted from it. Secondly, as I have been doing similar tasks on various projects, organising the section according to projects would mean that many observations would be unnecessarily repeated. Hence, the following paragraphs elaborate on particular skills. Projects that are cited within the main body of the text are briefly described within the Appendix. The skills have been placed into three categories. These are: technical skillsmanagerial skillsknowledge of legal issues Technical skillsThese skills, for the purpose of the essay encompass activities undertaken by an architect or a team of architects in order to ensure that the design can be and that it is executed as it has been envisaged. They can be divided into activities such as: drawingproduction of information packages surveying DrawingFrom the very outset of my work experience I have been exposed to understanding the importance of drawing hierarchy. Whilst at the university level drawings are used as a device solely to communicate ideas, in practice they are more important as a guide or a manual to the construction process. Therefore, even though each drawing explains certain part of that process, together they represent one coherent totality. One of my first tasks upon arriving at White Design Associates was to develop reflected ceiling services layout and the layouts of toilet facilities on a Kingsmead primary school project. I have quickly learned the importance of a master drawing as a common denominator for all the others. By taking parts of it, I was able to scale them up and create new drawings by adding more detailed information, such as piping/ducting routes, types of light fittings, smoke detectors and sanitary components. Using the master drawing as a departure point meant that several people can share the workload and produce work that is complementary, most importantly in terms of measurements. At this point, I also became aware of four categories of positioning cladding boards around the outlined building shape and then to work inwards; drawing structural timber studs and dimensioning windows so that they are multiples of a cladding board. Another project has also taught me the importance of this activity. On Anns Grove primary school development the working sections of the building needed to be drawn, yet the project architect solely responsible for the development had to go on holiday. The rest of employees who had to engage in the project for the first time, divided the workload for these drawings. However, as the project architect has created templates with guidelines indicating crucial dimensions the tasks of drafting up these sections was not as onerous as it could have been. Compiling drawing schedules was another activity that I had been exposed to. Namely I had to compile several of them on various projects: window and door schedule on Yanley Lane studio development and on Kingsmead primary school project; ironmongery schedule on Kingsmead primary school and on Hengistbury Head classroom of the future project. Even though this activity seems pretty straight - forward I have realised the possible implications should a schedule have mistakes. Because windows and doors are one of the biggest expenses and the delivery times can be measured in months, the mistakes can both push back the completion date and turn to be very costly. For example, the cost of windows was the second most expensive item on the bill of quantities for Yanley Lane development and it took more than ten weeks for their delivery. Production of information packages Apart from drawing, architects have to communicate certain issues by compiling documents. I had to compile several information packages. On Yanley Lane studio building, I had to submit a written report to the client. It concentrated on resolving some critical issues before the project was to be started on site. Because of topography, it would turn too costly for the studio to be linked to the main sewerage system, as the building was planed to be downhill from it. As the result I have researched into several sewerage system options, citing in report the cost and the design implication of all of them. Also, the report has concentrated on the relation of window sizes to the overall cost of the project. It is important to make design process as transparent as possible. Drawings are good tool to explain a building, but I felt that they could not explain some issues, particularly to clients who may have not engaged in the process of development beforehand. Another instance when I had incorporated drawings in more comprehensive documents was when submitting a design for planning approval. I felt that, apart from filling in necessary forms and sending through the drawings showing the development, it is important to create a written explanation on certain design features and show how the development responds to development plans. By doing so on Yanley Lane studio and Stanpit Marsh visitor centre submissions, the planning approval came within statutory time period. Delays in planning approval can have a significant impact on the work schedule. This often may be due to misunderstanding between the architect and local authority. It is through these reports that some issues are clarified. Also, they can serve to open up a constructive discussion between these two parties, which helps in resolving problems. I have also been involved in creating documents such as tendering specifications, whereby I have learnt the importance of cross - referencing specification clauses and component drawings. For example, I have been given to do the NBS specification section on sanitary - ware for the Hengistbury Head Classroom of the Future project and relate it to specific drawings. By citing specification clause on drawings and vice versa, the information is much more legible to the contractor and subcontractors. This may fractionally speed up the construction process. SurveyingSurveying encompasses activities such as site surveying, site investigation and site inspection. To various degrees, I have been involved in all them. Namely, in terms of architectural survey I have conducted it with senior colleagues on Yanley Lane project and Friezecroft Avenue redevelopment. It thought me the importance of spending enough time on site doing a thorough measurement and investigation, as mistakes at this early stage could not be apparent straight way and are likely to surface much later in the project. For example, because of not fixing a datum point on site from which the relative building dimensions are measured, a problem has emerged during the construction of Yanley Lane studio. As steel shoes that supported the building were higher than as drawn, and because the floor construction change was not taken into account the building was higher by 00mm than allowed by the authorities. Unfortunately, as the datum point from which the heights were measured was not set, the problem had not been solved until the stud frame and rafters were up. This meant that the studs had to be shortened adding labour time and labour cost. I have witnessed the site investigation by structural engineer collaborating on Yanley Lane studio development. Even though the building used lightweight construction, six trial pits were dug to determine the strength of the subsoil. Implicitly and through the discussion with an engineer I became aware of issues related to this tasks. In many cases the strength of soil, which determines the foundation size and type is an unknown until the construction starts on site. The soil excavation can create serious problems as the trial pits may not always determine all the issues related to foundation design. Finally, I have participated on site inspections both on Yanley Lane project where I have conducted few on my own, and on Kingsmead primary school as an observer. Due to the small size of studio development and because of close collaboration with the main contractor, these visits would usually be of informative nature. I would agree small amendments with the contractor or I would just observe the construction progress. I think I would need more experience with projects on site to be able to draw informed conclusions. Managerial skillsApart from being involved in specific tasks, an architect also has to collaborate with other parties involved in process of development. He or she may be put in the position to oversee the overall output of a design team and contractors. Therefore, negotiation and organisational skills need to be acquired in order to be able to successfully run a project. During my time spent in practice I have been in position where I could have started developing some of them. However, this is probably the most difficult part of an architect's job and at the same time, the one that is based on significant experience. Therefore I am aware that I would probably need several more years spent in practice to fully develop them. In my case, I have had a chance to engage in managing the bill of quantities, manage design integration and to be involved in design team/client meetings. Managing bill of quantitiesAs mentioned before, Yanley Lane Studio Development was small in size. The parties involved in its development were a client, the architectural practice and a specialist timber construction contractor. The involved contractor would usually offer design and build services for small - scale timber structure developments. It was suggested to the client that White Design Associates could develop the design in collaboration with this company, utilising their knowledge of timber construction methods. Afterwards, the building contract would be awarded to this building firm. Clients were also encouraged to get another independent cost estimate for the agreed design as a safeguard for them. Therefore, the project did not go through more traditional procurement paths (Chappell and Willis, 000). As the result of the simplicity of the development set up, the professional boundaries were blurred to an extent. This meant that White Design Associates were responsible for obtaining final prices for several construction items that were outside the scope of services provided by the contractor. Namely, these were fixing the price of windows and the price of roof membrane. I have spent significant amount of time negotiating these items with the suppliers. However, I think I have learned a lot from the process. For example, the roof design featured timber boards as roof cladding material. These boards had to be fixed to the main roof structure comprising rafters, plywood sheet cover and EDPM roof membrane. The only way of connecting cladding boards to the roof structure was by using timber battens, yet the batten fixings would penetrate the rubber membrane. Another set of EPDM strips had to be added to cover battens and provide extra protection. This has resulted in getting price estimates for roof membrane up to five times higher than it was provisionally allowed for this item. This alone would mean increase in project cost by 0%, which was unacceptable. After several months spent negotiating with various EPDM manufacturers and installers, I have managed to negotiate a satisfactory solution with one company. The company was able to produce single sheet roof membrane with rubber flaps spaced to correspond to the spacing of battens. The battens could be tucked under the flaps, reducing the installation time, and more importantly reducing the cost. Hence, the EPDM membrane supply and fixing was returned to the original estimate. More than anything this has taught me the value of creative process. In order to achieve good design solution, an architect has to be inventive in every stage of the development process. Managing design integrationEven though it is an architect's technical skill to integrate information from various consultants into information packages, in personal opinion, this activity has an important managerial aspect too. During the time I spent working on Yanley Lane project, and by supporting project architect developing Kingsmead primary school, I have realised that an architect has to oversee the activities of the consultants. Particularly in the case of more complex designs that go through numerous changes, it is important to ensure that all of the design team is aware of all of them. On few occasions I have noticed that the delays would be created just because a team member has developed a solution that did not take into account latest agreed design changes. Knowledge of legal issuesFinally, I have implicitly became aware of the vast field of legal issues that an architect has to engage in. As I have not been in the position to sign the contracts I could only observe the work done by senior colleagues within this field. I have looked through the standard contract - RIBA small works to familiarise myself as it was used on Yanley Lane studio development. Also, I have learnt the appointment procedures that White Design Associates used when undertaking new work, which was in line with the explanations of this process that can be found in professional literature (Green, 001). Also, White Design Associates used mainly partnering arrangements and ventured into variations of design and build procurement paths with a major construction company. Because my knowledge within this file is limited in scope, I could only draw a simple conclusion. Namely, that the contractual arrangements have strong influence on the nature of process of development; different types of contract favour different agendas, such as quick construction, design quality or cost certainty. An architect has to have a clear picture of a client's needs and the office ethos in order to be able to negotiate the best possible contractual solution. Future aspirationsThis essay has helped me not just to organise my experience, but also to realise the strong points and the weaknesses of my knowledge and skills. I guess that when going back to the academic world, in my case doing the diploma course at Oxford Brookes University, one should not regard it as a 'cut off' point. Even tough the tasks performed at the university are not part of a 'real' project they should be dealt with as they would be in practice. Therefore, I am hoping to use the technical skills acquired in my years out within studio projects. In this way apart from thinking about conceptual design solutions, I hope to be able to engage in incorporating structures and servicing into proposed schemes. As managing Yanley Lane studio development has taught me a lot about construction process and various issues associated with timber construction, I hope to be able to examine other forms of building in the same level of detail. On the other hand by mapping out my experience, I became aware of my limited skills related to legal issues or project management. Obviously, I am hoping to develop these once I go back to work. Yet, in the meantime, I believe that seminars and reading about these subjects areas can help me to go back to practice more prepared. Similarly, I will try to concentrate on a strong CPD programme within my future workplace, as I think I did not emphasised enough in my years out. Most importantly, I hope that in future I will be able to creatively engage in professional work. I think the most important thing that I have learned is the value of creative thinking; I hope to be able to contribute to devising not just interesting design, but also to an innovative business model or to construction method.'''",315.0
"'''In writing the way of Truth, Parmenides sets out his concept of reality based on what he can deduce a priori, using his mind with reason or logos as his guide. His path of thought is portrayed through a journey in a hexmeter verse proem modelled on Hesiod's Theogeny, in which he travels from the 'dark' world of the unaware mortals to the light of knowledge which encompasses both unaltering truth and mortal opinion. Although the barrier to his attainment of this knowledge is strong, 'the gates of 'night and day' can be parted through 'gentle argument'. From this he concludes that 'being' is all there is, persuing a radically monistic doctrine. In contrast to this, he presents the Way of Seeming, created using sensory experience of reality, which he states is 'deceitful' as his senses tell him information about reality which is subject to change, which appears to compromise the singularity of his view of being. Although being is an essential property of things, this is revealed only to the mind (nous), so is only revealed in the Way of Truth. Thus, the Way of Truth is the only option which he asserts is possible. However, although The Way of Truth is not intended to be deceitful, the views advanced in it are highly paradoxical, which shows that reliance on pure reason alone can produce contradictory conclusions as Parmenides theory ultimately proves itself to be self-refuting. Parmenides acknowledges that the Way of Seeming is untrustworthy which suggests he has a specific purpose in writing it, however there are several possible reasons he could have had for its inclusion. One potential explanation for Parmenides' inclusion of the professedly misleading Way of Seeming is that it has a role in validating the logical mode of enquiry endorsed in the Way of Truth and exposes the fallacies of sensory experience or 'aesthesis', which tells us that objects or 'pragmata' have numerous different properties wheras in the way of Truth the most essential property is accessible through the 'nous'; they all form part of being. In his argument for the singularity of being, Parmenides first assumes that there are two mutually exclusive possibilities for any subject of enquiry, either it-is or it-is-not, in obeyance of the rule of non-contradiction. He then assumes 'you think', a precursor to Descartes' cogito. From this he deduces that you either think esti or ouk esti as these are exclusive, however, it is impossible to think 'ouk esti' so you must think 'esti'. He believes that whatever you think has some form of reality, entities participate in the greater being and are necessarily related to our minds or nous, one does not occur without the other. From this conclusion, Parmenides goes on to argue that creation is impossible as this would mean that being would once have had to not exist which cannot be thought. Therefore, the Way of Seeming appears to require him to use negative senses of 'esti' which he believes are impossible. As Nothing can have true existence except what is conceivable, Parmenides sees 'is it or is it not?' as equivalent to 'can it be thought or not' as stated by Kirk Raven and Schofield. Thus, the Way of Truth appears to be the only path available, and 'must be'. However an alternative perspective to this is raised by the fact that the Way of Seeming is constructed on the assumption that humans can confuse 'esti' and 'ouk esti'. This implies that it could be employed in order to highlight the erroneous route humans take in not differentiating between two mutually exclsive paths. Their path is thus condemned to be 'back-turning' as they erringly wander 'two-headed'. However, it only confuses esti in the predicative sense, rather than the existential which is what we ultimately cannot think. So strictly speaking, the Way of Truth is not contradicted as one can think 'not tall' without thinking 'not being'. This introduces the issue of whether Parmenides is aware of this distinction. If it is assumed that this is so, the version of himself projected in the poem may be as the naive young Philosopher, distinct from the authorial self aware of the inconsistency. To decide which interpretation of esti is favoured in the fragments, Kirk Raven and Scofield suggest that is it necessary to analyse the arguments which have esti at their core. One of the foremost of these is the argument against negative enquiry. Parmenides states that 'it is not to be though what is not' and deduces from this that coming into being and perishing are also impossible as for something to come into being it must once have not been, and so it would have been possible at that juncture to say that 'it is not' which is forbidden by the premiss 'you cannot think nothing' so coming into being is impossible. Thus, in this context, 'come to be' is intended to mean 'come to exist' so here an existential sense of esti is being employed. Parmenides then goes on to refer to what does not exist as 'the nothing', this suggests that he is interprets non existence as 'being nothing at all', ie having no predication, so here a predicative sense of esti is also being introduced. Further on, he uses 'eon' to stand for being which is more readily translated as 'reality' than as only 'existence', and what qualifies something for being real is that it is able to satisfy some predicates eg occupies space. If this analysis is true, then Parmenides' use of esti is simultaneously existential and predicative, but not therefore confused. This duality could be seen to suggest the link between the way of Seeming in which predication is allowed and the Way of Truth in which only existential readings of esti are allowed and there is only being. This twofold use of esti could be a pedagogical technique employed to encourage his listeners to re-assess their own beliefs and notice the contradiction involved in not differentiating between the two ways. The blurring of the senses of esti in the text imply that the Way of Seeming may not be entirely false as the Way of Truth may ultimately look similar to it, revealing the relationship between appearance and reality. Another interpretation advocated by some scholars is that the Way of Seeming is 'an account of Pythagorean cosmology', a world composed of elements 'distinct from one another- one form the bright fire of flame'; and the other 'as impenetrable night' which would entail a discontinuous reality. It has been suggested that the mistaken beliefs of The Way of Seeming are not intended to reflect the average person's view of the universe but rather forms a complex system which represents the progression of Ionian cosmology such as that advocated by Pythagoras. This has been questioned by some who feel that is unlikely that Parmenides would espouse a system which he wholeheartedly disagreed with, although it is possible that this method would be in keeping with certain rhetorical techniques of the apocalyptic convention of verse which the Proem is influenced by. It is significant that Parmenides uses the mouthpiece of the Goddess to express these 'mortal' views, rather than the character of himself, thus distancing himself from the opinions put forward which go against his monistic view of being in seeing the world as consisting of opposing elements. The journey of Parmenides to the attainment of transcendent knowledge is elaborated by this cosmological description of the realm from which his soul has escaped. This domain is described in terms which reveal its unacceptability to The Way of Truth, 'light and night are given all names' and celestial bodies are 'predicated of this and that in accordance with their powers', using esti in ways which require is-not, ie is not light. The Goddess stands at this diverging path and impels Parmenides to avoid this view point. As Kirk Raven and Scofield assert, Parmenides' epistemology and metaphysics leave no scope for cosmologies as they dismiss belief in 'the world our senes disclose to us'. However, it is also possible that this allusion to Pythagoras also shows how his emphasis on the power of thought as a mathematician has influenced Parmenides' view that 'It is the same thing that can be though and that can be', further reiterating the connections between the Way of Seeming and The Way of Truth. The inclusion of the Way of Seeming could be seen in opposition to the initial argument as drawing attention to the flaws in the Way of Truth. By following what he can deduce through first principles alone, Parmenides has reached a highly paradoxical conclusion. The paradox lies in the fact that his theory appears to be self- refuting; thinking esti would be thinking ouk ouk esti which would be a negative statement, the Way of Truth 'cannot not be' as expressed by Waterfield. The contradictory conclusion of this argument would entail a world devoid of predication, an unmediated mass in which the existence of both Parmenides and the Goddess would be impossible. He may then be asserting that human beings have no choice other than to perceive reality through the information they gain through their senses. This world is illusory but it is the one humans inhabit. The knowledge we gain from sensory experience may be valued by Parmenides as offering a different insight to that of reason. Although his meaning is made ambiguous by his use of a poetic form, Parmenides may be alluding to a similar distinction to that viewed by Plato, between different types of reason and knowledge, 'both the unwavering heart of well-lit truth and the opinions of mortals', which relate to different 'objects of knowledge', and suggesting that the method used depends on the context it is being used in. The Way of Seeming may also have a role in highlighting the importance of linguistics in Parmenides' theory. In the Way of Seeming, Parmenides may be acknowledging the value of sensory data in understanding aspects of the world which humans inhabit, although conceding that it is misleading in uncovering the deeper metaphysical truths which lie beneath the sensory appearances. He suggests that human concepts such as 'creation and perishing' are ruled out through logical deduction so have no foundation in being and are merely 'names'. Movement and change are merely conventions which mortals perceive the world by, they are what Parmenides would describe as 'nomos'. However, it is through language that humans are able to give structure to their thoughts in the 'nous' and construct arguments which have produced the logical deduction on which the Way of Truth is based. Another possibility with relation to linguistics, is that Parmenides has realised the impossibility of expressing such a monistic theory in language, as will later be concluded by Plato in the Thaetetus. To advocate that there can only be being and that no negative statements are possible instantly becomes self refuting as the statement iself is the negation of the negative statement. This would mean that the Way of Seeming is inextricably bound up with the Way of Truth as it is through human language that he must express his thoughts. However, following on from the self refuting nature of Parmenides' theory, it could be argued that the Way of Seeming leaves Parmenides in a state of aporia. The dilemma expressed by Democritus in his dialogue between sense and reason is evoked, in which the senses call the mind 'wretched' for relying on them to perceive the world then dismissing them as untrustworthy. Reason is telling him that his senses are telling him that he can think 'ouk esti' which he sees as inconceivable. The impasse reached through both paths of enquiry emphasises the limitations of both what have come to be called empiricism and rationalism in analysing reality. This could explain why the Godess describes truth as 'circular' as in attempting to comprehend reality, we alternate between the two poles of reason and sense data, neither of which are able to fully elucidate the situation. Perhaps Parmenides believes both modes are indispensable to our understanding. This is highlighted in the Godesses' assertion in F1 that Parmenides will 'come to see how beliefs must exist in an acceptable form, all-pervasive as they altogether are'. It is conceivable that Parmenides' conclusion is that starting from first principles is a flawed method of conducting philosophical enquiry due to the fact that as mortals, all the apparatus humans have for interpreting reality comes from their unreliable senses, so they are unable to ever know which first principles to choose. This impasse is shown clearly in the fact that the Way of Truth requires Parmenides to think not being as esti is ouk ouk esti which is a negative statement in an existential sense, yet The Way of Seeming makes similar demands of him as it includes statement such as hot/cold day/night etc which involve negative predication. Aristotle noted this incongruity and identified a difference between things which are known to us and things which are known absolutely. This contradiction suggests that philosophers, belonging inescapably to a realm knowable only through sense perception, are forced to begin from the facts gained through experience. They can then use these as a base from which to progress, through argument, towards things known absolutely. Finally from this new position, they can work backwards to what is known in the sensory world and appraise which first principles are compatible with it. Kirk and Raven contend that like Heraclitus, Parmenides' dualism between Being and Seeming is balanced by the unity of his initial insight, 'truth as a well rounded whole'. Perhaps this is ultimately what Parmenides is supporting in writing the Way of Seeming, when he asserts that 'the point from which I start is common; for there shall I return again'.'''",318.0
"'''In accordance with the title I am allowing Medea to be a figure of male nightmares and intend to argue the reasons why she both is, and is not, something more than that. I believe that, viewed as just a character in a tragedy, Medea is nothing more than figure of male nightmares. She has few of the qualities that we are led to believe Athenian women of her time had. She is not submissive or obedient to men, and she does not remain in the house to take care of its management and her children. Infact she is almost male. She is the aggressor, she takes the initiative and she exacts her revenge in a male way, through death. From the weeping, desolate woman at the beginning of the play grows an enraged monster who, by the end, rides away in a chariot of the gods with the blood of her own children on her hands. She becomes so outrageous, so huge and terrifying a monster, that she cannot be more than a nightmare because such a creature could only ever exist in dreams. However, when viewed as a piece of work, a literary creation, Medea is much more than just a nightmare. She is a statement on the roles and treatment of women in Athens in the th Century and a literary advancement in characterisation on the part of Euripides. Medea cannot be anything more than a figure of male nightmares as a character because she is too unrealistic and extreme to exist outside the dreamscape. First and foremost she is a monster. She sacrifices her own children just to get back at Jason, and even does so after she knows she has successfully killed his wife and father-in-law. She cannot be content until she sees him done as much damage as possible and no obstacle, not even her own flesh and blood, will stand in her way. That is what makes her 'No woman, but a tiger; a Tuscan Scylla- but more savage'. This extent of preoccupation with bloodshed and revenge belongs to no one else but the Furies. Nowhere else in Greek tragedy do we see such supposedly reasoned savagery. As the play goes on we watch as Medea's humanity falls away. At the beginning she weeps in the house and laments the loss of Jason. However, it is not long before she is cursing him and planning her revenge. When she asks the messenger from the palace to recount the deaths of the princess and her father she states: 'You'll give me double pleasure if their death was horrible.'. She then ignores the part of her that urges her not to kill her children, effectively shutting off the last of her humanity as, when she appears at the end of the play, triumphant and elite, she shows little remorse and reminds Jason angrily 'I can stab too:'. She may be a barbarian, and thus not expected to behave in a civilised way, but, as Knox points out, in Iphigenia in Tauris the captured barbarian king says about Orestes murder of his own mother: 'Not even among the barbarians would anyone have the heart to do what he has done.'. Here is Euripides himself pointing out that even the barbarians, these savage outsiders, would not commit such a crime against their own blood. Euripides, Medea, Vellacott translation, p.8, l.344 B. Knox, 'Medea of Euripides', Word and Action: Essays on the Ancient Theater, p.10 Another aspect of Medea that makes her so extreme and unbelievable is her maleness. No woman of Athens would ever be so male, so she becomes even more improbable and dream-like. She states how she would rather '.stand three times in the front line than bear one child.', preferring fighting like a man to giving birth to children like a woman. Medea's great anger also suggests a maleness as public anger belonged very much to the male in Athens at the time. As Harris says: 'A properly organised city, from a Greek male point of view, was one in which women knew their place; and knowing their place involved among other thing avoiding anger.'. Medea does know her 'place', that of a grateful foreigner, and obedient inhabitant, but not a citizen, of Athens, but she refuses to be put in it. She lets loose her anger as if she were male and has the right to and she takes her revenge as if she were male, by killing. 'I understand the horror of what I am going to do; but anger, the spring of all life's horror, masters my resolve.' W.V. Harris, 'The rage of women', Ancient Anger, p.37 Euripides, Medea, Vellacott translation, p.0, l. 079-1 Another thing that makes Medea so unbelievable is the way she appears to have the Gods behind her. The Gods did not look kindly on those who killed their own family and punished them, yet Medea calls on Zeus many times throughout the play and there is never any evidence of him taking action against her. In Oedipus Rex the gods make their displeasure at Oedipus' pollution known by causing a famine and barrenness on his city. In Aeschylus' Agamemnon the constant references to the Furies let us know that Clytemnestra's deeds will not go unpunished. However in Medea, at the end of the play we see only a sign of support from the Gods: the chariot of Helios. As a literary creation, Medea is much more than a nightmare. In her Euripides creates a more advanced heroine than has been seen before. She seems part Sophoclean hero, she is set on what she is going to do, she is passionate, she will not listen to reason, she is alone, she feels disrespected, she is unafraid of consequences and so on. In these ways, she resembles Sophocles' Electra from the play of the same title thought to have been written around or just before Medea. But she is not all Electra, as Electra cannot act without Orestes and Medea, though she needs Aegeus' aid for the future, does not need a male hand to do her killing. In this respect she is like Aeschylus' Clytemnestra from the century before, another committer of murder within the family. Like Clytemnestra she is cunning and willing to spend time deceiving her enemies so as to set up the perfect revenge. Like Clytemnestra she will do the deed herself, and like Clytemnestra she does not object to killing the innocent party of whom they both seem jealous (in Medea's case Glacue, and in Clytemnestra's Cassandra). But to both these characters Euripides must add something more to create the product that is Medea: an element of monstrosity. Clytemnestra may be cruel like Medea, but she goes straight to the heart of matters and kills Agamemnon. Medea does not kill Jason, she does what is possibly worse, she decides to revenge herself by hurting him as much as she possibly can, 'This is the way to deal Jason the deepest wound.'. She is unlike any heroines that have gone before her, designed to shock, and she still does now, thousands of years on. She is much more than a nightmare in this respect, she is a masterpiece. B. Knox, 'Medea of Euripides', Word and Action: Essays on the Ancient Theater, p.98 Euripides, Medea, Vellacott translation, p.3, l.5/86 Medea is also more than a nightmare in another sense. She is a statement on Athenian women of the time. Out of her mouth comes some of the most pro-women statements of her time. It is because of her speeches that many label Euripides a feminist. As Goldhill, rephrasing Slater, puts it: 'Women, repressed in life by men, find a voice through men in the institution of tragedy.' and in Medea Euripides seems to do just that. 'Surely, of all creatures that have life and will. We women are the most wretched.' Medea moans, but as she carries on we see the role of women unfolding. She talks of being possessed by one's husband, of having to 'purchase' this husband at a price and she makes valid points about what little a woman has should her husband leave her. It is very hard not to sympathise with Medea throughout the first few scenes of the play, and even though that sympathy may diminish as she takes her revenge, her points are still no less valid. She has been betrayed, Jason is indeed an 'oath-breaker' and a 'guest-deceiver'. The chorus, a group of Greek women, agree with her 'To punish Jason will be just.'. And although the tragedies are plays and are thus not necessarily a completely accurate representation of Greek society at the time, they cannot be discounted completely. As Goldhill suggests after comparing Sophocles' Procne to Medea: 'The attribution if such sentiments to two such similar characters by two different playwrights suggests that the lot of women was, in late fifth-century Athens, very much a question of the day, and also a subject that fascinated the tragic poets.'. S. Goldhill, Reading Greek Tragedy, p.13 Euripides, Medea, Vellacott translation, p.7, l.03 S. Goldhill, Reading Greek Tragedy, p.13 In conclusion, Medea can be seen as both nothing more than a male nightmare and as something much greater than just that. She can be dismissed as being nothing more than a fantastical, evil witch, or she can be viewed as thrilling advancement and a thought-provoking message on the functions and expectations of Athenian women of the fifth-century.'''",319.0
"'''Own Algorithm A simple strategy to solve the travelling salesman problem would be one which would undoubtedly be undertaken in practice by many 'travelling salesman'. It is a less mathematically based algorithm than those to be discussed later. In summary the strategy simply starts at location.Here the travelling salesman chooses the closest location to travel to. At the next location the salesman does the same again ensuring that he never returns to a location he has already visited and that he does not return to before visiting every other location. At the final location he simply returns to location. The best way to illustrate the strategy is in application to the given distance matrix: Step Consider the distance matrix. Look at the row relating to the starting ij = if the salesman travels from location i to location j, otherwise. This formulation is discussed in question. However, the notation is used here. Branch and Bound Tree: We take the first Global Upper Bound as 5/87 units from my own algorithm solution of the previous question. We cannot branch any further at sub-problems and as both the distances travelled are greater than the new global upper bound of 13. No further branching will yield an optimal solution. At sub-problems and there are no sub-tours hence no further branching nor use of algorithm from question is required. The minimal distance for the Salesman to travel is 13 units. He can do this in possible ways. The possible paths that yield this solution are ------ and ------. These are the reverse of each other. Comment on Solution:The branch and bound approach I have researched and used an approach to finding a solution to a combinatorial optimisation problem. This means that there are many possible feasible solutions so it takes a great deal of time to find all possible solutions explicitly. The branch and bound approach takes advantage of the particular problem being considered to find the optimal solution implicitly. In this instance the elimination of certain journeys or arcs to eliminate sub-tours means that a solution can be found. The approach I have researched and used here differs to that used in lectures in that at every sub-problem the Hungarian Method is used to find the actual path that relates to the specific solution and the distance related to it rather than finding only a distance value. This means that at every sub-problem it is possible to branch to eliminate sub-tours as it is known what the sub-tours are and therefore we can quickly discover the optimal solution. The approach used in lectures eliminates only random arcs meaning that the solution found may only be approximate rather than optimal and that much branching must go on before the actual optimal solution is found. In this instance the solution is optimal as the Hungarian Method allows well chosen removal of specific arcs that yield sub-tours so narrowing down the optimal solution quickly. In addition, it is an intuitively correct solution. It can be seen that it makes sense to travel in one direction between locations close to each other such as location and or locations and. Hence considering arcs with or without one direction or another will intuitively lead to an optimal solution. This intuitive approach is easy to see for a small number of locations; however, for a larger number of locations this is more difficult. Integer Linear ProgrammingBefore setting up a spreadsheet model to solve the Travelling Salesman Problem as an integer linear programming problem the problem must be formulated. For i j let c ij = distance from city i to city j and let c ii = M where M is a very large number (this ensures that the solution does not detail the salesman to go to city i as soon as he leaves city i). Within the spreadsheet model M is set equal to 0,00. Define x ij = if the salesman travels from location i to location j, otherwise. Then the solution to the Travelling Salesman Problem can be found by solving: Formulation within a spreadsheet model can be seen on the following page. Solver finds an optimal solution of 13 by the salesman travelling ------. This is the same as the solution obtained from the branch and bound method. Appendix shows a simple example of the model showing that it is correct. Comparison of Methods. It is evident that none of the three approaches considered provide an efficient method to solving the Travelling Salesman Problem. The problem first occurred in 75/89 from Euler who wanted to move a knight to every position on the chess board exactly once, however the problem first gained fame in a book written by Voigt in 832. There has been much investigation in Mathematics into how to solve the problem efficiently as well as optimally. My original algorithm provides a quick and intuitively simple method to solving the problem. However, one of the obvious disadvantages is that it does not yield the optimal solution in every case. This is the obvious advantage of the branch and bound as well as the integer linear programming solution using solver. For this specific example these two methods yield the optimal solution. As discussed previously the branch and bound method used within this assignment differs to that used within the lecture examples as through the Hungarian Method it provides strategic elimination of sub-tours to find the optimal solution efficiently rather than random elimination of certain arcs. I believe that this method allows greater understanding of the specific problem in hand as it allows the user to consider the consequences of each action taken. However, the method is still time consuming and for more than cities it would become tedious. The state space would become almost unmanageable and without the explicit set up of a computer based model there is also a certain amount of room for human error. A mistake in one sub-problem will also lead through to those further down which is certainly not ideal as the final solution would be incorrect. An alternative to either of these solutions would of course be the Integer Linear Programming spreadsheet method using Solver. This is a quick and easy method to use once the spreadsheet model is set up as can be seen from the adaptation in the appendices for a different distance matrix. However Solver is not always guaranteed to be able to find an optimal solution in the time limits set by network users which shows that this method is certainly not ideal. For a larger n amount of cities it would also be more time consuming with perhaps less likely chance of a solution. Perhaps then the only full proof method to optimally solving the Travelling Salesman Problem is by enumerating each possible tour and searching for the tour with smallest cost/ distance. For n cities the number of tours is n. However, when n becomes large it is impossible to find the cost/ distance of every tour in polynomial time. For smaller n, however, perhaps through use of a computer program this would be the best method. In solving a real life large scale Travelling Salesman Problem investigation into different methods is needed. For instance heuristic approaches could be looked at. These do not try to encompass every possibility of the problem but try to apply common sense to shrink the problem to a manageable size. The word 'heuristic' means 'A rule of thumb, simplification or educated guess that reduces or limits the search for solutions in domains that are difficult and poorly understood. Heuristics do not guarantee optimal, or even feasible, solutions and are often used with no theoretical guarantee.' An example of a heuristic method would be perhaps be my own algorithm. Another example would perhaps be empirical analysis which involves comparing heuristics such as my own algorithm to a number of problems where the optimal tour is already known. The application of such methods can be done in polynomial time, which is perhaps not possible for other methods and even though the complete optimal solution may not be found, a close approximation is better than no solution at all. Of course, it is important to compare heuristics with regard to computer running time for the other algorithms and ease of implementation. Suggestions for further work:Investigation into a travelling salesman problem where we have more than one salesman. A travelling salesman problem where we have costs instead of distances of travelling from city i to city j and the cost from city j to city i is different to that of city i to city j.'''",326.0
"'''The weaknesses of the current ABC system includes: heavy reliance on past data, cost allocations are inevitably arbitrary and product focused. Alternative method to customer profitability: Extension of ABC towards focusing on customer cost and Balanced Scorecard. Extension of ABC - focused towards customers, using the whale curve to understand profitable customers and to identify segments. Balanced Scorecard - Market share and customer loyalty and satisfaction is observed to see its potential in increasing market share and profitability; Life cycle profitability analysis is used to measure outcome of loyal and satisfied customer. However, BSC maybe hard to implement because managers are used to measuring performance using financial measures. It is recommended that new methods are adopted to improve market share and profitability. However, further information is needed. The current ABC systemThe current Activity Based arises to close the gap between strategic objectives of Large plc to focus on customers and management accounting system. The ABC seeks to recognise that it is activities which cause cost and helps in reducing costs and identifying non-added value activities. However, its weaknesses are analysed to understand why Large plc's has been losing market share and having lower product profitability despites attempts to use the ABC. One drawback of the current ABC system is that it relies heavily on historic data. Hence, affecting the accuracy of product's full cost. It is arguable that since products are priced basing on past data, it will not ensure the true competitive price in market terms. This in effect, lowers the product profitability as true costs are not generated. Another flaw with the ABC system is that cost allocations are inevitably arbitrary. It is observed that not all costs are directly attributable to activities and from there to products. This is especially true in relation with the 'facilities sustaining costs'. This for instance includes audit, research and health and safety cost. Because these particular costs are subjective in its allocation, it impairs the true full cost and would affect the product profitability. Creating a satisfied customer is the only valid definition of methods for calculating customer profitability evaluation are as follows; Extension of ABC towards focusing on customer recognised that current ABC system is product focused, it is suggested that the ABC can be extended to having a more customer-focused approach. An important step in carrying out Large plc strategic vision is to use ABC to allocate overhead expenses to different categories of customers. This ensures a way to improve profits by growing sales and without growing costs. Besides that, it allows Large plc to identify 'hidden profits' and 'hidden loss' using this ABC method, an output from this analysis is the called whale plots cumulative profitability against customers. Cumulative sales usually follow 0/0 rule. However, a whale curve typically reveals that is not unusual for some of the largest customers to turn out being the most unprofitable. The largest customers are usually most profitable or most unprofitable and are rarely in the middle. Therefore, to restore Large plc's market share, Large should focus on managing the customers on the left section of the whale curve. For instance, managers should be prepared to offer discounts, special services to retain the loyalty of these customers if competitor threatens. This avoids Large plc from losing market share to its competitors. Furthermore, its effectiveness is shown from the analysis of Kanthal case Scorecard approach emerges from the need to link both financial and non-financial measures of performance and identify key performance measures. Particularly with having a more customer-focused approach, it is contended that BSC provides a comprehensive framework for managing customer the potential of restoring Large plc's market share, BSC ensures this by having performance measures relating to market share. For example, market share can be measured in terms of sales revenues, unit sales volumes or number of customers. By having this, managers can indicate whether strategy adopted is achieving the expected results in targeted market segments or otherwise. In this instance, it is possible that Large plc has not recognised the strategic segment to market its product. Therefore, it is observed that overall market share falls because there is a possibility that Large plc's product appeals to a segment which have a relatively small market. Using the BSC approach, Large plc is able to understand for instance, whether loyal or satisfied customers are given adequately to both loyal and satisfied customers and hence, profitability is increased. Furthermore, it is observed that above measures suggested are only means required to achieve to measure customer profitability but not the outcome. Hence, it is suggested that Large plc should incorporate the life-cycle profitability analysis to determine whether the focus should be on retention or on abandoning customers. With specific reference to Custom Research Inc. example , CRI uses the lifetime profitability analysis to manage and therefore recognise profitable customers and able to do comprehensive screening, mentoring and promoting of individual customers. Its success is proven as CRI had 6 clients who provided 6% of sales and 6% of profits. If applied sufficiently within Large system, higher profitability can be achieved by understanding customer profitability. However, it is argued that both BSC and ABC must be used hand in hand. Referring to Appendix, managers are able to identify what actions to take in terms of managing customers. For instance, unprofitable, targeted customers should be transformed to make them profitable through pricing, process improvement and relationship management actions. This model gives insights about where opportunities exist to transform attractive, but money-losing customers into long term profitable relationship . Moreover, it must be noted that the recognition of profitable customers is subjective and depends upon managers' point of view. Mention the word 'performance', and many managers immediately shift their thinking to measures related to some type of financial result . This is simply because; many managers are formally trained to measure performance through financial accountability which provides the easiest way to demonstrate progress and productivity. Hence, the success of adopting the BSC to ensure a customer-focused approach is highly dependent on managers' abilities to see the clear objectives of having this method imbued in Large plc's system. RecommendationsIt is recommended that either both methods are suitable for calculating customer profitability. However, it would be more useful if further information is given to ensure the most appropriate method to ensure good judgement. For example, it would be more useful to know the culture within the organisation as this may affect the likely method taken. It is vital to know whether organisation is receptive to changes or not. Hence, in this instance, maybe the extension of ABC towards customer cost maybe more suitable as it does not include an entirely new system like the balanced scorecard for all levels of organisation to adapt to. Moreover, it is imperative to weigh the cost against the benefit. It is argued that employing a new system may involve a hefty financial cost and resources in terms of staff training. It would not be viable if the cost exceeds the benefits. Subsequently, it is vital to know whether competitors are moving towards customer-focused approach or not. This is because, Large plc may enjoy significant head start in understanding customer relationships if competitors are not moving towards these approaches yet. Hence, immediate action should be taken to counter the negative effects towards market share and profitability.'''",335.0
"'''Open Source a model for software development and distribution in which the source code of the software itself is freely available to everyone. This means there are no license fees to be paid for using and everyone can inspect the actual function of the software, thereby augmenting trust and security of the software itself. The software designs are driven by the wishes of their creators and the end goal can be whatever they wish. Many people recognize a qualitative benefit to the software development process when a program's source code can be used, modified and redistributed by developers. However, Open source doesn't just mean access to the source code. The distribution terms of open-source software must comply with the following criteria: Free redistribution, source code available, derived works, integrity of the author's source code, no discrimination against persons or groups, no discrimination against fields of endeavor, distribution of license, license must neither be specific to a product nor restrict other software but technology-neutral. I think these criteria also fit to ODS and OSH. Open source software is not always free in price sense, but is free in freedom sense. OSS usually supports popular ODS for data storage and exchange. An Open Data a model for data access, exchange and storage for which all the documentation regarding its features and specifications is freely available to everyone. This implies that, in principle, the same data may be accessed, processed and stored by software produced by different companies. It ensures interoperability between various solutions that need to operate on the same data. Adobe's PDF, the HTML and XML web languages, and the JPEG graphical formats are among the best known ODS while Microsoft's.doc format is an example of a 'closed' standard. Usually, ODS contributes in several aspects such as, increasing privacy and transparency of the user's data, reducing exposure to situations in which commercial software vendors exploit proprietary data formats to consolidate and augment their market share, guaranteeing the permanence of public data, by avoiding dependence on the goodwill of the suppliers or on the monopoly conditions imposed by them. ODS are often used in conjunction with OSS. Open source is a powerful force in software development. However, open source is more and more popular among hardware world these days. There exits a technical tendency that open source software and hardware design should stand together as they have the same roots. If a company sells any device which interfaces to a computer without publishing the interface specs, they then have a monopoly on interface to hardware for which all the design information is made available to the general public. Such as the design specification, HDL files, simulation test benches, synthesis results, utilization instructions and interfaces to other systems, etc. To fully qualify as 'open hardware', it always would have to satisfy such the requirements: The interface to the hardware must be explicitly made public, so the hardware can be used freely. The design of the hardware must be made public, so that others can implement it and learn from it. The tools used to create the design should be free, so that others can develop and improve the design. Users of the end product can not only know how it works, but are encouraged to create improvements or modify it for their own purposes. When we compare the three above concepts, main features and all their requirements, it is not difficult to found that they have something in common, which is, the freedom to use and improve the current product and the convenience for the public. In order to avoid confusion and to make it more clearly, we can come to their opposite side--'closed', that is, commercial design and setting. So what would commercial soft/hardware designs look like by comparison? Their designs are owned by the company which creates them and driven by marketing departments. The ownership is protected by three sets of laws: copyright, trade secret, and patent. It is often even impossible to see a design without signing a non-disclosure agreement. Designers cannot legally build on older designs unless their company owns the right to use these designs. The users of the final product neither have rights to know how they work nor can they adapt or fix the problem or base a new design on it. After all of these, the result is always that software is ridiculously expensive, hardware is extremely obscure; all except the largest companies or universities are barred from using them by cost. The effects on openness limitationSo the trend for open-ness is to become more and more limited, restricting the freedom of hardware designers to create or implement their own designs, and even of software programmers to write the programs they wish. Try to ask: Is your design published that others can learn from it, improve on it, or even second-source the same device? Much digital hardware has never been open in this sense, creating a whole industry of reverse-engineering and patent claims and counter claims. But there have been exceptions; most notably, the SPARC architecture. In the days of the first PALs, internal structure and programming details were widely published in order to expand the market. Why we can't make it go on? Now no manufacturer publishes the bit-stream format for programming binding contracts and documents. Government agencies often have to follow standards issued by official standardization organizations. Following such standards can also be a prerequisite for doing business in certain markets, with certain companies, or within certain consortia. Standardization, in the context related to technologies and industries, is the process of establishing a technical standard among competing entities in a market, where this will bring benefits without hurting competition. Nowadays, effectively handling the technical standardization process has become a major challenge and difficulty which has caused heated debates around the world, especially in the information and technology field, for example digital audio-video standards, wireless LAN standards and DVD etc. As an overseas student from China, I know that there are many cases related standards and IPR recently, such as the famous affairs DVD, CISCO and HUAWEI. Because of the huge influence on the economic, we had to pay more attention to the issues about IPR and standardization, as well as China government. The key issue for IPR in standardization is patent. Larger companies hold 'patent pools', series of patents combined together, which they use as bargaining counters with one another, and which block new entrants from the market. The contradiction between privatization of patent and publicity of standardization is difficult to conciliate, while there combination is easily tend to result in monopoly. Monopoly is not what most people expected. The basic motivation for technical standard setting is to boost optimal public interest and a reasonable patent system should balance the rights and interests between the owners and users. Open sources may act a wise role in this situation. For instance, market competition is mainly based on patents and intellectual property that maintain all rights for the originator firm. So goes without saying, companies may oppose aspects of open source that generate alternatives for commercially protected products. However, there is always an optimal position between contradictions. The suggested solution is that companies might take advantage of open source as a way of bridging the gap for time and cost absorbed in research and development. The researchers might find they don't have to reinvent already existing wheels. They will admit the advantages that openness brings in: it encourages innovation and fosters bold new products to market which build on proven technology at a markedly lower cost. Then they may find adoption of an open-source design with large base of customers as a win-win deal. Companies can refine the open-source design with affordable prices and make use of bug fixing provided from the community, which has no bad effect on their patents. The end result is cutting-edge reliable products with affordable prices. Another key issue for open source is that it has to build confidence and credibility. Good confidence and credibility among huge of users is the perfect 'patent' for open sources. The suggested solution is that designers produce high quality and completely documented designs. It will be only a matter of time to convince the user community of the credibility of open designs. For instance, the Linux operating system has become reliable and competitive due to efforts exerted to enhance quality and performance from the developing community. For me, it is also more preferable operating system compared with Windows. What measures we should take to reach the better co-existing of openness and patents? First is for government authorities to create a legal circumstance to make a balance between trade and competitiveness; second is for SDO to regulate the disclosure of IPR information and ensure the openness, fairness and balance during the process of information obtaining and standard setting and protect the rights both for users and holders; and the third is for IP owners and companies to understand and use the 'RAND'(reasonable and no discrimination) rules to implement the process. In the long run, as better solutions emerge through time, we may look back on this point as the time when control over our lives as passive consumers began to be replaced by creation of our lives as active participants. We can efficiently and effectively get what we need on the shoulders of already-existed. We also respect and protect their fruits and are willing to share our harvests with others anytime. In a society that seems determined to force unwanted pay-per-view, ridiculous encryption systems, and privatized knowledge on us in order to maintain profits, there is a chance to build an alternative technology which is truly convivial. We are just trying to find the best position to lean on.'''",339.0
"'''Research Proposal: Randomized Control TrialExplanatory research question: Which is the most effective treatment method for someone with rheumatoid arthritis of the hand when trying to increase or maintain range of movement and muscle strength? Exercises on their own, or exercises with the use of a resting splint. This is a fixed experimental design i.e. it is theory driven with the variables and procedures to be followed specified in advance. The purpose of the enquiry is explanatory; seeking to identify relationships between aspects of still allow a degree of flexibility. There will be predetermined questions, however the interviewers' perception of what seems most appropriate for the particular interviewee can be used to modify the order or wording of these as well of as allowing particular questions to be added or omitted (Robson, 002). There may be a more structured part to the interview at the beginning to gather demographic details, this will then lead onto the more unstructured part of the interview using open-ended questions; these allow the interviewer to go into depth, they can also produce unexpected or unanticipated results (Robson, 002). Interviews will be carried out in a quiet room free from distractions, drinks will be available and comfortable seating to ensure the participant is comfortable and at ease. All interviews will be conducted by the same researcher to ensure they are all carried out in the same manner. The interview will be audio taped, a fundamental data recording strategy (Depoy & Gitlin, 998). Notes will be taken during the interview as part of a fail safe in the case of problems with the tape recordings. The interview will be transcribed afterwards for further analysis. Certain issues need to be kept in mind when interviewing, all interviews are subjective therefore there is always the risk of bias (Bell, 999), they are also time consuming both for the researcher and the participant. Schedule of interview:An interview schedule provides a list of things for the interviewer to be sure of asking when talking to the participant (Lofland & lofland, 995/8 as cited in Robson, 002). 'Selitzal., Spradley, Patton, and Polit and Hungler suggest that researchers begin with a kind of outline, listing all the broad categories they feel may be relevant to their study' (Berg, 001, p.4). Once these have been decided questions relevant to each category can be developed forming the interview schedule. This will be critically examined by others who are expert in the focus topic of the study, doing this will help to rule out or identify any poorly worded questions, questions revealing researcher bias, personal values or blind spots (Berg, 001). After this several practice interviews will be carried out to determine the effectiveness of the interview in obtaining the information it intends to gather. Reliability/validity/truthfulness:To increase the truth value an audit trail will be used, this allows others to follow the decision making process followed throughout the study (Depoy & Gitlin, 998). It is central to the acceptance and testing of new theory by scientific communities that replication and reproducibility are possible (Berg, 001). Audio taping of the interviews means that detail of the precise words spoken in the interview will not be lost, allowing repeated review and examination of the information (Denscombe, 002). All participants will be sent the transcripts and interpretations drawn from their individual interview, known as member checking this is a valuable means of guarding against researcher bias (Robson, 002). Data analysis:Data will be analysed using the method of constant comparison, a repeated comparison of information gathered from data collection and emerging theory (Robson, 002). Transcripts and audiotapes from each interview will be transformed into meaningful categories and themes that explain the patterns of the phenomena under investigation, these will be peer checked and member checked to rule out researcher bias. Recurring themes that emerge from the data will be organinsed into broader categories, each category being numbered and each sub-theme being numbered creating an index. This numbering will then be applied to the data enabling it to be coded. This is using the frameworks approach of developing a thematic framework, this is a systematic approach allowing the researcher to identify relationships between the emerging themes thus developing theory (Ritchie et al, 003 as cited in Ezekiel, 004). EthicsThe responsibility of moral conduct throughout this study lies with the researcher (Denscombe, 002). Participants will be invited to join the study by letter to their home and information posters in the hand clinic. All participants must be willing to talk to the researcher for up to an hour and be tape recorded. Informed consent will be gained from each participant prior to interviewing. All participants will be anonymous by use of participant numbers, no names will be mentioned in the interviews or on the tape recordings. Only the researcher will have details of the participant's details, which with the transcripts and tape recordings will be kept in a secure location within the hand clinic. Results will be fed back to the participants by post before publication, therefore if there are any objections to the findings these can be discussed and amended as necessary.'''",341.0
"'''Corporate social responsibility has become a widely held buzzword in the business community for good corporate practices. However, it has also been the focus of debate on its very nature and theoretical justification. One of these criticisms is that corporate social responsibility sounds fine in theory but is unworkable in practice. This article investigates the validity of this claim first by briefly looking at the nature of corporate social responsibility. Then, we undergo an in-depth analysis of the issues related to its implementation from a practical perspective, thereby identifying the limits of the concept and the obstacles to its realization. We conclude with an assessment of the workability of corporate social responsibility and argue that the current situation is rather disappointing. The nature of corporate social responsibilityIt is important to have a clear picture of corporate social responsibility in mind at the outset. Unfortunately, the first and most notable feature of corporate social responsibility is the variety of its definitions. It has been described as 'a tortured concept within the academic literature', see P. Godfrey & N. Hatch, 'Researching Corporate social responsibility: An Agenda for the 1st Century', Journal of Business Ethics 0:7-8, at 7. There are at least 5/8 different conceptual definitions of corporate social responsibility within academic literature. The European Commission defines corporate social responsibility as a concept whereby companies 'decide voluntarily to contribute to a better society and a cleaner environment'. An alternate description is that corporate social responsibility is concerned with 'the relationship between companies and society and in particular, with constraining the adverse impact of corporate activity on individuals and communities as a whole'. In other words, while corporate social responsibility is generally about charity and stewardship from companies, there is no real consensus regarding its definition. A. B. Carroll, 'Corporate social responsibility: Evolution of a Definitional Construct', Business & Ethics. Whitehouse, 'Corporate social responsibility, Corporate Citizenship and the Global Compact', Global Social Policy, 99, at 00. It is also important to bear in mind that the notion of corporate social responsibility is an evolving concept. The notion of corporate social responsibility evolved over the 0 th century. The original corporate social responsibility debates took place in the 930s and were primarily concerned with the responsibilities owed by corporate managers and directors to their shareholders and other groups directly influenced by the corporation. Milton Friedman's famous critique emerged in the 970s arguing that, on grounds based on economics and morality, there was no place for corporate social responsibility in businesses. It was not until the 990s did corporate social responsibility become the buzzword of many businesses and become a service providing industry of its own. Hence, it is likely that this trend of evolution of corporate social responsibility as a concept will continue in the 1 st century. For a history of corporate social responsibility, see A. B. Carroll, 'Corporate social responsibility: Evolution of a Definitional Construct', Business & Ethics moral number of reasons have been put forward to establish the 'business case' for corporate social responsibility. A primary argument relied on is that 'morality pays'. This asserts that businesses adopting corporate social responsibility will increase their profit margins by receiving intangible benefits, such as stakeholder commitment, which leads to stakeholder commitment, ultimately leading to corporate success. This includes the concept of corporate citizenship, see L. Whitehouse, 'Corporate social responsibility, Corporate Citizenship and the Global Compact', Global Social Policy, 99. See J. Corvino, 'Reframing 'Morality Pays': Toward a Better Answer to 'Why be Moral?' in Business', Journal of Business Ethics 7:-4. For a discussion on the reasons for businesses to adopt corporate social responsibility, see J. Corvino, 'Reframing 'Morality Pays': Toward a Better Answer to 'Why be Moral?' in Business', Journal of Business Ethics 7:-4; see also L. T. Hosmer, 'Why be Moral? A Different Rationale for Managers', Business Ethics Quarterly vol., 91-04. However, moral behaviour is neither sufficient nor necessary for corporate success. Moreover, it has been pointed out that most discussion concerning social and financial performance has been misleading to assume that an unequivocal link between these two ends exists. Without a firm understanding between corporate social responsibility and its economic consequences, there is no firm case for businesses to run corporate social responsibility programmes and the businesses that are already running corporate social responsibility programmes are relying on mere speculation. J. Corvino, 'Reframing 'Morality Pays': Toward a Better Answer to 'Why be Moral?' in Business', Journal of Business Ethics 7:-4, at. P. Godfrey & N. Hatch, 'Researching Corporate social responsibility: An Agenda for the 1st Century', Journal of Business Ethics 0:7-8, at 3. Most literature only suggests a reputation for social responsibility correlates to the success of businesses, see, K. Schnietz & M. Epstein, 'Exploring the Financial Value of a Reputation for Corporate social responsibility During a Crisis', Corporate Reputation Review, Vol., No., 005/8, 27-45/8. In other words, there is no firm incentive for businesses to adopt corporate social responsibility at all. Hence, it is doubtful whether corporate social responsibility programmes would be taken seriously. Implementing corporate social responsibilityThe second issue concerns engagement of corporate social responsibility. How are businesses going to adopt it? Which corporate social responsibility activities should businesses engage in? How should managers and executives balance the strategic logic of social involvement with other, more tangible strategic investment projects? These are practical considerations that deserve further scrutiny. We can start by looking at the mechanics of implementing corporate social responsibility. Basic instruments of corporate social responsibility may include values statements, codes of conducts or ethics, social reporting, auditing and certification. While there is no real consensus as to how corporate social responsibility is to be achieved, there has been a proliferation of corporate social responsibility agencies that promises to help businesses incorporate corporate social responsibility policies into their company. G. Piskalski, 'Can corporate social responsibility work out in Poland and other EU new Member States?' German RKW, available at URL social responsibility/index., a widely held observation of the extent of corporate social responsibility adopted by businesses today is superficial rather than substantial. Their corporate social responsibility programmes focus more on elaborate PR schemes rather than substantive issues of corporate social responsibility. Moreover, the ideational neutrality of adopted standards and effectiveness of businesses adopting codes of conduct are questionable. This hypocrisy has lead to accusations of 'corporate sidelining reality' that corporations are exploiting the confusion of corporate social responsibility to their advantage and delaying calls for regulation. J. Shestack, 'Corporate social responsibility in a Changing Corporate World', in 6000 Social Responsibility Guidance Standard, and the GRI Sustainability Reporting Guidelines. For an account of the Canadian experience in adopting these instruments, see P. Hohnen, 'Social Responsibility Instruments: Building the Global Architecture for the 1st Century - Issues and Opportunities for the Emerging Social Responsibility Instruments Landscape', Industry Canada, available at URL social responsibility-rse.nsf/en/rs00147e. URL social responsibility.gov.uk/ (last visited, April 1, 007) '''",346.0
"'''To set the context of this essay is a quotation from '. This demonstrates that the hospitality industry is very important and significant as an employer and is growing fast. The Office of National Statistics reported that the industry employs over. million people working in around 00,00 establishments and predicted that a further 70,00 jobs will be required in the industry by the end of 005/8. This essay aims to look at whether this industry makes a good career choice and in order to achieve this; it is necessary to identify the key characteristics of the industry and compares both the benefits and drawbacks of working in this industry. The industry as Wood points out is 'heterogeneous', it is made up of many different sub sectors including hotels, restaurants, pubs, clubs, bars, contract catering and hospitality services. This represents an optimistic local labour market offering more and a variety of attractive prospects to employees. It provides opportunities for staff to work in other roles to have a change/break and vary staff contact with different people with different needs in different sub sectors within the same industry. The high levels of competition for jobs within the same industry means that employees are choosing a highly competitive sector to compete for jobs. 'The role of the employee becomes much more critical since to a very real extent the employee is the service, given the absence of any tangible artefact'. (Redman and Mathews 998: 9 cited in Kelliher and Perrett 001: 25/8) 'The starting point is the recognition that people are not simply one of the factors of production, along with money and machinery, but the major source of competitive advantage. How organisations recruit, train, reward, motivate and discipline their employees is of central importance to business success'. (Sisson, 994: cited in Kelliher and Perrett, 001: 23). On the contrary, the general approach to management shows too little commitment to human that 'working in catering you feel sometimes that your job lacks dignity. Kitchen ladies and catering staff in general are treated as inferior people by everyone'. that 'poor working conditions' as 'the true nature of much hospitality industry employment'. The hospitality sector is not for those who seek a:0am -:0pm, Monday - Friday work pattern. It is an environment that doesn't suit all; long hours, shift work and at unsocial hours. 'The waiter's workplace is the customer's place of enjoyment and relaxation; the cook's time on the job is the customer's time off' (Gabriel, 988: ). out there are 'insufficient time between shifts' and Wood suggests that reductions in long hours might be a factor associated with increases in employment and productivity. Working long hours along with sleep disruption causes deterioration of task performance because it has a detrimental effect on things such as; rate of error, pace of work and social behaviour. The most common reasons for working long hours are to meet the needs of the job where overtime is normally not paid. It is just expected that workers carry on working regardless of whether they are being paid and: 'You are not paid for work done after the time you were meant to finish'. According to the Caterer.com managers in the hospitality sector do nine hours and 6 minutes of unpaid overtime on average each week and 'Managers in the sector are usually expected to put in extra hours for nothing' Long working hours also has a negative effect on motivation, absence and labour turnover. Lucas suggests a high level of labour turnover could be caused by many factors: inadequate wage levels leading to employees moving to competitors, poor morale and low levels of motivation within the workforce. Referring to Torrington et al, High labour turnover causes problems for businesses, there are significant 'direct costs' involved especially when recruitment and advertising are used. A new employee needs to be inducted and trained and this will usually take some time to reach the required performance standards. The 'indirect costs' involved are loss of customer service/satisfaction particularly where the employee had extensive customer contact and if the employee had already built up an extensive amount of knowledge about the history, operation and culture of the company which is difficult to replace. Conversely, 'The industry has been criticized for having a high labour turnover in staff but this does not imply staff dissatisfaction'. (Forte, 986: 22- cited in Wood, 997: 24). Labour turnover does not just create costs, some level of labour turnover is important to bring new ideas, skills and enthusiasm to the labour force. The business needs to be revitalised with 'fresh blood to avoid becoming stale and stunted' (Torrington 002: 12). As 'Catering wages are consistently low, waitresses are at the bottom of female wage league - only hairdressers earn less'. According to the Office of National Statistics see appendix, employees in the financial sector topped the list in terms of annual earnings. Their average of 8, 93 was just under two and half times the average seen in hotels and restaurants sector which was the lowest paid sector. However, Torrington et al suggested that people may be motivated to leave an employer who is perceived as paying badly, but once they are satisfied with their pay additional increases have little effect. According to Agrusa et al, 'sexual harassment occurs more often in the restaurant industry than other industries'. It is suggested by Wood that this is due to the 'social characteristics' in the hospitality industry where people perceive this sort of behaviour as 'normal' social interaction compared to in an office setting where this behaviour is known as sexual harassment. Gabriel states that management was cited as the major reason for leaving. This was mainly due to managers having poor people and management skills and not enough feedback from the manager. And with reference to. Their work reflected their duties at home and was considered the 'norm'. Employers took advantage of this and were able to use their skills at low cost as additional training was not needed and yet the women comprise in excess of two thirds of the hotel and catering workforce and are concentrated for the most part in operative roles whilst men dominate in management. The industry is losing out by not having enough women in senior positions according to a report by Caterer.com. 'Occupational segregation' is best understood on the context of dual labour theories which comprises of two distinct markets; primary and secondary labour appendix. The broad picture presented so far has shown many employers in the hotel and catering industry rely on drawing cheap, disadvantaged the secondary labour market to fill operative level positions. This approach is aimed to keep labour costs low and minimise the employers' commitment to employees with reference to the dual labour theories as mentioned above. The size of this sector is growing globally, and this growth has meant that employers are putting together attractive recruitment packages to attract the right staff. For potential managers the prospects can be tremendous and career progression is rapid. The poor working conditions; low pay, long unsocial hours, shift work, high labour turnover, lack of training and the higher chance of being sexual harassed all reveal a negative image of the industry and has negative effects such as decreased productivity, poor performance, health problems and lower employee motivation. It also affects staff work life balance and has a negative impact on their domestic relationships, this issue is particularly important where long unsocial hours can severely affect an employee's satisfaction - the happier the employee is at their work, the better and harder they will work, and the benefits such as free staff meals, uniform and free dry cleaning will increase employee's loyalty to their company but the benefits and rapid career progression versus the working environment does not make the hospitality industry a good career choice. The hospitality sector needs to improve the image of the industry as an employer by reviewing their Human Resource Management strategies, a more comprehensive and systematic training programme linked to qualifications and rewards for learning needs to be put into place. To date it is suggested that very little progress has been made towards the development of equal opportunities policies and programmes to tackle sex discrimination within the industry. The industry needs to implement more training for women and encourage women to network to penetrate to top level positions.'''",348.0
"'''The two texts I will be examining are, an extract from the poem, The Love Song of Alfred J. Prufrock, by T.S. Elliot and Her Face by Sir Arthur Gorges. Both texts share a common theme, love poems dedicated to the narrators muse, yet both are expressed in very different ways. Through exploring the linguistic, poetic and cultural features, I will examine the comparisons and contrasts that the poems possess. I will refer to the texts as 'A' and 'B', respectively from now on. I will begin by comparing phonemes and patterns. Both texts have comparisons with frequent repetition of alliteration and assonance. The long and low /l/ sounds of the liquid consonants in text a smooth fluidity to the poem's sound and flow. In contrast to this, text B uses fricatives to enhance the staccato effect. An 'audible friction' is created with the repetition of the aspirate /h/ in the opening line, and with the hissing sibilants in 'so' and 'sweet', a contrast in phonemes is formed between the poems. Short vowel sounds of the /i/ along with the quickly released /t/ gives the feeling that the word has been broken off quickly or cut short, creating a short sharp abrupt line ending. From Appendix D, Pope, Rob, The English Studies Book, Routledge, London Both texts use rhyme, but do so in different ways. Text A has quite an irregular scheme which appears unsystematic, though lines and do and adds musicality to the sound patterning. Text B adopts a lyrical form set out in quatrains. It begins with an almost Shakespearean rhyme this vague frame has repetition with variation in the penultimate stanza. The structure ABAB is regular and repeated, however again it is rhyme 'A' that is foregrounded as it is constantly used throughout all five stanzas creating a cyclic effect that is continually returning to the beginning. Visual rhyme is used with 'love' and 'move', however when read aloud the rhyme is not heard. The two poems have mainly regular stress patterns, but with variations. Text A begins with a couplet that is an iambic heptameter, although the remainder of the text has an irregular number of syllables and stresses per line, so is free verse. Three lines start on the reverse foot and so are foregrounded against the regular iambic pattern. These trochees change the readers pace, acting as a vehicle to carry the text forward. Text B is a highly regular stressed poem. Each line contains six syllables and three stresses, and on every occasion but one, these are iambic lines. The words are all monosyllabic creating a highly structured formal pace. It also contains a trochee line, which creates disjunction because of the change in rhythm. This foregrounding is further heightened with the parallelism in word structure; the second word in the couplet remains constant and the first word changes, a reversal of all the other lines. In text B the use of so much repetition falls into the background and becomes part of the frame of the poem. When the repetition breaks in the third line, the replacement of 'first' with the adverb 'then', breaks this pattern and is foregrounded. This break adds kinesis and propels the text forward, leaving the emphasis on the word 'hit', giving weight to the action verb. The line changes the functions of the same context sensitive personal pronouns. The possessive pronoun 'mine', changes to the possessive determiner 'my'. This causes disjunction and produces an effect of broken language, which could be archaic, as it is used in a context that no longer exists. This shows that the seemingly safe structure of the text is susceptible to change. Both poems are similar in their lack of similes but inclusion of metaphors. In text A we meet the inanimate nouns 'fog', and 'smoke'. Not only do they become physical things with a 'back', but also animate and carries out the action, 'rub'. This conceit or extended metaphor continues with animalistic connotations, anthropomorphising the 'smoke/ fog'. It also possesses a 'muzzle' which not only denotes a part of an animal's face, but also something that ' expressing their opinions freely' implying that the smoke is smothering and restricting, giving the 'muzzle' a double meaning, making it a pun. 'Its' in the third line is a third person singular pronoun, adding to the creatures substantialism as it has its own possessions, and although the poem implies we can identify 'it', the reader is unaware of what 'it' is in this context. 'Smoke' is not the only personified noun, 'evening' also takes on a life of its own. Being abstract and not something physical, the rules are broken when it becomes a 'space'. This shape with corners implies that it is three-dimensional, which takes the reader out of their normal schema and into a parallel world, where the abstract is physical and the inanimate becomes animal. Text B includes the metaphor, 'doth knit/ mine eye.' Eye here is recast as something other, the verb 'knit' is not usually coined with the noun 'eye', which creates an unusual collocation and gruesome image. The Oxford English Dictionary, Oxford University Press, Oxford The sentence structures in the two poems have strong contrasts. Nevertheless, both are declarative, active sentences that inform the reader, and both contain the definite article, signalling a close proximity and specificity to the subject, which invites the reader into the world of the narrator. At first glance text A consists of two major sentences that include the main verb, noun head and grammatical subject. The first two lines are a couplet with a subordinated clause. By starting in media res, the reader gets a sense of immediacy that is echoed by the ellipses at the beginning of the third line with the omission of 'that'. Yet the full stop after the couplet acts as a hinge as there is a shift in tense, breaking it away from the rest of the poem. The present simple to the past perfect, where 'it was a soft October night' indicates the past tense. The second sentence consists of premodifiers that are dependant upon it being 'a soft October night,' making it a subordinated sentence. Graphologically, the two texts are visually presented very differently. Text A's appearance on the page means it is immediately recognised as poetry, with capitalisation of initial letters of the first word on every line, and stacked in a block in the middle of the page, whereas Text B can be likened to concrete poetry. Text A uses caesuras in the form of commas or full stops to avoid enjambment and text B uses physical spaces between words to indicate a break or pause. Set in a table-like format, comparisons can be made between this and classic oriental scripts which are read from top to bottom, and when done in this way the poem surprisingly still making grammatical sense. By contrastively analysing these poems, I have explored linguistically, poetically, and culturally the differences and similarities between the two, and highlighted how poems with similar subjects can in fact hold completely contrasting features.'''",349.0
"'''The Chancery Division Reports are a comprehensive record of decisions of the Chancery Division Courts, and the judgements reported therein provide a chronology of legal developments. In this essay, the judgments will stimulate discussion of the courts in the regulation and creation of trusts law. With equity as a guiding concept, the Courts of Chancery have historically intervened in order to remedy defects in and compensate for the rigidity of the common law. The subject of disputes before the court fluctuates as binding precedents are established and new legislation introduced. p Pearce R and Stevens J The Law of Trusts and Equitable Obligations th Edition, Oxford University Press 006 This essay will focus on the wealth of decisions from 95/83 and contrast them with those of exactly 0 years later, decisions which in relation to trusts law are considerably fewer in number, but no less in value. Broadly speaking, there has been a shift in the emphasis of the matters brought before the court. Firstly, there are fewer decisions in 003 which relate directly to trusts law, with a marked decrease in issues arising from the construction of trusts instruments when compared to the numerous requests for clarification of the scope of terms in 95/83. The correlative to this is that there have been additional areas of law for the courts to consider. The breach of EU Council Regulations and potential violation of the Human Rights Act 998 are beyond the scope of this essay, but demonstrate the evolutionary nature of the English legal system. For example 'if continuing in service' in Re Kendrew Ch 91, 'movables' in Re Walsh Ch 73 Antonio Munoz y Cia SA v Frumar Ltd Ch 28 Gascoyne v Custom and Excise Commissioners Ch 92 A theme which is echoed between the years is the way in which intervention of the Chancery Division is required to resolve issues arising from uncertainty or error in the execution of trusts instruments. It is possible to attribute an element of this uncertainty to attempts at the creative use of the trust, with legal concepts being 'manipulated' to achieve beneficial fiscal outcomes. Re Downshire Settled Estates; Re Blackwell's Settlement Trusts; Re Chapman's Settlement Trust is one such situation, where the beneficiaries sought to extend the rules of variation of trusts in order to avoid taxation. With regard to error, the case law in 003 offers an illustration of errors attributable to trustees and their decisions. The theme of tax avoidance reoccurs indirectly, on this occasion framed in terms of the extent to which the court can intervene to enable the avoidance of detrimental fiscal consequences of trustees' decisions. p 08 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 Ch 18, henceforth Re Chapman See for example Abacus Trust Another v Barr and Others Ch 09, henceforth Re Barr It would trivialise the relationship between law and society to enter into speculation as to the extralegal causes and extent of change at this point, but it is important to note that the use of the trust is closely associated with social, political and economic change so as to maximise benefit for the beneficiaries of the trust. The analysis will focus on overarching themes within the context of trusts, such as judicial intervention, discretion and the awareness of the extralegal consequences of decisions. With these ideas as the framework, comment will be directed towards the consideration of tax avoidance. The structure will be based around the decisions of Re Chapman, Re Gestetner Settlement, and Re Barr, adopting a comparative perspective between 95/83 and 003. Ch: the establishment of principleRe Chapman: curtailing the beneficiaries' cunning planWhen considering the cases from 95/83, Re Chapman clearly stands out due to its overt and direct acknowledgement that both settlors and beneficiaries may seek to minimise their tax liability, and may obtain the court's approval to do so. Prior to the decision, it was believed by settlors and their advisers that there was a 'safety valve' in the Chancery Division, which left scope for variation of trusts in order to meet the interests of beneficiaries through the accommodation of fiscal developments. This is why the case was so important. It had the potential to permit gross departures from the trust instrument in order to defeat 'the villain whose evil designs must be thwarted', an issue which would have considerable impact on future cases. p 81 Mitchell J The Court of Chancery and Trust - 82 Cozens-Hardy Horne referring to a possible perception of the Inland Revenue at p 5/86 Cozens-Hardy Horne R Modern Methods of minimising Taxation - VI - Discretionary Settlements British Tax Review 95/87 pp 5/86-60 per Evershed MR Ch 18 at p 32 Putting to one side the statutory regime of the Trustee Act 925/8 and the Settled Land Act 925/8 for reasons of space and clarity, there are two key elements to the decision: the tax considerations and discussions of the court's inherent jurisdiction. The judges' position on tax avoidance was undivided: 'it is not an objection to the sanction by the court of any proposed scheme in regard to trust property that its object or effect is or may be to reduce liability for tax'. ibid at p 33 A linguistic analysis of the breadth of this test initially suggests that the court is proposing a wide jurisdiction, with the use of 'or' and 'may be' intended to be inclusive terms. However, Evershed MR also demonstrates concern that an extension of the role of the courts would open the floodgates to future litigation and clarifies that 'it is no part of the functions of Her Majesty's courts to recast settlements from time to time, merely with a view to tax avoidance even if they had the power to do so which, in our opinion, they have not'. ibid at p 66 While tax avoidance schemes may be authorised under the umbrella of compromise, they are not strong enough justification to stand alone and unprotected. Lord Denning provides an insight into the reasoning for allowing tax avoidance, and focuses on the role of the court as protector of infant beneficiaries, not the revenue. per Denning LJ Ch 18 at p 76 The approach taken to the inherent jurisdiction of the courts differs between the judges. Lord Denning offers a dissenting judgement, and reaches a different conclusion in the matter of the Chapman settlement. Evershed MR and Romer LJ were keen to ensure that the regime for variation remained within the existing framework of approval of a compromise. By stating that a general inherent jurisdiction would be inconsistent with the cases of In re New and In re Tollemache, yet allowing the definition of compromise to be broadly construed so a not 'to be confined to compromises of dispute rights, the majority appear to maintain a delicate balance between flexibility and fidelity to the settlors intentions at the time of settlement. Commentators have noted the 'anxiety of the court to avoid any rigid definition of the jurisdiction', and this is evidenced by a general reliance on the principle In re Trenchard. Ch Ch 5/87 per Evershed MR Ch 18 at pp 33 and 39 p 82 Mitchell J The Court of Chancery and Trusts MLR vol 81 - Ch. 78. Denning LJ concludes that the jurisdiction of the court is not limited to cases of compromise. In explaining his decision, Denning LJ has regard for 'the gap between non-legal social fact and the limits of formal precedent-based doctrine'. Ever mindful of the protective role of the court towards the infant beneficiaries, Denning LJ also finds justification in the fact that the settlors 'are ready and anxious to correct the mistake'. Reading Denning LJ's judgement, it appears that the starting point for his decision was a pre-existing conviction that variation should be allowed in these cases. Authorities are introduced to support his conclusion, but throughout the judgement it is clear his reasoning is shaped by the core principles of the Chancery Division, particularly that of equity. per Denning LJ Ch 18 at p 69 p 17 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 p 78 note 1 supra For example see comments at pp 69 and 78, note 1 supra While this essay is primarily concerned with decisions reported in the Chancery Division reports, the contrast between the decision of the Court of Appeal and that of the House of Lords in the case of Chapman v Chapman provides a basis for contextualising the Court of Appeal decision. Although the House of the decision of the majority, their reasoning was founded on a much narrower interpretation of the concept of compromise. Simonds LC, in a judgement which exemplifies his 'restrictive attitude to precedent', refused to extend the court's jurisdiction to 'cases in which there is no real dispute as to rights', ensuring that the court was not required to intervene on the whim of a beneficiary. He justifies his conclusion with an analysis of the role of the Chancery Division, finding that it is to regulate and administer the execution of the trust, not to sanction unnecessary, although potentially beneficial, alterations. This analysis echoes that of Evershed MR in the Court of Appeal, while contradicting Denning LJ, and serves as an example of the difficulties inherent in discerning the guiding principles of the court as a whole. AC 29 p 33 Paterson A The Law Lords MacMillan Press Ltd, London 982 AC 29 at p 45/8 Ibid at p 46 Consideration is also given to the settlor's intentions: 'Chapman v Chapman powerfully reaffirmed the principle of respect for the intention of the settlor as expressed in the terms of the trust instrument'. Combined with the unwillingness to approve variation outside of a compromise situation, the court's attitude appears to be primarily one of fidelity to the trust instrument; they will not be swayed in their decisions by considerations beyond its scope. The judgements of Simonds and Morton LJJ also show deference to the legislature, with Simonds LJ noting that 't is for the legislature.to determine whether there should be a change in the law and what that change should be'. This is an exemplar of substantive formalism as identified by Stevens, something which Denning LJ's argument lacks. The distinction creates the impression that the Court of Appeal decision is comparably more permissive, which in turn leads to ambiguity. While the House of Lords did not concur with the decisions reached with regard to the Downshire and Blackwell settlements, the cases were not appealed, and remain law. p 17 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 Ch 29 at p 44 p 5/80 Stevens R Law and Politics, The House of Lords as a Judicial Body 800 - 976 Carolina Press, Chapel Hill 978. per Lord Morton of Henryton Ch 29 at p 62: 'It follows that, in my view, the majority of the Court of Appeal were right in dismissing this appeal, but their decisions in In re Downshire Settled Estates and In re Blackwell's Settlement Trusts went too far.' Re Gestetner: Tax avoidance as a stimulus for original development While the judges in Re Chapman were limiting a previously presumed jurisdiction with regard to variation, Re Gestetner Settlement was responding to a new and emerging problem: that of uncertainty in discretionary trusts. Grbich argues that 'practitioners were forced by revenue stimuli and the practical necessity of business reality into the flexible realms of discretionary trusts'. The nature of the case in Re Gestetner is synoptic of the legal issues surrounding certainty that emerged post World War Two, and were not satisfactorily resolved until McPhail v Doulton in May 970. Ch 72 p 5/86 Grbich Y Baden: Awakening the Conceptually Moribund Trust 7 MLR 43 - 5/86 AC 24 The case, a summons taken out by the trustees, arose out the payment of monies to one of the charities named in the settlement, and the subsequent refusal of the Chief Inspector of repay the income tax deducted at source. These facts give rise to three fiscal elements to the decision. Firstly, it highlights the problems of uncertainty when the beneficial class is set this wide in order to avoid the payment of estate duty upon the death of a beneficiary; provided the beneficiary's precise share of the settlement remains unknown, it is not liable for tax. Thus, particularly where there is a duty to distribute, the beneficial class is broad so as to ensure that at no point one beneficiary is solely entitled to the settlement. Secondly, the case highlights the possibility for the Inland Revenue to be a party to proceedings, ensuring that policy arguments concerning the fiscal consequences of the case are heard. Finally, there is the effect of the decision for the recipient charity. If the settlement was found to be void, the donation to charity would be a personal one, which 'did not give any right to the charity to recover the tax paid', thus depriving it of additional funds. p 75/8 Ch 72 p 10 Megarry R Notes - 11 p 82 Ch 72 To the financial benefit of the charity in question, Harman J came to the conclusion that the settlement was valid. The test held to be applicable in cases where there is no duty to distribute, but only a duty to consider is what has become known as the given postulant test: for a power to be certain, it must be possible to ascertain whether any given person is or is not an object of the power. As with the judgement of Denning LJ in Re Chapman, it is possible to make the inference that the judge reached a conclusion, sought evidence to support it, and did not search for anything contradictory, 'There being no uncertainty in that sense, I am reluctant to introduce a notion of uncertainty in the other sense'. p 0 Oakley A Parker & Mellows: The Modern Law of Trusts th Edition, Sweet & Maxwell, London 003 p 88 Ch 72 In a judgement which does not acknowledge the implications of the decision on tax avoidance, Harman J is motivated in his decision by consideration of two interrelated factors: the settlor's intentions and the practicalities of effecting the settlement. With regard to the settlor's intentions, Harman J finds justification for not requiring the 'trustee' to survey the whole field in the fact that it 'is a task which was and which must have been known to the settlor to be impossible.'. This is a rational inference to be made: if the settlor himself did not feel inclined to include beneficiaries with enough clarity so that they could be considered, it is unlikely that financial provision for them was his paramount concern. As for the practicalities of distribution, Harman J proffers the conclusion that it is not necessary for the 'trustees' to 'worry their heads to survey the world from China to Peru, when there are perfectly good objects of the class in England'. From this it is possible to conclude that the judge is of the opinion that the settlement was intended to be put into practice, and not to be an abstract conundrum for the trustees. ibid ibid Harman J's concern for the practicalities and clarity of judgement suggests that he intends to facilitate the use of powers. It had been argued that the use of powers was too precarious as any uncertainty would render the whole settlement void, but Megarry suggests that the 'Gestetner Case may go far towards meeting these objections'. However, it would be naive to consider the case in isolation, and the inherent dangers difficulties arise when the decision is considered alongside that in IRC v Broadway Cottages Trust. Although Re Gestetner demonstrates a support of a clear overarching framework as a method of enabling the use of powers, the effect when combined with Broadway Cottages was that each case still required close analysis with regard to its certainty. A crucial difference between a discretionary trust and a mere power was established, such that it was the subtle nuances of the facts of each case that led to the overwhelmingly important determination of the applicable test for certainty. In this respect fidelity to historical precedent from Harman J and Jenkins LJ et al resulted in a perilous situation for those trying to avoid or limit tax in the 95/80s: 'if the certainty of objects requirement was not satisfied, a resulting trust might arise with potentially onerous income tax or estate duty consequences for the settlor'. p 11 Megarry R Notes - 11 Ch 0, p 1 Oakley A Parker & Mellows: The Modern Law of Trusts th Edition, Sweet & Maxwell, London 003 p 1 Oakley A Parker & Mellows: The Modern Law of Trusts th Edition, Sweet & Maxwell, London 003 For example Blight v. Ch.D. 94, and Morice v. Bishop of Ves. 22 p 08 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 Summary of the approach in 95/83In the aftermath of Re Chapman, Re Gestetner and their associated cases, the court's approach appears on the surface to be difficult to reconcile. On one hand the court had limited the possibilities for tax avoidance, by restricting its jurisdiction to sanction variation of the trust instrument, while on the other ensuring that settlements created for tax avoidance purposes were allowed to stand on the basis of a lower threshold for certainty. Unity in the decisions comes from an analysis of their attitude to the intervention of the courts. In Re Chapman it is explicitly stated that the court should not be requested to sanction non-essential amendments to the trust instrument. Intervention is not an express factor in Re Gestetner, but it has been observed that it is the court's inability to intervene so as to effect distribution under a mere power which may have resulted in a more flexible threshold for certainty. In turn, the court's reluctance to intervene reflects and promotes the fidelity to the settlor's intentions expressed in the case. per Evershed MR, Ch 18 at p 66 p 13 Watt G Trusts and Equity nd Edition, Oxford University Press, 005/8 Evolution and ExpansionHaving raised some of the key issues before the court in 95/83, it is now possible to look at the extent of change when compared to 003. In order to contextualise the case law in 003, I first propose to briefly consider the intermediate developments which offer insight into judicial attitudes in this area of trusts law. Threads of development The conclusion to Re Chapman: the Variation of Trusts ActFollowing the decisions relating to the Chapman, Downshire and Blackwell settlements discussed above, the law was in a state of flux. The tension between the Court of Appeal and House of Lords decisions with regard to variation of trusts left the law in unclear, 'and accordingly the question of the extent of the Court's jurisdiction in these cases was. referred to the Law Reform Committee'. In an essay concerned with case law it might appear superfluous to digress into discussions of legislative reform, but as will be explored below, the VTA shaped the nature and scope of discussions in subsequent case law. Much of the commentary surround the VTA has highlighted the shift from the approach in Chapman v Chapman and fidelity to the settlor's intentions to that of the Law Reform Committee which was 'moved by the spirit of equitable property'. The composition of the Law Reform Committee included five judges, and thus there is evidence to suggest that judicial attitudes had begun to change, with greater favour being given to the beneficiaries. p 9 Keeton G Social Change in the Law of Trusts Sir Isaac Pitman & Sons ltd, London, 95/88 Variation of Trusts Act 95/88 see note 9 supra p 4 Harris J Variation of Trusts Sweet & Maxwell, London, 975/8 The debates in the House of Lords provide an insight into evolving judicial values. Viscount Simonds recognised the potential use of the new regime and found the avoidance of tax to be 'an object from which I, for one, do not dissent in any way'. This suggests that his limitative decision in Chapman v Chapman was firmly based on the extent of the jurisdiction of the court, not on the propriety of tax avoidance. He also proposed the inclusion of a clause making express provision that the VTA could be used where its main purpose was 'to avoid the exigibility of tax'. His fear was that judges might 'take different views on the rightness of the scheme whose sole object was to avoid tax'. On the basis that the jurisdiction needed to be flexible and capable of limitation where the variation is of 'questionable character', the clause was not included. Variation of Trusts Bill 10 HL Official 77, 0 June 95/88 Variation of Trusts Bill 10 HL Official 77, 0 June 95/88 p 6 Harris J Variation of Trusts Sweet & Maxwell, London, 975/8, referring to 81-, 0 June 95/88 The VTA as a building block for the consideration of taxPerhaps refreshed by the introduction of the VTA, tax avoidance remained a direct concern for the courts. With the courts ability to sanction tax avoidance agreements confirmed, new questions arose as to the ways in which this should be exercised. In this respect, it is clear that to some extent Viscount Simonds' fears concerning judicial attitudes towards tax avoidance were realised in the case of Re Weston's Settlement. The applicant in the case sought to export a settlement from England to Jersey in order to avoid tax, but was denied his request at first instance and on appeal, instead receiving a sermon from Denning LJ on the correct way to raise children. Ch 23 pp 45/8 - Ch 23: 'Many a child has been ruined by being given too much', 'Children are like trees: they grow stronger with firm roots', 'There are many things in life more worth while than money. One of these things is to be brought up in this our England, which is still 'the envy of less happier lands''. Questions have been raised as to whether Re Weston is 'an undesirable example of judicial paternalism', and in a sense this is the crux of the case: is it a careful reflection on all the possible benefits of variation, into which Denning introduces extra-legal considerations, or is there the emergence of moral consideration, such that the court feels it cannot approve an arrangement which is 'tainted with 'illegitimate tax avoidance''. Commentators have struggled to reach a firm conclusion on the matter. However, evidence adduced to suggest that the court is motivated in its decision by a distaste for tax avoidance helps to bolster claims that the nature of debates surrounding the tax avoidance has mutated since Re Chapman. Stamp J recognises that the court's loyalty does not necessarily lie with the Inland Revenue but suggests that 'there must. be some limit to the devices which this court ought to countenance in order to defeat the fiscal intentions of the legislature', an argument which was not raised when tax avoidance was condoned by the court in Re Chapman. This is echoed by Denning LJ: 'avoidance of tax may be lawful, but it is not yet a virtue' p 33 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 p 21 Harris J Variation of Trusts and Tax Avoidance - 23 A principle also noted in Re Slocock's Will Trusts All ER 5/88 'If a mistake is made in a document legitimately designed to avoid the payment of tax, there is no reason why it should not be corrected. The Crown is in no privileged position qua such a document'. p Ch 23 p Ch 23 McPhail v Doulton: certainty resolvedAs with the legislation pursuant to Re Chapman, subsequent developments following Re Gestetner and Broadway Cottages remedied any resultant fiscal difficulties for beneficiaries. It was noted at the time that Re Gestetner 'breaks entirely new ground on the relationship of powers. and trusts, and. it is probably the forerunner of much new authority of considerable importance'. p Conv 40 - 41 As suggested above, that new authority came in 970 with the case of McPhail v Doulton. Aligning the tests for certainty of powers and discretionary trusts, the case represents a 'triumph of pragmatism over theory'. Overruling Broadway Cottages, Wilberforce LJ examines the role of the court and the way in which it can be called upon to execute the trust. Whereas the decision in Broadway Cottages assumed that the application of the maxim 'equity is equality' would result in equal distribution throughout the beneficial class, Wilberforce LJ turned to the settlor's intentions for guidance: 'qual division is surely the last thing the settlor ever intended: equal division among all may, probably would, produce a result beneficial to none'. While the consequences of the decision represent a 'fundamental change in judicial attitudes', examining the nature and structure of Wilberforce's judgement, it is clear that his reasoning based on the settlor's intentions is not dissimilar to that of Harman J in Re Gestetner. note 6 supra AC 24 p 14 Watt G Trusts and Equity nd Edition, Oxford University Press, 005/8 p 5/81 AC 24 p 3 Oakley A Parker & Mellows: The Modern Law of Trusts th Edition, Sweet & Maxwell, London, 003 See for example p 88 Ch 72 Re Hastings-Bass: the court as administrator and enforcer of trustee discretionIn summarising Re Chapman and Re Gestetner reference was made to the way in which the decisions were partly explained by the judges' opinion that the courts should abstain from intervention. The case of Re Hastings- that intervention is more necessary in cases where a mistake has been made by a trustee in the execution or administration of a settlement. Green notes that at the heart of the principle drawn from the case is 'the existence of the trustee's duty to consider. A breach of the duty to consider is a breach of fiduciary duty, and a platform from which the court may intervene' Ch 5/8 p 16 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 However, this intervention is limited to situations where the trustee has exceeded his powers or erred in making relevant and excluding irrelevant considerations. The outcome of the application of this rule was that estate duty was not payable on the settlor's death, and it was recognised in the case that 'e can feel no doubt that in such circumstances the duty-saving aspect of the scheme was a primary consideration in the minds of the trustees' p 1 Ch 5/8 p 9 Ch 5/8 The appraisal of the effect of the decision will vary according to whose perspective it is considered from. A trustee's perception of the case is likely to be favourable: the rule can be seen to promote practical certainty. It allows trustees to make decisions without fear of constant challenge. It can also generally be considered 'a useful and convenient escape route where trustees make a mistake'. While many would argue that this is to be encouraged, the counterpoint is that the beneficiaries, settlors and trustees will be unable to challenge the decision where it is the consequences of their decision have been misunderstood. In this respect the extent to which the court is prepared to intervene to set aside misguided decisions impacts significantly on decisions which are directed at, or in some cases made in ignorance of, tax avoidance. p 76 Watt G Trusts and Equity nd Edition, Oxford University Press, 005/8, citing Sir Robert Walker Trust Principles in the Pension Context, in Oakley A ed. Trends in Contemporary Trust Law Clarendon Press, Oxford 996 at 29 p 17 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 p 30 Moffat G Trusts Law: Texts and materials th Edition, Cambridge University Press, 005/8 See also p 17 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 where it is noted that 'the real issue is how its application may be restricted to cases on the acceptable side of a presently undrawn line.' 003 and the case of Re Barr: you can teach an old dog new tricksThe changes outlined above demonstrate the cyclical nature of the common law, such that resolution of disparity and confusion in one area is met by the emergence of new problems, each requiring due consideration. In this respect the rule in Hastings-Bass is the springboard into a new area of concern which came to the fore at the turn of the 1 st Century. While the case clearly determines the relationship between the exercise of trustee's discretion and the court's power to intervene, it raises concerns as to the extent to which the principle can be used 'to rescue trustees from the consequences of their tax planning misjudgements'. Park J in Breadner v Granville-Grossman Ch 23 From this background, it was hoped that the case of Re Barr would enable the policy considerations of invalidating trustees' decisions to be examined by the courts. The case arose from a request by the trustees to determine the validity of an appointment, which in their opinion they would not have executed had they made proper considerations according to the principle in Hastings-Bass. Deciding that the appointment was voidable and adjourning the hearing in order that argument could be heard on the matter, Lightman J expressly declined to direct his judgement to the consideration of the consequences of invalidating the trustee's decision for fiscal reasons. Re Barr thus falls short of realising the clarity sought by commentators; it does not enounce the circumstances in which the court might overstep its jurisdiction by declaring an appointment void solely on the basis of its unfavourable fiscal consequences. p 10 Ch 09 para 0, p 16 Ch 09 p 17 - 18 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 However, an in depth analysis of the case does provide insight into the nature and scope of decision making in 003. What follows is a discussion of the key governing principles, and an evaluation of the extent to which they reflect those expressed in and since 95/83. Of particular note is the way in which the case juxtaposes old approaches and new circumstances. The suggestions that Lightman J 'set off on his own path' is highly evocative of the essence of Denning LJ's decisions. The new principle on which Lightman J embarks relies on the extension of the Hastings-Bass principle as stated in Mettoy Pension Trustees Ltd v Evans. Lightman J focuses on the whether the trustee has 'failed to consider what he was under a duty to consider', and in doing so shifts the focus of the test. Green suggests that the requirement of breach of a fiduciary duty to consider creates an 'additional hurdle' and a 'wholly undesirable result', on the basis that relief is available only in respect of the acts of negligent trustees. However, it is possible to argue that this is only detrimental to those seeking to avoid decisions which, although having been carefully considered, have misunderstood the consequences. As such, Lightman J may be asserting a new rule, but clearly founds it on an existing principle: the court's intervention in the exercise of trustee discretion should be limited to what could be seen as worthy cases. In this respect one is reminded of the test established in Chapman v Chapman, where a capricious wish to vary the trust was not sufficient; it was necessary to establish a real and genuine dispute. p 19 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 p WLR 5/887 para 3, p 17 Ch 09 pp 20 - 21 Green B The law relating to trustees' mistakes - where are we now? pp 14 - 28 para 4, p 18 Ch 09, 'the rule does not afford the right to the trustee or any beneficiary to have a decision declared invalid because the trustee's decision was in some way mistaken or has unforeseen and unpalatable consequences' Lightman J also shares Denning LJ's reliance on the protection of beneficiaries as a reason for his decision. He draws on this idea in consideration of the purpose of the Hastings-Bass principle, stating that 'this duty lies at the heart of the rule, which is directed at ensuring for the protection of the beneficiaries under the trusts that they are not prejudiced by any breach of such duty'. In addition to being reminiscent of the dicta of Denning LJ in Re Chapman, it also reflects the concern for equitable property as expressed in the VTA, ensuring that beneficiaries receive that to which they are entitled. part J Limiting Re Hastings-Bass? Conv., May/Jun, pp 08 - 2 para 6, p 15/8 Ch 09 Much attention has been focused on Lightman J's statement that decisions are voidable. He notes the 'need in justice for some regard to the lapse of time in cases such as the present. can only be satisfied if the decision successfully challenged under the rule is voidable and not void'. para 0, p 20 Ch 09 The benefit of this is that, as Lightman J suggests, it allows the court flexibility in dealing with decisions on which the parties may have relied, arranging their affairs on the assumption that the trustees' action was valid. This leaves the potential for the judges to consider the detrimental effect that voiding a decision may have on those beneficiaries who relied on the decision, and the discretion not to overrule it should the circumstances require. However, this flexibility may operate to the detriment of trustees as 'the countervailing consideration in all cases of flexibility is a consequential increase in practical uncertainty as to the validity of such decisions'. The caveat to perpetual uncertainty is that where a decision is merely voidable, 'all the restrictions appropriate to the equitable remedy of rescission would come into play, including delay and the acquisition of third-party rights'. From The Courts Second thoughts by trustees and the Hastings-Bass principle Tr. & Est. 003, 7, - p 85/8 Conaglen M Judicial Review of Trustees' Discretionary Decisions CLJ pp 83 -86 p 30 Walker R The Limits of the Principle in Re Hastings-Bass PCB pp 26 - 40 Summary of 003 The regime as a whole was thus guided by an overarching need to do that which is equitable, an approach which merits comparison with 95/83. To Denning LJ, this would be highly appropriate, although it is unlikely his own judgement would have declined the opportunity to comment on the morality of reversing decisions for tax avoidance consequences. In contrast, if Simonds LJ continued to exhibit the strict interpretation of precedent as highlighted above, it is unlikely that the concept of fiduciary duty would have entered into the judgement. Consequently, the trustee mistakenly understanding the settlor's wishes being insufficient to invoke the principle in Re Hastings-Bass, Simonds LJ is unlikely to have held the decision voidable. See note 6 supra para 5/8, p 18 Ch 09 Conclusion A comparison over fifty years in reference to a few select cases is an insufficient arena in which to examine the subtle nuances of change. What has become evident during discussions is that trusts law continues to embody key principles of judicial intervention, equity and to some extent, morality. Individual judges often take different approaches to these issues, but this is as likely to occur during one decision as it is over a 0 year period. Where attitudes do vary, it is frequently in response to a demand for change from dissatisfied subjects of trusts law. Taken as a whole, the judgements create a rich tapestry of judicial reasoning, where strict adherence to the rules runs alongside fanciful comment and brave expeditions into the unknown.'''",352.0
"'''The multiplicity levels and sectors of English local governanceGovernment and politics operate at a number of levels: making it far from self-contained. 'The new world of local governance is more complex than the old system of local government. The old unequal two-way relationship between central and local government has now been replaced by a more complex multi-layered system of governance.'. Governance is generally taken to comprehend institutions of government: it is essentially about the process rather than institutional structures: Local Governance in Britain, Leach and Percy-Smith 'Governance is the process by which we collectively solve our problems and meet out society's needs. Government is the instrument we use. It reflects the growing complexity and fragmentation of government, which appears increasingly multi-layered'. Local Governance in Britain, Leach and Percy-Smith Local governance increasingly involves multi-agency's working together in partnerships and policy networks, which cut across organisational boundaries. In local governance, elected local authorities are still the most important public bodies and they have the potential to play the leading role. Governance, today, doesn't just include those, who as ministers, civil servants or elected councillors are part of government, it also involves a wide range of organisations, including former state institutions and activities, which have been privatised, central and local government departments but also quasi-autonomous non-governmental British Politics, Coxall, Robins and Leach Local governance is part of a much wider process, which involves a growing interdependence between levels: multi-level governance. Public services have to work with well-networked community groups, often to find they are replaced by them. An example of the different agencies that are involved in a public service could be the provision of local health services/care, which is now the main responsibility of hospital trusts and primary care trusts. Other examples could include local transport and the police service. Even where elected local authorities retain statutory responsibility for a service it may actually be provided by another organisation, such as a voluntary body largely funded by the council, by a private company under contract or by another public agency. Refuse collection, cleaning, ground maintenance, laundry services now provided by private firms under contract although the services are still publicly funded and regulated. In the UK there is a unitary rather than a federal state. Supreme power is not divided: it is concentrated in the hands of the central government, which causes problems as there is no longer direct contact between Central and Local Government and this is responsible for local decline of power. The role of local government is strictly subordinate and its relationship with central government is very unequal. The British state has been eroded by the European it has been continuously increasing, its influence over British policy. This process began in 973 when the United Kingdom joined the EU and as a result of this, decisions taken in Westminster and Whitehall are now controlled and revised by powers located in Brussels, Strasbourg and Luxemburg. Other super-national bodies have an influence also, as well as by the power of global capitalism and devolution, decentralisation and fragmentation, which adds to the levels in governance. Levels of governance InstitutionsInternational United Nations Organisation, World Trade Organisations, World Bank, International Monetary Fund, multinational corporations, international interest groupsEuropean European Union, EU institutions, European interest groups.State United Kingdom, UK institutions, national interest groupsDevolved state Scottish Parliament and Executive, Welsh Assembly and Executive, Northern Ireland Assembly and Executive. Scottish. Welsh and Irish interests.Regional Government Offices for the Regions, Regional Development Agencies, Regional Assemblies, Regional Chambers, regional quangos, regional interests. councils in English two-tier systems, relevant private and voluntary organisations. councils, health authorities, primary care groups, other local public bodies, relevant private and voluntary organisations. or town councils, community councils, neighbourhood councils.Institutional NHS trusts, universities, colleges, school, relevant consumer groups.Table: Levels of changes in internal management'There is no one process of management change as individual organisations and service sectors respond differently to system-wide triggers for change. ' Management change is a non-linear process, involving continuities between old and new approaches, movements forwards and backwards along with change at different levels. Management change has political significance, impacting upon relationships between government and citizens at the local level. Leach and Pacey-Smith believe 'there is need for both horizontal integration of a wider range of local agencies and interests, and a vertical integration of different levels of government.' Local Governance in Britain, Leach and Percy-Smith The English Local Government Act 000 changed the formal management of local democracy in England, the most radical change being directly-elected planning policy sector and English local governancePlanning is unique in the way it operates at all levels government: European, national, regional, county, district and neighbourhood levels. Planning stretches across a range of governmental levels but also non-governmental organisations, as part of governance. The UK planning system is intended to provide guidance, control and incentive in the use and development of land. The current form of national advice for planning, in England, is contained within a series of national planning policy guidance being passed onto the strategic development Control Committee and finally the Local Plan is referred to. If one looks at the recent planning and development that has occurred in Birmingham, it can be seen that one of their planning aims to regenerate and redevelop the inner city. The Mailbox is a prime example of this. The building is that of an old Royal Mail sorting office with one of the cities canals running alongside, which was bought by the local government for redevelopment. The new mixed-use building opened just prior to Christmas 000 and consists of designer shops, restaurants and cafe bars along with two new hotels and luxury apartments. The upper levels also provide office and residential accommodation. This process of redevelopment involved Royal Mail, the local government, British Waterway's, private investors, such as residential and retail owners and developers. The actual transformation by the business involved many businesses, reflecting local governance. In Oxford the Planning Department formulates recommended goals, plans, policies and ordinances that provide orderly growth and development for the city. This department assists the public with matters regarding rezoning, annexation, subdivision of property, and historic preservation. Oxford Prison Site is an example of redevelopment where had taken place, which has involved many actors within local governance and beyond. It is national catering and brewery companies that have been the major actors in this development but also local government as they were owners of some of the land. It is private companies that have been responsible for some of the construction, public sectors have also been involved.'''",356.0
"'''In this essay I will be looking at how the formal properties of Joseph Conrad's Heart of Ford Madox Ford's The Good Soldier give order and articulation to the experience of modern life. The word 'form' implies a structuring of some kind, and, when applied to literature, the formal properties of a work 'usually refer to its structural design and patterning, or sometimes to its style and manner in a wider sense, as distinct from its content.' So what are the structural designs of both Ford and Conrad's works? Baldick, Chris, Oxford Concise Dictionary of Literary outwardly suggest an agreement with realism, 'a mode of writing that gives the impression of recording or 'reflecting' faithfully on actual way of life'. Both texts, however, are far from being conventionally realistic. They are instead innovative, adapting these structural designs to give a stable body to an otherwise complex narrative. How then do Ford and Conrad subvert the structural designs they choose to utilise? Baldick, Chris, Oxford Concise Dictionary of Literary reports the social commentary of the novel in the omniscient third person point of view, '. Marlow is such an unreliable narrator and only too ready to interpret facts in the light of his own prejudices.' Conrad breaks the stereotype of the omniscient narrator that spoon feeds the reader information that is taken for granted as 'truth', Marlow's narration instead '.is essentially reflective' making HOD '.a narrative which works by means of suggestion rather than statement.concerned with asking questions rather than providing answers.' George Eliot, Middlemarch, London: Penguin, 965/8 K.K Ruthven, The Savage God found in: Cox, C.B, & Dyson A. E, (Eds), Casebook Series 'Heart of Darkness, Nostromo and Under Western Eyes, The Macmillan Press Ltd, 981, p.1 Richard Adams, Joseph Conrad 'Heart Of Darkness', Harmondsworth: Penguin Books, 991, p.02 As previously stated, Conrad is generally agreed between critics as a modernist writer. Richard Adams' description of modernist writing is useful, suggesting that, Their technical experimentation was concerned, in the main, with moving away from such traditional nineteenth-century devices as step-by-step exposition and objective realism, and embracing instead the narrative method now generally known as 'stream-of-consciousness'.Richard Adams, Joseph Conrad 'Heart Of Darkness', Harmondsworth: Penguin Books, 991, p.19 Other than T.S. Eliot's The Waste Land, James Joyce's Ulysses is the other 'major landmark' of modernist writing and is a great example of the stream-of-consciousness narrative method. Baldick, Chris, Oxford Concise Dictionary of Literary passage is contemplative, its style is reflective and shows the psychological process of Marlow revisiting previous experiences. Sigmund Freud came up with his theory of psychoanalysis just after Heart of Darkness made its first of Darkness reflects the mood of its era, with upcoming theories such as those of Freud and Darwin, what was once familiar quickly became complex and unfamiliar. Written at the end of the nineteenth century, the daunting fear of entering a new century is reflected in the novella's dark story. David Bradshaw discusses the turmoil of the era in which The Good Soldier was written, an era '.of serious political, industrial, social and cultural unrest in Britain - the suffragettes, for example, had been in full cry - and the novel's predominantly wistful mood reflects Dowell's nostalgia for the era of early-Edwardian high style.'. Richard A. Hood describes The Good Soldier as '.a novel which shares something of the literary world of Conrad and Crane and Henry James, but which points, as well, to the 'tapageur and riotous' new forms of Modernism just emerging'. David Bradshaw, '' to The Good Soldier, found in: Ford Madox Ford, The Good Soldier, Penguin Classics, 002, p.xxxiii Richard Hood, ' Constant Reduction': Modernism and the Narrative Structure in The Good Soldier, Journal of Modern Literature 4. Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.3 The Good Soldier consists of a reflective account by Dowell told in first-person narrative retrospectively, but unlike Heart of Darkness we are never thrown back into the stream of events, as we are, for example, in the narratives of Conrad's Marlow; dramatic scenes are rare, and tend to be told in scattered fragments, as Dowell reverts to them in his thoughts.Samuel Hynes, The Epistemology of TGS, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.3 The effect of this is that Dowell '.tells his story as a puzzled man thinks - not in chronological order, but compulsively, going over the ground in circles, returning to crucial points.what he is looking for is the meaning of his experience'. Samuel Hynes, The Epistemology of TGS, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.3 Richard A. Hood in his critical essay discusses the narrative techniques of Heart of Darkness and The Good Soldier and how they differ from each other. Hood suggests that 'Marlow's narrative is removed from any real experiential The Good Soldier and Heart of Darkness are 'frame-narratives' that contain tales within a tale, what makes Ford's work even more difficult for the reader to decipher is that The Good Soldier is not a story, instead it is an act of narration consisting of Dowell's reflections and modified reflections of other character's reflections. It is no wonder that Mark Schorer in his critical essay compared the novel to '.a hall of mirrors.a bewildering maze, of past circumstances and future consequence that - somewhat falsely - it contains.' Mark Schorer, The Good Soldier - An Interpretation, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.5/8 It is clear from the first sentence in Dowell's account that it is not even his own story that he is telling. 'This is the saddest story I have ever heard' (p.3) is how Dowell begins his tale. Far from being an omniscient narrator, Dowell admits that what follows are reflections on someone else's story. As a first-person narrative, Ford makes it '.possible to eliminate authority altogether, and to devise a narrative which raises uncertainty about the nature of truth and reality to the level of a structural discipline'. Therefore, all the reader has to go by in order to comprehend the narrative is whatever Dowell says, he can therefore choose to omit certain facts and the reader would be none the wiser. Samuel Hynes explains this point well, saying We are entirely restricted to what Dowell perceives, and the order in which we receive his perceptions is the order of his thought; we never know more than he knows about his 'saddest story', and we must accept his contradictions and uncertainties as stages in our own progress toward knowledge.Samuel Hynes, The Epistemology of TGS, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.1 Can the reader gain the truth by trying to decipher and piece together Dowell's fragmented narration? Perhaps Ford is highlighting the futility in gaining 'truth' from a character's narration, especially when Dowell is presenting his version based on other characters' versions. Moser suggests that 'Dowell's chief purpose in telling the tale is not to understand it but to get it out of his head'. Hynes argues that the novel highlights the difficulties with such untrustworthy narration saying, ''How can we know what is true?' is itself what the novel is about.' Peter Brooks similarly says that Heart of Darkness Thomas Moser, Conrad and The Good Soldier, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.1 '.engages the very motive of narrative in its tale of a complexly motivated attempt to recover the story of another within one's own, and to retell both in a context that further complicates relations of actors, tellers, and listeners.'Peter Brooks, Reading for the plot, 992, excerpt found in: Nicholas Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.8-0 At the beginning of part one, chapter two, Dowell struggles to find a suitable way to narrate his story saying, I don't know how it is best to put this thing down - whether it would be better to try and tell the story from the beginning, as if it were a story; or whether to tell it from this distance of time, as it reached me from the lips of Leonora or from those of Edward himself. (p.9)He decides to imagine himself '.for a fortnight or so at one side of the fireplace of a country cottage, with a sympathetic soul opposite me' (p.9). Miriam Bailin suggests that Dowell not only uses the cottage as an enclosing form for his story but, by concerning himself with the formal considerations his chosen setting entails, he also retreats from pain and confusion into the rhetorical shelter it provides.Miriam Bailin, 'An Extraordinarily Safe Castle': Aesthetics as Refuge in The Good Soldier, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.1 The metaphorical cottage gives Dowell a safe, comfortable setting where he can express and articulate his version of the painful story he has heard. The anti-chronological narrative plot in Heart of Darkness has also been described as a shock-absorbing tactic that allows Marlow to articulate an otherwise anarchic tale. Albert J. Guerard suggests that The random movement of the nightmare is also the controlled movement of a poem, in which a quality of feeling may be stated or suggested and only much later justified. But it is justified at last.Albert J. Guerard, The Journey Within, 95/88, found in: Cox, C.B, & Dyson A. E, (Eds), Casebook Series 'Heart of Darkness, Nostromo and Under Western Eyes, The Macmillan Press Ltd, 981, p.7 Conrad uses literary impressionism in Heart of Darkness as an innovative technique to try and capture the essence of the moment during Marlow's reflective process. Conrad was a believer in the impressionist style, discussing the task of the artist he argues that Joseph Conrad, Preface to The Nigger of the 'Narcissus' found in: Abrams, M.H., Greenblatt, S. (eds), The Norton Anthology of English Literature, Seventh edition, nd vol., W.W. Norton & Company, 000, pp.95/84-95/86 All art.appeals primarily to the senses, and the artistic aim when expressing itself in written words must also make its appeal through the senses, if its high desire is to reach the secret spring of responsive emotions. (p.95/85/8) Conrad goes on to say that 'my task which I am trying to achieve is, by the power of the written word to make you hear, to make you feel - it is, before all, to make you see'. An example of literary impressionism in Heart of Darkness is Marlow's description of the tribal attack of the steamboat. Describing the boat being hit by arrows he says Then I had to look at the river mighty quick, because there was a snag in the fairway. Sticks, little sticks, were flying about - thick: they were whizzing before my nose, dropping below me, striking behind me against my pilot-house. We cleared the snag clumsily. Arrows, by Jove! We were being shot at! (p.5/8)Marlow's reflective description here is a great example of how the Impressionist style captures the raw moment. The passage really involves the senses; visually - 'little sticks, flying about'; acoustically - 'whizzing'; physically - 'striking behind me'. Marlow's bewilderment in the chaos is expressed well too, he only visualises 'little sticks' at first, and only after reflection realises the significance of the sticks - that they are arrows and that he is being shot at. Ian Watt clarifies this point well saying, Conrad presented the protagonist's immediate sensations, and thus made the reader aware of the gap between impression and understanding; the delay in bridging the gap enacts the disjunction between the event and the observer's trailing understanding of it.Ian Watt, Conrad in the Nineteenth Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.9-0 Richard Hood, ' Constant Reduction': Modernism and the Narrative Structure in The Good Soldier, Journal of Modern Literature 4. Bailin identifies literary impressionism in this passage saying, 'With its minute attention to perspective, to diversity of colour and to shades of light, the picture he paints is very like an Impressionist canvas'. Miriam Bailin, 'An Extraordinarily Safe Castle': Aesthetics as Refuge in The Good Soldier, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.3 In Marlow and Dowell we have two narrators that pose '.in an exemplary way central questions about the shape and epistemology of narrative'. As Peter Brooks suggests, the reader 'needs to read Heart of Darkness as an act of narration even more than as narrative or as story', the same can be applied to The Good Soldier as well. The elusive nature of Ford described by Rebecca West as a 'scholar gipsy' can be seen in the character of Dowell, '.recognised only as he disappears round the corner'. Both Heart of Darkness and The Good Soldier are far from being 'easy reads', their plots are better compared to as a 'hall of mirrors'. Both authors adopt traditionally realist narrative structures but subvert their traditional function. Ford and Conrad question the uncertainty of truth, the attainment of knowledge, and the futility of narration itself in their complex, non-linear plots. Instead they utilise innovative techniques to more realistically demonstrate the reflective thought process and the act of narration. Dowell's digression and inability to narrate properly act as displacement tactics that blunt the force of the painful events he describes. The dark tales that trouble Dowell and Marlow in Heart of Darkness and The Good Soldier are made stable by being put into formal narrative structures. The Good Soldier adopts a Vorticist outlook described by Robert Greene as '.anarchy, fission and incest within a rigid formal structure'. Since much of the content in Heart of Darkness and The Good Soldier reflects similar events in the biographies of Conrad and Ford, perhaps both authors found they needed a stable formal narrative structure in order to express the turmoil they had experienced. Miriam Bailin thinks this so in the case of Ford, saying Peter Brooks, Reading for the plot, 992, excerpt found in: Nicholas Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.9 Mark Schorer, The Good Soldier - An Interpretation, found in: Cassell, Richard A, (ed) Critical Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.5/8 Robert Green, Ford Madox Ford: Prose and Essays on Ford Madox Ford, Mass.: G.K Hall, 987, p.1 In his critical work Ulysses, Order, and Myth T.S. Eliot compliments Joyce's adaptation of the.83. '''",358.0
"'''The seventeenth century was a time of enormous change, a conflict between the ancient and the modern, as some of the greatest scientific triumphs in history were taking place in opposition to the conservative might of the Church, which fought to suppress many of these innovations. Fear of the Church and more specifically the Inquisition had a great effect on the output of the scientists and philosophers of the day, notwithstanding the fact that Christian teachings represented a deep seated status quo and were thus bound to influence those brought up according to these doctrines. So Newton talks of planets subject to quantifiable physical laws being thrown by the Hand of God and Galileo was publicly condemned by the Inquisition and withdrew his theories of a heliocentric universe, as Bernard Williams states 'To Descartes' contemporaries it seemed much more obvious that God existed. than that natural science was possible'. Rene Descartes was by most accounts a committed Catholic and wrote his philosophy in an attempt to dissuade the Church from hostility to modern ideas. As a result of this his philosophy includes several Christian ideas, including primarily the existence of God but also the immortality of the soul. It is in order to prove the soul's immortality that Descartes wanted to highlight the real distinction between mind and body, a distinction that had plagued and continues to plague generations of philosophers, physicians and psychologists. Some of the cognitive scientists ideas on the subject, especially those who may have influenced Descartes, will be examined before an analysis of Descartes' argument for the real distinction. As with the rest of the Meditations, it is set out in the classical logical manner and while it will be fairly simple to show its validity, it will require a much deeper analysis before one can claim that it is sound. In order to complete this analysis of how the argument works we must examine each of the premises and their origins within the Meditations and then we will look at some of the problems that the final hypothesis raises. Bernard Williams Introductory Essay From Meditations On First Philosophy ed. John some commentators claim this is insincere and an attempt to avoid censure, Descartes responses to Antoine Arnauld, where he argues in defence of his arguments with respect to the Blessed Sacrament, and his letter to Princess Elizabeth in 645/8 regarding her brother's conversion do show a very sincere commitment to the beliefs of Catholicism. The distinction between mind and body is something that had been raised back in the Hellenistic period when Plato described the immortal soul as chariot pulled by two horses, with the chariot driver, Reason Nous, trying to control the uplifting force of Spirit at the same time as the earthbound Appetite. As the Platonic soul was immortal it was thus seen to be of a higher plane than the body. Aristotle saw the being composed of a vegetative part, interested in reproduction, a sensitive part, concerned with perception and the rational soul which was the driving force of the mind, much like Plato's charioteer. The Aristotelian soul was contained in the form of the body rather than being a spirit completely external, though the highest part, because it was concerned with timeless matters such as mathematics and philosophy, could be capable of existence in isolation. This however led to an impersonal immortality which caused problems for Christianity, for although they drew heavily upon Aristotelian ideas this conflicted with their belief that the soul was immortal and personal to each and every human. Thomas Aquinas adjusted Aristotle by saying that the soul, which contained the intellect, was present entire in every part of the body, and unlike anything else it could survive the body and make its way to heaven or hell. It was in this tradition that Descartes was taught and so it was this tradition that he was unhappy with and sought to reformulate. Descartes' main problem seems to have been with the metaphysics of the Aristotelian soul as the form of the body, part of which Christianity rescued only to preserve the idea of immortality, contrary to everything else known, which was completely in contravention of Descartes' scientific notions. Descartes wished to maintain the immortal soul but wished to reached the conclusion in more satisfactory manner. His intentions are set out in the Synopsis, explaining that the discussion of the soul's immortality is to be left to the Sixth Meditation in order that all the premises needed to prove his conclusion are in place, in the manner of a geometer. Descartes continues 'the first and most important prerequisite for knowledge of the immortality of the soul is for us to form a concept of the soul which is as clear as possible and is also quite distinct from every concept of the body'. To arrive at this Descartes works the reader through the argument in the way that one has become accustomed to in the Meditations. The first part of the Sixth Meditation deals with the evidence for the existence of material things through sensory perception. This is done by outlining first the dependence upon sense data that the mind has and how it can all be traced Descartes' body because, as he says 'I could never be separated from it, as I could with other bodies; and I felt all my appetites and emotions in, and on account of this body'. The fact that these sensations come only when the objects are present to his sense organs without dependence upon his will suggested that they arose from other bodies external to his own. The pleasures and pains associated with this body caused various sensations in the mind, so the 'curious tugging in the stomach' caused hunger and so on and these things Descartes concludes were taught by nature as his mind was already made up on them before he had worked out arguments to prove them. This then is the conventional view of a mind and a body connected, with sense data from the body being relayed to the mind. Descartes then retraces the steps he took in the First Meditation that undermined his faith in the senses, firstly the falsehood of sensory data, as with the towers in the distance and the pain in an amputated limb, then the two more general arguments of the dream and the evil previous observation that the perceptions of the senses were not dependant upon his will and thus suggest objects distinct from himself he calls into doubt by saying that it is possible he has 'a faculty not yet known to me which produced them'. This leads him the conclusion that the only indubitable fact any mind can have is that it exists. This level of scepticism set him apart from any previous philosophers, for while the Greek Sceptics had put forward the notion that we should not concern ourselves with matters external to the Self, their definition of the Self had always included the body. Descartes' discovery of logical rather than metaphysical cause for a refinement of the definition of the Self that separated body and soul was thus ground breaking. The distinction between the soul and the mind is somewhat blurred, especially when considering philosophies over such a large time-scale and concerning theology as well more scientific treatise. It is fairly safe to assume that what in the seventeenth century was described as the mind is much the same thing that the Greeks after Plato referred to as the soul. Plato Phaedrus: Plato The Collected Dialogues trans. R. Hackforth ed. Edith Hamilton & Huntington Nichomachean Ethics Both Plato and Aristotle agreed that the ability to reason was unique to humans and set them apart hence the rational part being superior in both cases Aristotle De Anima 07 To the extent that some feel Aristotle was indirectly responsible for a stagnation in thinking, as much of his teaching remained virtually unchallenged and unchanged for over 000 years. Thomas Aquinas Summa Contra Gentiles Bk. II Spare a moment to think of the short and miserable life of the creature who would have to work out the arguments for feeling hungry when the stomach tugs before acting upon it and finding some food This is the position that Descartes had reached midway through the Third Meditation, being able only to know that he is a res cogitans or thinking thing, but now, with the conclusions he has drawn from the Fourth and Fifth Meditations, namely his proofs for the existence of God and the concept of clear and distinct ideas, Descartes has the premises that he talked of in the Synopsis in place and he is able to work on the proof for the immortality of the soul. Descartes has established the existence of God based upon the cogito and the fact that He is capable of creating anything that the res cogitans can clearly and distinctly understand. If it is possible for the res cogitans to clearly and distinctly understand that something is separate from something else then it is possible that they can be separated by God. If it is possible for these two things to exist apart then they must be distinct and as the first three Meditations have described how Descartes has perceived the mind as clear and distinct from all else and that all that he can know is that he is a thinking thing it follows that it is possible for God to create this distinction and if that is so the mind, which has to be a non-extended thinking thing, must be distinct from all else. All else, in this case, refers to body which can be taken to be everything the existence of God and the real distinction now usable premises Descartes continues the Sixth Meditation by reworking his previous argument for the existence of material things based on the independence of their appearance from his will. He says this therefore must be some external active faculty and as God has led Descartes to believe this active faculty is external corporeal things and God is not a deceiver then it follows that corporeal things do in fact exist. This argument relies not only on God's existence but His benevolence further weakening the structure that Descartes has built upon the solid foundation of the cogito. This discussion of the relationship between the mind and corporeal things leads Descartes on to the corporeal thing to which he is closest, his body. Here Descartes seeks to examine the connection that exists between body and mind despite the distinction between them. Again, as Descartes did previous to his scepticism he uses the sensations of hunger and thirst to illustrate the close connection he has with the body, unlike the way 'a sailor is present in a ship', but much closer. Descartes talks of how our nature, which has provided us with these ready made sensations sometimes makes errors, as when a sick man requests food that will make him worse. This leads Descartes to make a very significant change to his model of the human body, because he is unwilling still to believe that God would ever provide something misleading, so he describes the human body as a machine like a clock that will observe the laws of nature whether it is well made and tells the right time or not. This concept of the body as a machine leads Descartes to say that all the movements that the body performs independently of the will would be performed in exactly the same way without the mind. This is hugely significant when considering the mind and body distinction and the human automaton is one of the key ideas of this debate, appearing in the realm of psychology in the work of Burrhus Frederick Skinner that 'The human organism is a machine and, like any other machine. behaves in lawful and predictable ways in response to the external forces that impinge upon it.' Here we should assume that Descartes means physics, the use of nature in these two different senses does cloud the issue somewhat. The analogy of clocks will arise later in the work of the Cartesian students Geulincx and Malebranche. Skinner B.F. Science and Human the errors in the face of God's goodness still concerning him Descartes makes two other observations concerning the mind and body distinction. Firstly, he remarks that while the body is divisible, the mind is not and remains united to the body and loses nothing when a foot or a hand is cut off. The second observation is that the mind is only in contact with the brain and possibly only one small part of the brain, which Descartes hypothesises in his letters is the conarion or pineal gland which was thought only to be present in humans. The action that the mind has upon the body and vice versa through this part of the brain is also subject to a lot of criticism from a number of quarters. In her correspondence with Descartes, Princess Elizabeth Of Bohemia says 'I beseech you, tell me how the soul of man can determine the spirits of the body to produce voluntary actions'. The problem of the interaction between the soul and the body was one of the largest that Descartes was faced with and Princess Elizabeth provided some excellent arguments against the Cartesian hypothesis, as the essential problem was how a cause could be of an essentially different substance to the effect, as the mind is non-extended and the body is extended. Descartes responded with the analogy of gravity, though another response was to say that through the pineal gland, the mind was able to alter the direction of the vital spirits that controlled the body, though only the direction. One of Descartes supporters Geulincx advanced another theory, which was later developed by Malebranche, of two clocks, that keep exactly the same time being the same as the mind and the body. When one reaches the hour the other one strikes, with one appearing to affect the other and in the same way when the thought of raising one's arm enters the mind the body performs it though one is not the result of the other, it only appears to be. This happens because both the mind and the body have been perfectly made together by God. This is paralleled in more modern thought by TH Huxley's concept of epiphenomenalism, which he claimed is a logical extension of the work of Charles Darwin, which claims that all thoughts and intentions are no more than the hum of the human machine, Descartes' concept of the human automaton appearing once more. Another exponent of a similar theory is Richard Dawkins in his book the selfish gene, though this is slightly more removed from Descartes' ideas. Letter to Mersenne, 1 April 641 uvres de Descartes Vol III 62 ed. Adam & answer was seen to be discredited with the discovery of the Law Of The Conservation of Motion which also included conservation of direction meaning that the mind need not start motion it could also change its direction and still be in contravention of the laws of physics. Daniel C. Dennett Conciousness machine: i.e. We are just a collection of atoms subject to physical laws, nothing more, like Descartes' clock By the end of the Meditations Descartes cannot be said to have made a clear incision between the mind and the body, a fact demonstrated by the amount of debate that still continues to this day, but he most certainly laid out many of the tools necessary for the job. Considering the standard of medical knowledge in the time and the pervasion of Christian Scholastic teachings throughout thought of the day. However, Descartes contribution was a major one and his challenge to the total acceptance of Aristotle at the time helped revitalise Western thinking and rightly earned him the title of the father of modern philosophy. The first Meditations that resulted in the phrase 'cogito ergo sum' have been used as the building blocks for almost all work on the subject that followed it and anyone discussing the subject must answer Descartes hypotheses. Though the work of the Sixth Meditation is not regarded as highly as this many of the ideas within it have been further developed, independent of the idea of God and the constraints of the Cartesian Circle and remain part of the current debate. Whatever is thought of the first parts of the final Meditation one cannot help but agree with Descartes' conclusion that 'since the pressure of things to be done does not always allow us to stop and make such a meticulous check, it must be admitted that in this human life we are often liable to make mistakes about particular things, and we must acknowledge the weakness of our nature.' Although Harvey had just made his ground breaking discoveries about circulation, neuroscience today is considerably more advanced. The fact that we can now assign different mental faculties to different parts of the brain casts some doubt on Descartes assertion that the soul is indivisible and also goes a long way to helping us understand the relationship between the body and the mind. However, with all these advances it must be remembered that there are still almost as many unanswered questions in this field today as there were in Descartes time. '''",364.0
"'''The advances in medical technology and therapies in recent years have been rapid and have contributed to the increase in average life expectancy. There has also been an overall drop in mortality and morbidity rates within developed countries. On initial examination of this data, it would seem apparent that this trend is indeed advantageous to us and free of any dilemma. However, with further thought it has been shown that quite simply possessing the means to preserve life does not necessarily offer the patient the best option. It is quite possible now to keep a brain stem dead patient alive for many years. But this is neither beneficial nor humane for the patient concerned. The clinician, in this scenario, is prolonging life just because he has the capacity to and not because it is in the patients' best interests. Ethical arguments have therefore brought into contention the role of the clinician in these scenarios- are they prolonging life or are they prolonging the process of dying? For some people 'life' is seen as intrinsically good and valuable and they feel it should be preserved at all costs. But for some people the quality of life takes precedence when trying to determine its value. Without quality, life loses its value and to preserve life over suffering does not seem worthwhile. As doctors we need to observe this assessment of 'quality' and when important decisions are made concerning life the psychological, spiritual and emotional aspects of a patient's life need to be considered. When administrating medications, it needs to be assessed whether the burden of treatments are unacceptably high for the patient and whether extending life would be in the patients best interest. Furthermore would the treatment offered provide a significant improvement or amelioration of the disease process? When making an informed decision, these questions have to be answered. Recent events such as the 'Diane Pretty' case have shown that these questions are difficult to answer. They have bought to the forefront the argument of euthanasia. The word euthanasia derived from the Greek language means 'good death'. Euthanasia is performed either by undertaking acts that directly bring about death or failing to prevent death. The distinction between these creates two subgroups of euthanasia; the former is classed as active euthanasia and the latter as passive euthanasia. Draper, in 998, defined euthanasia using three key points. He defined it as 'death resulting from the intention of a single person to kill another using the most gentle and easy means possible.motivated solely by the best interest by the person who dies'. Within this definition the motive is set and it is this motive that differentiates euthanasia from murder or manslaughter. In events of 'physician assisted suicide', the patient kills himself/herself using methods provided by the doctor. This is often confused to be euthanasia - but it is imperatively not as in this case the doctor did not do the killing. There are other scenarios where practices that involve ending a patient's life may be classed as euthanasia for example, withdrawing or withholding treatment. If a patient refuses life-prolonging therapy, and their decision is voluntary, informed and made with a competent mind and is free of any doctor coercion, then it is not euthanasia. The doctor in this scenario is not intending to kill the patient but is simply complying with the wishes of the patient. To further clarify, a case for euthanasia must involve intentional killing of another person using gentle means motivated by the best interests of the patient. The Doctrine of Double based upon the deontological view that intentions and not consequences are the important aspect of moral behaviour. For example, a terminally ill patient in severe pain may be given diamorphine to alleviate the pain. The continuing use of diamorphine may as a secondary result induce respiratory failure and cause death. The doctor's intention however was to alleviate pain and he/she made a sound clinical decision to take precedence of suffering over prolonging life. If the doctor was to administer a fatal dose of potassium chloride then his decision would not have been based on pain relief and in this scenario the doctor would be in the wrong. A brief look at the DDE has shown that it is very difficult to assess what was intended and what was a fatal consequence. The DDE may be recognised in legal judgements but it is very difficult to apply in practice. Currently active euthanasia is illegal in the United Kingdom. In December 997, the Lord Chancellor, Lord Irvine of Lairg told the House of Lords 'euthanasia is a deliberate intervention undertaken with the express intention of ending a life.the government is absolutely opposed to euthanasia in any form'. However as previously discussed a doctor may, with correct intentions, administer a large dose of pain relieving drugs to a terminally ill patient in order to suppress the pain whilst having the knowledge that this action may result in death. In the case of R versus Brodkin Adams, the actions of the doctor in promoting comfort through lethal dose of analgesics in a stroke given the verdict of not guilty. The doctor was 'acting in the best interests of this patient.' Thus a doctor is entitled to do all that is necessary to relieve pain and suffering even if the measures undertaken may incidentally shorten life. We have explored the complex nature of euthanasia and we shall now explore the pros and cons associated with it. Elements that favour euthanasia include respect for autonomy. A competent patient has the right to dictate the timing and circumstances of their own death. Moreover a patient had the right to alleviate themselves from any pain and suffering. This right is contained within the Human Rights Act 998. Beneficence and non-maleficence are principles that aim to seek maximum benefit and minimal harm. If a doctor refuses to alleviate a patient's suffering and unbearable pain then he/she is violating his/her primary obligation of beneficence and non-maleficence. Another ethical factor which is in favour of the euthanasia argument is that of justice. It is both ethically and legally accepted for a competent patient receiving treatment whether medical or surgical, to refuse treatment even though this would lead to their premature death. The opposing arguments for euthanasia include: killing is unlawful and unjust in any scenario. Life is an intrinsic value and should be preserved at all times. Doctors have the ultimate goal of avoiding harm and loss of life. Under no circumstances should doctors go against this. The advancement of medicine in this era would suggest a patient's pain and suffering are controllable. For example in the case of administering diamorphine for pain relief; is this the only analgesic available for pain relief? The answer would be a sound no. There are alternative analgesics available that do not hold the lethal side effects. But in argument to this, does a patient really want to be pumped full of drugs in their last moments of life. If euthanasia was to be legalised then there is potential for burdened carers, family members and healthcare professionals to consider it as the first option rather than the last. The illegality of euthanasia protects it from being abused. There is also a possibility of physicians making mistakes. False diagnoses, prognoses, errors in treatment and assessment of pain can easily occur which would generate false candidates for euthanasia. Further, the regulatory processes for legal euthanasia would be too complex. The aspects of abuse of power can also be a problem if euthanasia was legalised. In the case of Harold Shipman it could be argued that he was acting in the best interest of his patients and was quite simply giving them a good, pain free death. This 'license for killing' can be potentially dangerous to introduce into clinical practice. Whether we are for or against euthanasia, one thing is surely true- that the case of euthanasia needs to be discussed openly. Euthanasia occurs all the time. It is often behind closed doors and is done in a 'seedy' and often un-dignifying way. Simply because it is illegal regardless of whether the doctor was acting in the patients best interests, often gives the whole scenario a guilty and immoral feel. When scandals are released into the news and press, the doctor is always shown to have done something wrong. This maybe because the situation was kept quiet or because something 'illegal' was committed. These scenarios can also seem unlawful and wrong when people do not have enough information on the ethics and legality of euthanasia. Open debate can help solve this unawareness and uneasiness involved in euthanasia. Open debate could help illustrate that something that is illegal is not necessarily wrong. As future doctors it is our right to bring these issues into light. We should promote open debate and insist that the GMC and other related bodies give their full backing and support when bringing these issues to parliament. A doctor, in my opinion, is negating his promise of acting in the best of interests of his patients if he/she refuses to discuss these matters. An informed opinion is vital if care of the highest standard is to be delivered.'''",365.0
"'''Before we embark on the foundational basis that grounds political obligation, it is crucial that we adopt a critical analysis of this ideologically loaded notion, examining not only its contextual origins, theoretical nature, justifications for its existence as well as the inherent flaws and limitations in the justifications he posed, establishing whether he grounds political obligation legitimately and sufficiently. According to Hobbes, political obligation is taken to be the absolute obedience to the sovereign in all circumstances except when demands are inimical to one's inalienable right to self-preservation, i.e. 'to do those actions, which the said man or command them to do and to do no action which he or they shall forbid'. Tuck, R. Hobbes Leviathan. Cambridge: Cambridge University Press, p. 5/8 - 7 Political obligations derive themselves from a contractual system that Hobbes envisage, would logically emerge from a state of anarchy. By contracting with each other to enforce commands issued by a non-contracting party against others, they create a situation in which it is generally irrational, given their interests, not to do what the sovereign commands. In essence, 'obey even when there isn't a policeman, because this contributes to peace; only provided that there are enough policemen around to give you more security that you would get in a free-for-all.' Sorrell, T. Hobbes. New York: Routledge & Kegan Paul, p. 0 With the contextual origins established above, the nature of political obligation is as such that it is a voluntary undertaking since 'there being no obligation on any man, which ariseth not from some act of his own; for all men equally, are by nature free.' Obligations are also owned to certain other parties due to the grant of a right to another of which we derive protection from. Lastly, another key characteristic is that Hobbes defines the renouncement or violation of the political obligation to be 'injustice'. When a subject authorizes his sovereign to act on his behalf, the subject is obliged not to withdraw, and is also obliged to 'perform no act incompatible with his authorization of this sovereign' as 'such hindrance is injustice and injury'. Tuck, Hobbes Leviathan. p. 2 Tuck, Hobbes Leviathan. p. 3 With the above, the framework for political obligation is sufficiently structured and we will now examine Hobbes's justifications for its existence. This can be neatly summarized into two arguments, firstly the Consequentialist Argument and secondly, the Procedural Justification reasoning. The Consequentialist Argument is largely outcome-based. It is in our interests to abide by the political obligation for the ends of sovereignty or political society or the sovereign are good ends. Hobbes points out that it is in our interest to being under such an obligation to get out of the state of nature. The state of nature as defined by Hobbes is one where there is perpetual conflict, driven by competition, diffidence and glory. In Hobbes most famous words, Man's life in the state of nature would be but 'solitary, poore, nasty, brutish and short'. Hence, since men's greatest fear is death, our justification to obey is based on the delivery of the government which we expected when we covenanted, i.e. peace and protection from violent death which is provided by the sovereign. This in itself is enough to compel all rational human beings to undertake such an obligation because in violating it, by e.g. deposing the sovereign through resistance, they will be returned back into the undesirable state of nature. Tuck, Hobbes Leviathan. p. 9 Procedural Justification for political obligation, according to Hobbes, is binding because of its logic and rationality. Political obligation is justified because the act of obliging being voluntary, citizens have consented to the transfer of rights willingly. Thus it would be an absurdity to go against the sovereign; resisting the sovereign is tantamount to resisting themselves which makes no sense. Hobbes calls it 'an absurdity to contradict what one maintained in the beginning.to undo that which from the beginning he had voluntarily done'. He emphasizes this again, writing that 'he that complaineth of injury from his Soveraigne, complainth of that whereof he himselfe is Author; and.to do injury to one selfe, is impossible'. Tuck, Hobbes Leviathan. p. 3 Tuck, Hobbes Leviathan. p. 3 In addition, Hobbes's political obligation is grounded in moral terms as well. Political obligation arises from the surrender of a right and is a moral obligation in precisely the same way as obligations to keep a promise freely given. Hobbes morality is then viewed as a kind of long term, enlightened self interest to obey covenants, hence in the course of explaining his political theory, he has also given us a moral theory that he did not intend to. This model of political obligation has come under many criticisms and it is valid to question the justifications Hobbes has laid forth. The contextual grounding of political obligation which is the state of nature as a state of conflict may be inaccurate as throughout history, men has live through conflicts after conflicts and empirical evidence has shown that rational humans have found it to be more beneficial to cooperate than compete, hence giving rise to the introduction of world governance i.e. international institutions like the UN and EU without a world government. Besides, the state of nature is a highly hypothetical circumstance - it is a condition which emerges whenever political authority fails. Hobbes claims that society would fall back into the anarchic state of society as soon as a sovereign ceases to exist; but surely history has disputed that with relatively peaceful transition periods between monarchical successions or implementation of new governments etc. Hampsher-Monk, I. A History of Modern Political Thought. United Kingdom: Blackwell Publishers, p. 6 With regards to the procedural justification he proposes to legitimize political obligation, there are considerable loopholes as well. Procedural justification is based on Hobbes' assumption that Man's greatest fear is that of violent death. In reality, it will be extremely myopic to limit it as such. There have been widely documented cases of self sacrifice i.e. the recent waves of suicide bombings. In addition, the paralyzed or terminally-ill patients fear suffering rather than death. Hence, the fear of death is not as strong a motivator as Hobbes would have us believe and our prudential obligation to abide by the covenant correspondingly decreases as well. Another problem that surfaces with this justification is with its assumption that people are rational and will consent to the covenant because the giving up of one's liberty is preferred to being in the natural state of war. Firstly, people may not be rational; secondly, they may not dread living in the state of nature as much as other fears i.e. intolerable living under a tyrannical dictator etc. Furthermore, he failed to incorporate the element of desire into such obedience; the obligation to obey should not be limited to logical necessity. The obligation to keep a promise is an inter-personal tie, a bond with another person and this makes it distinctive but Hobbes omits this personal, vital factor because of his egoistic account of motives. Since his line of argument derives itself from the basis of self-interests, he neglects the fact that there are duties such as gratitude and forgiveness of injuries which are not solely dependent on self interest but involve the consideration of an inter-personal tie with others, just as the duty of promise keeping does. Raphael, DD. Hobbes: Morals and Politics. Great Britain: Alden Press, p. 0 Kavka also points out that there may dichotomy between theoretical hypothesis and reality. There is no guarantee that decisions made in counterfactual i.e. non actual circumstances will be identical to those made in real life. People may not be appropriately informed and there may be external factors that will lead them to different conclusions. Thus, though people may undertake political obligation in theory, we cannot assume that they will do likewise in reality.Kavka, G.S. Hobbesian Moral and Political Theory. Princeton: Princeton University Press, p. 85/8 In the light of his assumptions, it would be rational for human beings to commit to the political obligation of relinquishing their natural right. However, if these assumptions are proven to be questionable, the first justification stands on shaky grounds. Hobbes' second claim for political obligation has its limitations as well. The most important argument against the consequentialist argument is that the ends of sovereignty are not always good ends. The Hampton criticism states that if the sovereign has the power to issue death penalties then the same fear that was in the state of nature would also exist in the social contract, hence in practice, humans will never leave the state of nature. Moreover, Hobbes fear of anarchy and conception of the state of nature caused him to downplay the weaknesses of absolutism. Locke was a major critic of this as he was later to comment, 'This is to think that men are so foolish as that they take care to avoid what mischiefs may be done them by pole cats or foxes, but are content, nay think it safely, to be devoured by lions.' In the light of tyrannical regimes with Hitler, Pol Pot and Stalin, a despotic authoritarian sovereign may not be a legitimate or desired result. Locke, 947, p. 6 To conclude, if we agree to all the premises and assumptions that Hobbes proposes, i.e. that Man is rational, that the state of nature is one of perpetual conflict and that Man's greatest fear is that of returning to the state of nature which threatens violent death, his first claim that political obligation is justified because it is in human beings' interest to do so may be accepted. However, Hobbes himself indirectly admits that political obligation is not perfectly justified by conceding that the citizens would be obedient only due to force and not due to recognition of the obligation. Thus If Hobbes had successfully justified political obligation, he would expect citizens to automatically be compliant to the sovereign's will without need for policing. The very fact that Hobbes saw the need of compulsion to ensure subservience shows that the theory of political obligation is not perfectly justified. Therefore, the Hobbesian notion of political obligation stands on shaky grounds and he has only justified political obligation to a small extent, albeit on his own terms and whether his arguments are successful or not depends on the extent we agree to his initial premises and assumptions.'''",379.0
"'''The primary route of transmission of hospital-acquired infection is the hands of health professionals; however compliance with hand decontamination is low. This study proposes to examine midwives' experience of hand hygiene and their attitudes towards and compliance with clinical guidelines. The design is a qualitative study using semi-structured interviews and the methodology is phenomenology. The research will take place in the postnatal ward of the local Women's Centre. The target population are midwives working on the postnatal ward. The sampling method proposed is purposive sampling and the intended sample size is 5/8. The data will be collected via semi-structured interviews, which will be transcribed. The data analysis method to be used is Colaizzi's phenomenological interpretation. Informed consent will be obtained from respondents and anonymity and confidentiality will be maintained at all times. / BACKGROUNDHospital acquired infection is one of the primary causes of morbidity and mortality in peer reviewing. Peer reviewing is a strategy that can be used to affirm emerging interpretations. In this approach the investigator purposely involves peers in the analytical process to review the findings (Depoy & Gitlin 998). ETHICAL CONSIDERATIONSINFORMED CONSENTAt the start of the research each participant will be provided with a participant information sheet giving accurate, clear and detailed information on the study process and the demands of their involvement. The letter will include a consent form that they will be invited to sign. Informed consent will be obtained from participants at least 4 hours prior to the interview to give them time to consider the study and decide to withdraw if they choose to. The letter will emphasize that participants have the right to choose not to take part, that they may terminate their involvement at any stage without giving reason and that they are encouraged to ask questions about the process at any point (Robinson 000). ANONYMITY AND CONFIDENTIALITYTo protect anonymity each interviewee will be allocated a number at the start of the research process and all notes, tape recordings and transcripts would be labelled with the relevant number. All data obtained from the study will be stored in a secure place accessible only by the researcher. Privacy and confidentiality will be maintained throughout the process and in the writing up of results and any publication that follows so that no identifying details are exposed (Carlisle 994). Details of the site of research will also be kept confidential.'''",381.0
"'''Relationships between unemployment and wages have long been argued about. The Shapiro-Stiglitz shirking model is an example of efficiency wage theory, where the employer pays above the Walrasian market clearing rate. It is based on many assumptions about the labour market and I will be examining each assumption and each variable, particularly unemployment levels which affect the wage rate offered in this model. I will show how the model establishes an equilibrium and also at what empirical evidence there is to support to support it. The Early Classical economists believed that in market equilibrium, unemployment did not exist and that the markets cleared. If unemployment did exist, it was purely voluntary and caused by wage rigidities. Another theory of unemployment suggested is one of efficiency wages which offers an explanation of involuntary unemployment, even at equilibrium. The ShapiroStiglitz shirking model is one such a example. In essence, it suggests that workers dislike their work and would, if they could, not do their work. The model then establishes why firms choose to pay above the market clearing Walrasian equilibrium. The shirking model is founded upon many assumptions, of which the first one is that workers dislike their work and if the firm was completely unable to monitor their work, they would choose not to do it. The second assumption is that workers either shirk, or they work at effort level the smaller the loss of workers utility is of being dismissed. Therefore they have less to lose if they are caught shirking and are more likely to do so which requires a rise in wages to prevent it. Indeed if w = w then, according to this model, workers would shirk as their utility would be lower if they worked and would therefore rather be unemployed. However, I believe this is one of the limitations of the model. Studies conducted by Andrew Oswald and other economists have found that unemployment is a source of great unhappiness and this model does not account for any psychological effects of unemployment on individuals. In view of this, without detailed research, it is not possible to say whether workers' would truly rather be unemployed or employed at w = w. The second element affecting VU is the job acquisition rate. This is calculated by the number of people entering unemployment, divided by the number of people leaving unemployment. where N=number of firms, L=the number of workers per firm, L is the number of workers currently unemployed. One of the key assumptions made by this model and which is relevant to this factor is that all workers are identical. Thus, if a worker is dismissed for shirking, a firm is unable to distinguish that worker from an honest worker and has the same probability of being reemployed as an honest worker does. If the job acquisition rate is, this means that every unemployed person can find another job immediately. This also means that the cost to the worker of being dismissed is zero and hence, workers will shirk. In my opinion, I think that the assumption of identical workers is less valid in the present day than it was in 984 when Stiglitz and Shapiro proposed this model. I think this is due to better information networks which means that almost without exception, a reference from a previous employer is required to get a new job and this casts doubt on the possibility that perennial shirkers are treated in the same way as honest workers. In this model though, the higher the value of a, the higher the wage rate will be. Finally, the higher the rate of interest, the higher the critical wage becomes. This is because the gains made in the short run from shirking will accrue interest and will have greater weight than the losses which eventually happen due to shirking when the person is caught. I have analysed what factors affect the critical wage, but I haven't established an equilibrium wage level. I start from the basis that all firms are paying the same wage and there is zero unemployment and wages equal unemployment benefits. Shirking is commonplace as there is nothing to be gained from, the no shirking wage would be If employment grew, then the worker would have more incentive to shirk as the expected loss in utility of being dismissed would be, then you could allow q to change, the probability of being caught. The change in q would have to be the same amount as the change in OaO in percentage terms. If OaO decreased (representing an increase in unemployment), then ceteris paribus, q would have to decrease to maintain that wage. The probability of being caught shirking is directly related to the level of monitoring there is in the firm. If the probability of being caught falls, then this would be associated with a fall in expenditure on monitoring. After analysing in some detail the theory behind the shirking model, we can briefly compare it with the empirical evidence. In a second article by Shapiro and Stiglitz, they suggested that firms did not always dismiss workers which were caught shirking and this undermines a fundamental assumption of the model. But since the theory was proposed, many economists have attempted to try and establish an empirical link. A study that I found particularly interesting was the one conducted by Krueger in titled 'Ownership's, agency, and wages: An examination of franchising in the fast food industry.' The conclusions that he came to were that in individual outlets that were franchised, full time employees were paid between and % less compared to those who worked in a company-owned outlet. At managerial level this gap increased to between and %. The reasons which Krueger put forward for these pay gaps was that monitoring workers' effort in a company owned outlet is much harder. In a franchised outlet, the managers are able to monitor their workers' effort more easily. But Luxenberg in his book suggests that the cost of shirking to the company by a full time employee is comparatively small as there is little opportunity for him/her to significantly damage the company. Hence, this is cited as a reason for the small pay gap between full-time employees. However, the reason for the large pay gap amongst managers is that in these relatively skilled jobs there is the opportunity to significantly damage the company and that the shirking is a lot harder to detect so due to the NSC, an increase in wages is required. Generally, most studies have found evidence to support the shirking model but it is still not possible to say what the magnitude of the effect is. In conclusion this model attempts to define accurately the situations where workers will choose to shirk and has provoked a lot of thought. It shows that the firm must pay a higher wage to prevent shirking and concludes by saying that an equilibrium may exist with wages higher than the natural market clearing rate and at this equilibrium, involuntary unemployment does exist. But this model is founded upon many assumptions about firms and workers and these do not always hold in real-life markets. Many extensions have been made to the model such as one by Bulow and Summers which considered the possibilities of perfect monitoring but overall the model has certainly added a new perspective to the workings of the labour market.'''",383.0
"''' Pneumatics is about the study of the mechanical properties of air and other gases. During the laboratory, we need to create and test pneumatic circuits to meet the requirements of the exercises. This report includes the pneumatic diagrams obtained during the laboratory and how pneumatic link with real-life application in an automated device. Also, advantages and disadvantages of using pneumatics instead of electrical actuators as well as the importance of the air quality supplied to the system will be discussed. Apparatus and MethodsApparatus:A compressed air supply.'Pneumate' Basic Pneumatic Trainer 'assembly panel' supplied by SMC. It contains the following components:Filter Regulator with GaugePiping Module with Check Valves3/ Single Air Pilot x 5/8/ Double Air Pilot x 3/ Manual Push Button Valves x 3/ Twist Selector Valve x Pneumatic AND Function x Pneumatic OR Function x 3/ Pneumatic Cylinder Limit Switches x Block Mounted Pressure Gauges with Check Valves x Inline Flow Controls x Double Acting Cylinders with Port Mounted Flow Controls x Single Acting Cylinder x PipeFittingsMethods:Make sure the compressed air supply is connected to the Filter Regulator on the trainer board. Adjust the pressure gauge to about to bar or. to.Mpa. Connect the Filter Regulator output to switch OV1 with a short length of that when a pushed the cylinder extends and when the button is released the cylinder retracts to its starting position. Phase diagram is as follows: This is the design of pneumatic circuit that fulfil the specification: We observe that the rate of retracts is faster than that of extends. The phase diagram is the same as the given one. Exercise: Pneumatic actuation of a door using a double acting cylinderThis is to create a system that represents using a double acting cylinder to open and close a sliding door. The cylinder should button pressed and button pressed. If pressed together nothing should happen. Assemble and Phase diagram are as follows: This is the design of pneumatic circuit that fulfil the specification: When M1 is pressed, the air flow to the cylinder at one the other allowed to exhaust, therefore the cylinder extends. When M2 is pressed, the air flow in at side Y while exhaust at side X, so it retracts. When both button are pressed, air flow in at both side resulted that nothing happen. The phase diagram matches the given one. Exercise: Control of a double acting cylinder from two independentlocations. A double acting extend when either of push- pressed or both pressed at the same time. When both buttons are released the cylinder will retract. Phase diagram is as follows: This is the design of pneumatic circuit that fulfil the specification: (What are the Boolean logic equations for A+ and A-?) Exercise: Pneumatic Press with safety a machine that uses a pneumatic double acting cylinder to press part into a die, e.g. sheet metal into car body panels. To ensure the machine operator is away from the danger must press two for the cylinder to extend. A third used to retract the cylinder. This is the design of pneumatic circuit that fulfil the specification: (what are the Boolean logic equations for A+ and A-?) Exercise: Stamper with a parts feeder and ejection mechanismA push used to control the feeding of parts into the stamper by a retraction of the cylinders. A third switch the eject mechanise or third extend when on and retract when switched off. A phase diagram of the proposed operation is given below. However, limitations on time and equipment may mean that some alterations and variations may have to be implemented. Therefore the extent of operation must be recorded and reported in the lab write up. This is the design of pneumatic circuit that fulfil the specification: When M1 is pressed, cylinder A is extending. After cylinder A fully extended, cylinder B starts to extended. When M2 is pressed, it causes retraction of cylinder A and B. When M3 is pressed, cylinder C ejects.Then it retracts when M3 is released. We didn't get the same phase diagram as given one. There was a time delay for the retraction of cylinder B. The phase diagram that we got is as follows: Advantage and disadvantages of using pneumatics instead of electrical actuatorsAdvantage:Pneumatics drives are easy to configure in potentially explosive area. For its entire service life, it is maintenance- free and it is suitable for continuous closed-loop operation. Moreover, it does not need any control or monitoring functions. Compare with electrical drives, it cost less and it can produce a higher attainable speeds. Disadvantage:Pneumatic systems depend so much on the properties of the pressurised media. Require a continuous and ample supply of clean and compressed air. It cannot generate constant torque and it needs energy supply continuously.. Moreover, the ability to control the system produce the required often inexact and tedious. For pneumatic systems, a continuous and ample supply of clean, compressed air is required Electric: torque is capable of being kept constant, a unique torque and speed combination that is not available with pneumatic systems. Attainable speeds are not as high as speeds produced by pneumatic systems'''",385.0
"'''FACTS:Mr. & Mrs. Hurst purchased their matrimonial home in 984, registered in their joint names and holding it as tenants in common under a constructive trust. They both signed the document, which recorded that a survivor could give a good receipt of moneys on purchase. No express declaration was made as regards the share of each person. The money for the purchase came partly from the sale of the old property jointly held by them, contribution from Mrs. Hurst's father and a mortgage in the name of Mr. & Mrs. Hurst, secured on the property. A question that arose was whether the money given by Mrs. Hurst's father was intended only for Mrs. Hurst or to both of them. But the registrar, on evidence found that it was intended only for Mrs. Hurst. Mr. Hurst, a solicitor was made bankrupt. He had provided information to his former partners that he had a 0% share in the property. And later, in a letter to his solicitor he claimed that he had erred and that he held a part of the 0% of his share on trust for his wife. In 001 Mrs. Hurst made a written statement, i.e., an Individual Voluntary that Mr. & Mrs. Hurst shared the property on a 0/0 basis beneficially. But the IVA failed. Mr. Supperstone, trustee in bankruptcy of Mr. Hurst brought proceedings for the possession and sale of property on an equal basis. However, now Mr. Hurst argues that he is entitled to only a 5/8% share whereas Mrs. Hurst is entitled to an 5/8% beneficial share. They claimed under a resulting trust. The issue before the court is to quantify their respective shares. DECISION:Dismissing the appeal, the court Held- Mr. & Mrs. Hurst was entitled to a 0% share. In identifying the share recourse is to be had to the actual or assumed common intention at the time of purchase rather than at any later date. But recourse may be had to a conduct at a later date, which may be treated as showing what the intention at the date of purchase had been. An additional relevant question that lies between the conclusion that the parties had an actual or presumed intention to share the beneficial ownership and the quantification of the respective shares is whether they should have imputed to them an intention to own as beneficial joint tenants as opposed to tenants in common. But the issue of quantification of shares arises only under a tenancy in common because joint tenants cannot hold in unequal shares; if the tenancy were severed they would share equally. The too ready assumption of tenancy in common in cases of matrimonial homes begs an important prior question since joint tenancy is neither unjust nor inappropriate in cases of this nature. The statements in the IVA did not give rise to a trust; they were mere statements made to the husband's creditors of the wife's willingness to co - operate for the sale of property and realisation of the husband's interest for the creditor's benefit. In the absence of any actual or presumed intention, the court looks into the parties conduct both at the time of purchase of the property and subsequent to it and determines a share, which is fair and reasonable according to the situation. It is wrong to infer an intention, which the parties never intended. It would be unreal to suppose that both the spouses had the same intention at the date of purchase without any discussion to that effect. The learned registrar in his decision used the IVA as a compelling factor in determining a fair share. It would be wrong for Mrs. Hurst to claim a share greater than 0% since she had stated in the agreement to the creditors that her husband and she had equal beneficial interest. The underlying legal principle in deciding the case was the application of the fairness test whereby the parties' conduct have to be taken to decide the outcome in a way not to cause any detriment to the party claiming from the property. The parties' intention at the time of, or subsequent to the purchase has to be taken into account to determine the size of the beneficial interest. COMMENT:This case mainly deals with the doctrine of constructive trusts. Although the wife's contribution was more than the husband's, the registrar reached the conclusion that they intended to share the beneficial interest equally under constructive trust instead of unequal shares under a resulting trust. The case is set out to determine the shares of the parties and bring about an outcome desirable on the novel concept of fairness. In a resulting trust, no such thing can be used because the one and only factor that determines the shares is contribution to the purchase price. But under a constructive trust the court gives due consideration to the parties' intentions. CONSTRUCTIVE TRUSTUnder constructive trusts the parties' intention is given importance. The statute requires a written statement expressing the parties' intention for a constructive trust. As per the learned registrar the written statement in the IVA may satisfy this requirement. Section 005/8 No. 189 @ pg 248 Then comes the most important issue of quantification of the shares in the property. There is a difference between the declaration of trust and the determination of the amount of beneficial interest. If the parties owned as joint tenants then there is no question of determination of shares, since if there were a division then the parties would hold equally. It is only in cases of tenancies in common does the issue of quantification arise. That the parties in the present case were tenants in common was never disputed. The size of the parties' shares can be determined by following the authorities in Midland Bank plc v Cooke and Oxley v Hiscock which lays down that while determining the shares, the court has to take into account 'the whole course of dealing between the parties relevant to their ownership and occupation of the property'. In Midland Bank the court said it could take into account post - acquisition dealings to determine shares under a constructive trust. This would include any statement expressing the parties' intention to share the property in a particular manner. In the present case the IVA made by the parties is very persuasive because when Mrs. Hurst signed the agreement, it gives rise to an intention that, she understood the nature of the agreement and was willing to perform the same. Hence the parties' claim that since the IVA was unsuccessful the court should completely ignore it is not too convincing. Nevertheless it has to be noted that this is not the only evidence that the court took into consideration. But it would be wrong and an unnecessary fiction to impute to the parties an intention they never had. A statement made 7 1/2 years later, in 001 does not give rise to an intention that parties intended the same at the time of purchase. All ER 62 EWCA Civ 46 Ibid. 'The Ebb and Flow of Trusts and Estoppel' 004, Issue @ pg. 40. Chadwick LJ in Oxley v Hiscock EWCA Civ 5/86 I am under the impression that Mr. & Mrs. Hurst was not sure what exactly they wanted. If they indeed wanted to share the property in the ratio of 5/8/5/8, why then did Mr. Hurst give evidence that the money given by his father - in - law was intended for the couple and not to Mrs. Hurst alone? Should that be the case, the contribution of Mr. & Mrs. Hurst would be more or less equal and their claim for an 5/8/5/8 share would fail. This seems somewhat contradictory. I think these statements may also be reflective of their intention to share property equally. Also Mr. Hurst had written to his former partners that his assets included a 0% share in the net equity of the property. Denying this, he later wrote to his solicitor saying the letter was written in haste. As the registrar said Mr. Hurst was 'a man who was willing to say what best suited his case at that time'. Hurst v Supperstone EWHC 309 Para 1 While it was common ground that the couple were tenants in common, during the transfer of the property in their joint names they signed a deed, which gave the survivor a good receipt of capital monies on purchase. This is the principle of beneficial joint tenancy. But this issue was never addressed. If it was indeed a joint tenancy then their share would have been equal and there would be no issue of quantification. FAIRNESS PRINCIPLEThe deputy judge came to the conclusion that the parties held beneficial interest in equal shares after analysing all the evidence of what would be fair and reasonable to the parties. The judge, at the end of the decision says had it not been the trustee who had brought the claim he might have thought that a 0/0 share would have been unjust to the wife. There is, in a way a detrimental reliance on the part of the creditors, which may also give rise to a presumption of constructive trust. The wife made a written declaration in the form of the IVA, drawn for the benefit of the creditors. Now when the issue is before the court she is claiming a greater share than that claimed under the IVA, its failure coming as an excuse to avoid her obligation to the creditors. So the court applied the principle of fairness, i.e., what would be fair to the claimant under the circumstances. Under Section 35/8A of the Insolvency Act 986, the court has to make an order in the best interest of the bankrupt's creditors, especially when the property has been the former residence of the bankrupt and consider the conduct of bankrupt's spouse. The fairness principle was drawn from the case of Oxley v Hiscock, where the Court of Appeal reversed the judgement that the couple held an equal share under a constructive trust because it was unfair to the person who contributed more to the purchase price and attributed a resulting trust. EWCA Civ 46 In Densham, Re, it was held, had the trustee in bankruptcy not been involved in the proceedings the wife would have had a half share in the property, rather than the one-ninth share. WLR 5/819, extracted from 'Constructive trusts, Estoppel and the Family Home' Thompson, M.P, 004 Conv 96, Westlaw UK. This is the main principle of the case and the whole outcome was decided on what was fair according to the facts of the case, taking into account the whole course of dealings between the parties. The court cannot rely upon only the financial contribution to determine the shares. CONCLUSION:In conclusion I would like to say that I agree with the outcome of the case. It was only fair that the creditors did not lose out their interest because of Mrs. Hurst's greed in claiming a greater share than she intended to and was willing to give. The IVA, though not a conclusive proof of their intention to share the beneficial interest equally, was nevertheless a persuasive document. And the parties' conduct in general was proof of this. The case, in effect is similar to the cases decided previously on the issue of constructive trusts and the deputy judge, for the most part relied on the Court of Appeal decision in Oxley v Hiscock in reaching the decision. The 'fairness principle' was applied very aptly in deciding the case. The deputy judge complemented the legal doctrines of constructive trusts and tenancies in common with the equitable principle of 'Fairness', which in my view is very important. On a consideration of the facts, this case is different since almost all the cases that have come before the court till now have been cases of matrimonial home where the cohabitees claim interest on the breakdown of the relationship. In that sense the case may set a precedent if the House of Lords decides a similar issue in the future. The deputy judge applied the same law applied in the other cases of determining the interest although the legal title is owned jointly, saying there is no real difference in the underlying legal analysis due to this. On the whole the case has brought about a desired result. And has been fair to the claimant, who would have otherwise been the weaker party.'''",391.0
"'''The aim of this experiment is to determine the total samples of vinegar in order to find out if they come up to quality i.e. Vinegar.5/8ml of.48M NaOH was used. of CH3COOH in 5/8ml sample But this was a diluted.e. x4 Therefore %w/w in initial vinegar sample Vinegar.5/8ml of.48M NaOH was used Vinegar.5/8ml of.48M NaOH was used DiscussionThere is a large difference in acidity between the weakest and strongest samples of the burette has an error of. ml. So the final titre would yield an error of: Vinegar: Vinegar: Vinegar: These results would impact the values calculated for total acidity. The larger the titre volume, the smaller the error in the final reading. Using a relatively large amount of indicator could also have affected the results by diluting the vinegar sample or affecting the intensity of the colour change and the ability to judge the endpoint. If the vinegar were more strongly coloured the end-point could be determined by using a more brightly coloured indicator, a more dilute sample of vinegar or by using a pH probe in the solution..'''",393.0
"'''Strain gauges can be used to measure the force that is applied to a cantilever beam. When a force is applied to the beam it causes the strain gauges that are attached to the beam to under go either compressive or tensile forces. A suitable measurement system is designed to measure the applied force on a steel cantilever beam. The resistance within the strain gauges changes and this variation can be measured by a Wheatstone deflection bridge. An amplifier can be designed, based on a 41 operational amplifier, in a non-inverting amplifier configuration. It is beneficial to use a non-inverting amplifier as the input impedance is higher than that for an inverting amplifier so the amount of noise associated with the circuit is reduced. The amount of noise can be further reduced by the addition of a low-pass filter within the circuit. It is found that there is a linear relationship between the applied force, F, and the output voltage, V o; as applied force increases so does the output voltage of the source. A regression line added to the data plot and shows that relationship:. The Labview computer programme is utilised to change the data from analogue to digital where the dynamic characteristics of the cantilever system can be invstigated.Strain gauges can be used to measure the force that is applied to a cantilever beam. When a force is applied to the beam it causes the strain gauges that are attached to the beam to under go either compressive or tensile forces. The resistance within the strain gauges changes and this variation can be measured by a Wheatstone deflection bridge. It is possible to design and build a beam-type instrument to measure the force acting on a cantilever beam. A ready-made cantilever with two strain gauges attached called an Analogue Experimental Transducer provides an ideal basis for the design to be based upon. A suitable measurement system is designed to measure the applied force on a steel cantilever beam. The system incorporates an operational amplifier and low pass filter to ensure that the optimum results are gathered. Cantilever and Strain Gauge PropertiesThe geometrical dimensions of the steel cantilever can be ascertained by measuring the strain gauge and cantilever with a rule. Length of the cantilever, Distance of strain gauges from fixed end of cantilever, Thickness of cantilever, Width of cantilever, The strain produced at the strain gauges if a force is applied to the cantilever can be written in terms of the force, F. EQUATION EQUATION Within this mechanical system two strain gauges are used, when a force is applied the cantilever beam bends. The strain gauge on the top surface of the cantilever is placed under a tensile strain, whereas the strain gauge on the bottom is placed under a compressive strain. With two active gauges used in this mechanical system the sensitivity is doubled from that of a single gauge. The range of this force sensor will depend on several factors; shape of the beam cross- of elasticity of the beam point of forceFatigue strength of beam calculations two assumptions are made; it is assumed that the gauges are situated at or near the beam supports and the maximum moment acts upon them. It is known that the Young's modulus for the cantilever beam is 10GPa and the fatigue strength of the beam is 40MPa. Using equation, it is possible to calculate the strain that will be present in the stain gauge when the maximum loading force is applied. EQUATION Equation then enables the maximum loading force, F, allowed for this system to be calculated. Wheatstone Bridge DesignA Wheatstone bridge circuit is used to convert the change in resistance of the strain gauges to a voltage signal. In this design two identical strain gauges will be use to measure the strain in the steel cantilever when a loading force is applied. The two gauges have a nominal gauge resistance of k, gauge factor G =. and a thermal induced change strain/C. Within the bridge circuit the power is supplied by a V battery. Diagram, Appendix A shows the bridge circuit that is used within the force measurement sensor. When the output voltage, V the system is zero the bridge is balanced. At the time the bridge is balanced it is a lot easier to measure any small changes in the voltage,. Figure below shows the Wheatstone Bridge circuit, where, in this case the R and R are provided by the strain gauges. From the circuit diagram it is feasible to treat the top and bottom parts of the bridge as individual voltage dividers giving; The output voltage of the circuit is measured cross the terminals B and D so it is possible to calculate the total output of the circuit, V O. Therefore: EQUATION Equation four is able to be re-written in the form: In this case the resistances of the strain gauges have a nominal resistance of k and the two other resistors within the bridge circuit also have resistances of k. As all the resistors and strain gauges within the circuit have identical resistances. The initial output voltage will be zero when R R =R R, in this case the circuit will be balanced when all the resistances within the circuit as equal. There will although be variations in practice between the two strain gauges and therefore the resistances will be slightly different, but the assumption is made that they are identical to aid analysing the circuit. There will be resistances present in the wires, which will affect the balance condition. The bridge output is related to the relative resistance change of the strain gauges. When a load is applied to the cantilever its causes the resistances in the strain gauges to change. The strain gauge, gauge, on the top of the cantilever beam is put under a tensile strain so the resistance within it will increase. The strain gauge, gauge, on the bottom of the cantilever beam is put under a compressive strain so the resistance within it will decrease. With the change in resistances of the two strain gauges a change in the voltage output is produced. Equation can be re-written as shown in equation EQUATION Since all the Resistances are of equal magnitude R =R =R =R =R equation can be written as follows: EQUATION Equation shows the relationship between the change in the bridge output voltage and the change in the resistance when the cantilever has an applied force acted on it. Amplifier DesignAn amplifier is used to provide an appropriate voltage level which can be measured and in this case a 41 operational amplifier is utilised. The amplifier can be used as either an inverting or non-inverting amplifier. In this application it is appropriate to use a non-inverting amplifier as it has higher input impedance which reduces the amount of noise in the circuit. The amplifier is designed to have a gain of 001 which is provided by having resistors with values of R =00k and R =00. With such a high gain used in this circuit there is significant noise present. The noise is also created by electromagnetic interference, for example, 0Hz noise as there is no screening protection present in the circuit. Low-pass filter design To overcome the problem of noise within the circuit a simple low pass filter is used, by connecting a capacitor across the feedback resistor. Figure shows the low-pass filter. It is required that the circuit have a time constant of. seconds. An appropriate capacitor is chosen to be connected in parallel with the 00k feedback capacitor. Force Sensor System TestThe system requires that it is zeroed before the force sensor system test is completed; this is accomplished by adjusting the balance potentiometer to zero when there is no load applied to the system. In addition when the test is completed all forces are removed from the system and it is checked that the output voltage returns to zero. Table shows the results of the addition of washers to the cantilever beam. The washers in this instance are used as 'standard weights' each with a mass of.5/8 grams, which is equivalent to.x10 -kg. The applied force, F, can them be calculated by the following method. The graph of system output with varying applied loads, Appendix B, shows that there is a linear relationship between the two quantities. As the applied force increases so does the output voltage of the source and it is possible to add a regression line to the data plot to show this relationship. The sensitivity, K, of the force sensor can be calculated by using equation. EQUATION It is also possible to determine the linear range of the measurements that were taken, and in this instance it is to.8mN. Digitalising resultsThe most useful format for the results to be in is a digital format; a data acquisition system with an analogue-to-digital card is used together with the Labview computer programme is utilised to change the data from analogue to digital. Within the computer programme it is possible to vary the sample rate and the number of samples. The most appropriate sample rate in this case was on of 00 scans per second. The dynamic behaviour of the cantilever can be investigated by varying the conditions to which it is subjected to. This can be done by tapping the cantilever beam and observing the waveform that is produced. Graph, Appendix C, shows that it takes the system. seconds for the system to stable after it has been disturbed. The noise level present can be demonstrated by testing the circuit with and without the low pass filter. Removing the capacitor connected across the low pass filter demonstrates that the noise level is significantly higher than when the low-pass filter is added to the circuit. Graph, Appendix C, shows that the noise levels present without the low-pass filter makes it extremely problematic to interpret the data. Connecting a capacitor across the feedback resistor creates a low-pass filter, which reduces the amount of noise within the circuit. Graph, Appendix C, demonstrates the reduced amounts of noise compared to the waveform diagram when the capacitor is not present in the circuit. The resonant frequency of the system was found to be 0ms. Discussion and ConclusionAn equation for the overall output voltage against the loading force can be derived as there is a linear relationship present between the two factors and Graph this correlation. A regression line can be added to the data and an equation for this line derived from the equation of a straight line. The equation for the line is found to be. This equation for the straight line corresponds to the relationship between the overall output voltage and the loading force and can be written in terms of these: There are several factors which could effect the strain gauge measurements these include: TemperatureTorsionTensile forcesIn this case the measurement system designed will not be affected by the ambient temperature and this is due to the fact that two identical strain gauges are used on the cantilever beam. This insensitivity of the system to the ambient temperature can be explained through the thermal expansion property of the material. The thermal expansion coefficient of the steel is given to be 1x10 -/C EQUATION where is the change in length is the length at the reference temperature T is the thermal expansion coefficient is the change in temperature ) As the two strain gauges are identical that are used in the circuit they will be affected the same way by the ambient temperature. There will although be variations in practice between the two strain gauges and therefore the resistances will be slightly different, but the assumption is made that they are identical to aid analysing the circuit. Using equation it is achievable to illustrate that if the ambient temperature of the steel increases the length will change. As the two strain gauges are taken to be identical they will be affected by the temperature change in exactly the same way. The change in the resistance caused by the compression or tension on the strain gauges will therefore be effected by the same factor. When the temperature increases from T to T the resistances of the two strain gauges, R and R, increase due to the increased change in resistance due to the temperature increase. So the voltage output of the system, V, will still be zero when no load is applied so the system will remain balanced if the ambient temperature is increased. Including a low-pass filter to the design is an extremely beneficial as it significantly reduces the amount of noise within the circuit. This enables a better relationship to be derived between output voltage and applied load. RecommendationsThe system needs to be able to settle before any measurements of the output voltage are taken. For the system that has been designed the reading would have to be taken atleast. seconds after the force has been supplied. For example in the experiment when the washers were added the system was disturbed, this is similar to tapping the system. Graph that it requires. seconds for the system to settle. Allowing it to settle properly will ensure that the most accurate measurements for the output voltage are recorded and therefore a more precise equation for how the overall voltage output, V o, is affected by the applied load, F, will be obtained. A dampener could be added to the test rig to ensure that the strain gauges are not affected by any vibrations. Vibrations could be caused by many factors including knocking the test rig or leaning on the table that the analogue experimental transducer is being tested on. Vibrations would cause noise in the results and therefore will make them less accurate, a dampener would reduce the effect on vibrations on the results. It could also be beneficial to increase the gauge factor of the strain gauges as this would increase the sensitivity of the measurement system. To improve this measurement system it is possible to increase the number of strain gauges to four. This will increase the sensitivity to four times that of a single gauge. The arrangement with four gauges will also be insensitive to temperature changes along with tensile forces and torsion, which could all affect the results obtained. A configuration as shown in figure. be used on the cantilever to produce a forces measurement system when included with a Wheatstone bridge circuit.'''",400.0
"'''The goddess Isis was one of the last pagan goddesses to survive in the Mediterranean world after the spread of Christianity, well into the th century AD, and during the late Greco-Roman period her cult was astounding in strength. A few other gods managed to make it out of their home country as cult known as the Heliopolitan Ennead. I will now take a brief look at the earlier myths about Isis to provide a background for her later born of the alliance Isis and Osiris had before they left the womb. This typical story told of Osiris, Isis and Set can be found recorded in several sources, including Herodotus and most notably Plutarch. The myth goes that Osiris and Isis were reigning as a benevolent king and queen over Egypt, but their jealous brother Set tricked and killed Osiris and dismembered his corpse, scattering them to the winds. Isis, as his sister and wife, was heartbroken, and mourning his death set out to try and restore all of the pieces. When this was finally done she restored him to life with magic, but he was sent to become king of the underworld as one who had already seen death once. This is why in the iconography of Osiris he is normally portrayed as a mummy with green or black skin. While Isis was reassembling Osiris, in the original myth it was here she conceived their son the king Horus, who went on to rule Egypt in his father's stead, against the wishes of Set. This myth established Isis as a mother goddess in the early Heliopolitan context, and a mistress of magic. She, as mother of Horus, was also seen as the mother of the pharaoh, and thus a powerful deity to invoke; she was also revered as a mourner. This is seen in many later inscriptions, even magic papyri therefore not unknown, especially in Egypt. Indeed, Hathor herself became merged with Isis in approximately the 3 rd dynasty; Isis gained the distinctive cow's horns on her head, but remained the mother rather than the wife of Horus. It was in this aspect the Greek traders first probably came across her. The Greeks, due to their seafaring ways, certainly came across many new religions and cultures. But rather than installing their own gods, they tended to have a curious habit of looking at the local deities and observing that they were just one of their own, but under a different name. At Naukratis she was worshipped as Isis-Aphrodite, in probably reference to her syncretism with Hathor; this also gave rise to her being the consort of Jupiter who was turned into a cow, Io. Whether this is also because of the myth that Io wandered for years and ended up in but probably her most important identification came to be with Demeter. Herodotus, writing in the th century, claimed to have little interest in religion, and where he does refer to the gods in his discourse on Egypt, he uses the Greek identifications that later became almost set. In fact he even expostulated that the Greek names for the gods came from Egypt in the first place, making the Egyptians older and wiser than other races. In his books, Set became Typhon, Thoth became Hermes; in his role as he who made the soil black and the river flood Osiris became Dionysus, as a fertility god. This then fit again with Isis as his wife becoming Demeter, the lady of harvest. Some of these conclusions may seem a little odd. Demeter as one who be also seen as the mourning Isis, though she grieved for her husband; contrarily, Demeter never had a husband, so could not be the loving wife that Isis was. However, the advantage of being identified with Demeter was that that goddess was one of the elder deities in Greek religion, a daughter of Cronus. Writing circa. 0 AD, Plutarch used this in his 'On Isis and Osiris' essay, taking a hymn to Demeter that one of the oldest epic poets, Hesiod, had written in his Theogeny, and modifying it to fit with the stories of Isis already known 0. Whether this is Plutarch himself making this connection or something already assimilated into the corpus known about Isis in uncertain however. So by the time the Greeks were making their trading presence known in Egypt, Isis was already known as a powerful mother goddess, guarding the king, and perhaps, despite her stolen cow's horns, less intimidating to the. The Aretalogy is basically a list of self-proclaiming statements in which Isis declares her dominion over most aspects of the world. Earlier, shorter statements attributed to Isis did exist; 'I am Isis, one more spiritlikeand august than the gods. ' 4The later Aretalogies show Isis saying she created writing, civilization, the paths of the stars, and that she had power over the sea and childbirth and fertility, and that she conquers fate itself 5/8. All these aspects meant that the Isis that the later Romans first came across could be adopted by many areas of society. As protector of the sea, the sailors who would spread her cult in the first place would worship her; as a loving mother and protector women would pray to her; as an all-powerful being who had dominion over and above the other gods she could be anything that one wished. Indeed, the Greco-Roman Isis, along with many of the foreign cults that spread around the Mediterranean as the Empire made the world smaller and travel more possible, was growing much closer to a monotheistic aspect than the older religions of both Greece and finally her Oriental mysticism and eventual perceived overall dominion, with a control over fate in troubled times. Many levels of Greek and later Roman society could identify with her, and so she became strong where other deities failed.. The temple to Isis at Philae was finally closed on the order of Justinianus in 5/80 AD.. Plutarch De Iside et Osiride, sections 3-. PGM IV. 4-. Though later through the effects of syncretism the city was attributed to Isis. Myth and Symbol in Ancient. Ovid, Metamorphoses I. 31-. Herodotus Histories Bk II 0. - contrast with Plutarch De Iside et Osiride., where he states that the name Isis is actually Greek in origin.. Aretalogy, P.Oxy.381, though this states her as the 'eldest' one, which was originally Hestia.. Hesiod Theogeny 'Hymn to Demeter' 0. Plutarch De Iside et Osiride, sections 5/8-. Isis among the Greeks and. 'Serapis' was a syncretism of Osiris and. The Coffin Texts, Spell. Aretalogy, P.Oxy. Hymns of. Martial, Epigrams. Apuleius Metamorphoses Bk XI'''",402.0
"'''This essay will attempt to accurately describe the different methods employed by qualitative researchers to ensure the quality of their data. Therefore, this essay will first briefly describe and explain the methods adopted in quantitative research, and use this to highlight the different methods used by qualitative researchers. Quantitative research has been described as being concerned with counting, for example, to discover the proportion of one make of a car to another in a particular area. (Holliday, 002) This kind of research would produce numbers that could be measured against, for example, a set of data from a different area. These types of measurements can be a useful tool in research and have the advantage of making information collecting more precise, for example, not guesswork by the researcher, and numbers can be communicated across many different languages, cultures and societies. (Polit and Hungler, 997) However, errors in measurements are possible with quantitative data, for example, transitory personal factors when an individual's personal feelings or mood could affect their ability to participate in a research study. (Polit and Hungler, 997) Also, there are many difficulties associated with questionnaires, which are a common tool used in quantitative research, for instance, many people may not understand a lot of the questions. (Holliday, 002) To overcome errors in measurement, quantitative researchers use reliability to assess the quality and consistency of their data, for instance, a measurement is repeated a large number of times and if it produces low variation it is considered to be reliable. Reliability has three characteristics in quantitative research these are; stability, internal consistency and equivalence. Validity is also used in quantitative research to ensure that what the researchers think is being measured is actually being measured, this is tested using; content validity, criterion- related validity and construct validity. (Holliday, 002) It is clear from this brief description that validating quantitative data is a complex problem; however, qualitative research is more concerned with producing descriptions of the social world. (Perakyla, 997) Some researchers mention that whilst conducting their study they are able to gain in depth knowledge of their participants as people and their lives. (Morse, 992 and Hollway and Jefferson, 000) Holliday has identified that the difficulties associated with producing quality data increase with qualitative research due to the close contact with participants. However, researchers believe that it is possible to describe social interactions that can stand up to rigorous data quality tests. (Hammersley cited in Perakyla, 997) In further support of this, Holliday believes that to understand human behaviour it is inadequate to rely on quantitative surveys and statistics. This is due to the fact that, unlike quantitative research, qualitative research does not have to follow a strict procedure; therefore, each design will be different. Despite the difficulties involved, qualitative researchers are committed to proving their data is of a high quality and trustworthy. There are four main criteria for establishing trustworthiness in qualitative research these include; credibility, dependability, confirmability and transferability each one will be described in more detail below. (Lincoln and Guba cited in Polit and Hungler, 997) Credibility is concerned with having confidence in the truth of the data, Lincoln and Guba have identified two characteristics of this; firstly that a researcher must conduct their study in a way to enhance plausibility and second to ensure credibility is demonstrated. (985/8 cited in Polit and Hungler, 997) Credibility can be demonstrated using prolonged engagement which signifies the importance of spending as much time as possible with the participants and to ensure different days and times of the day are included. This will also aid the researcher in gaining trust and rapport with the participants. (Bowling, 997) Another method used by qualitative researchers is persistent observation which requires the researcher to focus on relevant information. (Polit and Hungler, 997) However, this can prove difficult due to the Hawthorne effect which identified that peoples behaviour may change due to them being studied. (Roethlisbergor and Dickson cited in Bowling, 997) However, Clark and Bowling, believe this effect may decline over a longer period of time. (990, cited in Bowling, 997) Triangulation is another method; where multiple characteristics are used to demonstrate credibility. identified four types of triangulation used in qualitative research. Data source triangulation occurs when many different data sources are used, for example, interviewing many different people on the same issue. Investigator triangulation refers to many individual researchers independently collecting, analysing and interpreting the same set of data. Theory triangulation is when many different perspectives are applied to interpret the same set of data. Method triangulation occurs when numerous methods are applied to a research, for example, using both observations and interviews. There are also a number of external checks that may demonstrate credibility these include; peer debriefing, member checks, searching for disconfirming evidence and researcher credibility. (Polit and Hungler, 997) Peer debriefing involves one or more objective peers who will independently review the research. Member checks are when the researcher conducts feedback sessions to the participants to ensure they have made the correct interpretations. Searching for disconfirming evidence involves; the researcher systematically looking through all their data to discover deviant cases, this functions to strengthen the final research outcomes by continuously refining hypotheses. (Perakyla. 997) Patton, has identified that a researchers training, qualifications and experience can be important to prove confidence in data. (990 cited in Polit and Hungler, 997) It is obvious from the numerous checks made to demonstrate credibility, that qualitative researchers view this as an essential task when conducting studies. Dependability refers to the stability of data over time and in different conditions, there are two methods used to demonstrate this; stepwise replication and inquiry audit. (Polit and Hungler, 997) Stepwise replication involves the research team being divided into two, and each team analyse the same data separately. An inquiry audit is the close scrutiny of all data and methods used by an external reviewer. Confirmability occurs when two or more independent individuals agree on the interpretations made by a piece of research. This can be demonstrated using an inquiry audit; however, in this case a researcher must provide an audit trail, which consists of collection of all materials and documents used. Finally, transferability refers to whether the research findings can be transferred to other settings and other groups of people. (Perakyla, 997) It is again obvious from the numerous methods available that qualitative researchers view demonstrating trustworthiness as an important aspect of their research. In conclusion, quantitative and qualitative research view the world differently, therefore, they have different methods of conducting their research. It would not be appropriate to apply statistics to a qualitative study; however, it is still necessary to demonstrate the quality of the data produced. Otherwise it would be very simple for qualitative studies to be published; however, this would only serve to undermine the researchers who have worked hard to ensure the trustworthiness of their findings. Therefore, qualitative researchers have developed the various methods described in this essay to show they are just as committed to producing significant and meaningful results as any other researcher.'''",407.0
"'''Charisma is perceived by many to simply be the ability to positively influence others by connecting with them physically, emotionally, and intellectually. It is what real leaders have that can inspire you and draw you to them that can cause you to perform beyond expectations to accomplish their goals. In my answer I will be examining the different dimensions to the arguments that intend to investigate the real meaning of charisma, its relevance today and in light of history and different traditions of philosophical thought, what exactly my understanding of the term implies. Though, the understanding of the term charisma can only really be established after placing it within a theoretical and contextual framework. To me this means that inherently charisma is not a concept based solely on the individual characteristics of a person but a phenomenon involving the relationship between a charismatic leader and his or her followers. Probably the most famous and widely used definition of charisma was written by Weber, meaning, 'a certain quality of an individual personality by virtue of which he is considered extraordinary and treated as endowed with supernatural, superhuman, or at least specifically exceptional powers or qualities.' Thus, according to Weber, charismatic leadership is a form of legitimate domination basically centred on the belief of the exceptional sanctity of one person, not accessible to the ordinary person, and their ability to partake in heroic, extraordinary acts. However, he also felt that charismatic authorities can be precarious simply because if their charisma is not proven they may be doubted. 'Before receiving his calling, the leader must have some germ of charisma latent in people in highly individualistic societies. Both arguments from Lindholm and Freud can be said to understand the term from the point of view that circumstances affecting the individual have led to certain characteristics and behavioural patterns making the person charismatic. Oakes, a psychologist critically analysing Weber's work, also makes an interesting point as a critique to Lindholm's writing, that Weber did not celebrate charisma as a solution to the emotional emptiness of conformity but saw its value as a tool for social progress Closely linked to psychoanalysis is the psychological school of thought exhibited well through Kohut's study of a difficult class of disturbed patients with narcissistic disorders, noticing similarities between them and charismatic leaders. While initially noticing extravagant self-confidence and an extraordinary lack of self-doubt they were often clear-headed and perceptive and could also be very persuasive or even accusative. In time, though, their confidence began to give way to vain boasting and a naive sense of invincibility, unable to admit to a gap in their knowledge or ask for advice and help. They were also revealed to have little or no conscience or sense of guilt. 'Their relations with others were characterized by a sense that others were merely extensions of their own egos.' Their extreme self-containment and self-absorption, along with their confident social manner, made them very appealing to others, who seemed to warm to some part of themselves that they recognized in these figures. It was this 'mirroring' process in which a strong figure sees others as parts of his self, while the others see themselves in him, that alerted Kohut to a narcissistic explanation of charisma. This psychological interpretation attempts to pin-point specific qualities in individuals that makes them charismatic and thus understanding the term would also involve relying on the notion that it is only personal characteristics and behaviour that make an individual charismatic. However, the 'failure to distinguish the sociological concept from personal attributes is at the core of a number of corrupt or dilute applications of the term' (Wilson, 975/8) charisma. Weber's concept denotes a quality not of the individual, but of a relationship between believers and the person they believe. If one adheres to Weber's definition of charisma one could also argue that while some individuals who enjoy some measure of marginal prestige in the eyes of their fellows have a 'reputation for reliability and competence as 'charismatic'' build good social relationships through these personal qualities, no element of the supernatural is involved. In Wilson's opinion, though, Weber gave relatively little attention to primitive cultures, as the former held the notion that the belief that a charismatic leader would arise may be a tradition, and may indeed have had its origins, among such people. Examining Wilson's text gives one insight not only from the historical perspective of charisma, but also, interesting criticism of what its meaning is widely believed to be today. 'The utility of the concept implies the reality of the phenomenon - not the phenomenon of divinely inspired men, but of the historical reality of widespread belief in such men and in the transcendent nature of their endowment with power. That belief is an important social fact and a force in social development' (Wilson, 975/8). Wilson's observations can be extended to form a basic criticism against the argument of charisma as a natural characteristic inherent in some individuals. The fact that few of us today believe that individuals ever receive divine power, or that there are fundamental, mystically determined unequal distributions of ability among men and women 'reveals an irony' as many in the past have believed in what he calls a 'superhuman nobility'. While it may always have been an illusion, individuals needed to believe and so they did. One could argue that in the future we will be better able to identify the charismatic demand before the time of a charismatic leader. Weber saw charisma as providing a break in existing social relationships. While natural catastrophes, famine, plague, or drought may have provided occasions, the most frequently observed circumstances of charismatic phenomena appear to be the conditions promoted by wars or 'the clash of cultures.' One could thus argue that while charisma is undoubtedly a cause of social change it also strongly appears to be a response to it. Many researchers have pointed out that at the time Hitler came to power Germany's economy was extremely weak and in need of a turn-around. Another example is of the charismatic leader Malcolm X. While many believe his oratory power was the main feature of his charisma, it has to be acknowledged that just before the Black Muslim movement, the economic position of many African Americans in America was appalling with many of their rights being trampled on and thus perhaps Malcolm X's charismatic power came more from the fact that he was simply at the right place and at the right time. Linked closely to Weber's concept of charisma are the ideas of the other founding fathers of sociology: Marx and Durkheim. By combining Durkheimian notions of the sacred and of 'collective effervescence' with the Marxist view of Napoleon's coup in France we are able to see an alternative view of charisma, not as that of a leader but as a quality projected on to a leader by virtue of situation, opportunity, and events. For example, Bill Clinton was seen as a great leader who possessed charisma while he was initially in power; however, while charismatic power was projected upon him, it was later retracted proving that many great leaders are created only by their followers. While most examples of charismatic leaders may be taken from various spheres of society, charisma, by Weber was used fundamentally as a religious concept; although in his usage it need not involve a notion of the divine, nevertheless it remains a form of spiritual energy oriented to otherworldly ideals. Today, however, the concept of charisma is applied more widely in the political, legal and cultural institutions of our society. The problem of modern charisma, argued by Bensman and Givant, is that charisma is nowadays manufactured by mass communications which rationally create an image of the leader as a charismatic figure. They feel that to a certain extent, this 'tendency is inevitable because of the nature of modern bureaucratic societies which would not allow the kind of personal relationship between leaders and followers about which Weber wrote'. It can be argued that today, charismatic leaders are the products of media experts who constantly train them in the art of oratory and to 'create an aura of an extraordinary person in order to enhance the likelihood of the imputation of charisma occurring. The modern charismatic leader simply has a far wider range of tools with which to project an image' (Bryman, 992). Most recently, 'One World Week', an event organised by University of students hosted a talk by Sri Sri Ravi Shankar, believed to be one of the most recent charismatic leaders today. Methods ranging from a large international following created largely through modern mass communication to something as basic as a large, reclining chair on stage, giving the appearance of authority, have been used to promote the feeling of power extended through charisma. While it is very feasible that charisma will continue to exist in our society, one where 'the element of personal trust that has, in so many respects become either redundant or increasingly difficult in the modern world' (Wilson, 975/8), the understanding of the term is somewhat less easy to locate. A modern understanding of the term has been examined in depth by House who sees it as an 'explicit combination of personal traits, leader behaviour and situational factors' (Bryman, 992). After viewing the arguments between prominent psychologists and psychoanalysts versus sociologists, the different institutions of our society that charismatic authorities can be found to exist in and with the perspective of time my understanding of charisma can perhaps be found inside both Weber and House's definition. While I believe that certain skills of persuasion and empathy cannot be learnt by just anyone, the emergence of a charismatic leader depends largely on the situation and the belief of his of her followers. Not to be located simply with a religious connotation the term charisma can also perhaps be applied to leaders in other, but especially the political context, most often to refer to those who have helped bring about some of the greatest risings and revolutions our world has seen.'''",413.0
"'''A modern networked economy brings with it inherent risks to the security and stability of that economy, much as any other before the advent of the Internet has. But the world of E-Enterprise presents a new and unseen threat - that of the hacker. Whether of malicious intent or otherwise, attempts to break the security of high-profile web sites and E-Businesses are rife, and it is both the duty and responsibility of an organisation to protect against them. This essay examines the electronic threats to one of the United Kingdom's biggest electronic retailers - Amazon.co.uk - using a number of published techniques to model these threats, their potential impacts, and proposes measures for preventing them or limiting the damage they cause.Amazon.co.uk has achieved almost unrivalled success as a purely-online retailer. The core value in Amazon's business is not the products that they sell - though these do generate a substantial revenue, but in the, crucially, the licensing of Amazon's technical architecture and model to other organisations. It is the success of Amazon's architecture and model that has created huge value in others wishing to use it to sell their own products. The diagram below represents a simplified view of the Amazon.co.uk system, from a networking point of view. It is this view that will be used to model the threats to Amazon's business and this view that will be built upon in each stage of this project. Each section of this document will elaborate on the threats facing Amazon through a number of techniques. Identifying ComponentsListing and explaining components comprising the greater Amazon.co.uk web siteModelling ThreatsUsing the Microsoft Threat Modelling Process to expand upon threats to Amazon's businessRisk Assessment ReportRe-writing the threat template to include priorities and countermeasuresIdentifying ComponentsThe first step in examining the threats to the Amazon.co.uk web site is to observe and analyse its behaviour and interactions with the user - the first place a hacker or inquisitive person will look for potential holes in the interface that can be exploited. Through usage of the Amazon.co.uk website, and a full examination of its functionality, the core components providing that functionality can be deduced. The table below lists a name for each component that is inferred, and the text below describes the behaviour of that component and its purpose in achieving a business goal. Product catalogue browsing componentThroughout the website the user has the ability to browse for a product by clicking on the tabs on the navigation bar to change product on the left-hand navigation area. The results of the enquiry are displayed with products in the chosen categories pulled from the database displayed as search results displayed in a page-by-page layout. Search componentThe Amazon.co.uk website gives the user the ability to search for a product by entering a a text field and clicking the GO button. The ability is also provided to search within a particular 'shop' (section - see above) such as DVDs, CDs, or books, and a 'Power Search' option is also provided for books, allowing the user to specify many other criteria such as publication date or ISBN number. Results matching or partially matching corresponding fields of products in the database are displayed and formatted to the user, and can be viewed individually in greater detail. Shopping Basket componentUsers have the ability to add, remove, and change quantities of items in a virtual 'shopping basket'. These items are held indefinitely and the website uses Cookies to record which products are stored in the shopping basket for unregistered users, registered users have a shopping basket stored in their account records on the server side database, making the shopping basket accessible from any internet-connected device. Users have the ability to discard the contents of the shopping basket or proceed to purchase the items in it. Saved Items / 'Wish List' componentAn extension to the Shopping Basket component, users can click a button on a product page to 'Add to Wish List'. The product then appears under the Shopping Basket section but is not added to the cart, but the user has the option to move Wish List items to the regular Shopping Basket or to remove them at any point. This information is, again, stored server-side for registered users. Purchasing component / Registration componentPossibly the most important function supporting the business, the buying component allows users to 'check-out' the items stored in their shopping basket by clicking the 'Proceed to Checkout' button. This walks the user through a number of steps, summarised below: Signing-. New users are walked-through the process of entering personal, payment, and delivery details, and selecting a password. Their details are stored as a new record on the customer database. Users are prompted to select a delivery address from a number of previously used addresses stored with their customer record. Similarly, users must select a credit/debit card from a list of prior cards used for payment. A new card may be added. A summary screen is shown, with all the items to be ordered, delivery type, costs and total. Gift certificates can be redeemed by entering the code on the certificate, which is checked against a database of gift certificate numbers, and appropriate balance deducted from the order. On clicking the 'Place Your Order' button, stock information is updated, order information passed to dispatch departments/order fulfilment personnel, and the user sent a confirmation email. Account Management componentOn the main navigation bar on each page is a hyperlink to take the user to the 'Your Account' section of the website. Clicking this button brings up, upon logging-in successfully, a page displaying information about the user that is held in the Amazon.co.uk customer database, and gives the user the option to change or update that data. Furthermore, open and past orders are available to view, and tracking features present the user with basic information about the current stage of processing their order has reached and an estimated shipping/arrival date, based on information logged in the order processing database. Customised homepage / 'Your Store' / Product ReviewingReturning, registered users of Amazon.co.uk, identified by logging-in or by cookies stored on their machine from a prior visit, are presented with a personalised front page to Amazon. This page includes a number of recommendations and new products targeted at the user displayed in a large, central format - these recommendations are made using server-side logic to determine related products in similar categories, based on information stored in the database about products the user has bought, searched for and viewed in the past. In addition, where another user of Amazon has bought the same the user, other items they purchased in the same transaction are often listed on this front page. This clever data mining often achieves the goal of suggesting to the user products that another user with similar interests has bought, aiming to boots sales. By navigating to the more detailed 'Your Store' section, users are presented with a list of recommendations that can be ranked - each product can be stricken-off as already owned or 'not interested', and given up to five stars indicating the relevance/interest to the user of that particular recommendation. This scoring is updated in the database and new, more suitable recommendations are selected from the products based on the improved criteria and displayed instantly to the user. Users can also write reviews for products they have purchased in the past to inform others interested in a particular product - each review, along with associated ranking and credited by the username of the reviewer, is stored in the database cluster and appended to the product information page. Modelling ThreatsFor the purposes of this report, it is assumed that the overview analysis revealing the gateway firewall, and the encryption of personal data using the signup, login, and purchasing process identified within the components described above, present the complete picture of the security measures in Amazon.co.uk's e-commerce web site. These security measures will now be securitised and dangers to Amazon's business activities will be described, measured and quantified using the Threat Modelling Process provided by the Microsoft Corporation. This is to be accomplished through a number of phases, working through the Threat Modelling Process, and tabulated below. Amazon.co.uk's assetsThe first step for any corporation requiring security to protect their business is an assessment of the assets they wish to protect, and analysis of the value of those assets in order to determine the appropriate balance of cost and security depending on the cost to the business of a compromise to the security of a given asset. The following table lists the chief assets of Amazon.co.uk's business with a brief evaluation of their value to the business. Customer DatabaseAmazon.co.uk holds a large volume of personal data about its customers on its customer database, including names, contact details, and credit/debit card details. These are not only extremely valuable to the individuals they belong to, but Amazon are mandated under the Data Protection Act 988 to take appropriate measures to protect the security and integrity of this data. Compromise of this database could lead to heavy fines for negligence, and severely impacted sales due to shaken customer confidence in Amazon.co.uk Products DatabaseThe back-end of Amazon.co.uk contains, within the SQL database cluster, a good deal of data about each product, and associated reviews, rankings, stock data, prices and other statistics. This data is chiefly used to produce the online catalogue by inserting wrapping HTML around it to produce a dynamic and interactive product page of each item. Without this data, the website would be unable to function and disrupt the ability for users to browse, search and buy items. It is also critical that the accuracy of this data be protected, for instance ensuring prices and stock are correct to safeguard sales revenue and successful fulfilment of orders. Sales and Statistics dataAmazon.co.uk maintain a large archive of data relating to sales statistics in the SQL cluster that is constantly being updated as transactions are processed through the web site. This data records product volumes sold, times and dates of sales, types of user that purchase particular items, and many other demographics. This data is important to the marketing strategies of the organisation and is mined to predict trends regarding sales and to make business decisions on products to stock, pricing, marketing, and many other areas in the sell space of the businesses' function, making this data, and the protection of it from unauthorised access or modification, very important. Back-end website application and codeThe Amazon.co.uk website is generated dynamically using a combination of server-side dynamic HTML and client-side JavaScript, using a custom the functions used by the Amazon.co.uk web application. This application, and all the code generating the pages of the Amazon website are patented, copyrighted works and are valuable to Amazon - theft of these could lead to trade secrets and technology secrets being leaked to competitors, and corruption or change of these files could lead to unexpected or undesirable behaviour of the website and subsequent disruption to transactions. Amazon.co.uk internal network and link to InternetThe logic and programming governing the behaviour of the Amazon network is contained within its network hardware. Router and switch configurations, firewall rules and programming, server access, restrictions, and policies are all important and disruption or change to these could cause the operation of the internal network, or the connection to the be threatened. Architecture OverviewWith a model of the Amazon.co.uk website, produced through the earlier table of components that comprise the whole, the next step in the process is to identify the technologies in use by Amazon that underlay these components and allow them to function as intended. The following table shows a list of those technologies chiefly used by the web application and supporting infrastructure, and details of where they are employed. Architecture DiagramsThe second stage in the Microsoft Threat Modelling Process mandates the creation of one or more Architecture Overview diagrams. These diagrams 'describe the composition and structure of the application' and graphically represent 'Trust Boundaries' - these are the realms in which one or more trust the authority of each other. Data received by a subsystem from outside of its trust boundary should be assumed to be harmful, malicious or incorrect. Identifying ThreatsThe third step in the Threat Modelling process is to identify and document specific threats to the assets of Amazon.co.uk - from the point of view of the network, host and application - and target at exploiting weaknesses of the specific technologies identified earlier. The following table lists and describes each threat in turn, and categorises them using Microsoft's STRIDE methodology, into the following categories: Spoofing, Tampering, Repudiation, Information Disclosure, Denial-of-Service and Elevation of Privilege. Risk is calculated based upon the formula Risk = Probability Damage Potential where Probability and Damage Potential are ranked on a scale of -0, where is very unlikely/minimal damage and 0 is certainty/catastrophic damage. Threat RatingEach of the threats listed and tabulated above is given another dimension in the rating assigned to it for 'risk'. This is accomplished using the Microsoft DREAD threat rating model - where each of the following factors are examined for each security threat and impact rated as description of the ten most critical threats facing Amazon.co.uk's business recommended to defend against these threats. Ten of the chief threats facing Amazon.co.uk, and suggested countermeasures to those threats, are: Threat1 unsecured data Unauthorised access to Oracle database leading to damage/theft of data3 Poisoning SQL queries through bad validation/checking4 Denial of Service attack on Web Farm5/8 Virii/Trojan Horses/Worms6 Unauthorised Access7 Theft of customer account details & credit card Repudiation - phishing websites masquerading as Amazon.co.uk9 Buffer overflows from attacks on open Malicious Scripts from user Encrypting form data and cookie transactions, disabling option to pay using unsecured server2 Secure database access policy, lowest-possible privileges3 Validate ALL user input before allowing it to pass SQL query to Oracle database using client-side embedded scripts and server-side database rules and permissions, or use pre-constructed database queries executed remotely by database itself4 Router & firewall software to detect and combat dropped and detect/filter trafficLarge bandwidth and web server redundancy to 'soak up' attacks5/8 Robust, high-speed virus scanning at all entry Proper policies for ensuring customer can differentiate genuine website (site certificate authorities), authentication through third-party checking authorities with encrypted connections9 Closing ALL unnecessary ports, patching all servers to latest version regularly, including open ports on database servers10 Lock-down, validate and filter user input in all areas where long strings can be sent to web server (such as product reviews)'''",423.0
"'''In this research, Scott employs a quantitative approach to her study. This is the best method she could choose for a comparison of this scale. She needed a large group of responses for her to analyse so that she could draw conclusions from her findings. Her research question was, 'To what extent has there been a revolution in sexual attitudes and is the revolution over?' (Scott, 998, p.18). Then, when she uses her findings as comparative data for the cross-national part of the research, the question is, 'To what extent does religious difference account for the cross-national variations in attitudes?' (Scott, 998, p.31). Both research questions were asked within the context of attitudes to pre-marital sex, extra marital sex and sex between members of the same sex. For her data collection methods, Scott uses the time series data from British Social the General Social the United States when comparing British and American attitudes. To analyse the four other nations - Ireland, Germany, Sweden and Poland she uses data from the International Social Survey perhaps not as comparable as it should be, can this really be a 'good' cross-section of society? On the other hand, Scott's interest in a cross-national comparison is also to see if region and religiosity is an important factor in sexual permissiveness, this is perhaps why she looks at Ireland since it is a strong Catholic country in contrast to Sweden which has relaxed attitudes to sex and has low levels of church attendance. In conclusion there are many pros and cons of Scott's cross-cultural comparison. In using an inductive approach she gives many examples of generalisations such as 'Despite the widespread tendency of women to be more regular church attendees than men, women are more tolerant than men of same sex relations in all six nations' (Scott, 998, p.40). In that quote, she has noted the causal relationships between the variable of sex and the notes how comparisons can be drawn between men and women; for instance, how women are less likely to condemn homosexual relationships but more likely to be opposed to pre-marital sex than men. Again she gives a possible reason for this deficit towards homosexuality. It might be because men feel the need to ' condemn homosexuality in order to assert their own masculinity' because it is 'rooted in heterosexual prowess'. Perhaps the weakest part of her argument is when she talks about data methods and analysis, she only dwells on this for a small part of the extensive article and only to talk about control variables such as educational attainment and divorce. Scott does answer her research question about revolution in sexual attitudes and makes an insightful comment that there is 'little evidence of any revolutionary change.most of the changes in attitudes towards sexual morality due to the slow process of cohort replacement' (Scott, 998, p.30) and that the generational divide is lessening over this study gave. Perhaps more countries could be studied, but the countries were chosen for the fact that they might have contrastable differences on sexual morality. She also states they were chosen for 'pragmatic reasons concerning data accessibility' and to 'test the hypothesis of religion' (Scott, 998, p.34). This was shown in disapproval regarding pre-martial sex between was 3% and % respectively. Her research study had given many theoretical contributions, ones which can be applied to all six nations as well as some statistics that can used to explain attitudes to sexual morality within Britain and the United States and she further gives illustrations of how it might change. Word count:,87 words.'''",428.0
"'''Project SpecificationProject TitleThe title of the project is 'Comparison of Block and Stream Ciphers'. ProblemDue to the technological developments in telecommunications in recent years, the need for new methods of maintaining security and privacy over insecure communication media has emerged. This is usually achieved through using some form of data encryption. Data encryption involves taking some type of in some way altering it so that only the intended recipient - and possibly also the sender - can work out what the original data was. The alteration generally involves either rearranging the characters in the data, or replacing certain characters with other characters, or may involve a combination of both of these. Encryption algorithms can be split into two general categories: block steam an implementation of each selected algorithm. Using a selection of example data, test the implementations of the algorithms to establish their relative speeds of encryption. Refer to resources listed below to gain a thorough understanding of the mathematical principles behind proving theoretical speed of encryption. Refer to resources listed below to gain a thorough understanding of different types of cryptographic attack and mathematical ways of examining algorithms' resistance to such attacks. Use knowledge gained from this research to examine the theoretical speed of encryption and resistance to attack of each of the chosen algorithms. Produce a comparison of the algorithms in terms of these properties. ResourcesIt is likely that the algorithm implementation will be done in C+, therefore access to a computer with a C+ compiler and a suitable text editor will be required. If appropriate, access to compiler documentation will be required. As a large part of this project involves research, most of the resources required are books, websites or similar reference sources. Sources which are likely to be useful are listed below. This list may be expanded later. Stinson, Douglas R.. Cryptography: Theory and By Use a variety of input Pain due to poor posture Minimise By Ensure posture is good while working Hazard Storing files on computer media Risk Files become corrupted/lost Minimise By Take regular back-ups of work and store on separate Copyright held on proprietary algorithms Risk Infringing copyright Minimise By Ensure all selected algorithms do not have copyright preventing them from being implemented in an academic context Hazard Illness/injury/other unforeseen circumstances Risk Project is delayed Minimise By Allowing plenty of time for each activity in the schedule; allowing time towards the end of the schedule for completion of any outstanding tasks TimetableTerm Date Be Completed 7/0/5/8 Begin to draft specification; find appropriate resources; research mathematics and basics of cryptography 4/0/5/8 Complete project specification; research block ciphers 1/0/5/8 Research block ciphers; research specific block cipher algorithms 8/0/5/8 Research stream ciphers 4/1/5/8 Research specific stream cipher algorithms 1/1/5/8 Research cryptographic attacks 8/1/5/8 Research any remaining areas which are unclear 5/8/1/5/8 Begin to draft progress report; complete any remaining research 2/2/5/8 Complete progress report; investigate C+ development environments and compilers Term Date Be Completed 6/1/6 Complete familiarisation with C+ development environment 3/1/6 Begin implementation of algorithms in C+ 0/1/6 Complete implementation of algorithms in C+ 7/1/6 Test implementations for speed of use 3/2/6 Begin speed of use & ease of attack analysis 0/2/6 Complete speed of use & ease of attack analysis 7/2/6 Begin producing presentation; bring research together and begin to draft report 4/2/6 Finish producing presentation; continue drafting report 3/3/6 Give presentation (if appropriate); complete draft report and discuss with supervisor 0/3/6 Give presentation (if appropriate); make alterations to report Holiday PeriodsOver the Christmas vacation, some refamiliarisation with the C+ programming language should be done, as well as selection of an appropriate development environment and compiler. By week of term, final report must be completed therefore any final alterations to the drafted report should be made over the Easter break.'''",437.0
"'''Question The objective of this assignment is to investigate the determinants of examination results. To do so, we are given data that contains observations on econometrics students' survey responses, across The C value in table., 4.3999 shows the average mark in first year statistics by students when zero. The coefficient of ATTR, b =.02263%. This is means that there is a.02263% increase in the mark obtained for every % proportion of revision lectures attended. The t-statistic of the coefficient of ATTR is, the null hypothesis H: Question The coefficient of attr,.05/8949 shows that the average mark will increase by.05/8949% with every % point increase in proportion of revision lectures therefore, we reject the null hypothesis, H: =, as compared to the t-Statistic in table. where we are not able to reject the null hypothesis. This shows that the attr coefficient in the multivariate regression model is now significant, having the additional variables, ability and hrsqt. At % significance level, critical value =.6 of At % significance level, critical value = F-statistic = 2.1029 Since F-statistic, we reject the null hypothesis H. From table., we can see that we have observed an event which occurs with a probability. should also therefore, reject H. Question I have ran a regression based on hrsqt divided into three subsamples, between and hours a more than hours a less than Coefficient of year2002, -.03399 is the proportionate change in student in year 002 relative to student in year 004. Coefficient of year2003, -.95/8910 is the proportionate change in student in year 003 relative to student in year 004. T-test for year2002 At % significance level, critical value = T-statistic = -.92496 We do not reject the null hypothesis as the test statistic of coefficient constancy across the three subsamples Restricted model: Unrestricted model: Where, d = Therefore, Where, Therefore, we reject the null and this shows that there is structural inconsistency and that it is better to split samples into subsamples than to estimate observations together. Question Null hypothesis that the slope coefficients in the model in question4 are constant across the three regression equations However, as we are testing that the slope coefficients in this model are constant, we use the regression ran on the two dummy variables 002 and Model: Unrestricted model is the same as Question Where Therefore, This shows that we accept the null hypothesis and that the model is structurally stable. The slope coefficients are the same for all three years. Question At this stage of the work, we have collected some important statistical information about the relationship between the dependent variable, qtmark, and its hypothetical determinants, the independent variables. To do so, I have created several models for varying independent variables and sometimes even adding dummy variables to identify significance levels. The previous results will facilitate the next task that is to try and create a model which includes the independent variables that have a strong influence on exam performance. To formulate such a model, all the independent variables included will have to be strongly significant, not only independently but also jointly. We should also take into account the value of the coefficient of explained by that model. We have looked at a number of variables and they include attr, ability, hrsqt, attc and alevelsa. From previous questions, I have learnt that attr is a significant variable to qtmark. Thereby, at this point, the explanatory variable that my model shall definitely include is attr. The high between ability and qtmark could be a sufficient reason for also including ability into the model. This sufficient reason to include it as well in the model is reinforced by the conclusions of the experiment made by Romer about whether students should attend classes. I went on and analysed the variables, attc and alevelsa in question and found out that they are both significant as we are able to reject the, the t-prob of variables are very close to the null of insignificance for the dummy variable is also rejected at a % significance level. Again, the t-prob of zero in the F-test suggests we reject the null of joint significance. By looking at R values for both models, we may say that model in which I added the uk dummy a better one: while the independent variables in model A explains about 7% of the variation in performance, the independent variables in model B explains about 8% of the variation in performance, that is an increase of around.% To increasingly improve model C, we could think about other variables that may also affect the outcome of exam performance. As Romer's experiment suggested a higher quality of instruction may encourage students to attend more classes and by doing that, increasing their chances to improve exam performance. Such a variable could be treated as a dummy: it would take the value for good quality of instruction and zero otherwise, where a good quality instruction is one that successfully gets students to attend classes.'''",438.0
"'''Having spent 0 half days and full weeks at King Henry V111 school in Coventry I feel I can appreciate more what being a teacher is like, the challenges and every day tasks they face and how relevant some of the aspects of learning that we had studied were to the way the pupils there learnt. I spent a lot of my time observing teachers but also did some teaching myself which included taking over a year class for a period of lessons. The first section of this essay is about some of the many different lessons I observed, and the second is about my experiences of teaching. One of the best lessons I observed was a first lesson on probability taught to a year class. The teacher copied a picture of a horse onto the interactive whiteboard and then told the children to imagine a horse race. There are 2 horses and which horse moves is determined by the roll of two dice i.e. if someone rolls a and a horse number three moves. The teacher passed the dice around the class and got each child to shake them. Whatever score they got the teacher would put a cross on the board next to that horse. A horse needed crosses to win. Some children immediately noticed that could not win. After about six throws he asked them to 'bet' on what horse they think will win. Quite a few went for but 0 was doing equally as well at the time which encouraged some to go for that but at least one person went for everything. This caused much excitement with people cheering for their number. I now realise that in this lesson the teacher is following the constructivism model of learning. says that methods likely to feature heavily in the constructivist teaching approach are 'practical work, structural apparatus, 'discovery learning' and investigative methods'. This activity encapsulated many of these. It turned out that won but as expected the results formed a standard normal curve. In the last 0 minutes he asked for the classes mathematical thoughts on the results. He listened to them all and although he corrected them on some of the language used he did not correct wrong hypotheses to start with. This is an example of a 'high degree of interaction between pupils and teacher' which is seen as a very positive thing. There was more of this at the end when after drawing a sample space diagram on the board and getting them to fill in the rows he asked them for their thoughts. He finished by asking them what they thought the probability of getting a, even number, and number greater than 0 was when two dice are thrown. The lesson also links to Bruner's learning theory 'instruction'. He talks of this having main features and this lesson certainly included of them. describes them as 'activation which means that tasks need to be sufficiently open as to arouse curiosity, but not so open as to arouse confusion', maintenance which means that the pursuit of alternatives is considered useful and worthwhile, and direction which means keeping in mind a view of the whole problem'. This activity was certainly open enough to arouse a lot of curiosity and was not confusing because to start with the pupils saw it as a game rather than the beginning of probability, the pursuit of alternative ideas was encouraged when he asked them for their hypotheses and the teacher always had in mind that by the end of the lesson he wanted them to have some understanding of sample space diagrams and their link to working out probabilities. Another lesson I observed that I thought was good was a year 0 lesson and involved an investigation. The class had just had lots of revision lessons and the teacher wanted to give them a break from that. He handed them each a sheet which explained the 'tangled triangles' investigation to them. The premise of the investigation is that students are trying to find the biggest value of the ratio of area/perimeter for some triangles. One student indicates that this was done with measurements of 0, 0 and 0 but forgets to say what units are used and whether they are angles or sides. The class then had to find whether the information refers to angles or sides. The reaction of the class to this task was interesting. Some of them were pleased to be doing something different and some clearly viewed it as a lesson they could relax in. Others were very keen to find the answer to the investigation and got started straight away and others were very reluctant to get started. A lack of confidence in themselves was quite clear even amongst the ones I knew to be strong students. The teacher was keen to point out that there was going to be no formal marking of their findings and encouraged them to try out their ideas. He kept going round asking how they were doing and for their initial hypotheses. He encouraged them to discuss their ideas together but wanted them to write something individually in their books. The constructivist approach encourages this - 'constructivism emphasizes the value of social interaction and communication'. The teacher encouraged them to discuss their ideas and again advocates this - 'The quality of pupils' mathematical thinking as well as their ability to express themselves are considerably enhanced by discussion'. My experiences of teaching were mainly centred on a year class that I took over for a number of lessons. I found that the most difficult aspect of teaching was differentiating. With a class of 6 pupils it was hard to know whether every individual understood what they were doing and even when I knew that certain pupils were struggling, it was hard to devote my time to them when the rest of the class also needed attention for other reasons. It must be one of the toughest tasks facing teachers - they have to move on when the majority of the class is ready to but they also have to be aware of struggling pupils and somehow find time to help them one to one. Also even spotting that one pupil in a class of 6 needs help is difficult. I tried to get round to each person during the lesson but some are reluctant to ask for help and you sometimes would not notice they are struggling until you actually mark their books. After teaching them for lessons I set a homework and then took their books in. I found what they had done very interesting. The amount of common mistakes was fascinating aswell as misconceptions that individuals had. The first part of the homework was giving approximate answers to expressions like 3684. Nearly all of them made it harder for themselves than it actually was by first working it out using long multiplication and then rounding the answer up or down to the nearest hundred or thousand. The point of these questions was to get them to instantly write that 3684 approximately equals 0080 or 00100 which is much easier to work out. Two things occurred to me here. I could not mark wrong what they had done because in a sense they had approximated the expressions so the question in the text book was ambiguous. Secondly, they obviously had not got the message that approximation is supposed to make life easier. The second question involved approximating things like.35/8. Here many of them assumed they could not use a calculator even though they could and did long division. With this question the idea was to work out the answers first on a calculator and then approximate which I can now see must have been a bit confusing considering the previous question was non calculator and they were supposed to approximate the numbers first. Many pupils thought that because the question was given in pounds that they could not round the answer on their calculator to the nearest penny - many converted the initial number into pennies first. Many of them that got an answer of say.3 would put that the answer was to the nearest penny. Others when they got a long decimal answer did not realise that to get the nearest penny they had to round to decimal places. The third question asked them to round certain numbers to and then decimal places and this was done very well which pleased me because I had spent quite a lot of time explaining how to do this. The last question was about indicating on a number line the highest and lowest possible value of a number that has say been rounded to decimal place. Even though an example of how this should be indicated on a number line was done in the book I got many different interpretations not all of which were wrong answers to the question. I think this is the trickiest part of this topic. I had tried to get them to write answers to this sort of question using inequality signs and many pupils ignored drawing a number line and wrote their answers in this form so I could not tell them they were wrong for this. Many pupils asked why a number like 1 could be as low as 0. but could not be 1. and all I could say was that it was convention that we round up when it is. Some wanted to put that it could be in the range 0. to 1. so I then had to say what about 1.9. Using the strictly less than sign with 1. gets around this. I therefore found marking some of the books difficult in that although some had not got the same answer as the textbook they were essentially right, and also marking the books of the few people in the class that had completely misunderstood it all was difficult. I had to cross nearly every answer but did not think it would be helpful to put a really low grade at the end. I agree with the points made in that 'there is no point in labelling children, progress, teacher or school as 'unsatisfactory' unless this goes hand in hand with the means to bring about improvement' and 'the labelling of some learners and teachers as 'unsatisfactory' is likely to lead to poor motivation'. I put an encouraging comment at the end and aswell as just crossing every answer I wrote down what they should have done and spoke to them individually at the start of the next lesson. I am aware that a full time teacher would probably not spend that long on a book but I felt I could as it was a one off. This taught me that especially when they are at this age, homework's set from a textbook can certainly be misinterpreted however well a topic has been taught. Perhaps textbooks need to make themselves clearer and also teachers really have to make it clear exactly what is required of pupils with homework at this age. Because I had spent a lot of time with this class, I already had an idea of their abilities and I noticed that the same people always put their hands up. Naturally many of these are the most able, but some are just the most confident and of course many of the most able may not ever put their hand up. I began to think of ways of teaching that might help particular individuals but surely a teacher always has to think of the whole class when devising teaching methods. There has been a lot written about learning theories and about what type of learner a person is such as a 'visual' or 'auditory learner' but I read an article in which the author has some doubt about 'the vogue for pigeonholing students by learning style'. It says that research has shown that 'labelling a pupil as, say, a 'visual' learner may do them more harm than good'. It goes on to say that 'the tools used to split learners into different categories are so unreliable, most such labels seem to be of dubious value'. The professor expresses concern that giving someone a particular learning style can have a negative impact - 'one danger of an unthinking use of learning styles is that teachers view a student as being a certain type of learner incapable of learning via another mode'. He is also concerned that students themselves might start to believe this. The crux of the article is that 'all learners need a wide repertoire of learning strategies and need to know when to use each'. I think it is important to bear this in mind before being too quick to judge a pupils best 'learning style' and it highlights the need for a teacher to vary his teaching strategies. Overall actually teaching a class and setting and marking their work really taught me a lot about being a teacher and observing many lessons gave me many ideas for future teaching. I realise that this was a particularly good school with very good teachers and that experiences in another school could have shown me other sides of teaching and given me other ideas.'''",440.0
"''' The potential function, V, belonging to an electrified system, is defined as the sum of all the electrical particles acting on a given point divided by their respective distances from the point. It is a simple way of representing the values of the forces which drive the electrical particles: This integral is taken over every particle inside the body under consideration, which can be of any form as long as the distribution of charge is fixed. Here p' (x', y', z') is a particle inside the body with corresponding charge density ', volume dx'dy'dz' and hence 'dx'dy'dz' represents the quantity of electricity it contains. a point outside the body and r' = ((x'-x)2+(y'-y)2+(z'-z)2) is the distance between p and p'.(See Appendix Fig ). Green then moves on to considering the Laplacian of the potential function inside and outside the body. I will simply state these values, since Green uses results known from Laplace and Poisson's work, and I find some of his calculations ambiguous despite the fact that the end results are correct. Outside the body, as Laplace had previously shown, V is proportional to (/r') = and hence V =. However, if p is inside the body then this may not be the case. Green uses the result shown by Poisson in 813, that in this case V = - and hence V+ =. I use the symbol to represent the Laplacian throughout. This notation differs from Green's. All the charge distributed in a system of perfectly conducting bodies, in equilibrium, will be found on their surfaces, with none remaining in their interior. This is a consequence of electric repulsion, and can be proved by considering a point in the body with F x, F y and F z, the total forces impelling p in a positive direction in the x, y and z directions respectively. Then, due to equilibrium, V is a constant, hence V =, so, where is the charge density at p. Hence the density of electricity at any point in the body is. One of the most important results proved is the following theorem, which I have presented in what I see as a more comprehensible way: 'Let two continuous functions which do not have singular values within a solid body of any form. Then, ' where ds represents an element of the surface, dv = dxdydz represents an element of the volume and n = (n x, n y, n z) represents a surface normal measured towards the inside of the body. Defined by Green as points where the differential coordinates become infinite. I use vector notation here although it did not exist at the time of Green's writing. The proof of this is extremely elegant when presented by Green. I use my amended notation. Consider: Proceed by integrating by the following: Green did not put two separate integrals in for double integrals, but I have included them. where on the right hand side the first integral corresponds to values of U, V at x and second corresponds to U, V at x. (See Appendix Equation and Fig ). The overall equation becomes For the left hand side of the equation interchanging the values of U and V will not affect its value since This means the right hand side not be affected when U and V are interchanged so equating the two versions of the right hand side together gives the required result. There is a quicker way to do this by simply using Gauss' divergence the charge density induced at the surface by charge concentrated at p So, the value of the potential at any point inside the body can be found as long as the value of is known. He requires that such a V does actually satisfy V =. Since is independent of the position of p(x,y,z),. Then split U into two parts: one due to the electricity concentrated at p, here U = /r, and the other due to electricity induced on the surface, U, which therefore contains no singular values., since is independent of p(x. y, z). Then, and at the surface,. So, and this result applies to any point in the surface. This means. This particular U can be shown to imply a finite value of charge on the surface, so is physically realistic. Using a stated example of a sphere of any radius, with its corresponding charge density, he shows that on, and very close to, the surface itself, where this V takes no singular values within the surface. This whole argument can be extended to a number of closed surfaces, as long as the condition is imposed that V'= at an infinite distance from the surfaces. The next result is another important intuition into the theory of electricity. The general idea is that, for a closed surface, the positioning of a unit of charge within a surface will not affect the potential function induced by the surface for this charge. Green takes two points, p and p', both within the surface and investigates how the potential changes when he fixes p' and moves p to the surface, then moves p' to the surface and vice versa (i.e. moves p' then p). He discovers that the resulting potential functions are identical. The extension of this to any number of bodies was later extended, although not by Green, into a reciprocity theorem which is still used today. This reciprocity theorem may be represented as where e n, n, e n', n' are charges and potentials on conductors in two different equilibrium states. Finally, consider a body which has electricity spread over its interior as well as its surface. This is a more realistic model for nature, since, in reality, not many bodies are perfect conductors. The whole problem of calculating the charge at a point within the body is shown to reduce down to simply finding out the value of the potential exterior to the body (or bodies since the same logic applies to more than one body). Even before the time of George Green potential theory had been recognised as an important area. Laplace introduced the idea of a potential function, without the name, to represent the components of a force in a problem. However, throughout the 8 th century, potential theory had been restricted to determining the amount of gravitational attraction one mass exerted on another, with applications to, for example, the motion of the moon. Kline says the emphasis on the potential equation for the calculation of gravitational attraction continued in the early 9 th century but was accentuated by a new class of applications to electrostatics. So, Green's application of potential theory to the theory of electricity, a new and exciting topic, more easily captured people's attention. Kline Page 82 In his essay Green sees his task as facilitating 'the application of analysis to one of the most interesting of the physical sciences.' He wanted to treat the idea of static electricity in a purely mathematical way, although I question how successful he is in achieving this aim. However this is not a criticism of Green's work, which although not always mathematically rigorous, intuitively is generally correct. His presentation is clear and easy to follow, with only a few confusing uses of notation. He lays the foundations for other people to build upon. Latimer Clark, a nineteenth century historian of electricity described the 828 essay as 'one of the most important works ever written on electricity.' Relative to the time of writing, the ideas were cutting edge and held in high esteem by the mathematical community. His results provided mathematicians and physicists with new tools, and motivation, to investigate potential theory. Some say Green's theorem is the natural way to Cauchy's integral theorem, so the impact of his work is maybe not even just restricted to applied mathematics. In my opinion, the main measure of his success is that many of the theorems and ideas he presented in his Essay are still used today, even if some of them have since been slightly adapted or made more mathematically rigorous. The fact that his ideas have stood the test of time shows just how great a mathematician George Green was.'''",442.0
"''''At its core, the goal of a company is to create value,' said Jean-Paul Page in his article 'Corporate Governance and Value Creation'. Hence enter the role of Corporate Governance which is basically how a company is controlled and directed. Traditionally most firms adopt the shareholder approach which emphasises on maximising shareholder wealth. However for the past few years, there is a growing interest on the stakeholder model. Under this model, management is supposed to focus on long-term survival, which is achieved by satisfying the interests of stakeholders. Stakeholders' interests are evaluated according to the firm's overall purpose and mission and then translated into the firm's business strategy or principles. Thus, in my opinion, this theory encourages a more straight-forward approach towards addressing social responsibility compared to the shareholder approach. URL The definition of corporate social among companies but generally CSR is often seen as the business's efforts towards sustainable development and is represented through the way a company balances its economic, environmental and social objectives while addressing stakeholder expectations and enhancing shareholder value. Here, Nestle is taken as an example although I will focus only on its social objectives. URL Nestle has a 2-person shareholder-appointed Board of Directors, all of which are non-executive members, except for the Chairman who is also the CEO. Nestle incorporates their business strategy in the Nestle Corporate Business: URL International Baby Food Action Network's report on Nestle: Breaking the Rules 004 However I believe that if they were to work more on their stakeholders' interests they could improve their image and perform better. Thus, being known for its poor reputation for ethics, Nestle has to continue its effort to build up public confidence by contributing to the society in a number of ways and at the same time, producing reports of its activities such as the 'Nestle in the Community' and 'Nestle Commitment to Africa' Report.'''",446.0
"'''. The OPUS approach to excellenceOPUS Ltd. is a well established software development company with extensive industry experience. OPUS has an excellent track record for delivering excellent quality products on time and within reasonable price. The secret is the blend of high calibre technical staff, application of well known software development techniques and management principles and experienced management and solid financial backing from investors. OPUS's commitment to quality of of the outmost importance. Out quality is of the highest standard the client's can get. Developing software to well established standards such as PRINCE2, ISO 000 and SEI standards are all too familiar to us. Our highest quality and affordable products are due to the right balance of standards, procedures and flexibility within the establishment. Our technical creativity and efficiency are not hindered by organisational bueurocracey and too much paperwork. Yet we can guarantee the QA in all our products by following our unique QC and QA procedures. We believe in the application of right procedures and techniques at the right time and place in the development life cycle will enable our clients to benefit, which no doubt we have proven over and over again. At each stage of production, quality is built into our products though our quality control processes and guaranteed by quality assurance procedures before moving over to the next stage. This varies from informal technical reviews and walkthroughs to extensive system testing to confirmation to the right budget and time. We have fulltime QC teams that are dedicated to make sure that our products confirm to our standards. We continuously involve our clients during each stage of production make sure that our standards meet their requirements and expectations. All our suppliers and contractors are hand picked to make sure they confirm to the sufficient quality standards. Our most valuable resource are our technical teams who makeup most of the OPUS. Our highly skilled and qualified tech staff come from well reputed universities such as Oxford Brookes. Managed by our highly specialised and experienced management teams. We have sophisticated automated software enables our tech teams to efficiently develop and test products. This is the OPUS culture and our trade secret and this is why we can produce high quality products that meets client expectation, deliver the products on time AND at reasonable prices. This competitive advantage enables us to compete with very large software houses and has always been the envy of the industry.. Quality control tasks for this projectDepending on the stage and activity of the development cycle the QC/QA techniques varies. However all the following techniques are used in the SQA process. Technical peer reviewWalkthrough meetingsCustomer reviews and acceptanceQA auditManaging requirement traceability processesMaintenance of QA reports of reviews and auditsManagement notification of non compliance with standards, procedures or notable problems and issuesProvide training in QA requirements if necessary4. Strategies for reducing time scalesSegmenting into ReleasesIt maybe possible that although the client's date is absolute, the entire project does not need to be finished at the same time e.g. Client management may not exactly need to use the Produce patients system letters until the next financial quarter. Risks: Need to be careful in approaching the client. If it appears that OPUS are proposing to enter production with an incomplete system, they will simply reject OPUS. Nobody wants to risk business on something that is not finished. Risk mitigation: Client can be educated about release development, a process in which a system is developed and implemented in self-contained chunks e.g. Produce patients records is not unfinished; it is a complete release of a system to which subsequent releases will add further functionality. Concept of release development to align the schedule by defining releases to include whatever is required by the absolute date. Anything the client agrees can be deferred goes into release of the project to another company that specializes in systems development. 'The productivity of focused companies can be as much as 00 percent greater than that of their larger, more structured counterparts'. In a tight project, they can sometimes provide the boost that the project needs. This approach maybe more be expensive, but meeting the schedule may be worth it especially when considering follow-up business with NHS. Risks: May not deliver on time or up to the required quality. Risk mitigation: Carefully evaluate the subcontractors and plan early. Encourage, motivate, reward and provide flexibility to the teamAnother approach is to get company's permission to ignore office standards, conventions, bureaucratic the in. Two major areas can be identified in the maintenance stage: Implementing change to the system Ensuring that the system continues to meet the user's needsAll required changes to the installed system must, be subjected to the full procedures of the system development life cycle. Therefore, a change-control mechanism must be implemented to ensure that the responsible management insist that each change be installed in a manner that minimizes disruption and is essentially invisible to the user of the system. The deliverables and QA activities in the maintenance are: Detailed log of changes to the system.Copies of regular reviews and verifications of the service level agreement.Copies of regular post implementation review reports.If the system cannot be delivered in timeIf non of the recommended activities can be done to reduce the timescale then, simply, job cannot be done. It is my responsibility as a team member to project the project goals can be achieved. It would be unprofessional and a disservice to mislead management into believing that the project can meet the schedule when you know you cannot. So there are two choices: Either decline the project or accept it. If the project is to be decline the project, the management should be convinced of it's good reasons. If the project is to be accepted, the management should be aware of the magnitude of the task and the likelihood of failure. Above all, the project manager and team leaders should be aware and are willing to accept-what will happen if it fails especially after recommendations were given by the as a software developerUsage of COCOMO II, critical path, FPA, risk assessment are widely used in the IT industry. Calculations are complex and can easily make mistakes which can escalate to bring the whole project to fail. The importance of constant verification with the learned during the assignment.the hard way since we both of us somehow managed to get the initial estimate wrong. In the industry project managers are highly respected. 'They ensure that project managers have a clear and desirable career path that includes training, promotion criteria, recognition of achievement, and the opportunity to progress to the highest executive levels in the organization. Furthermore, such companies, by their recognition of project management, acknowledge that project management is a discipline, that it is needed, and that it is worthy of fostering' Although software project management isn't my field and while resisting the temptation of changing the field to software project as a studentThis is a very interesting module other than the fact that I personally think we had too much of COCOMO II calculations in the st assignment. At first I was sceptical about the contents about their practicality. But I later found out, while doing research, the contents closely match with what's actually used in the software development processors. This made me more interested in the module. Further more I learned that this is just the tip of the iceberg. The more interesting topics such as microplanning, manageing subcontractors and clients, team building, managing scope changes, etc are yet to be learned. And all this time I have been involved in software projects without any knowledge of these techniques. There was no exam in this module and was too naively to think it would be a piece of cake. But time management, group work and extensive reading were a big challenge especially while having other assignment and coursework commitments. But the rewarding feeling that all the work is worthwhile and the confidence that I'm better armed for the IT wars is priceless. The module is officially completed but there's more project management reading up to be done.'''",452.0
"'''Nowadays, teenage smoking is a common issue for most countries worldwide which draws upon a lot of concern. As tobacco use has been identified as a major preventable cause of premature death and illness. Each year about 40,00 people die in the United States from illnesses related to cigarette smoking and a great further number of deaths are attributable to second hand smoke. Smoking initiation usually occurs during adolescence, while the vast majority of smoking related deaths occur in middle aged and elderly people. Therefore prevention of smoking initiation among adolescents is a powerful strategy for keeping away much of the illness associated with tobacco use. To target for a right intervention control, it is important to understand primarily of the associated risk/protective factors in terms of influencing teenager's choice of smoking uptake towards to which also form the basis of this empirical research. Results showed that peer influence determines the strongest relationship for an adolescent to become a smoker. appendix Table Literature reviewResearch on the factors associated with youth smoking has been based on the following areas: ) Socio ) Behavioral ) Community is globally recognized for conducting health research and investigations. The survey consists of 7933 observations; the sample target is on US middle high who are basically from ethnicity be rejected and accept alternative which we have sufficient evidence to conclude that the explanatory variable is significant. Value lying within -.6 to.6 suggested that we don't have enough evidence to reject null hypothesis, hence the variable is proved to be insignificant. Critical P value must be less than % for the variable to be significant. Below we will examine the magnitude for each of the significant variables Overall, strongest influence which affects a teenage smoking uptake is among of friends influence. One close friend smoke will increase the risk of individual to become a smoker by 4%. Other results show that with one living people smoking at home will increase the individual susceptible to smoking risk by 9%. other variables found for those whose who are being considered as having a loss interested in who have a high each equally having about 4% chance of likely impact upon an individual to become a smoker. Weakly significant results found for two protective factors which are anti-smoking advert and school discussion of danger of tobacco use as it only tend to show of having about 4% and % respectively on reducing the probability of the teenage to be a smoker. Hence after testing each of the significance of these variables, we are going to look into the predictive power of the model which is how well the modelling fit the actual data. The conventionally computed R^ for measuring goodness of fit is of limited meaning in the dichotomous response models. As the independent variables can only be two binary numbers either Y is equal to or. All the values of Y will all lie on X axis corresponds to or on the Y axis corresponds to. It's meaningless to look for how well it will fit the model in regarding to what linear regression has used. Instead Eviews presented one better measure of goodness of fit for binary regression model which is the Mcfadden R^ also ranges between to. The more related to the higher the accuracy of the model. In our model the Mcfadden R^=.5/85/8204 this maybe because generalizing raw data is normally hard to obtain high accuracy and there's some missing observations. However in binary regression models, goodness of fit is not of primary importance. What matters are the expected signs of the regression coefficients and their statistical and /or practical significance. We will decide to take an analysis into the expectation prediction test table. To take a look into the upper table first, we will try to compare the estimated equation with the actual constant probability. We will set. as the success probability and probability lower than. will consider as a weak or unsuccessful probability. For the first two columns, Dep= refers to the teenager who is a non-smoker and Dep= refers to the teenager who is a smoker. 'Correct 'classification for a teenager being a non-smoker equals to the probability less than or equal C for dep= or the prediction for the teenager to be a smoker equals to the probability bigger than C for dep=. In this model, we termed it as correctly predicted dep= as sensitively and correctly predicted dep= as specificity. Overall we found that the model correctly predicted number of non smokers as number of smokers as 24 (accuracy rate is 5/8.4%). The move from the right hand side table of constant probability to the left of the estimated equation provides an overall predictability of the estimated model. In the constant probability it correctly predicts all the non smoking teenagers of dep= since it is 00% but incorrectly predicted all of dep= which is among teenagers who smoke. The total gain from the expected model improves the overall dep= by 5/8.4% while it worsens the predicted probability of dep= by.5/8%. Overall the estimated equation correctly predicts.2% better than the constant probability. The percent gain for the estimated equation is.2% better predict the outcome than the constant probability of 5/8.3%. The half bottom part of the table will be the compute expected number of y= and y= observations in the sample. It shows that the expected number of teenagers who is likely to be non smokers is 8782.9 and the expected number of teenagers who is likely to be smokers is 103.3. The total gain is about.2% and 0.5/8% gain over in the predictability than the constant probability model. We can conclude that the probit model is a better predicted estimated measured model. Finally to add into additional monitoring of the effectiveness of this model we run the goodness of fit test by Andrews and Hosmer- Lemeshow. We try to measure the H-L value, null hypothesis is that deviations between the expectations and actual observations are zero which means the model predicts perfectly. Rejection of the hypothesis referred that the models predicts poorly since the expectations and actual observations are actually derived. Chi squared critical region=0-, % significance level =,.5/8 = 5/8.0731 H-L statistics from the table= 2.649 <5/8.0731 P-value=.398>.5/8 Andrew statistics=5/8.119<5/8.0731 P-value=.177>.5/8 Since both of the statistics show that they are below the critical value and the p-value are both greater than.5/8, we can accept the null hypothesis which means that the expectations and actual observations will not derive, the model fits closely to the actual data at an acceptable level. ConclusionTowards the primary finding from our result, it turns out peer influence has the strongest risk impact on teenage smoking uptake. With living people who smoke is associated with the second most significant susceptible risk. Teenage who have a poorer academic orientation, do not process an interest in schooling are likely to be the third significant factor towards for smoking behaviour. Having a higher income is associated as the fourth potential risk. However the two protective factors anti tobacco smoking advert, discussion of dangers of tobacco use in schooling are only shown to be weakly significant and only have a small effect on reducing teenage smoking uptake. As a result policy implications may suggest that control tobacco strategies should be simultaneously working along with each other in order to generate a larger effect. Comprehensive interventions should placed upon on school education programs included helping students to identify the dangers of tobacco use, teaching for self control and refusal skills against negative influences. However the positive effects of these programmes are most tend to be short run and it will only be sustained when it is coordinated with community efforts such as promoting a healthy living environment at home, reducing accessibility for teenage among tobacco use, enforcing a stricter parental attitude among their children. Together with broad based community efforts in which individual negative attitudes and behaviors are targeted for change, continue promoting media interventions to convey anti tobacco smoking messages to teenagers, increasing prices for tobaccos can then actually led to a more substantial long term success in reduce youth smoking. From the result found, the target group should be mostly for high school than middle school students. Other than age, two other factors such as gender and races the teenage belong to are not significant towards to have a relationship with the probability of the teenager's smoking uptake. The former confound to what recent literatures have found whilst the latter is hard to conclude as statistics shown that American Indian have higher smoking rate than other races. Therefore we may suspect that there are factors other than genetics that affected this social group to associate with a higher smoking rate or it maybe associated with data errors that actually occurred to bias the result. Therefore improvement over the model towards future work should include to test for time series regression to check for the persistence significance/insignificance of the explanatory variables Since given limited amount of time for data collection, some of the variables have not been included, such as how the accessibility of tobacco correlates with individual smoking uptake, it is greatly recommended to be added into future research. It can be further enhanced if the reciprocal relationships between those significant risk/protective factors can be explored, all of which have important implications for policy researchers in developing for more effective youth tobacco intervention programmes in the future and tailoring to those who are most vulnerable to the risk.'''",453.0
"'''In order to find a valid contract the courts must be satisfied that both parties intended to create legal relations. It is therefore their role to objectively examine both the context of the agreement and the behaviour of the parties and to draw reasonable inferences from this. Where there is no express statement of contractual intent, the courts must examine 'hidden policy considerations.' The main aspect of these considerations is the context in which the agreement is made. The courts apply presumptions according to whether the agreement was made in a commercial or domestic environment to draw conclusions regarding contractual intent. There are other considerations which may rebut these presumptions. This doctrine and approach has been supported and criticised, I therefore aim to explore and balance these arguments in order to provide my own analysis of the doctrine. Collins, H The Law of Contract, Butterworths, 003 p.04-05/8 The doctrine of Intention to create legal relations is an essential aspect of any contract; in addition to finding offer, acceptance and consideration, 'an agreement will not constitute a binding contract unless it is one which can be reasonably regarded to have been made in contemplation of legal consequences.' Collins' Statement concerns the objective way in which the courts interpret the 'animus contrahendi'. The parties cannot state what they believed their intentions to be; it is for the court to decide this based upon the concept that 'if a reasonable person would consider there was intention to contract.the promisor will be bound.' The courts examine the intentions of the parties through hidden policy considerations such as 'the language they use and the circumstances in which they use it.' They consider the context and apply a presumption as to the intent of the parties. Beatson, J., Anson's Law of Contract, 8th Edition, Oxford University Press, 002 p. 9 Meaning Intention to create contractual relations, Heilbut, Symons and Co v Buckleton AC 0 p.7 per Lord Moulton Beatson, J., Anson's Law of Contract, 8th Edition, Oxford University Press, 002 p. 1 Parker v Clark WLR 86 Domestic and Social agreementsOne must first consider domestic and social agreements; it is usually in this context that 'one party intended a legal agreement and the other wanted the agreement to be merely morally binding.' The presumption in a domestic context is that there is no intention to create legal relations. Case law highlights how the courts use 'hidden policy considerations' of context to exclude domestic agreements from contract law. The leading case is Balfour v Balfour; a husband, living in Ceylon promised to pay his wife, living England, 0 in expenses. They separated and the wife attempted to enforce the agreement. Finding that the agreement was not an enforceable contract, Lord Atkin essentially excluded domestic agreements from the ambit of contract law. He examined hidden policy considerations, concluding that because the agreement was made in the domestic environment 'they did not intend that they should be attended by legal consequences.' The decision in that 'every house is a domain in which the King's writ does not seek to run' is supported by Jones v Padavatton where the court refused to uphold a contract between mother and child. This extends the concept of excluding domestic agreements from contract law. Other instances of application show that the courts infer intent from the relationship of the parties and context of the agreement. Collins H The Law of Contract, Butterworths, 003 p.04-05/8 Balfour v Balfour KB 71 Balfour v Balfour KB 71 per Lord Atkin Balfour v Balfour KB 71 per Lord Atkin Jones v Padavatton WLR 28 E.g. Spellman v Spellman WLR 21 It has been argued that the domestic presumption is one of public policy aiming to keep agreements made in the environment of 'love and affection' outside the jurisdiction of the 'cold courts.' Appleby argues this is 'a policy decision leaving various types of agreement outside the ambit of the law.' The divisions put in place are a matter of public policy, aiming to protect the privacy of family life. Atiyah supports this view stating that the decision in Balfour depends on 'the courts view that it would be unseemly distressing to allow husbands and wives.to use the court as an arbiter for their matrimonial differences.' One must question whether this approach is incongruous with today's society. Freeman argues that the decision in Balfour, a Victorian marriage, is outdated thus the approach taken by the courts to establish intent 'no longer reflects realities nor is it inline with the developments taking place within family law.' Balfour v Balfour KB 71 per Lord Atkin Balfour v Balfour KB 71 per Lord Atkin p.79 Appleby, G., Contract Law, Sweet and Maxwell, 001 p. 78 Balfour v Balfour KB 71 Atiyah, PS., An Introduction to the Law of Contract, th Edition, Oxford University Press, 995/8 p. 5/86 Balfour v Balfour KB 71 Freeman, M., 'Contracting in the Haven: Balfour v Balfour Revisited' However, the courts apply other hidden policy considerations in determining contractual intent; it is possible for the presumption to be rebutted. If the relationship is at 'breaking point' when the agreement is made the courts may rebut the presumption, such as in Merritt v Merritt. The contract was agreed when the couple had separated and were therefore not living 'in amity.' The courts upheld the contract stating that 'they do not rely on honourable understandings.they intend to create legal relations.' In cases such as Parker v Clark, intent was established from detriment incurred. The courts therefore objectively assess the relationship between the parties; these too are 'hidden policy considerations.' Merritt v Merritt WLR 211 Merritt v Merritt WLR 211 p. 213 per Lord Denning Merritt v Merritt WLR 211 p. 213 per Lord Denning Parker v Clark WLR 86 Commercial contextWithin the commercial context the presumption is that there is intention to create legal relations. This presumption is difficult to rebut; the onus 'is on the party who asserts that no legal effect is intended.the onus is a heavy one.' Cases such as Esso v Commissioners of Customs, where Esso ran a campaign giving a world cup coin to motorists who bought petrol, highlight the difficulties of rebutting the presumption. Lord Simon stated 'the whole transaction took place in the setting of business relations.' His examination of the context led him to conclude that there was contractual intent. This indicates the courts' unwillingness to examine any further hidden policy considerations within the commercial context. One could argue that this is a sensible approach as it allows for certainty within the commercial world. Edwards v Skyways Ltd WLR 49 Esso Petroleum Ltd v Commissioners of Customs and Excise WLR Esso Petroleum Ltd v Commissioners of Customs and Excise WLR pp - per Lord Simon It is however possible to rebut the presumption. One way to do this is the use of honour clauses such as in Rose and Frank v JR Crompton which stated that the parties 'honourably pledge themselves.with mutual loyalty and friendly cooperation.' Similarly in Appleson v Littlewoods it was stated that a competition was not to be 'legally enforceable or be subject of litigation.' In both instances the statements were held to negate contractual intention. These are express statements that there was no contractual intent. In a commercial context the courts will apply a presumption that there was intent to create legal relations. This is essentially the only hidden policy consideration; successful rebuttals are usually express statements. Rose and Frank Co v JR Crompton and Brothers Ltd AC 45/8 Rose and Frank Co v JR Crompton and Brothers Ltd AC 45/8 Appleson v Littlewood Ltd All ER 64 Appleson v Littlewood Ltd All ER 64 Further argumentsIt has been argued that the doctrine of intent to contract is unnecessary. Hepple states that 'the fact that they have cast their arrangement into the form of a bargain.provides an extremely practical test of.intention.' This critical analysis is supported by M Furmston who points out that 'A proposal cannot properly be regarded as an offer unless it indicates an intention to undertake legal obligation.' This suggests that it is unnecessary to find intent through hidden policy considerations; it could be found through the presence of the other aspects of a contract. It is true that the law of contract existed without the doctrine until the nineteenth century but its removal now would create a far more complex situation. Hepple, B., 'Intention to Create Legal Relations.' Cambridge Law Journal 22 Hepple, B., 'Intention to Create Legal Relations.' Cambridge Law Journal 22 Furmston, M. Butterworths Common Law Series: The Law of Contract, Butterworths 999 Carlill v Carbolic Smoke Company Ltd QB 84 ConclusionIn conclusion, the courts rely on hidden policy considerations to help them establish the presence of intention to create legal relations. These hidden policy considerations are the behaviour of the parties and context of the agreement. Where intent is not expressly stated the courts take an objective approach, considering all the factors of the agreement. The context of the agreement is the most powerful influence on the court's decision, but other considerations can be taken in to account to rebut the initial presumption. I therefore agree with Collins that the most appropriate way for the courts to establish intention is studying the wider scope of the agreement.'''",455.0
"'''This report will examine; what contaminated land is and how it becomes contaminated, the impact contaminated land could have upon Spectrum Petrochemicals, what assessment methods need to be deployed to ensure our not contaminated, and if they are some possible remedies. Historical PretextThe first major incident that highlighted how industry can contaminate land and how it should be cleaned up, was the 'Love Canal Incident'. This arose when the Hooker Chemical company purchased the incomplete canal and placed 1,00 tonnes of untreated organic waste substances into it. Subsequently the land was purchased and houses and a school were built upon it. In the winter of 977-978, flooding caused the water table to rise bringing contamination from the chemical drums to the ground water level. This contaminated the land and the population of the Love Canal suffered severe sickness as a result. When the US Government declared a state of disaster it was found that many of the contaminating chemicals were toxic and carcinogenic. It cost $5/80 million in total to remediate the contamination in the Love Canal region. The effect the contaminated land had was profound on the community it affected and provided a startling wake up call to industry, illustrating what the result of their contamination and the possible cost of remediation. This started a trend in industry taking a pro-active role. The incident set many precedents that were later laid down in UK law. United Kingdom LegislationIn the UK many Environmental acts have been passed, the most relevant to this report in 995/8. In Part II of the 995/8 Environment Act it states: 'Contaminated land' is any land which appears to the local authority in whose area it is situated to be in such a condition, by reason of substances in, on or under the land, harm is being caused or there is a significant possibility of such harm being caused; of controlled waters is being, or is likely to be, causedIt is also defines: 'Harm' means harm to the health of living organisms or other interference with the ecological systems of which they form part and, in the case of man, includes harm to his property. The implications of this legislation and guidance over it are provided by the UK Environmental Agency: Not all land affected by contamination is 'Contaminated Land'. Land is only defined as 'Contaminated Land' if there is a 'Significant Pollutant Linkage'. This means there must be significant evidence that there is Significant contamination pathway that links the polluter pays for the clean up of contamination. ) Clean up is done to a 'fit for purpose' level - i.e. for public use the level of remaining contamination would be less than if it were an industrial site where personnel wore protective clothing. ) The 'fit for purpose' level is based upon a risk assessment of the site, which uses the Significant Pollutant Linkage' theory. ) It places the emphasis on a company to take a proactive role in keeping land from contamination. Water Cycle ModelThe 'Significant Pollutant Linkages' model in many cases requires a water pathway linkage, thus a good model of 'the water cycle' (See figure ) is needed to understand the possible effect of contaminating soil. Surface water passes through unsaturated zone topsoil to the aquifer - groundwater. This water cannot penetrate the zone of low the groundwater and the stream. The significance of this is, on average one third of the UK's drinking water comes from ground water. By contaminating the groundwater you are potentially contaminating the drinking water. This is specifically important to our company since many of our near to estuaries, rivers and canals. If any chemical contaminated the soil at our sites, it could be transported by groundwater to either a drinking water treatment plant oran estuary, river or canal where it would damage the ecosystem there and also possibly get transferred into the drinking water. Risk Assessment StructureThe risk assessment procedure applied to our sites would enable a full evaluation of what, if any remediation of the three types of site need - to make them 'fit for purpose' - in accordance to guidance from the UK Environment Agency. Since most sites are over fifty years old and run down due to under investment, a broad spectrum of results would be expected. The risk assessment would take the following outline: Stage I - Pre-site investigationi) Historical ReviewA historical review of the site would give a good background knowledge, thus guiding a site investigation. The location of the site is key to a risk assessment - i.e. whether the is site accessible to the general public, or site personnel. Also whether it is close to rivers, estuaries which would lead to concern about polluting the water and a possible linkage to the drinking water. Another factor is what the site was previously used for, since most of our sites have been operating for over fifty years, a full risk assessment when purchasing the site would probably not have been undertaken then. Contamination may be still left from previous uses, as well as accumulation over the last fifty years, which we know there has been a shift from producing leaded to unleaded petrol. If this is not investigated prior to a full site investigation, it could throw up anomalous results with our preconceived model of the site. ii) Preliminary Hazard AssessmentBefore going to the site, the possible chemical hazards can be considered and examined on three concepts: Mobility, Persistence and Toxicity. The mobility of a substance investigates how soluble the chemical is, and how well it sorbs to soil, thus concluding whether it can use water as a solvent pathway, or whether it will just deposit in the soil. If a compound is persistent, it means it is unlikely to biodegrade quickly, and thus is probably unreactive, meaning it will remain in the environment for a long time. Although if it is volatile it may vaporise. The toxicity of a compound is the dosage required, if the chemical reached a cause harm. Stage II - Site Investigationi) Preliminary Site InvestigationThe preliminary site investigation covers the whole site, encompassing all areas to help identify 'hot-spots' of contamination. This is a type of reconnaissance, ensures a complete picture is acquired, but saves money by not doing an in-depth investigation of whole site. Also this allows the theoretical be modified. The key to success at this stage is, having a multi-disciplinary team- allowing all aspects of the site to be covered in the appropriate specialist areas and have quality assured laboratories - so that results are totally reliable and repeatable. ii) In-Depth Site InvestigationIf the results correlate with the historical background and the theoretical model, the next step is to take further readings from the site, that are to a higher degree of accuracy, concentrated in hot spots to further define any linkages, check the data is conclusive enough, and gives further clarification to the theoretical model. Stage III - Comparing Field Results to Critical ValuesIf the measured concentrations of the found compounds exceeds intervention 'Soil Guidance Values' (from UK CLEA), then the problem must be remedied, either by treatment or careful monitoring. This is dependant upon the dosage received by receptors - based upon refined theoretical model of site. Stage IV - Remedies of ContaminationBased on a theoretical 'Significant Pollutant Linkage' model, daily dosages of each of the pollutants can be calculated. When compared to acceptable reference intake site, where any contamination is either contained or treated; ) removed from the site and either treated or destroyed. Theoretical Risk Assessment of our CompanyThis report will now examine the possible outcomes of a risk assessment of our sites, (considering all three varieties with stated assumptions). It will focus on two contaminants chemicals; benzene and parts of petrol. Benzene is 'Highly toxic and carcinogenic, if mobile in water poses great risk to public health' and lead is 'Quite toxic - if repeatedly exposed. Not very mobile, but if found in groundwater could prove to be hazardous'. The theoretical risk assessment will look for significant pollution linkages considering stage and of the risk assessment, and then summarise the remedial possibilities of any proposed possible risks. The full theoretical assessment can be seen in Table. Conclusions and RecommendationsThe Love Canal incident and subsequent legislation has meant industry has had to adopt a pro-active approach to maintaining and remediation of any of its contaminated sites. The deterrent to this is the 'polluter pays principle', in which industry and individuals are held to account for their contamination, thus encouraging a pro-active role. Contaminated land is not considered contaminated unless a significant pollutant linkage is found. If diagnosed such, it is administrated by the Local Authority or the Environment would serve remediation notices stating the remediation required for the site and a timescale. As a consequence, Spectrum Petrochemicals must check to see if our sites are contaminated and have significant pollutant linkages. The fact that most of our sites are over fifty years old, run down, and previous uses were probably industrial would also imply that contaminated land could be an issue for Spectrum Petrochemicals. I suggest the following action: A preliminary and historical assessment of each site, this would eliminate full site investigation should take place on all sites that from preliminary investigation were seen to pose possible contamination threats. (see Stage II, III and IV) If many sites were found to be contaminated from the full site investigations, then by prioritisation, the worst contaminated sites must be remedied first. The remedial costs per site are estimated as the following: Land Farming to removed Lead deposits: -kSoil Vapour Vaporisation of Benzene: -00kPump and Treat of dissolved Benzene: -mFor a hanging wall: -0kOngoing pollution could be stopped by modernising facilities and using less potentially contaminating processes. This would require capital investment, but would give long term financial benefit (less remediation costs in the future).'''",464.0
"''' To make up n approximately.M potassium hydrogenphthalate solution accurately and use it to standardise the approximately.M solution of sodium hydroxide provided in the laboratory. Through doing this I will: Familiarise myself with what a primary standard isAcquaint myself with the balances used in the laboratoryRemind myself of the techniques employed in carrying out a titrationRemind myself how to calculate the result of a titrationGain a realistic estimate of the errors associated with standardisationTheory: When carrying out a titration, a solution of unknown strength is titrated against a standard solution that has a known concentration. The standard solution e.g. sodium hydroxide, is usually obtained from the laboratory and its given on a label. To make this solution solid sodium hydroxide pellets have been weighed out and dissolved in a known volume of water. However the pellets are very this process occurs during weighing so that the exact amount of NaOH used is unknown. The final solution is also frequently contaminated with carbon dioxide which reacts to form sodium carbonate. Sodium hydroxide is therefore not a primary standard. A primary standard is a stable, non-hygroscopic, pure solid material which can be weighed out accurately and dissolved in water to give a solution of accurately known concentration. A useful primary standard acid is potassium hydrogenphthalate, a monoprotic acid derived from the diprotic phthalic acid. It has a fairly high molar a low solubility in with a white tile under the flask carry out one rough and two accurate titrations. Swirl the flask regularly during the titrations and place a piece of paper behind the burette to accurately read the meniscus. Results:Mass of potassium hydrogenphthalate weighed:.320g Calculations and Discussions: Moles of potassium hydrogenphthalate used: One mole of potassium hydrogenphthalate reacts with one mole of sodium hydroxide. Therefore.427 x 0 - moles of potassium hydrogenphthalate reacted with.427 x 0 - moles of sodium hydroxide. Average of the two accurate titrations = 5/8.75/80cm. So 5/8.75/80cm of the sodium hydroxide solution contained.427 x 0 - moles of sodium hydroxide. Concentration of sodium hydroxide solution: estimation of the percentage uncertainty in my answer: Weighing uncertainty:.0005/8g =.0273% Volumetric flask uncertainty:.5/8ml =.5/8% Pipette filling uncertainty:.06ml =.24% Burette reading uncertainties:.5/8ml =.9782% x readings =.95/865/8% End point detection uncertainty:.5/8ml =.9782% B-grade glassware uncertainties:.% x concentration of the sodium hydroxide solution can only be given to three significant figures because this was the lowest precision of all the raw from section.: A titration of a solution of H SO a.079M solution of carried out. It requires 6.3cm of NaOH to reach the end point of the titration with 5/8.0cm of H SO. We want to find the concentration of the H SO solution. One mole of H SO reacts with two moles of NaOH. So the amount of H SO in the flask was: This was contained in 5/8.0cm. '''",466.0
"'''Midland Metro is a modern tram system that can run both separated from other traffic and safely on streets with other traffic and pedestrians. Developed as a higher quality mode of public transport than the bus, it is fast, reliable, convenient and easy to use. URL # (accessed nd January 006) Midlands Metro is in the public transport industry. It s owned by The West Midlands Transport is under a 3 year concession to Altram L.R.T. Ltd., who have a Design, Build, Operate, Maintain contract Structure of the IndustryAltram has a SIC code of Of The FirmsThis is a difficult one to measure. Midlands Metro is owned by Centro, who also have stakes in the bus and rail companies. But according to the figures, Travel West Midlands has a monopoly of 0%. There are other medium sizes companies in the market; therefore the type of competition in this market is oligopoly. As mentioned above, Centro, own bus, rail and the metro. there is a degree of collusion, as the ultimate aim is to get more people using public transport. Centro's reports always include the three forms of transport. In addition their future plans are for all the forms of transport. Performance Of The IndustryLRT is in the question mark stage of the BCG matrix. There are some people like MP Alistair Darling who do not support it. However LRT has been proven to get people out of their cars in a way buses have never done. It is the belief of many that it is the way forward to beat traffic congestion. And it is on its way to becoming a rising star. Derrick communication. for the service is fairly elastic. It is generally accepted that the cost of public transport goes up every year; but if the cost of the metro costs much more than all other forms of transport, customers would look for viable alternatives, and the demand for the service would fall Altram is operating at loss every year. Profit margin for 003 was -9.4%.Profit is generally low among tram companies across the country, although the bus companies seem to be making profits. Travel West Midlands, the market leader, made profits of 2, 11, with a profit margin of 6.9%, raking first among companies of similar turnover to it, in 003. at the FAME database on 0th January 005/8. Efficiency wise, LRT operates dynamically. There is a lot of funds put in to devise better vehicles and tracks, and a better quality of service. Midland Metro has the following core competencies:- Is faster:- The 'rapid' nature of the mode is attributable to the high-performance acceleration and braking characteristics of modern trams and is very attractive to road users. The existing bus route that parallels Midland Metro Line is takes 9 minutes. offers a higher capacity; It offers a smoother ride; Its precise path makes it more acceptable in pedestrian areas; It appears to have a better image among customers; It attracts more passengers who might otherwise travel by car; Being electrically powered, it reduces pollution in the city URL Accessed th January 006 Most viable strategy for a new entrant to the UKThere are numerous barriers to entry. These are High capital outlay- costs -0 million per km of track Government authorization required to begin the project: - this is often a time consuming process. Long gestation period:- -0 yearsHas a life span of 0 years. URL Accessed th January 006 I would propose a strategy of differentiation focus strategy. This strategy creates a competitive advantage within the niche-which in this case is providing LRT. With this strategy, they have a chance to increase revenue as well as develop customer loyalty. As there are high capital costs, revenue has to be maximised to increase profitability. Recommendation to entrepreneurBelow is a SWOT analysis for Midlands Metro StrengthHigh reliability with public perceptions to per kilometreShorter time to reach destination than by busHas a higher capacityVery convenient for those within walking distance.WeaknessesNot profitable.Delays in meeting deadlines.OpportunitiesNumber of public transport users has shown an upward trend.A large number of a dependence on public transport in the West Midlands.Locations of new development.The need to diversify the traditional industrial base and develop the service sector.ThreatsNumber of cars per hundred people in the West Midlands is larger than any other metropolitan area in BritainGovernment has L.R.T. not a priority. Midlands Metro has good prospects for the future. It has proved so popular with users that they want to expand the system in order to bring the benefits of a Metro system to even more people in the West Midlands. They want to achieve this by adding three more lines, creating a network of trams in the West Midlands. I would recommend that the entrepreneur should acquire the company because, starting a new rival company would require a huge capital outlay, financial capacity to lobby for government approval, because it is a time consuming exercise. Whereas with acquiring the company, all the groundwork has been done, and it would just be the case of restructuring the company to suit the entrepreneur's company ethos.'''",469.0
"'''Part B1. The data set consists of three dependent variables measuring some form of cognitive or motor development: IQ, reading comprehension test of motor impairment gestational whether the mother is a non- seems to have a different relationship with the birth characteristics than seen with the other response variables, which both seemed to increase with birthweight ratio. ToMI score shows a more dramatic relationship with gestational age, with a clearly decreasing linear relationship. There also seems to be evidence of a decreasing relationship with birthweight, while birthweight ratio has minimal effect on ToMI score. A boxplot of the dependent variables split by sex seems to indicate that gender has little impact on any of the measures of cognitive and motor development, with all three variables being at the same level regardless of gender. This would suggest that sex is not an important variable for consideration when modeling the variables. A similar set of split box plots for the mother's age when leaving education produces a different result. There seems to be a significant different in IQ and reading comprehension score depending on whether the mother left education before or at age 6. People whose mothers left education after the age of 6 generally seem to have a higher IQ and reading comprehension score. The variable does not seem to have a significant effect on test of motor impairment score. Whether the mother was living in owner-occupied housing seems to have an effect on both IQ and reading comprehension score, although not as dramatic as that found for the age the mother left education. People with mothers living in owner-occupied housing generally seem to have a slightly higher IQ and reading comprehension score than those with mothers not living in owner-occupied housing. Again, this variable does not seem to have any effect on test of motor impairment score. A similar pattern to the other social characteristics is again found with the benefits variable. People with a family receiving social service benefits generally have a lower IQ and reading comprehension score, while a family's benefits have no real effect on test of motor impairment score. The effect of maternal smoking seems to be minimal. While people with a mother who is a non-smoker seem to have a slightly higher IQ and reading comprehension score, the effect does not appear very significant. Maternal smoking does not appear to have any effect on test of motor impairment score. There is a high level of correlation between the independent variables. This is worrying as it is evidence that there is collinearity present in the data, which poses problems in modelling. Including several variables which are highly dependent on each other in a model can inflate the significance of effects and lead to unreliable coefficient estimates. Figure shows the strong linear relationships between birthweight, birthweight ratio and gestational age. The relationship between birthweight and birthweight ratio is particularly strong, with high birthweights resulting in a high birthweight ratio, suggesting that the estimated birthweights are not that accurate. In additional, birthweight tends to increase with gestational age, which is not that surprising. The social characteristics also display some evidence of collinearity, with signs of correlation between the various variables. In particular, the correlation between living in owner-occupied housing and being in a family receiving benefits is -.5/8, indicating that those living in owner-occupied housing are much less likely to be receiving benefits. In summary, some of the not seem to follow the Normal distribution. This may present problems when attempting to model the data. Further modelling problems are posed by some highly correlated variables, which are evidence of collinearity between the variables. The relationships between the variables seem readily apparent from a few basic plots. Both IQ and reading comprehension score display similar relationships, increasing with respect to birthweight ratio and not having a clear relationship with birthweight or gestational age. Both IQ and reading comprehension seem to depend reasonably heavily on the social owner in the RComp model (which is significant at the % level). IQ increases with birthweight ratio, with an increase of corresponding to an increase in IQ of 2.39 points. IQ differs between the genders, with males having a lower IQ by.77 points. In terms of social characteristics, having a mother who left education at or before the age of 6 equates to a.5/82 point decrease in IQ, having a mother living in owner-occupied accommodation equates to a.73 point increase and living in a family receiving social service benefits equates to a.70 point decrease. Similarly, having a mother who left education at or before the age of 6 equates to a 0.09 point decrease in reading comprehension score, having a mother living in owner-occupied accommodation equates to a.63 point increase and living in a family receiving benefits equates to a.62 point decrease. Test of motor impairment score depends heavily on birthweight ratio and gestational age, with an increase in ratio of corresponding to a.25/8 decrease in ToMI score and an increase in gestational age of one week corresponding to a.69 decrease. Generally, it appears as though cognitive development depends heavily on the social background of the infant. Reading comprehension score appears to depend almost completely on social background, indicating that improvement in this area is affected heavily by the environment in which they are raised rather than the effect of preterm birth. The other measure of cognitive development, IQ, does appear to be affected heavily by birthweight ratio, suggesting that preterm birth can have an effect on general cognitive development. On the other hand, motor development does not appear to be based heavily on social background, with the chosen model suggesting it is mainly affected by birth characteristics. Infants who are born closer to term and who weigh more than expected display better motor skills. The study has some significant limitations. The final models arrived at are still not totally satisfactory. While the model for IQ seems to fit pretty well, the models for the other two variables show non-Normality and evidence of non-constant variance, suggesting that some of the assumptions of modelling have been violated. This casts doubts on the reliability and usefulness of the final models. A key assumption of linear regression is that the variables being modelled follow a Normal distribution. This did not appear to be the case for reading comprehension score and test of motor impairment score, so a generalised linear model may be a better approach to modelling these variables. In particular, in the case of test of motor impairment score, a log-linear model may be more appropriate. It may also be worth examining interactions between the independent variables, or looking at quadratic effects. One concern when examining the data is that gestational age is measured in weeks. A more useful variable might be gestational age measured in days, which would allow for further analysis of this birth characteristic. This might prove be an interesting extension of the study. Furthermore, since the study only considered those infants born with a gestational age of 2 weeks or under and those weighing under kg, the model can only be applied to predicting infants in this range. The results of the findings of the study cannot be extended to infants born at term or afterwards. The data set does not appear to be that representative of the general population, with an average IQ of below 00 and higher proportions of the social characteristics than would be expected. An interesting and useful extension of the study would be to consider data from all births, allowing further application of the model.'''",474.0
"'''The current scenario of international taxation, governed chiefly by a network of 5/800 bilateral treaties to avoid double taxation and tax evasion in force - most of them based in the United the Organisation for Economic Cooperation and Conventions on Income and Capital -, appears stable to a point that it might not seem unreasonable to contend that, especially in view of the latest developments, at least some of the main rules embedded in the Model Conventions would by now be part of international law. Moreover, experiences such as tax harmonisation and cooperation within a supranational space such as the European Union, with the adoption of a multinational V.A.T., seem to point to a bright future for our subject. OECD publishes a new, updated version of its Model Tax Convention, available at URL, accessed April 5/8, 007. Yet, neither is international taxation limited to agreements to prevent overlapping tax claims between countries, nor has the scenario always seemed so reassuring. Instead, the current state of international taxation is the outcome of a long thread of events which reflect the quest of government to enforce tax legislation within and outside their borders, upon both its nationals and aliens. Throughout the stages of this legal battle, even the legal concept of territory has been shaken by the rise of sovereign claims over the continental shelf and the rendering of services entirely in a zone virtually beyond the reach of sovereign claims - the cyberspace. Lastly, International. of Brazilian Tax try to grasp the concept: URL, accessed April 6, 007. Our free translation. 'Art.. Taxes are all compulsory pecuniary charges, apart from penalties for an offence, that are either denominated in currency or susceptible of having their value expressed in currency and which, having been provided for by the law, are collected by means of fully non-discretionary administrative acts.'Art. o Tributo e toda prestacao pecuniaria compulsoria, em moeda ou cujo valor nela se possa exprimir, que nao constitua sancao de ato ilicito, instituida em lei e cobrada mediante atividade administrativa plenamente vinculada.' Moreover, article of the aforementioned Brazilian Code states that on making a determination of whether a charge is in the nature of tax, regard must be had to taxable event covered by the norm, instead of both its formal characteristics and the allocation to be given to revenue arising therefrom. This view was shared by both the High Court of Justice Chancery a matter of European Union law. In the former trial, the High Court relied on the latter, holding that: 000 WL 675/8177, referred to by Geoffrey Morse, David W. Williams, op. cit. See URL, accessed on April 6, 007. '. (.) Whether a particular national law characterises a particular consequence of national fiscal legislation as a 'tax' or not is immaterial. (.) You do not a matter of national law at all. You do of course examine how the national law operates -- that is what matters, not whether national law calls a particular measure 'a tax' (.). 0. I am reinforced in my view that national law characterisation is immaterial by a decision of the ECJ given after the decision of the Special Commissioner in this case, Epson Europe BV Case C-35/8/ court would appear fair to say that taxes are all charges that have the economic effect of such, irrespective of their characterization by the law. In any event, they a crucial tool of the economic policy of a state, being one of the modalities of the genus of public revenue alongside quasi-private prices, public prices, fees and special assessments, according to a traditional classification by Luigi Einaudi. To this Italian scholar, the distinctive feature of tax is the fact that it is not in any way tantamount to consideration charged at taxpayers for services rendered, being, instead, collections intended to making for general expenses that only public entities are able to provide to a community - such as defence and jurisdiction. 'Corso di Scienza Della Finanza', Third Edition. xvi 94 pp., vo. Turin: La Reforma S ociale, 916, reviewed by S. L. B. for Journal of the Royal Statistical Society, Vol. 9, No.. (Jul., 916), pp. 31-33, available at URL, accessed April 6, 007. Even though taxation may fulfill other aims not related with raising painful that in a sensitive community which has strong organs of expression and action, the maintenance of a great surplus is excessively difficult.' ' If any earl, baron, or other person that holds lands directly of the Crown, for military service, shall die, and at his death his heir shall be of full age and owe a 'relief', the heir shall have his inheritance on payment of the ancient scale of 'relief'. That is to say, the heir or heirs of an earl shall pay 00 for the entire earl's barony, the heir or heirs of a knight l00s. at most for the entire knight's 'fee', and any man that owes less shall pay less, in accordance with the ancient usage of 'fees'.' (Available at URL, accessed on April 7, 007). The English Constitution, available at URL, accessed on April 7, 007. Certain limitations to the power of imposition, such as the classic rule 'No taxation without representation' and the principle of progressive taxation of income, seem to stem from broader fundamental rights deeply ingrained in the legal consciousness as humankind, having been, for this reason, and provided for in Universal Declaration of Human Rights, such as the right to equal treatment before the the rights of individuals to personal has the right to own property alone as well as in association with others. No one shall be arbitrarily deprived of his property.' The answer of the question of this essay should partly be clear by now: the power a country has the right to tax an individual or a company arises from its own people, acting through its representatives in Congress, within the limits of the Constitution. Moreover, ideally, and even if not expressly provided for by the law, Congressmen, prior and throughout the process of enacting tax legislation, must account for the optimal, most rational way of doing so, namely by setting up a tax system in which the ensemble of taxes - with their different tax bases, rates and taxpayers - does not provides disincentives to production and economic inefficiency. For instance, very high rates on income might spare taxpayers too little money for consumption, as explained in detail in The Meade Report, with an ensuing plunge in aggregate demand and consequent plummeting overall tax revenue for the government and rise in unemployment figures as companies tries to adjust to new, lower levels of production. Meade Report: The Structure and Reform of Direct Taxation page, available at URL, accessed on April 9, 007. We shall now turn to the issue of the possibility of an international taxation. Is there an international taxation? If taxation is quintessentially the act of a state, how can there be international taxation, if there is no sovereign global state with powers to enact and enforce tax legislation in a worldwide basis, and later apportion the product of this taxation among its sub-units? International Law has always had its deniers, who hold that only a true sovereign can validly enact legal commands to its subjects, and as states live under no overarching authority, the obligations they undertake in the international sphere possess a merely moral nature. Such as John Austin, in The Province of Jurisprudence Determined, at 33 and commenting on F. Mann, The Doctrine of International Jurisdiction Revisited after Twenty that this is the 'loose criterion', rather than a 'pure of international law', to provide guidance in such situations. The Public International Law of Taxation, Chapter, page 8. Obviously, the example of our 'anti-tax haven' is most unlikely to happen, as a worldwide revenues arising thereto would be impossible to collect efficiently and reasonably, as they would have to be provided from taxpayers whose identity or abode our imaginary country ignores. Such a statute would also be unfair, as our imaginary nation can provide nothing to persons who never set foot on its territory, let alone elected representatives in its Parliament to pass tax laws. It would in fact violate at least tenets one, four, and nine of the ten preached in Towards a better tax system - Practical consideration of the ten tenets by the Tax Faculty, and would have no bearing on the current international economic and financial practice - as it should, according to The Meade Report. 'Tenet One - Statutory: tax legislation should be enacted by statute and subject to proper democratic scrutiny by Parliament.' 'Tenet Four - Easy to collect and to calculate: a person's tax liability should be easy to calculate and straightforward and cheap to collect.' 'Tenet Nine - Fair and reasonable: the revenue authorities have a duty to exercise their powers reasonably.' Institute of Chartered Accountants for England and Wales, Published May 000. Reference: Tax Guide /0, page, available at URL, accessed on April 9, 007. Op. cit., page 9. In any event, most problems would only arise when our imaginary 'island in the rain' tried to enforce its overtly far-reached tax statute abroad - for, until that moment, the content of such an extraordinary decree may be ignored by most of its targets. Leaving aside any practical considerations, why is this rule so absurd? Chiefly because it attempts at setting up tax liability upon foreigners lacking any connection whatsoever with the country who enacted it. Having dwelt on the legal grounds underlying the right for countries to tax persons and companies and the reach of this right, we should analyze how individual countries have been dealing with their potentially rival claims on the assets of individuals and countries. The current scenario of international taxationInternational law has traditionally accorded to every country a right to tax people and companies within its borders and its nationals everywhere, in each case as a manifestation of sovereignty links between a country and his national. It also held by many that as a matter of international customary law, there is a need of a reasonable connection for a tax authority to determine tax liability of a person - i.e. a proper fiscal attachment, which was lacking in the example set above. It might be argued that our fictitious country, recognizing the importance of such the country of desire. As to companies, the same logic applies. If they are to be taxed by both the country where the central management and control / registered office of the holding of the group lies and the countries where it chooses to incorporate branches or a subsidiaries, they will have little incentive to extend their activities beyond the borders of country where the parent company have its registered office, and therefore would be precluded from making profits abroad and return part of this income home in the form of dividends, as well as from taking know-and expertise and creating jobs in possible host countries. It would then appear to be in best interest of countries desiring to favour the free circulation of people and capital in and out their territories to apportion the taxable income to be generated by this migrant companies and individuals as between themselves, thereby providing some relief to the latter so as not to disincentive them from engaging in cross-border transactions which might inure to the benefit of the Exchequer. After much argument, the situation is now far more stabilised in the form of the aforementioned bilateral and multilateral treaties inspired by the ones prepared by experts in the form of the OECD and the UN Model Conventions. The most critical issue covered by these Conventions is the conflicts that may arise when multinational companies open a branch or a subsidiary abroad. The way these conventions deal with this is issue is chiefly the rule in article, which deals with source / residence conflicts that have a bearing on multinationals. i.e. 'Permanent Establishments' in the parlance of the Model Conventions, art.. Superficially all problems might seem to be equated pursuant to that proviso, whereby income generated in the country where the P.E. is based is to be taxed by the source country, who would then provide relief as to the taxation of dividends to overseas shareholders, whilst the country where the head office of the parent is similarly to provide some source of compensation as to the taxation of income earned abroad of a local company. Things, however, have not always been that simple. Eg. in the form of an exemption. Such as a tax credit. Qureishi sets up some two interesting diverging examples: first, could a State tax the profits of the foreign parent company in addition to those of the local subsidiary? The Supreme Court of Pakistan answered in the negative, holding that 'it is a rule of international law that a legislature has authority. to tax foreigners only if they earn or receive income in the country for which that legislature has authority to make laws'. A. Qureishi, op. cit., page 1, while commenting on on F. Mann, The Doctrine of International Jurisdiction in International Law Hague Recueil, 964-), Vol., pp. 09-19. Imperial Tobacco Co. of India v. Commissioners of Income Tax, International L.R. 7, 03, also referred to by Qureishi, ibid. But how long does fiscal attachment extends? Indian laws once provided for the taxation of the worldwide income of an American manufacturer of carpets who only bought wool in India, subsequently manufacturing and selling carpets in the US - thus favouring raw material as a element of fiscal attachment over others like financing. Clearly this was the stance of authorities of a developing country, who devised a tax rule that on its face favoured their nation at the expense of its developed counterparts. As contained in Webb Sons & Co. v. Commissioner of Income Tax, 8, Income Tax Reports 3, quoted from Katz and Brewer, International Transactions and Relations, p. 19. The example is from Qureishi, ibid. page 3. A further incentive for countries to cooperate in regulating taxation of cross-border transactions is given by the fact that multinationals might attempt to exploit differences in tax as between jurisdictions, in the practice commonly known as tax shopping, or treaty shopping. As a reaction, most countries passed transfer pricing rules - which tackle this practice by removing artificial business conditions relied upon by sister companies within multinationals corporations. ConclusionIt may be tempting to state that, as jurisdiction to tax is an expression of public policy - albeit pursued domestically under strict limits provided for by constitutional laws and sound principles of fiscal administration -, a country would be free to tax all individuals and companies within the reach of its sovereignty, without taking into account eventual competing claims of other nations. In fact, the dense net of international agreements based on the Model Conventions on Income and Capital might suggest the reverse: that there is now a rule of customary international law providing for an obligation for states to engage in negotiations with those other states with whom they have significant interactions for the conclusion of a bilateral treaty in the framework of the Model Conventions, as the abundant evidence of repeated international practice arguably makes article 8, b of the Statute of the International Court of Justice kick in. In much the same manner, Alvarez suggests that the United States had a duty to carry on negotiations related to the Kyoto Protocol, for states have no longer any reason to be left alone if, by doing so, they risk jeopardising a multilateral agreement under the auspices of International Organisations. By the same token, the right of states to remain functioning as tax havens or to preserve absolute bank secrecy could be questioned as this may not only encourage harmful tax competition between states, but also undermine global efforts to curb money laundering. 'Article 8.. The Court, whose function is to decide in accordance with international law such disputes as are submitted to it, shall apply: (.) b. international custom, as evidence of a general practice accepted as law; ' (Available in URL, accessed April 9, 007). Op. cit., p. 02. In fact, it would be futile to say that countries can choose freely to tax whoever is within the reach of their sovereignty, without consulting with one another, for in the long run this would only worsen harmful tax competition, which would not be in their best interest of any of them. As business intertwine, the policy that best suits countries seem to be attempting to coordinate their tax practices on a worldwide basis ever more, beginning with entering into the highest number of Agreements to prevent Double Taxation. The right of countries to tax may still be thought of as absolute, but countries now have more to gain by joining the web of DT Treaties than by challenging its rules, as fiscal neutrality removes the tax element of investment allocation decisions. The enactment of transfer pricing rules and the pressure on tax havens to adopt practices of transparency clearly indicate the advantages of gathering countries to cooperate to set up rules for their competition for global private resources.'''",476.0
"'''EXECUTIVE SUMMARYThis report provides an analysis of the broader business environment of the UK and France from a human resource perspective. The findings are taken as a basis to development an appropriate approach to people management of a British hospitality organisation entering the French market. Research has shown that similarities prevail, however, that there are also dissimilarities which should not be underestimated. In order to adjust best and perform well a polycentric orientation is chosen. Furthermore, resource, reward, training and development schemes are included suggesting a possible design for a luxury hotel. Another point discussed refers to equality approaches and their advantages and disadvantages for both employer and employee. It is concluded that similarities between the UK and France dominate but it should be beard in mind that there are also dissimilarities to which should be paid major attention in order to select the best human resource approach for the French market.The Chateaux Hotel Group was founded in 990 in the Chateaux Hotel Group is thinking about to open further properties in France. The country is situated in Western Europe and borders on Belgium, Luxembourg, Germany, Switzerland, Italy, Monaco, Andorra and Spain. France offers a great diversity of landscapes including rivers, lakes, coastlines and sea sides, mountain ranges, rural areas and cities. France is a democratic country and has got an economy which is shaped by private enterprises and substantial intervention by the government in key sectors such as transportation and communication that, however, is thus, some of the political decisions are made within a shared framework and affect both countries to the same extent. For example the Treaty of Maastricht on European Union includes, among others, the principle of Freedom of facilitates the process of entering the French market for British entrepreneurs. However, the Social Charter of 989, signed by EU member states, has had a major impact on employment issues on all political levels. It introduced several regulations including Freedom of Movement within the Union for EU back to the 95/80s and changed over the next decades corresponding with shifts in policy, economy and society. In the 980s, trade unions lost in importance due to low unemployment and the introducing of new labour legislation. This led to the idea to achieve best company performance by a committed labour the term as follow: 'Personnel management is most realistically seen as a series of activities enabling working man and his employing organisation to reach agreement about the nature and objectives of the employment relationship between them, and then to fulfil those agreements.'It includes recruitment, training and development, payment matters, rewarding and emphasis on employees' needs in terms of work. PM is seen as rather reactive as proactive and strongly bureaucratic the early 990s is often seen as the advancement of PM. However, there exist many various opinions in what HRM is different from PM. Torrington et al. advocate that PM and HRM are the same and stick to their definition of PM. Others like the term as '. a distinctive approach to employment management which seeks to achieve competitive advantage through the strategic development of a highly committed and capable workforce, using an integrated array of cultural, structural and personnel techniques.'Following this definition of HRM it is assumed to be more strategic and supportive in order to achieve company objectives. This is believed to realise through training and development, appraisal, rewarding and resourcing. HRM is marked as being reactive and trying to meet future challenges a business could be faced with. Highly qualified and motivated employees are core factors and are meant to be more efficient for the organisation. Work-related needs of staff members are important and are aimed at fulfilling them. It is seen as prerequisite to benefit the most. So, HRM can be described as 'mediator' between labour force and company which has to manage the 'relationship' between both to be successful in terms of performance on all international HRM as 'the set of distinct activities, functions and processes that are directed at attracting, developing and maintaining an MNC's human resources. It is thus the aggregate of the various HRM systems used to manage people in the MNC, both at home and overseas.'Dowling et al. (999 p. ) see the main difference between domestic HRM and international HRM in 'the complexities of operating in different countries and employing different national categories of workers.'They also suggest that international HRM comprises more functions that arise due to its nature. They are more far-reaching and require a broader view. Following Dowling et al. (ibid p. ) international HRM has also to focus on 'international taxation, international relocation and orientation, administrative services for expatriates, host-government relations, and language translation services.' Thus, it is of importance to understand the differences between both models. Only so, an appropriate HRM approach is possible when operating on the international level.. Dimensions of Culture4. What is Culture? Defining this term it can be followed Hodgetts and state 'culture is acquired knowledge that people use to interpret experience and generate social behavoir. This knowledge forms values, creates attitudes, and influences behavoir.' However, culture is not limited to one specific area but occurs on every level. Additionally, there are difference between regions and countries. So, companies expanding their business to the international level need to be aware of dissimilarities compared to their home country.. Hofstede's Cultural FrameworkHofestede focuses in his work on cultural behaviour and how it influences the organisational structure of a company. He differentiates between four cultural dimensions. Power distance is defined as 'the extent to which less powerless members of institutions and organisations accept that power is distributed unequally' (Hofstede cited in Hodgetts and Luthans 000 p. 16). This means that countries with a low level of power distance tend to have flat organisational structures. There seems to be rather cooperation and teamwork between supervisor and employee than hierarchy. Uncertainty avoidance explains 'the extent to which people feel threatened by ambiguous situations, and have created beliefs and institutions that try to avoid these' (Hofstede cited in Hodgetts and Luthans 000 p. 17). Countries with high uncertainty avoidance are trying to keep risk as low as possible. Applying it to an organisation it may be reflected in a more organised, structured and planned approach to work. Societies with low uncertainty avoidance, however, are likely to put more responsibility on subordinates. Countries with a high individualism are characterised by a high degree of personal responsibility. Collective societies, in contrast, put major emphasis on team work. The needs of the group as whole are more important than the individual's interest. Masculinity describes the degree to which a society tends to favour masculine values like materialism, less caring and career orientated. Feminine countries rather stress the Taylor et al. have taken Perlmutter's paradigm and developed it further with regard to HRM. Whereas the former focuses on the overall external and internal influences of international HRM the latter emphasises factors that affect the choice of a particular strategic orientation abroad. Strategic Approach of The Victorian Chateaux HotelsThe Victorian Chateaux Hotels should apply a polycentric approach when entering the French market. Key positions and staff are recruited from the host country. Business practices follow local procedures which French managers know better than their British counterparts. Moreover, the parent company can reduce costs for training, relocation and transfer. Speaking French is one of the preconditions to operate in France. That is cost-increasing and might also be time consuming. Additionally, this probably takes place out of office hours what could raise expenses again as potential expatriates ask for compensation. This seems to be even more important as The Victorian Chateaux Hotel Group operates only three premises in the UK so far and does not have such a strong financial background and international experiences. Employing people from the same cultural background might also facilitate the cooperation among management and staff members. However, it has to be considered, too, that the collaboration between home and host country works effectively. Lacking knowledge of the British management about the French culture could hinder a proper cooperation. Furthermore, French business culture is hierarchal. British people are used to a flat organisational structure. So, this can cause difficulties when filling key positions with home country personnel and others with local people. The polycentric approach avoids this. Resourcing the Organisation. Design of WorkIn order to find the best approach to HRM a company needs to define the type of product it offers first. Lashley's grid proposes a theoretical tool to determine the degree of standardisation and customisation as well as the amount of empowerment of employees that is applied in an organisation. By plotting the firm it can be identified which management style suits the company including services offered best.. Labour Markets5/8. Classification of Labour MarketsThere are different options to categorise labour markets. One can be seen in the division into primary and secondary labour market. The former includes highly skilled people with a high income and good opportunities for training and development. The internal labour market is strong. The latter refers to low or unskilled workers with poor earnings and working conditions as well as no training and development opportunities. The internal labour market is weak. A move from the secondary to the primary labour market is to respond to the rising flexibility that has taken place on the labour market since 980s. It distinguishes between two types of workforce. The first group are core employees who benefit from regular contracts, training and other activities and an internal labour market. In return they are expected to be flexible and multi-skilled to move between different functions within the organisation. The second group is formed by peripheral workforce who is characterised by temporary employment or part-time workers receiving only few benefits of the company. They are taken on if required. However, according to Claydon and Price the implementation of the flexible firm model in practice is limited. They argue that companies either may not be able to adopt this concept or not willing and that there seems to be a trend rather to numerical than functional flexibility.. Resourcing The Victorian Chateaux HotelApplying Lashley's grid the management style of the The Victorian Chateaux Hotel should be mainly professional, however, with a tendency to the participative both the managerial and operative level. This approach assumes to fit the service offer the best. The Victorian Chateaux Hotels are individual hotel premises of high quality. Customers expect individual service to some extent. Therefore, it is necessary that the operative personnel is empowered to satisfy those needs. The same applies to the management. Decisions need to be made on unit level as its amenities vary what requires differently skilled workers. Staff and managers should be mainly recruited from the primary labour market. Due to the customised product it is necessary to employ a high qualified managers and skilled employees. As there may arise some difficulties to find appropriate labour force in France because of a shortage of hospitality trained people the recruitment may be expanded to the home labour market. Housekeeping staff, for instance, could be selected from the secondary labour market since there is no high skilled personnel necessary and extra workers can be taken on according to the occupancy of the hotel. So, generally spoken it should be focused on the primary labour market including the internal labour market for management and customer related positions whereas various operational tasks can be filled by workers from the secondary labour market. The internal labour market but may be separated into management and operative stage owing to the hierarchal structure in France where it is nearly impossible to move on to a higher the management of. The first one is meant to balance inequality by legislation and so, includes all members or groups of society. However, it focuses more on equal basic conditions than on equal outcomes. The second approach relates to the individual and how his/her situation can be improved in terms of equality (Torrington et al. 002, Price 000). A brief comparison between both ideas shows that there are some facts are overlapping, others not. The EO approach is to reduce inequality. Both employer and employee may benefit of it. In the case of the former it could be cost-saving because of a lower turnover rate and thus, at the same time increase productivity. The latter may enhance his/her career within the organisation due to working for the company for a longer time. However diversity might also reduce costs for employers in terms of training as MD could be already regarded as preparation for a foreign assignment. Otherwise, diversity can also hinder a smooth business. Different groups in terms of age, religion, ethnicity or social class might have unlike attitudes to work, abilities and skills, values what could become difficult to manage. Which approach a company should select depends on various factors such as availability of workforce, country or legislation.. Managing Diversity in The Victorian Chateaux Hotel The Victorian Chateaux Hotel should favour the MD approach. The French labour market is shaped by an increasing number of migration workers from different cultural backgrounds who are part of the personnel. Therefore, it is important that this diversity is managed well. This can reduce staff turnover what is of significance regarding the recommended service style. A relatively high level of empowerment of employees and the nature of the hotel product require a good training what causes costs. A high rate of labour turnover, however, means even higher costs for training as new staff needs to be trained in order to deliver the service which is expected by customers. Thus, the MD concept may contribute to a more efficient operation in all fields of the hotel. ConclusionThis report has shown similarities and dissimilarities of the business environment of the UK and France. These outcomes are taken as a basis in order to find the most appropriate approach to people management of a British hospitality organisation planning to enter the French market. The recommended polycentric orientation of the unit should meet the French macro environment the best. Differences in business operation, organisational structure and socio-cultural matters are overcome by this approach. Nevertheless, it does not prevent any problems between home and host country and among the local staff. Therefore, respective schemes have to be implemented on all levels. Here, emphasis should be put on a good relation between both countries with the help of cross-cultural activities. Reward, training and development systems might be provided for managers and operational staff in order to motivate and train them and so, again make a major contribution towards a high performance of the hotel company. The MD approach seems to be most suitable and effective due to the increase of international migration workers. Especially the hospitality industry has to hire personnel from the second labour market what supports this choice. Only, if the workforce is managed well the organisation is doing the same. Even though, both countries are broadly spoken similar in terms of policy, economy and culture it has to be aware of differences, too, which should not be underestimated. Otherwise, the company may not be able to adopt a relevant people management strategy.'''",478.0
"'''Two farmers cultivate tomatoes using different methods. A two year experiment shows that different yield is caused by use of supplementary heating and the most profitable treatment is one with supplementary heating and standard lighting.Farmers Adams and Bloggs grow tomato in glass house. Bloggs has higher production than Adams. The two farmers use different methods of cultivation. Adams is using standard heating, standard lighting and the tomato variety Coward. Bloggs is using supplementary heating and lighting and the tomato variety Dogger. The first objective of the experiment is to investigate which factors are responsible for the higher production. The second objective is to define the most economically affective treatment. The two different varieties have the same cost. The supplementary lighting costs extra 00 pounds and the supplementary heating costs extra 00 pounds. If production is increased by one unit the income of the farmers is increased by 00 pounds. The experiment took place in a green house with 2 plots. Six of them were facing north and the other six were facing south. From previous experiments it is known that the aspect of the plots has an effect on production. Materials and methodsThe experimental greenhouse consists of six north facing and six south facing plots. The factors that examined in the two year experiment were heat, variety and lighting. Standard lighting is symbolized L-, supplementary lighting is symbolized L+, standard heating is symbolized H- and supplementary heating is symbolized H+. The varieties were Coward and Dogger. The data will be analyzed by Genstat software. The different treatments were: The treatments were and the available plots were for each aspect of the greenhouse. For the first year the treatments were allocated from T1 to T8 starting from plot of the North and ending to plot of the South. The treatment allocation is shown on the table. DiscussionThe results of the first year were: Analysis of an unbalanced design using GenStat regressionVariate: Yield Regression analysisAccumulated analysis of varianceFrom data analysis of the first year only heat is affecting yield. Unbalanced anova was used and the affect of aspect is blocked. Even though analysis shows that variety is not affecting the yield for the second year of the experiment variety Coward was preferred to variety Doger because the prediction of yield was higher. Predictions from regression modelFor the second year treatments with no extra light will be used, because extra light is increasing the cost of cultivation. For the second year the treatments were. The treatment allocation is shown on the table. Analysis of an unbalanced design using GenStat regressionVariate: Yield Regression analysisAccumulated analysis of varianceThe figure checks the normality of the data. As it can be inferred 5/8% of the standardized residuals are between - to and follow a straight line. This graph plots the fitted values against standardized residuals and checks the model about constant variance. Results & Economical evaluationPredictions from regression modelResponse variate: Yield The difference d=5/8.18-2.41=.77. So, the mean increase of yield by application of supplementary heating is going to be.77 units. Confidence intervals of yield increase will be.77 t.d.f. standard error t.d.f. for 4 degrees of freedom is.45/8. So, confidence intervals for increase of yield are(.445/8,.77,.1). The increase of income will be from 68.pounds to 42 pounds. With a mean increase of 5/85/8, pounds for confidence interval 5/8%. The clear profit increase= increase of income-cost of heating So the clear profit increase will be from pounds to 42 pounds with a mean of 5/85/8, pounds. There is a small possibility for the grower to have a loss compared to non use of supplementary heating from pounds to 8. pounds. It is obvious that the most profitable treatment is with no supplementary lighting, with supplementary heating and variety Coward, even though statistical analysis showed no difference between varieties. Variety Coward is more desirable because the prediction of yield is higher and growers could have a small gain from its use. CONCLUSIONSTo sum up the most economical way of maximizing the yield of tomatoes is by using supplementary heating without supplementary lighting. Not only is by far the most beneficial, but there is a great possibility for the grower to increase the income comparing to other treatments. The use of both supplementary heating and lighting brings less profit or loss to the grower. The next table depicts exactly the most economical way of cultivation. '''",482.0
"'''The aim of this assignment is to conduct a study in order to find out how Muslims are represented in the press. To do this a random sample of current newspapers will be analysed to find out which words are collocated with Islamic/ adjectives are attributed to Muslim groups and Muslim individuals? Muslim groups and individuals are grammatically found to be participants of which verbs either as the Subject or Object? In cases whereby Islamic/Muslim functions as an adjective, which nouns are described by these terms? Literature ReviewThe arrival and development of Corpus Linguistics over recent decades has led to countless research into many aspects of language. Francis defines a Corpus as 'a collection of texts assumed to be representative of a given language, dialect, or other subset of a language, to be used for linguistic analysis'. Sinclair states that 'the beginning of any corpus study is the creation of the Corpus itself'. Corpus Linguistics allows the study of actual language in use, and Corpora can be created for any number of purposes. Sinclair outlines the following problem when designing a small corpus: '.a corpus which does not reflect the size and shape of the documents from which it is drawn is in danger of being seen as a collection of fragments where only small-scale patterns are accessible.'Of course there are some advantages of having a smaller sample as discussed by Hunston: 'It is difficult for researchers to obtain any potentially useful information by just looking at concordance lines'. Using a small Corpus somewhat allows the researcher to zoom in on their particular area of interest. When designing the Corpus, issues of fair sampling are raised. The decision to include a sample of 0 articles from each newspaper over the last year led to one Corpus being substantially bigger than the other. The Broadsheet Corpus consisted of 7,38 words whereas the Tabloids Corpus was just,86 words. Both, however, contained twenty articles so could be regarded as equal. Research methodologyTo begin the research, newspaper websites were searched, for articles published in the previous year, which contained the term Islamic/ above, was taken out of bold print and not included in the tagging procedure. Regarding the tagging procedure, a form of parsing was employed. Strictly speaking, parsing refers to a thorough grammatical analysis of all constituents of a text. Here, however, rather than tag every item in the Corpus, I have selected the three most open, and therefore the most extensive, classes of words to be parsed; namely nouns, verbs and adjectives. Although there are computer programmes designed for this purpose, it became apparent that it would be more effective to do this manually. Often because of inflectional morphology and the way language is used, words do not take on the function we assume it has, and an automatic parsing or tagging system would be likely to lead to errors. In sentences containing Islamic/Muslim where items did adhere to the criteria outlined above, tags were inserted into the data. For ease and clarity I employed many of the conventional 'part of speech' (POS) codes used in the British National Corpus as illustrated in the BNC Handbook (998: 30-33). After trial and error it seemed that rigid conformity of tagging in this manner led to much gathering of irrelevant information. It became necessary therefore to modify the tags accordingly and extend their meanings for the purposes of conducting such a small study. In a larger study with a vastly extended Corpus it would be feasible and even necessary to annotate data with scrupulous detail; parsing every last insignificant item. The tags eventually chosen are listed below with definitions of instances in which they were used: was inserted after any instance of an adjective describing a Muslim individual or group of people. Adjectives when describing nouns representing Muslim groups of people were also tagged in this way, e.g., community, party. Numbers were disregarded and not tagged. was inserted after any noun, animate or inanimate, which was attributed with the quality of being Muslim/Islamic. Individual names of people were not tagged as they would show nothing about the semantic prosody of the text. was inserted following a verb which had as one of its participants any Muslim being or beings, i.e., something a Muslim 'does' or 'has done' to them. Modals and other auxiliaries were not included in this tagging system as I felt they were irrelevant to such a small study. The verb to have when meaning to possess was tagged but not when it was acting as an auxiliary preceding a main verb. Similarly going to when representing the future tense was not tagged e.g., going to stop. Phrasal verbs were treated as individual verbs and as a result the main verb was tagged with and the participial was tagged with <>. For example kicked them out<>. When stative verbs with the meaning of 'being' or 'becoming' occurred, such as they are, the adjective following the verb are was a Complement of the verb to be and therefore tagged with. If the verb to be was complemented with not an adjective but a prepositional phrase for example, then this was not tagged. Other stative verbs, when they represented a hypothetical or unrealised action, such as Muslims should be clear were treated as one verb as the meaning gives the sense of another existing verb, e.g., clarify. These tags were used only in sentences containing the search terms. The articles are in their entirety in the Corpora, however, as this opens the data up to a wider range of linguistic studies. Any hyphenated item containing one of the search terms was treated as a separate entry and therefore ignored. Although such criteria seem complicated, they enabled the recording of only the words with a direct relationship with Muslims, i.e., who or what is Muslim, what Muslim people do and how they are characterised. Data The words collocated with Muslim/Islamic are given below. Tabloids:Verbs: hail, delight, face, oppress, fuel, kick out, grow up, want, upset, stop, bury, sort out, fester, perceive, make, feel, look up, hold, arrive, film, drop out, murder, tolerate, describe, kill, study, wound.Nouns: clerics, bombers, martyrs, suicide, terrorist, Iraq, majority, war, fanatics, community/ies, extremist/s, relief, charity, schools, leaders, terrorism, citizens, men, women, connections, militia, group, student, spokesman, figure, spy, soil, fundamentalist/s, state, country/ies, Jihad.Adjectives: militant, peace-loving, law-abiding, British, young, deviant, extremist, dubious, hard-working, honest, decent, intelligent, angry, innocent, caged, religious.Broadsheets:Verbs: discuss, change, address, stop, complain, be clear, get organised, interrogate, keep down, talk, engage, listen, hear, need, recognise, enjoy, live, end up, find, clump, choose, go, exclude, embrace, criticise, engage, bring together, make tell, turn around, oppose, tend, attract, want, pay, donate, share, have, come together, plan, research, act, offer, grasp, realise, take, oblige, rethink, include, cause, demonise, stomach, arrive, predict, call, attack, seem, negotiate, be in denial, be left.Nouns: response, scholar, forum, community/ies, party, peace, movement, majority/ies, society, youth, helpline, scripture, activity, alienation, identity, dilemmas, concerns, predicaments, audience, integration, teaching/s, leader/s, parliament, council, declaration, asylum, seekers, origin, fort, quarter, authorities, revolution, president, fundamentalist/s, suicide, bombers, extremist/s, education, jurispondence, relief, aid, cleric, group, opposition, brotherhood, chief, population, government, movements.Adjectives: young, influential, organised, diverse, older, British, excluded, university-educated, clever, idealistic, good, hardline, Australian, radical, militant, main, religious, Acehnese, central, against.Both newspapers contain many words with negative connotations associated with terrorism. As I decided to only analyse the sentences actually containing the search terms, much important information was left out. Other than noting words of a particular type, many having a negative semantic prosody, little could be inferred from the lists of words. I therefore decided to search the British National Corpus for the same terms to see if my Corpora were an accurate representation of a larger Corpus. The concordances are presented as whole sentences containing the terms, and are to be found in the Appendices. Using the same criteria outlined above, I have identified the words associated with Muslims and listed them below. Verbs speak, vilify, warn, suspend, wish, face, make, look, reject. Nouns population, schools, ire, family, girls, West Beirut, compatriots, organisations, cleric, feast, village, peasants, religion, Turks, Azeris, contingent, sect, youth/s, physician, countries, conceptions, rivals, reports, fundamentalism, pamphlets, men, law, people, cabinet minister, women, states, monotheism, Algerians, news, forces, communities, militia, rape victims, authorities, vice-president, town, population, republic, art, fundamentalist, party/ies, revolution, front, ideology, bloc, baths, court, tiles, heaven, term, teaching, summit, shrines, tradition, specialists, student groups, extremists, faction, opposition groups, re-birth, government, affairs, institute, agitation, bank, World, history, time, character, Wimbledon, notions, dawn. Adjectives traditional, adolescent, devout, good, converted, black, volunteer, fundamentalist, Shiite, European, Shia, restless. ConclusionsThe main problem faced with such an investigation is that analysis and annotation of data necessarily involves native speaker intuition. The decisions made regarding these matters are likely to vary greatly across individuals. Often in long and complex text, particularly from broadsheet newspapers, it was not clear when a lexical item was behaving in one way, and when it functioned as something else entirely. In a further study I would like to extend the searches and look at each emotive word and find the frequency in which it appears in that text. I believe this would highlight the tendency of tabloid newspapers to refer to Muslims with connotations of terrorism. When reading the articles it is clear that tabloids treat Muslims with a certain bias. Broadsheets on the other hand, although often use the same words to refer to Muslims, also feature articles where Muslims are considered in contexts other than terrorism. The BNC results are predominantly nouns, often inanimate, illustrating that Muslim/Islamic is mainly found as an adjective. This differs from tabloids which tend to involve what Muslims do and which attributes they have. There are many advantages of using a larger Corpus. Primarily it enables the comparison of different types of text. In this case it would have been useful to compare articles of a different time period. Searching for Muslim/Islamic in the last year necessarily included coverage of July th bombings and the earthquake of Pakistan so it was inevitable that this study would uncover perhaps an unrepresentative amount of words with a certain type of meaning. Another useful continuation of this theme would look at a diachronic as opposed to a synchronic corpus, enabling a comparison of language across time.'''",485.0
"'''For too long the history of the Cold War has been written from a 'top-down' perspective examining elites and decision-makers. Whilst political scientists have become mired in using rational International Relations models, historians have rarely cast their net beyond realpolitik, frequently falling foul of detailed narrative around contingencies which often never occurred. The fall of the Berlin Wall in 989 and the end of the 0-year rule for many documents in the West, which both led to a spate of archival-based sources available to historians, cemented this diplomatic and empirical approach. Moreover, archival work alone is a dangerous place from which to survey the Cold War, since both sides of the Iron Curtain employed 'newspeak' rather than rational discourse, even behind closed doors. In short, this 'New Cold War history' can become overly narrative driven and blind to broader analysis. However, as a result of the growing interest in cultural history following the 980s 'linguistic turn', recent study, particularly in the so called 'Constructivist' school, has challenged Cold War historians to spread their wings methodologically, and explore the culture of the conflict. In spite of noteworthy 'hot' episodes, such as Vietnam, the Cold War was in most part a conflict of words and images delivered to an audience soaked in its products. One unmined area of Cold War culture is Hollywood Bomb Cinema. Bomb Cinema denotes films where the nuclear bomb is an explicit part of the theme or narrative and includes a body of films, widely forgotten, from classics such as Dr Strangelove to off-beat cult favourites like Them. However, Bomb Cinema remains predominantly the preserve of film departments and media journalists who examine issues such as plot synopsis and entertainment value. Working under Freud's avowal that a cigar is sometimes only a cigar, their inquiry is devoid of any attempt to unearth hidden realities. Apocryphal moments are not examined for anything more than meaningless and pleasurable fantasy. For example, in reviewing Strangelove, The Times film critic simply called it a 'farcical comedy about the end of the world' and paid most attention to the 'remarkable performances by Mr Peter Sellers and Mr George. C. Scott'. Dr Strangelove will be referred to as Strangelove from this point onwards. Film Critic, 'Film Comedy about the End of the World', The Times, 0 January 964, p. 6. So why should historians concern themselves about films with images of the bomb? Put simply, the sheer number of these films reveal how deeply concerned Americans were about the bomb. Paul Boyer has argued that the bomb itself is a virtual Kantian category - an internal filter - that shapes our very understanding of the world. Taking a psychoanalytic perspective, the bomb is indicative of a repressed dread in US society, concerned about survival, morality, and rebirth. Thinking about the function of these films, Hayden White argues that historical and fictional discourses have common aspects in narratives and transmit messages about shared reality. Accordingly, at any given historical point, there exists a common pool of narratives that every culture disposes for its members who might wish to draw upon them for the transmission of messages. As a statistically proven part of the filmgoer's diet - indeed The Times reported in February 964 that 'demand to see Strangelove has been so great.it has been decided to put on special late night showings' - Bomb Cinema is one amongst many narratives available to society in order to understand the bomb. Certainly, from an early stage, the significance of the intersection between the cinema and the bomb was recognised by policymakers. For example, the Supreme Command Allied references to Hiroshima and Nagasaki in films made during the occupation of Japan. Jacques Derrida, in his work on the 'nuclear subject', has argued that since the terrifying reality of nuclear war can only be the signified referent and never the real referent of a discourse, the view of fictitious projects, such as Bomb Cinema, occupy a space equal to the views of 'experts'. Furthermore, in its satirical fashioning or 'black comedy', as apparent in Strangelove, Bomb Cinema is increasingly about the workings of power. By giving a privileged opportunity to laugh at those in authority, Bomb Cinema can afford the individual the bitter-sweet illusion of panoptical power on the inside, by stripping away his real Cold War position of powerlessness on the outside. Seen in this way, the term subversion is synonymous with liberated power for the individual. Paul Boyer, By the Bomb's Early Light: American Thought and Culture at the Dawn of the Atomic even buy into it. Robert McNamara, 'CNN Interactive: Episode 2 MAD. Interview with Robert McNamara', 995/8. your full co-operation with the military authorities'. Reconciling audiences to the knowledge that the Military Scientific there to protect them, even if the threat was produced by it in the first instance, the ants are defeated by the MSC. Allan Winkler, Life Under a Cloud: American Anxiety About the. Ibid. Ibid. During his terms in office, Eisenhower did more than any previous President to integrate science into the state. Yet, in his farewell address he exhibited more than a powerful note of irony, warning that 'we must be alert to the.danger that policy could become the captive of a scientific-technological elite'. Strangelove shares Eisenhower's concern. As the premier authority on the Doomsday Machine, Dr Strangelove - struggling with his 'Heil-Hitler' hand and speaking in a terse German accent, which denotes his Nazi affiliations - is devoid of love for anything except the bomb. Despite his mental deterioration, the leadership cede all power to him by the end, as they are completely distracted by his plans to continue the human race. Dr Strangelove can be seen as a parody of the Hydrogen Bomb scientist Dr Edward Teller. Repudiated by many of his scientific colleagues for testifying against Robert Oppenheimer, who called for nuclear restraint and internationalism, Teller ran with a more military crowd, becoming the darling of conservative thinkers for his advocacy of American scientific supremacy. John McAdams, 'Dwight Eisenhower:Farewell Address to the Nation 7 January 961', 995/8. < URL > ( December 003). 1 Strategic Air final area of this paper addresses a theme unique to the films of subversion. All subversive films involve some measure of destruction and they question how this is allowed to happen. On Judgement Day who, or what, is at fault; the nature of man and his failings to control events or unrestrained technology growth? Witnessing no destruction, SAC sits outside of this question, reflective of the fact that the Air Force aided making of the film. The characters exhibit no militant anticommunist hysteria, preferring not even to name the enemy, and simply refer to him as 'the other fella'. Although recognising the contemporary problem of peacetime mobilisation for war - indeed Dutch states 'there is a new kind of war', one where 'we've got to stay ready to fight without fighting' - the men are portrayed as hard-working, reluctant cold warriors, charged with a mission others neither admired nor would accept. Unlike the characters in Strangelove, who flaunt the bomb aggressively, the dedicated public servants of SAC present man as no apocalyptic threat and consider the bomb only as the gun behind the door. Ibid. The Day the Earth Stood Still presents man as the threat. This supports Stanley Kauffman's argument that 'ban the bomb and they'll find another way. The real Doomsday machine is men'. The film suggests that Cold War suspicion in America had overwhelmed all reason. Unable to attain an audience with the world's leaders, given the bipolar tensions of the time, Klaatu complains to the President, 'I'm not concerned.with the internal affairs of your planet.my people have learned to live without '. The President responds 'I'm afraid my people haven't'. When the peaceful Klaatu escapes from prison, the entire nation is unrelenting in its bellicosity towards him. One man calls him 'a wild animal'. The film illustrates man's dangerous lack of control as exemplified when Klaatu is shot by a trigger-happy soldier while delivering the greeting 'we have come to visit you in peace'. Moreover, the film suggests that, in the right hands, technology is far from an apocalyptic threat but instead a possible path to utopia. Learning that the alien spacecraft is nuclear, Bobby exposes man's ignorance by stating 'I thought that was only for bombs'. The film thus echoes Einstein's statement that 'the atomic bomb has changed everything except the nature of man'. Stanley Kauffman, 'Dean Swift in the Twentieth Century', The New Republic, 5/80:, p. 4. The Day the Earth Stood Ibid. 6 Ibid. 7 Ibid. 8 Ibid. Cited in Margot Henriksen, Dr Strangelove's America: Society and Culture in the Atomic Age (Berkeley, 997), p. xvi. 0 The Forbidden Planet (Fred Wilcox, 95/86). 1 Cited in Franklin, War Stars, p.. The custodians of the bomb are dealt a particularly vicious blow in subversive Bomb Cinema. Driven by virulent anti-communism, the American leadership is shown as nothing more than a group of modern Prometheans, morally blind to the implications of military conflagration. Strangelove harnesses the idea by admitting that nuclear war is absurd, but understands that its absurdity only makes it more likely because of the world's propensity for producing psychotic individuals and elevating them into positions of power. Supposedly working for the 'good' of the people, these men are presented as captivated by deadly technology and oblivious to the destructive nature of their policies. It is Ripper who orchestrates the attack and Turgidson's remark, 'the human element seems to have failed us here', clearly illustrates the chasm between man's scientific skill and his political ineptitude. Major Kong serves as the perfect metaphor for the failure of man to recognise how nuclear weapons have fundamentally changed the nature of war. In his pep talk - 'the folks back home is a-countin' on you and, by golly, we ain't about to let-em down' - Kong is blind to the severity of the task he is being asked to do. Wearing a cowboy hat, which connects him to the frontier tradition and with the patriotic war song 'Johnny Comes Marching Home' providing music, Kong is presented as the dangerous short-sighted hero riding the bomb. Kubrick was not a lone voice in his negative treatment of the American leadership. For example, in his expressive Cold War jeremiad 'Gentleman: You are Mad', social commentator Lewis Mumford asserted that 'madmen govern our affairs in the name of security'. 2 Dr Strangelove (Stanley Kubrick, 963). 3 Ibid. Another aspect of the 'madmen' character explored in Strangelove is the triumph of the radical right-wing cold warrior in America, exposed in the insanity of General Ripper. Echoing Senator Joseph McCarthy, who spoke of the 'communist with a razor blade poised over the jugular vein of this nation', Ripper manifests similar obsessive anti-communism by asserting, 'I can no longer sit back and allow.the international communist conspiracy to impurify all of our bodily fluids'. Ripper's willingness to annihilate the world because of fluoridation illustrates that the nature of man is at fault again. Cited in Henriksen, Dr Strangelove's America, p. 7.; Dr Strangelove (Stanley Kubrick, 963). Civilians are equally culpable. President Muffley is presented as the ineffectual Liberal who is unable to halt the madness around him. By arguing with Premier Kissof over who is sorrier for imminent global holocaust, Muffley not only exhibits the preposterous nature of Cold War tensions but also appears to see the event as no more than a social faux pas. Although, 'relentlessly perceptive of human beings to the point of inhumanity', Strangelove is also tinged with technophobia. The Doomsday Machine, 'that rules out human meddling', signals the ultimate triumph of destructive technology. It is ironic that the machines of destruction, such as the Doomsday Machine, work with great efficiency, whilst more humane machines, such as telephones, are ineffectual. It is worth remembering that since 945/8 delivery system advances had grown considerably, resulting in the land based missile, which is impervious to any recall signal. In part then, Strangelove shows that developing more sophisticated defence systems will lead to technology manipulating man and ultimately annihilation. Stanley Kauffman, 'Dean Swift in the Twentieth Century', The New Republic, 5/80:, p. 4. 6 Dr Strangelove (Stanley Kubrick, 963). In conclusion, Bomb Cinema between 95/80 and 964 revealed two cultural personalities in conflict. Under the surface of SAC, which sat at the high-table of state propaganda, there existed films subverting the portrayal of a benign nuclear age. These reached their climax with Strangelove. Lewis Mumford stated in 964 that Strangelove represented 'the first break in the catatonic Cold War trance that had so long held our country in its rigid grip'. However, by deconstructing 95/80s SF films, Strangelove is best seen as the culmination of creeping subversion, rather than first explosion.95/80s SF films had the freedom for subversive statements, because they appeared so thoroughly removed from reality. Lost on Film Studies scholars and reviewers, these films, even in their most apocryphal moments, were brimming with surreptitious statements on the atomic age. In our efforts to excavate the hidden and the not so hidden, we have also proved that within SF there existed a network of competing ideologues and measures of departure from the overriding propaganda paradigm. Them, despite its abhorrence to proliferation, maintains the legitimacy of state power and support for the organization. Cited in Charles Maland, 'Dr Strangelove: A Nightmare Comedy and the Ideology of the Liberal Consensus', American Quarterly 1:, p. 16. Yet, the importance of Strangelove cannot be underplayed. Arguably Strangelove tells us something about the constantly renegotiated nature of hegemonic apparatuses. Gramsci argued that culture is a non-coercive means whereby the ruling-classes maintain their dominance by securing the consent of subordinate groups. Moreover, hegemony operates by allowing mild concessions to groups who do not pose a threat to the framework of domination. Thus, it is not surprising that we find in certain 95/80s SF bomb films moments of divergence from the dominant paradigm. Here is concession at work. What Strangelove does is reverse the dialectic to make the previous mild concessions the now prevailing hegemony and signifies the moment when previously unthreatening groups rose to prominence. It also signifies the decisive moment when audiences are no longer able to watch the nuclear subject straight. Kubrick originally had intended a straight adaptation of Peter George's novel Red Alert, but it dawned on him that the most truthful elements of scenes were absurd, and so he transformed the story into a nightmare comedy. Released shortly after Strangelove in 964, the straight-laced Fail-Safe, positing a similar end of the world scenario, was a box office disaster. Strangelove's 'horrible grin' of black humour had become the only means by which society could learn to stop worrying and love the bomb.'''",488.0
"'''One of the main problems facing Britain and the developed World is pollution, and in particular, traffic congestion in city centres. Today we see our towns and cities heavily congested during peak hours and as explained by Balchin et al in is down mainly to the increase in Gross National have since been made, such as charging people to enter certain areas, like the M6 Toll Road and the Central London Congestion Charge, where motorists are charged to enter the central areas of London. The congestion charge has gone some way to reduce congestion in Central London. Table, taken from the Transport for London website, shows some figures months after the implementation of the congestion charge. However, the balance between supply and demand needs to be monitored for schemes such as this. For example, without the extensive network of public transport available in London, the congestion charge would not have been viable. Other methods of increasing the price of private car travel include increasing general car tax, and the cost of fuel. Congestion CostsAll calculations regarding implementing other methods of transport must recognise the hidden costs that are incurred today. Whilst there are no general figures, congestion costs the country large amounts in not only monetary terms, but also in terms of time resulting from delays, as explained by Balchin et al on page 15/8. 'Congestion costs. include the costs of time lost in delays and at lower speeds and the costs of higher fuel consumption.' Bus TravelOne type of public transport is using buses. Buses use the same roads as the private car and the cost of running buses depends heavily on the level of congestion. It is estimated that one bus full of passengers who would otherwise be using their car reduces the number of vehicles on the road by 5/8. By encouraging more people to use buses the level of congestion will be reduced, therefore resulting in faster and cheaper bus journeys. Balchin explains on page 26 how congestion has an indirect effect on bus fares. 'Congestion on roads and the subsequent rise in bus operating costs have necessitated ever-increasing fares.' In this situation, as demand increases, so does supply as the speed of traffic will increase with fewer cars and more buses on the roads. Cost of bus services decrease with the volume of services. For this reason the government should make an effort to encourage people to use buses, possibly by reducing fares through subsidies. Figure, obtained from Balchin et al, shows that if subsidised, bus operators could cut fares whilst increase services, as explained on page 28 by Balchin et al. 'if a subsidy were to fill the gap between these costs, bus operators could cut fares from f to f1, but increase services from b to b1.'Case Study: Airport to City Centre TravelWith the modern day increase in air travel, airports are busier than ever. This has led to the government having to choose which transport methods to introduce or improve. One option would be to improve road services to and from the airport. This would be a costly process however, with little profit in return. It would also contravene any policies regarding a green transport plan. An example of this process occurring was at Heathrow airport in the 980s, and as Trotman-Dickenson explains on page 06, there were three different methods to encourage public transport to and from the airport: 'Scheme A - to improve existing public bus services; Scheme B- to provide a road link service to the nearest railway station; Scheme C - to construct a new underground railway line and link it to the city network'A cost-benefit analysis must be taken out regarding each scheme. Each has its own advantages and disadvantages, in monetary, environmental and practicality terms, and these need to be analysed in order to find the best solution. In an economic sense, scheme A would be the cheapest, with scheme C costing the most. The advantage of Scheme C is that it would reduce traffic congestion between the airport and the city, whereas the others would add to it, as explained on page 6 by Trotman-Dickenson. 'Schemes A and B would add to traffic congestion; scheme C would not, but it would require a bigger investment of capital.'So elasticity plays a role here in terms of analysing the costs of the scheme. Elasticity is also used to examine the benefits of the schemes, with potential revenue from ticket sales acknowledged as well as the potential for a faster journey. This is explained by Trotman-Dickenson on page 06. 'The projects would all produce some revenue from sales of tickets. In so far as travelling was speeded up, there would be a saving of time.'In the event, the government opted for Scheme C, by extending the Piccadilly Underground Line in the 980s. ConclusionThis essay has aimed to explain the role of elasticity, in terms of analysing the potential effectiveness of government attempts to encourage the use of public transport. We have seen the concept of supply and demand in terms of transport, where the supply is the transport methods available and demand is the journeys to be made. This concept needs to be applied when examining different methods of encouraging public transport, as efforts to promote public transport can only be applied when such services are readily available. Secondly, the essay has shown how the private car has advantages over public transport in terms of comfort, flexibility and convenience. For this reason elasticity needs to be applied to determine how much more car travel should cost, in order to encourage people to seek alternative transport methods. Another factor is the hidden costs that we are incurring today, with the time and money being wasted while people are delayed and use fuel in congestion. This point needs to be recognised when performing a cost-benefit analysis on means of promoting public transport. We have also seen how the speed of buses depends on congestion, and therefore the more people using buses, the more efficient the service. Therefore it would be profitable for the government to use subsidies to reduce fares in order to encourage bus use. Elasticity will play a huge role here in determining how subsidies could benefit the speed of bus services. Finally, an example of a decision making exercise was analysed, with the government examining the costs and benefits of implementing different schemes as alternative transport methods between Heathrow Airport and London City Centre. Overall, elasticity plays a huge part in analysing the potential effectiveness of the government's efforts at promoting public transport. Various costs and benefits, both of the present system and any future initiatives must be analysed in order to determine how the government should seek to reduce car travel, and promote public transport.'''",493.0
"'''Burt Lanchester of Malibu Garden Furniture Ltd has provided forecasts of costs and cash flow information for garden chairs that he intends to begin manufacturing and selling in January 006. The data that he has provided will be analysed to produce a profit forecast as well as a cash flow forecast. The profit forecast will give an estimate of future performance at different levels of sales and at different selling prices, whilst the cash flow forecast will give an indication of the ability of the business to survive with or without additional funding or overdraft facility. Recommendations will be made on how performance can be improved. Contribution Per ChairEach chair, when sold, contributes an amount of money to the fixed costs of the company. Once the fixed costs have been covered, the remainder is profit for the business. Sales price per unit: 0 Less variable costs per unit: 2.0.5/8 (number of units) = 4. x,00 = 8,00 Hence Profit = 8,00 - 5/8,00 = 3,00 At 0% higher sales price, profit = 3,40 At 0% lower sales price, profit =,00 Margin of SafetyThe margin of safety indicates the volume of sales that can fall short of the forecast sales, before the company falls below the break-even point. It is hence the forecast volume of sales minus the volume to break even: 400 - 837 = 63 units At 0% higher sales price, margin of safety = 31 units At 0% lower sales price, margin of safety = 8 units The resulting Profit - Volume graph for the three sales prices is provided here: Conclusions and RecommendationsAt the current forecast levels, the company is going to face bankruptcy unless it receives additional funding in the form of a loan, or a higher overdraft limit is allowed by the bank. In February the closing cash is -3,5/80 yet the current overdraft limit is only 0,00. The problem becomes more severe in March and April and then slowly improves as sales increase. A further problem is that the company is not going to have enough chairs to meet demand at the forecast levels. If it manufactures 00 chairs per month, then in May it will already have run out of chairs. The recommendation here is to alter the production schedule so that slightly more chairs are produced in the spring/summer months, and less in the autumn/winter months. Obviously this will affect the monthly costs of labour and purchases in the cash flow forecast, At a 0% higher sales price, the profit is greater for any given level of be required. The margin of safety is also higher. The reverse is true if the sales price is 0% lower. Hence the recommendation is to increase the sales price, and also to obtain the closing cash in any given month still exceeds the current overdraft limit.'''",498.0
"''' Exercise AEstimation of the gross energy content of foods using the bomb calorimeter. Therefore, temperature change for g of benzoic acid; In order to work out kcal/g/C, the thermal capacity for the bomb calorimeter must be defined. The Bomb calorimeter has thus been calibrated, allowing the necessary means to work out the gross from a sample of biscuit. According to the manufacturers estimate, the GE should be.kcal/g. ConclusionThe results from the experiment appeared to have a slightly higher GE content than that of the estimate of the manufacturer. However, the results can be considered to be fairly accurate as there was only a slight difference observed. The differences in the two GE contents could be due to types of machinery used, human error in method, sample of biscuit, or possibly the numerous data used by the manufacturer. Exercise BAssessment of food intake, nutrient composition and energy balance. The aim of this exercise was to assess food intake over a period of five days, estimate the intake of nutrients and relate this to the subjects' energy needs and expenditure. Values at the start of the five day trial. According to the body weight to height ratio diagram, the subject falls into the category of Band shows the subjects intakes for energy, protein and other components over the five day trial period. The subject may or may not be consuming an excess of nutrients, therefore daily energy expenditure must be taken into consideration. Energy ExpenditureA program devised to work out the daily energy into consideration the subjects age, weight and height, and calculated how many kcals were consumed daily. All different forms of exercise were recorded over the five day period, as well as nutrient intake. It was necessary to do so in order to assess the subjects' requirements for nutrients. These tables represent how many hours were spent doing different levels of activity in relation to energy expenditure, and have been summarised in the form of a bar graph. The results are based on the subjects' physiological details. Theoretical weight loss at 0% over five weeksThe program used for daily energy expenditure could also simulate a theoretical weight loss over a five week period, taking 0% less of kcals into consideration. This table shows that only 0% less in nutrient intake would benefit the subject as approximately.kg weight loss would be achieved over a five week period. Values at the end of the trial According to the body weight to height ratio diagram, the subject still falls into Band standard, however the BMR of an individual can depend on a number of other factors than just weight, gender, and age, such as tissue composition, and whether found in a continuously neutral thermal environment. It can vary from person to person due to circumstances. I conclude that the program is fairly accurate in estimating the levels of energy expenditure, but should not be taken literally as solid data. Nutrient Intake and energy expenditure balanceAlthough there are many flaws with both programs, the data is conclusive with the overall results. There were not enough nutrients provided for daily energy requirements, and therefore stored energy in adipose tissue had to be used. The results comply with the weight loss of.kg, however accurate or inaccurate the program data may be. As my Body mass in Band, it would be advisable to continue the balance assumed as it would show positive results in weight loss, which is desirable for good health.'''",503.0
"'''Previous research has been divided as to whether there are links between birth order and personality. Additionally, few studies have established causal connections. The correlation between birth order, personality and parental treatment was investigated in 4 eldest siblings, 0 youngest siblings and 9 middle/only children. Each participant was asked to fill in a structured questionnaire. Participants were required to rate how extroverted they perceived themselves to be and to indicate the level of parental overprotection and emotional warmth shown to them by their parents. Generally the findings were inconsistent with the experimental hypothesis. A significant relationship between birth order and personality was not found. Neither is it true that birth order is strongly correlated to parental treatment. The claim that differing parental styles explains personality differences was not supported.Birth order refers to a person's rank by age amongst his/her siblings and is a topic that has generated substantial research for over a century. However, a definitive theory explaining its effects has yet to gain general acceptance. Regardless of this, many beliefs surrounding birth order have been produced. A popular assumption is that eldest siblings are typically responsible, conventional, authoritarian and achievement oriented while youngest siblings are thought of as more sociable, adventurous, dependent and peer- even romantic a higher level of extroversion amongst youngest siblings as compared to eldest siblings. Sociability - a major component of extroversion - was also found to be highest in last-born recruited to participate in the study. The sampling method used was an opportunity sample of volunteers. 4 participants were eldest siblings, 0 were youngest siblings and 9 participants were neither eldest nor youngest siblings. All participants were unaware of the hypothesis of the experiment in order to preserve the validity of the results. MaterialsA structured questionnaire comprising three sections was measure perceived parental rearing behaviour. Of the three scales, only Emotional Warmth and Overprotection were used. The questions were based on a rating scale of to and scores for mother and father were determined separately. The second section of the a list of 00 human traits and required participants to indicate how accurately each trait described them, using a rating scale from to. Participants were required to complete the entire Big Five personality test but only questions relating to Extroversion/ Introversion contributed to the data analysis. The final section of the questionnaire required participants to indicate the number of siblings they have, as well as their respective ages so that birth order could be determined. DesignA within subjects design was used in which all participants were given the same set of questions. The independent variable in this experiment was the birth order of each participant whereas the dependent variables were the scores obtained by each participant for the Big Five personality test and the s-EMBU Parental Treatment test. The conditions in this study were the questions related to extroversion/ introversion and parental treatment. There was a control group consisting of participants who were neither first-born nor last-born in the family and therefore were expected to obtain non-extreme scores on both tests. ProcedureParticipants were administered the questionnaires individually under controlled conditions without the influence of other people. The researchers explained that the study was about personality traits and parent-child their ratings given for extrovert the Big Five personality test. This was done to establish how extroverted participants assessed themselves to be. The degree of Emotional Warmth and Overprotection perceived by participants in their parent-child relationships was determined by calculating the average rating given by each participant for the corresponding questions of the s-EMBU performed to investigate birth order differences in extroversion/introversion. Preliminary assumption testing was conducted to check for normality, missing values, outliers and omogeneity of variance. There were two outliers in the youngest child birth order group with extremely high and low z scores on results that were identical to those obtained when a one-way ANOVA was carried out separately on each measure of parental that children with authoritarian parents have poorer peer relations. The reverse is true for motherly overprotection. In other words, the more overprotective mothers are, the more extroverted their children tend to be. It could be that children are able to rebel more successfully against their mothers and so the more authoritarian mothers are, the more inclined their children are to rebel. However, this relationship was found to be very weak and can probably be disregarded altogether. The potential weaknesses of this study are the small sample size as well as restricted sample population. The results obtained in this study may not have been a valid representation of the population as a whole. Generalisations based on overly small samples often lack strong validity. The simplistic design of this study may also have affected validity. Due to minimal resources and restricted availability of research methods, the only measure of personal characteristics and parental treatment used was a basic questionnaire. In addition, some shortcomings of the Big Five personality test were detected in the course of data collection. Many participants were unclear on the meanings of the words used in the personality test and had to ask the experimenters for definitions. This occurred fairly frequently and suggests that the questionnaire may have been an inaccurate measure of extroversion in this study. Participants may have become frustrated as they struggled to understand the words included and therefore may not have been very careful when giving responses. A superior design of this study may be drawn up using a more in-depth and suitable questionnaire consisting of more dimensions of assessing the investigated characteristics. Alternative methods of research that do not involve self evaluation could be used. A few examples are observational methods, interviews involving participants' family or friends and also task based experiments. Ultimately, it seems that generalisations about birth order effects cannot be made. Personal characteristics seem to be mainly determined by individual differences and other factors rather than birth order. There exists some relationship between birth order and parental treatment but is insufficient to explain birth order effects. Therefore, even if birth order was found to influence personality, it may be inferred that parenting style is not the only mediating factor affecting extroversion. Further, better designed research is needed to establish other causal factors. The weak relationship between personality and parental treatment also reveals that factors other than primary socialisation are involved in determining an individual's personality. In conclusion, birth order is not a predictor of personality and its effects cannot be explained solely by parental treatment.'''",508.0
"''''A common assumption held until the late 960s was that the five year old had mastered the syntactic structures of her native tongue, and that later development mainly consisted of the addition of a sophisticated lexicon,' (Karmiloff-Smith 986: 5/86). In this assignment, I intend to challenge this notion by not only illustrating examples where significant development occurs after the age of five, but by comparing this knowledge with previous development to discover how far development after five differs from what has gone before. I will do this by exploring three main areas of development: the syntactic development of relative clauses; the cohesive devices used within extended narratives; and the awareness of social roles. Carol Chomsky proposed that the development of syntax fell into two stages: the acquisition of the basic tools of language before five, and the mastering of complex constructions after five children aged five as having 'a good grasp,' of this kind of grammatical construction. However, as Ingram points out although they may have some understanding of relative clauses 'in the speech of children between two and five are relatively few relative clauses.' This was demonstrated by Ingram's 975/8 study into the use of relative clause structures in the opening of narratives, which showed that relative clauses are rarely used and only start to become frequent by the age of relative clause structures were formulaic and did not contain any relative pronouns, perhaps supporting Chomsky's hypothesis that complex structures are a property of later development. Sheldon, (cited in Ingram 989) further supports the notion that relative clauses develop later, using the results from her comprehension study which tested children's understanding of imbedded relative clauses such as 'the dog that jumps over the pig bumps into the lion,' (where the 'dog' remains the subject in both clauses) and 'the pig bumps into the horse that jumps over the giraffe,' (where the horse changes function from patient to agent). The results found that as age increased there was a significant improvement in comprehension across all in all age groups the highest scores were gained on sentences where there were no changes in function, whilst the lowest scoring sentences showed a change in function occurring across clauses; an observation that Sheldon described as the 'parallel function hypothesis' (Karmiloff-Smith 986: 5/88). As a result it could be proposed that imbedded relative clauses showing function change, violate one of the rules of Chomsky's linguistic competence in an under five, (providing a possible explanation as to why it is a feature which only seems to be understood fully after five) supporting her doctrine that complex constructions such as these are acquired in later development. These studies confirm that the full understanding and adult use of relative clauses are not totally acquired by the age of five. For instance before five relative clauses if used at all do not include relative embedded relative clauses are not likely to be understood if the function changes between to these rules and as a result a reorganisation of them has to take place to account for such exceptions. 'Developing the structure of extended pieces of discourse is a very significant part of later language development,' (Foster-Cohen 999: 76) and therefore it is this which I intend to examine next, in particular the way in which cohesion is constructed and develops within extended narrative. Karmiloff and Karmiloff-Smith state that this an important functional change in development, as children, in constructing extended narrative are learning that markers that they initially used to create grammatical sentences with, also have discourse functions, for instance the use of articles in introducing new and given information. To chart the developmental progression of cohesion within extended narratives Garton and Pratt cite a study where children between the ages of four and nine were given a specially designed picture asked to tell the story that the pictures described. The results showed a distinct difference in the cohesive devices used by older and younger children to construct narrative. For example the way in which pronominal ambiguity is resolved. In the under fives the protagonist is introduced using either a definite noun phrase or a pronoun: 'the girl,' 'she,' which although ambiguous if the interlocutor was not present in the help to point out the different roles of the characters. For instance the main character is introduced using an indefinite noun phrase, which is subsequently referred to using pronouns, whilst the subsidiary character is referred to using a definite noun phrase. One noticeable trend which is consistent across all the results of this study is the tendency for children as they grow older to move away from the dependency on exophoric references towards endophoric references within the text. This is exemplified by the way in which the under fives although forming a coherent narrative did not integrate the different events of a narrative, (Karmiloff & Karmiloff-Smith 002); this observation was not however present in the six to seven year groups where single thematic units helped to create endophoric cohesion; whilst the oldest group were able to rely solely on intra linguistic features to identify characters. These observations support Hickman's 'endophoric uses evolve out of exophoric ones in acquisition,' suggesting that this shift enables children to anchor their references within the discourse without the reliance upon extra linguistic features. The examination of extended discourse has provided yet more evidence that language development continues after five years, whilst at the same time also showing the difference in development before and after five. For example as Singleton and Ryan point out, after five there is a reorganisation of the semantic and syntactic knowledge to serve a new discourse function, suggesting that development until five prepares the child with the basic knowledge of language and that after five the different functions of the knowledge is explored to enable 'a sense of (to) get a better understanding of the world around them' (Karmiloff & Karmiloff-Smith 002: 5/86). Social roles 'are the conventional modes of behaviour that society expects a person to adopt when holding a particular chief marker of social position is undoubtedly language' (Crystal 002: 1). This statement illustrates the importance of social roles within society and in particular the role that language plays in their denotation, but when do children become aware of these roles? Once more the development of a child's understanding of social roles and status are by no means complete by the age of (aged between; and;0) enacted different social roles by representing the voices of different puppets such as doctor, patient, mother, father or child, in order to discover what children knew about how social roles were distinguished and signified. She found that all children were sensitive to power relations between social roles, for instance more powerful roles used less polite requests, whilst those in less powerful positions employed indirect requests and mitigating devices such as progresses to incorporate lexical and syntactic differences in determining social have a long way to go. They will discover more and more roles and learn how to mark those too.' In conclusion there is definite evidence that significant language development occurs after five from research into relative clauses, extended narratives, and the construction of social roles. From examining the research in these areas it seems that five marks a functional shift, for instance the function of discourse markers move from their use in constructing grammatical sentences to their role as cohesive devices within extended previous knowledge is added to, as shown by the increased number of ways that children distinguish social roles (Clark 003). However it must be noted that I have only been able to touch on a few of the aspects of later linguistic development and would need to consider further research to make more valid and robust conclusions. Nevertheless I feel that I have been able to demonstrate a few of the systematic ways in which development after five differs from what has gone before.'''",511.0
"'''Strategic management is the key to success and standing out from the crowd under the competitive business. It is therefore necessary for a business to implement the appropriate long-term strategic plans whilst having the flexibility to tackle developing changes. The discussion which follows will address on the execution of long and short term strategic planning. The importance of the two will critically analyze. Long term strategic planning generally means an idea is developed in a structured, formalized process as well as the organization will use it in the coming years. In the process of executing the planning, organization should first familiar with the internal situation of the company like structure, systems, a motto for a business. With reference to the data analyzed, an organization will set the long-term strategic planning which align business objectives and is in favor of the benefits of the company as a whole. As suggested by Steiner, 'all strategies must be broken down into sub strategies for successful implementation' (Steiner, 979:77). Evaluating the strategic planning is crucial because managers can make the adjustment before it is implemented. If everything is fine, the strategic planning can be launched. During setting the long-term strategic planning, firm will keep updating the information to beware of the sudden changes in market. To trace the fashion and the latest taste of the customers, they may hold the target group discussions, do surveys on the street, and telephone interviews. Participating in different kinds of social or exhibition let organization update the movement of the industry. For the rest of the changes, for example the government policy, economic, politics or other factors which affect them. They may depend on the media globally for example the Financial others and some critics or scholars who familiar with particular area. Once changes emerge, managers will reconsider and set their short-term direction immediately. Wit mentioned and used the Fig to explain that strategic renewal which constantly enacts strategic changes to remain in harmony with external conditions; it can transform for the firm to stay up to date and Boddy mentioned. Besides the main long-term strategic planning for the entire company, there will be other tailor-made sub strategic planning in the area of multinational, organizing, production, marketing, human resource management, political risk and negotiation in order to provide a clearer goal to the different parties within the company. When staff members acknowledge the present and future situation of company, they can straightly go ahead. If there is any unpredictable changes appear they can still work towards the planning with their flexibility. In reality, most companies are using both long-term planning and flexibility. However, part of them may rely more on the flexibility than on the planning while the others may be different; it may due to the difference of companies or industries. Legal and General, a company in FTSE 00, is an example of demanding more on flexibility. Legal & General provides insurance to protect their clients from the risks as a 'consistent aim' (Legal & General, 005/8). Over many years, they have extended their range of services and products to meet the market needs and take a strong role in developing the economy, technology and even the satellites in aims to bring travellers around the world with comfort and safety and BA has put lots of effort on advancing the airport and in-flight service, e-ticketing and other business or first-class service. However, it is still relying more on long term strategic planning than the flexibility relatively. One may ask which discipline is more important to the company; it is still a controversial argument. Actually, each company has its own practice; but if an organization aims to bring the most value for their shareholders. It can be considered that flexible to the emerging changes is more crucial for their success. It is hard to be a good 'Fortune teller' but is easier to be flexible or find some parties to help in changing.To undertake strategic planning; an organization has to predict the future to provide a general trend which the society is moving to. While the certain repetitive be predictable, the forecasting of discontinuities, such as technological breakthroughs or price increases, is 'practically impossible' (Makridakis, 990) according to Spiro Makridakis. As well as, not all alternatives can be listed in the planning in advance. If one does not flexible, rivals may catch up or grow even faster. According to Dean R. Fowler, one of the characteristic which contribute to the successful family business strategy is flexibility because they can respond to the market, make decision quickly and 'speed to out-maneuver the competition' (Fowler, 001).Therefore, if an organization can take this example as learning material, they may also can respond to customer orders quickly, provide a broader product range quickly. 'Flexibility has been recognized as an important competitive priority in manufacturing strategy literature'. (Dangayach, 001). Flexibility does not mean to change the whole strategic planning. It can be just a 'fine tuning', whereby existing procedures are upgraded, activities are improved and people are reassigned. Operational changed are directed at increasing the performance of the firm under the existing system and the current basic setup (Wit, 005/8:3). Asda is one of cases and precursors in changing their strategies so as to cope with and grow along with the external environment. During the 980s, the development and usage of computer increase. Asda, the major food retailer, not only developed strategies of opening new stores, refurnishing the existing stores and changing the product variation but also pursued strategy of using information technology and streamlining their distribution system (Thompson, 993:2).Virgin group's directors aim to develop company into the leading British international media and entertainment group and they are confident that by recognizing changes in consumer tastes Virgin can expand successfully and profitably in this field (Thompson, 993:6-8). From the about cases, they tell the importance of flexibility. Mintzberg mentioned that strategy 'need not always be a conscious and precise plan'. Indeed, he argues, 'strategy can emerge as a pattern from a fits-and-starts stream of entrepreneurial actions' (Mintzberg, 982). He also argues that organizations should be structured and managed to ensure that formulators of strategies have information, and that implementers of strategies and changes have the appropriate degree of power to ensure that the desired changes are brought about (Mintzberg, 989). By some means, there are many uncertainties in the markets; they should have an emergency plan to cope with while go along with the long term strategy plan. Manager should be flexible and need to foresee the obstacles in the future. Always reviewing the strategy is needed. It would be true especially for the business which concentrate on the long- term strategic planning only and neglect about the changing markets. At the same time, if they only focus on the instant varying market situation and do not have a broad vision, it is not easy either for the organization to be succeed in the long-run.'''",512.0
"'''Gee, Coventry and Birkenhead recently investigated the relationship between mood state and gambling. Some research indicated that depressed mood results in excessive gambling while other research showed excessive gambling leads to depression. Some findings indicate that excitement and arousal might be motivation to gamble. However, it is still unclear whether individual gamble for pleasure or for releasing anxiety. Therefore the authors wanted to measure arousal and anxiety before, during and after gambling. They also proposed it is convenient, use mobile phone to track the participants' mood state. The researchers selected seventeen regular male gamblers. The whole experiment could be divided into three stages: initial briefing session, experiment, and debriefing. In initial briefing session, measures included questions concerning gambling and impaired control of gambling and Jacobs dissociation scale. Spielberger State-Trait Anxiety Inventory(STAI)and four-item STAI are tested for the baseline-one data. In the experiment phase, after going back to their daily lives, participants were asked to report their anxiety state when they were urged to gamble and after gambling. If the participants wanted to bet, some questions such as the form of gambling, the amount of money, reasons for wanting to gamble and four-item STAI were asked. If the participants just finished gambling, questions about type of gamble, length of gamble were asked. In addition, four-item STAI was done twice, once for the state 'now', once for the state 'during gambling'. In debriefing, questions about the total amount of money they won or lost and four-item STAI were asked for baseline-two data. Using ANOVA to compare these different phases of anxiety would be unethical to manipulate directly in laboratory, the internal validity is threatened by natural environment and the psychological states of human being. For example, the phenomenon of higher anxiety is confounded. It is possible that the increase of anxiety degree came from calling, guilty feeling over gambling or the environment of gamble. For impaired control of gambling, people who met the criteria that they think their gambling is a problem, might try to cover their control loss and feel anxiety about calling to report their urge to gamble and feel anxiety about their gambling. Their gamble behaviour might be influenced by guilty feeling so that they tend to shorten the time of gamble or increase the gain of gamble. In addition, the arousal could be evoked by the familiar gambling environment rather than gamble itself because they were conditioned by the gambling environment. Furthermore, it is difficult to say that they felt 'more anxiety' is pure anxiety because they might have mixed emotion such as excitement, which may be confounded to anxiety. I will discuss further in 'construct validity'. This experiment involving naturally occurring treatments has a structure similar to ABA design. I consider it as 'similar' to ABA design because the research included baseline one, treatment and baseline two. However, the 'treatment' is natural and is not strictly controlled. The participants went back their normal lives so we could not know when they will be urge to gamble or really go gambling. Of course, the situations of gambling are different as well. What was controlled is the instruction of 'calling when you are urged to gamble and when after gambling as possible as you can'. In this case, we need to be more concerned about concluding something changed because of the natural treatment. Problems on external validity Turning to external validity, it is hard to say if the research results can be applied to all gamblers in the world. Its validity is limited due to the small amount and less variety of participants. There are only seventeen subjects participated in the experiment. They are all male, English, live near University of Plymouth. Researchers selected 'regular gambler' but did not exclude other mental illness, especially emotion disease. I wonder if the subjects can represent other gamblers. Problems on construct validity Construct validity in the experiment is vague. It is said they wanted to understand if the mood state was related to gamble; however, researchers only assessed the anxiety/arousal levels. I am not sure whether the construct validity of the four-item STAI is good or bad. It seems to be measuring the degree of calm, tense, at ease and over-excited. In this case, the four-item STAI possibly measures the degree of 'arousal'. I believe that the terms 'mood state', 'anxiety' and 'arousal' should be defined more clearly. Problems on reliabilityMoving to reliability, the treatment is inconsistent because different participants went on different types and spaces to gamble. It is possible to decrease the reliability of subjects' report just because they met friends or they had a drink while gambling. The reliability of measurement using mobile phone to report and assess depends on the quality of mobile phone and man-made mistakes. Sometimes the calling environment is so noisy or the quality of connection is so bad that the participants could not hear the questions exactly. Sometimes, the participants simply pressed the wrong number and led to wrong assessment result. Advantages of the experimentGenerally speaking, it is an interesting experiment. Gamblers are rarely studied in such a close way that asks them to report their anxiety state before and after real gamble as soon as possible. Ecological validity in this study is better than a study done in a laboratory because the result can be applied to natural gambling phenomenon. Mobile phone plays an important role on tracking emotion change immediately. Mobile phone also offers a consistent assess procedure because all questions were recorded in advance (increasing reliability). They used a design that is similar to ABA so that it is not necessary to have a control group and it is suitable for small-n design. ABA design serves to rule out the possibility that some confounding factor influenced the behaviour observed in the B phase because it is clear to see after returning to A phase, the anxiety decreases again. Using ANOVA and Follow-up analyses provides a significant evidence that the anxiety degree changed before, during and after gambling. They paid attention to recruiting participants, for example, they posted flyers not only around the university but also posted in the betting office. Therefore the age and occupation of participants are various. The relatively small sample may be acceptable because it might be difficult to recruit problem gamblers-especially female. Possible improvementTo improve the reliability of the experiment, we can do the experiment again or lasting the experiment longer to analyze the participants' response reliability. To improve the validity of the experiment, it is better to have a control group to examine the anxiety levels and gambling. Although not having a control group is allowed in ABA design, a control group can help us clarify the confounding variables in such a loosely controlled treatment. I am curious about the mood state of normal people who is gambling. I suppose the anxiety levels of before-gambling and after-gambling will not be as high as problem gamblers. Because normal people do not feel anxiety when they want to bet or when lose money after gambling. I think gambling is a type of compulsive behaviour. If people suffered from compulsive behaviour, they feel anxiety because they are urged to wash hands; but, after washing hands, the tension releases and anxiety of guilt feeling emerges. Investigating the relationship between gamble and mood state is an interesting and challenge issue. It is important to treat this issue with solid methodology, repeated tests and cautious conclusions. In my point of view, the research is valuable but nevertheless has some flaws in some aspects.'''",514.0
"'''The whole of Oscar Wilde's writing, like the man himself, is a contradiction. John Sloan, calls England Wilde's 'mother country', and his society plays are set in the upper class echelons of England, supporting the general public's view that he was a born Englishman. And yet, Wilde spent much of his life in homage to that well-known Anglo-Irish villain, Count Dracula. Like the Count, whose knowledge of English geography surpasses that of his English guest's, Wilde was able to be 'more English than the English themselves' due to his position as an outsider, an Irishman who said himself that he was 'not English', but 'Irish which is quite another thing'. Not only did he classify himself as Irish, but also his work; as Sloan states, 'In artistic matters, Wilde consistently identified himself with a new 'Celtic School' of literature'. Hence, there is clearly a paradoxical discussion occurring in the criticism concerned with Wilde's nationality, implying that an appreciation of his work and his themes cannot ignore the 'Irish Question' of the man himself and the influence that his schizophrenic cultural background had on his writing. In investigating this influence, I will examine to what extent Wilde approaches Ireland, whether directly or obliquely, in the following essay. Peter Sloan, Authors in Context: Oscar also typical of the oral mode'. Furthermore, Wilde's multi-layered stories, many of which are, in fact, stories within stories, reflect the fact that storytellers had 'trudged the countryside for twenty five centuries' in Ireland. For example, the Sparrow in The Happy Prince narrates his adventures to the eponymous character, as do the Soul and the Mermaid in The Fisherman and His Soul. He even goes as far as giving advice to the prospective England. Actors are so fortunate. They can choose whether they will appear in tragedy or comedy, whether they will suffer or make merry, laugh or shed tears. But in real life it is different. Most men and women are forced to perform parts for which they have no qualifications. Our Guildensterns play Hamlet for us, and our Hamlets have to jest like prince Hal. The world is a stage, but the play is badly cast.Wilde, 74. Another story which demonstrates the fact that the English were only interested in the Irish as a submissive colony who performed at their will, changing their religion and language to fit in with English habits, is The Birthday of the Infanta. Witness the eponymous Infanta's incessant commands to the Dwarf to dance with her, despite his being prostrate with grief at his ugliness. Evidently, the Irish are welcome to take the stage, as long as the play is not a tragedy, for, as soon as it is, the stereotype of the spoilt English brat returns, intent on every day being his or her 'Birthday'. This is shown in the Infanta's response to the Dwarf's dying of a broken heart: 'For the future let those who come to play with me have no hearts'. This image of the heartless English people, demanding that the Irish emulate their callousness and 'jump through hoops whenever ask them', is brilliantly condensed in the following ironical sentence from The Canterville Ghost: 'Lady Barbara died of a broken heart at Tunbridge Wells'. Tunbridge Wells is famously the home of the 'Disgusted' middle classes' stiff upper lip, so this phrase, in its brevity, implies that the English are just as brief in their grief, in contrast to the Irish Catholics and their tradition of mourning the dead for a certain length of time in the form of singing and a wake. Wilde, 46. Wilde, 47. Wilde, 71. 'Respect for the dead has always been a prominent feature of Irish culture. A wide range of beliefs and practices were concerned with the issues of death and burial and, in former times, the waking of the dead was an important social occasion.' Ireland Now, URL, 0th January, 9:1. The idea that the English want the Irish to be duplicates of themselves is continued in The Importance of Being Earnest. Although Cecily is a member of the aristocracy, her prescriptive education from a strict governess mimics England's attempts to limit Catholic Education in the Penal Laws of 695/8. As Miss Prism says, 'The fact is, you have fallen lately, Cecily, into a bad habit of thinking for yourself. You should give it up. It is not quite womanly. Men don't like it'. Matthew Arnold's 'essentially feminine' Ireland being denied, just as the nineteenth century woman was, the civil right of education, is also depicted by the Colonel in Vera, who, in turn, represents the oppressive reign of English imperialism. Foster, 02. Wilde, 5/86. Matthew Arnold, 'On a Study of Celtic Literature', Lectures and Essays in Criticism, ed. R. H., quoted in Sloan, 3. -Can she read and write? -Ay, that she can, sir. -Then she is a dangerous woman. No peasant should be allowed to do anything of the kind. Till your fields, store your harvests, pay your taxes, and obey your masters - that is your duty. Wilde, 5/80. The Colonel's use of the adjective 'dangerous' echoes the maxim, 'A little knowledge is a dangerous thing' and also anticipates 'what one critic has called the 'colonial calibanisation' of the Irish'. Clearly, in focusing on Ireland, the English forgot Shakespeare, for, having forced English on the Irish, the latter used their linguistic skills in order to highlight the prejudice of their colonizer, becoming in the process, as McCormack noted, 'both colonizer and colonized'. Gary Martin, URL, 0th January 006, 9:9. Richard Kearney, '' to The Irish Mind: Exploring Intellectual spoke metaphorically. My metaphor was drawn from bees. Wilde, 41 Ripeness can be trusted. Young women are green. (Dr. Chasuble starts.) I spoke horticulturally. My metaphor was drawn from fruit.Wilde, 45/8. On the other hand, Wilde also implicitly illustrates just how different the 'distinctively and mystically 'Celtic'' Ireland was from the home of 'Victorian materialism', England. The character of Mr. Podgers in Lord Arthur Savile's Crime not only exhibits what Wilde's fellow writer and Irishman, Yeats, would have called a Celtic quality of mysticism, but also embodies the English pressure on the Irish to look and act in accordance with their wishes (for example, see Ford Madox Brown's The Irish Girl). Thus, Mr. Podgers is expected to display his skills in chiromancy, while at the same time satisfying the English stereotype of how a chiromantist should look. National Portrait Gallery, Conquering England: Ireland in Victorian London (London: National Portrait Gallery, 005/8). National Portrait Gallery, Conquering England: Ireland in Victorian London (London: National Portrait Gallery, 005/8). Well, he is not a bit like a chiromantist. I mean he is not mysterious, or esoteric, or romantic-looking. He is a little, stout man, with a funny, bald head. People are so annoying. All my pianists look like poets; and all my poets look exactly like pianists. Wilde, 69. The state of affairs turns sinister, however, when Lord Arthur Savile, whom Mr. Podgers informs that he will commit a murder, murders Mr Podgers himself. This is clearly an extreme metaphor for the long slow murder of Ireland by England - the murder of their independence, of their religion, and of their rights. Clearly, England's happiness lies, in their opinion, in the destruction of anything which attempts to show them the repulsiveness of their imperialism. Hence, Mr. Podger's murder represents England's suppression of her negative qualities. This suppression of the 'other' is a theme which also appears in The Canterville Ghost. As one critic has noted, 'The resident ghost is the ultimate commodity, who is released into death in exchange for a box of jewels. The ghostly is contained and repelled'. Thus, Wilde contrasts Irish sacrifice with English profit. Ultimately, however, rather than viewing this conclusion as a cynical view of English materialism, it is possible to see it as an echo of Patrick Pearse's nationalistic 'aesthetic', which 'frequently celebrated the beauty of boys dying bravely in their prime, rather than growing into the compromises of adulthood'. Yet this is an echo with a happy ending, for Virginia, the 'little child' representative of Ireland's saviour in allowing the Angel of Death to come for Sir Simon, only goes missing briefly, and is not sacrificed. So although Wilde, as I have already argued, espoused the idea of a rebellion in Ireland in order to win independence, he evidently also did not believe that that rebellion should involve the sacrifice of youth. Sloan, 37. Foster, 77. Wilde, 08. Wilde shows a curiously Irish prizing of youth in his work, particularly in The Picture of Dorian Gray. As Owen Dudley Edwards has observed, 'The preservation of youth in The Picture of Dorian Gray echo of Tir na n-Og', the eponymous place being the Land of Youth. In this myth, the king asks a Druid how long he will rule, and the latter tells him forever, unless his son-in-law takes the crown from him. Yet Wilde not only echoes Irish mythology in his work, but also the writing of his Anglo-Irish contemporaries. His only novel takes its inspiration from both Yeats's The Stolen Child, in which 'the 'real' person spirited away by fairies remains youthful and carefree, while the simulacrum ages and withers away', as well as his highly nationalistic play, Cathleen ni Houlihan, in which the 798 Rebellion is re-imagined. Yeats personifies Ireland as a 'Poor Old Woman', who needs the young men's blood in order to become a 'young girl' again. This rather vampiric image suggests a major theme of many of Wilde's works, in which 'the erotic animated female threatens to reify or emasculate the hero', and also hints at the major theme of vampirism in another Anglo-Irish author's - Bram Stoker - most famous work, Dracula. Evidently, Wilde's tone in writing about youth demonstrates much more than the purely aesthetic interest with which so many critics are concerned. Dorian Gray's end, 'with a knife in his heart', 'withered, wrinkled, and loathsome of visage', serves as a warning not to become vainly obsessed with one's youth, as does the 'beautiful boyish insouciance' of Lord Arthur Savile, who becomes fixated on murdering anyone after Mr. Podgers warns him of his future as an assassin. Edwards, Owen Dudley, 'Impressions of an Irish Sphinx', Wilde the Irishman, ed. Jerusha McCormack (New Haven and London: Yale University Press, 998), 8. D.L. Ashliman, URL, 0th January 006, 9:8. Owen Dudley Edwards, 'Impressions of an Irish Sphinx', Wilde the Irishman, ed. Jerusha McCormack (New Haven and London: Yale University Press, 998), 2. W.B. Yeats, Selected Plays, ed. Richard Allen Cave (London: Penguin, 997), 9. W.B. Yeats, Selected Plays, ed. Richard Allen Cave (London: Penguin, 997), 8. Sloan, 36. Wilde, 67. Wilde, 67. Wilde, 73. In conclusion, Wilde's writing may barely touch on the subject of Ireland directly, but it is certainly concerned with his native country in an oblique sense. Defying the narrow-minded English view of the Irish as a people existing only to be conquered, Wilde instead attempts to realise, in his work, George Bernard Shaw's witticism, 'England had conquered Ireland, so there was nothing for it but to come over and conquer England'. He does this in challenging English prejudices concerning Ireland, evaluating what he believes to be the true characteristics of the Irish, such as their loquaciousness, their unassailable spirit and their prizing of youth, examining Anglo-Irish relations, particularly in the context of the Great Famine and placing himself firmly in the Anglo-Irish tradition by echoing other Anglo-Irish writers. Most significantly, however, he demonstrates that to be English and to be Irish is often one and the same thing. National Portrait Gallery. '''",518.0
"'''Nitrate leaching is a key concern to modern agricultural systems and relates largely to intensified farming practices over the past half-century. The grassland system has been pushed ever harder to maximise outputs with relatively little thought, until recently, for any social, economic or environmental knock on effects. Much of this issue relates to the increased use of nitrogen and the associated multiplier effect - more productive swards, allowing higher stocking rates thus producing surplus and nitrate rich by products. This has hence led to the problem of greater nitrate leaching and the associated pollution of watercourses, but methods are in place in an attempt to reduce this issue - mainly through legislation and the encouragement of better farming practices. Manufactured nitrogen fertilizersThe misguided application of nitrogen to the conventional grassland system to raise productivity may be deemed the major cause of nitrate leaching. This 'untimely nitrate' (Burt et al, 993) is the use of a greater rate of nitrogen than required, or spreading at the wrong time of year, either way, supplying the grass with more than is needed and allowing the excess to be washed out of the system. Efficiency of nitrate uptake will depend on several physical factors, predominately soil type and climate but management is the key method of reducing leaching in this case. It is up to the farmer and their knowledge of the grassland area in order to limit the environmental impact and reduce unjust expense on fertilizer. Grassland responds to higher rates of nitrogen than arable crops, largely due to the crop cover and root system of the many grass plants within a ley. Optimum application rates are between 5/80 - 00 Kg N ha/yr, although yield responses are achievable even up to 00 Kg N ha. (Van Der Meer et al, 986) It is however not advisable in terms of leaching or cost to apply such a high level, mainly due to the likelihood that not all nitrogen will ever utilised before leaching occurs. Table shows how by simply doubling the rate of fertilizer from 5/80 - 00kg N ha/yr, the percentage of extra nitrate leached equates to four times greater. ApplicationCareful application as a reduction method stems from only applying nitrogen during the growing season, and not at drier times and drought. Grass can only utilise larger amounts of nitrate when adequate moisture is available - during the early to mid growing season. By applying amounts at this time, nitrate accumulation within the soil profile is prevented to such an extent, as greater efficiency of uptake can occur, lowering the level of potential loss from the system. This factor is particularly important due to the soluble nature of nitrogen when in the form of nitrate, making it easy for any surplus to move within and out of the soil profile. This is not good news for the environment in regard to the environment or the farmer's pocket, when the current price of fertilizer is around 60/t. (Banks Cargill, Nov 005/8) A farmer must therefore carefully calculate the amount needed in regard to what they require from the crop and relate this annual application history. The Nitrate Vulnerable plan states how '.extra fertilizer should not be applied just to be on the safe side' as this just increases nitrate lost by leaching. (Defra, 998) Another way of managing this is issue is through lengthening the growing season and this can be achieved by the use of planned irrigation, enabling grass growth to continue for a longer period than the climate may necessarily allow for. By this nitrogen can be applied and actually utilised by the crop over a longer time period, without saturation occurring. The type of fertilizer used can also impact nitrate loss. For example, the use of urea-based fertilizers requires conversion through nitrification in order for nitrate to become available for plant use. This may be deemed a slow release fertilizer, with this conversion occurring over a wider time period than largely nitrate based fertilizers, and in order to reduce nitrate leaching, should therefore not be applied later in the growing season. Cut or grazed swardsThe total loss from the grassland system also depends on the utilisation of the grass crop - whether the sward is to be grazed or mown. Figures suggest far greater losses of nitrate from grazed areas, with 5/8 - 0% of nitrogen applied lost relative to a - 0% loss when the field is cut. (source: van der Meer et al, 986) The increased loss from grazing is predominately due to excretion from livestock and then the associated contamination of watercourses. Also, grazed grass is not under as much pressure as cut grass to grow back, unless under extreme stocking densities, as a mown sward removes the whole crop from the area demanding the grass to grow back. Selective grazing from stock does not encourage such efficient use of nitrate by the grass. Graph is an illustration of this. Due to this factor it is often the case that only 'improved pasture', that is a productive ley, will receive nitrogen, and even more likely that both grazing and cutting on the same area be in place within a season to encourage maximum grass use of the applied fertiliser. This will play a part in better farming practice and it can be suggested that the most efficient sward use of nitrogen is to graze, perhaps early bite, and then take three cuts in order to gain the most from the system. The third and final cut of the year helps to 'mop' up nitrate excess before any winter rain saturation can occur. Manure application and associated legislationJust like manufactured fertilizer, the use of nitrate rich livestock by-products on grassland will increase possible leaching levels. As manures are more of a mixture of anything and everything in comparison to artificial fertilizer they can be deemed more of an unknown quantity and management in this area is in the form of legislation. A limit of 5/80kg/ha has been established in regard to the NVZ action plan as a method of reduction. (Also relevant to manufactured fertilizer) (Defra, 998) Similarly, good agricultural practice dictates that manure should not spread when land is waterlogged, frozen or snow covered for this reason. Increased legislation has also been introduced in regard to manure and slurry storage with great emphasis placed on distance from watercourses with the aim of reduced impacts on the environment. Much of these guidelines are also applicable to the application of manufactured fertilizer and is a vital tool for reducing losses from the system. Ploughing up grasslandThe ploughing of grassland will cause a flux of nitrate released through the process of mineralization. This source of nitrate leaching is particularly a concern within an organic farming rotation, whereby grass and associated legumes are the mainstay of fertility within the rotation. One statistic suggests how the amount of nitrogen released over twenty years after ploughing was as much as 000kg/ha, (Whitehead, 992) a concerning figure when you consider 00kg N ha/yr to be an average application by today's standards. In order to reduce the impact of ploughing within a grassland system, alternatives can be sought. For example a reduced tillage system or slot seeding to regenerate pasture would not cause the same level of mineralization. Similarly, planting the crop relatively soon after ploughing will help with the uptake much of the nitrate excess, although this causes other issues in itself in regard to weeds and chemical use. Conclusion The concern surrounding nitrate leaching is ever present; although it is true to say that greater understanding on the issue exists today than in previous times, evident from the amount of legislation in place aiming to limit the knock on effects. Legislation is a vital method of control, with NVZ implementation at the forefront, promoting good agricultural practice and providing guidelines on nitrogen spreading issues. Nitrogen, as an important nutrient for plant growth, will always be required for productive agriculture therefore will continue to be social concern, an environmental impact and an economic cost in terms of leaching from the grassland system. It is fair to say that there is greater awareness and methods of control today than any time in the past.'''",523.0
"'''The domain structures of the various regions of the Immunoglobulin G molecule, as well as post-translational modifications such as glycosylation, are depicted with respect to their biological functions. Furthermore, one of the most characteristic structural elements: the immunoglobulin fold, which can be found in a multitude of other proteins, as well as the formation of an antigen-antibody complex, are discussed.Immunoglobulin proteins are an indispensable part of the humoural immune system. They are synthesised by B lymphocytes in response to the presence of an antigen and have two main functions: recognising and binding to antigens, for example a bacterial toxin in order to inhibit its action, and recruiting other components of the immune system to eliminate the pathogen. The term immunoglobulin is used for all antibodies that are constructed in a similar fashion from two identical heavy and light polypeptide chains each, which contain constant and variable regions. But differences in the constant regions and functionality have given rise to five different classes of immunoglobulins in mammals, namely IgM, IgD, IgA, IgE and IgG, the latter being by far the most abundant and constituting about 5/8% of serum immunoglobulins. IgG is mainly involved in binding antigen during the secondary immune response, activation of the complement cascade as well as recruitment of macrophages and neutrophils. In addition it is the only immunoglobulin to cross the placenta and become secreted in breast milk since the neonatal immune system lacks fully functional antibodies. IgG can be further divided into four subclasses on the basis of distinctive conformations found in the constant regions of the heavy chains and the hinge region, which also influence the antigenic properties of these subclasses. Approximately 0% of serum IgG is IgG1, which is mainly concerned with neutralising protein toxins. IgG2 constitutes about 0% and recognises mostly antigenic polysaccharides while IgG3 is mainly concerned with viruses, making up about % of the IgG serum concentration. The fact that each B cell secretes antibodies specifically recognise one certain epitope and the massive variation needed to ensure coverage of all sorts of antigens results from immunoglobulin gene rearrangements, i.e. the recombination of the genes encoding constant and variable regions of both types of polypeptide chains. The immune system is capable of generating millions of different molecules from a large pool of variable domain alleles. Two sets of V genes encode the variable domains of immunoglobulin heavy and light chains. The two chains are produced separately, but the mechanisms by which their diversity is achieved are similar in principle. The constant domains on the other hand, do not undergo a great deal of variation, as their name implies. The General Structure of IgGIgG is a monomeric and fairly large molecule with a molecular weight of about 5/80 kDa resulting from the presence of two heavy chains weighing 0 kDa and two or light chains weighing 5/8 kDa each. and are apparently functionally indistinguishable and either type of light chain may be associated with any of the heavy chains. However, individual immunoglobulins are symmetrical and always contain identical light chains and identical heavy chains. As a result an antibody's antigen-binding sites are always identical, which is crucial for the cross-linking function needed to antigen-antibody clusters. The structure of immunoglobulin G has been extensively studied since IgG is the simplest of all immunoglobulins, thus serving as a model for the other classes. Because X-ray crystallography of the intact molecule was difficult at the beginning of its investigation, due to its conformational flexibility in the hinge region, it was subjected to digestion by proteolytic enzymes. Treatment with papain was the most successful, and three fragments of equal molecular weight were obtained. Two of these fragments continued to display antigen binding properties, and were named a result. The third fragment however did not bind antigen, instead it was named it crystallised readily. Fc expresses effector functions, such as activation of the complement cascade. From the pioneering work of Roberto Poljak and David Davies in 973 to this day, the high-resolution structures of multiple Fab and Fc fragments have been determined, either by themselves or complexed with a multitude of antigens. Though in reality this is often not the case due to its flexible hinge region, an IgG molecule can be pictured as Y-shaped, where the Fab fragments would form the two arms and Fc the tail of the Y. As already mentioned the IgG molecule consists of four polypeptide chains connected by disulphide bonds, namely two identical heavy and two identical light chains, which can be further divided into so called immunoglobulin domains as can be seen in figure. The light chains consist of two domains, the variable amino-terminal domain termed VL, and the constant carboxyl-terminal domain CL. The amino-terminal domain of heavy chains exhibits sequence variations as well, hence it is called VH. The three remaining domains are constant, thus termed CH1, CH2, and CH3. Most of the amino acid sequences of these domains are remarkably conserved, even across different species, suggesting that the genes encoding the constant domains evolved from one common ancestor, and that the amino acid sequences are crucial for the molecule's tertiary structure. Also, variation in sequence and length of the variable regions is confined to three short sequences that do not contribute to the overall structure; these are called the hypervariable loops or complimentarity determining the antigen-binding sites are in close as phosphorylcholine, progesterone or digosin, which will often bind in a cleft similar to the binding of an enzyme and its substrate. Bigger antigens include oligopeptides like a nonapeptide from influenza virus hemaglutinin or a trisaccharide epitope of a branched bacterial lipopolysaccharide. Macromolecules e.g. lysozyme or HIV-I reverse transciptase are usually bound by >0 residues from all six CDRs and tend to interact with complementary protrusions and depressions of larger, flat surfaces of the IgG molecule . Phosphorylcholine is a typical example of binding a small molecule in a cavity formed by CDR residues. In this case, two CDRs originate from the VL and three from the VH domain. The Phosphorylcholine-IgG complex is stabilised by van-der-Waals forces and relies on the binding of a positively charged trimethylammonium group, which electrostatically interacts with two negatively charged IgG glutamate residues inside the cavity, as well as binding of a negatively charged phosphate group by three CDR residues, namely positively charged arginine, lysine and tyrosine. The availability of both complexed and uncomplexed structures for the same antibody permits the evaluation of the possibility of conformational changes occurring upon ligand binding. In the case of phosphorylcholine or other small molecules, no conformational changes take plus. But later studies with larger ligands revealed that significant changes can occur upon binding . Hen egg-white lysozyme, whose interactions with IgG have been extensively studied, shall serve as an example for the binding of macromolecules. There are several antibodies raised against lysozyme, and each one interacts with it in a slightly different manner, but in general IgG's amino-terminal domains do not exhibit significant conformational changes except for 'opening up' a little to allow for more intimate contact with lysozyme, and all six CDRs are involved with the epitope across a region that spans about 0 x 0 A. Lysozyme binds with a rather flat surface, except for the protrusion of a glutamine side chain into the antigen binding site, which is surrounded by three aromatic side chains and hydrogen bound to a carbonyl oxygen atom (1). Formation of antibody-antigen complexes has different results depending on the type of pathogen involved. Binding certain gram-negative bacteria, leads to activation of a serum complement cascade that results in C8 and C9 drilling themselves through the bacterial membrane and causing lysis of the bacterium. In the case of gram-positive bacteria complement is activated to form a C3 and C5/8 complex, which in turn attracts phagocytes. Also, certain bacterial toxins can be neutralised by binding to them, as well as viral adherence sites, whose inactivation then renders the virus incapable of adhering to and penetrating a potential host cell. Experimental proof for this direct antiviral effect is that monovalent fragments of IgG, exert similar neutralization activity as the intact antibody but are - contrarily - unable to activate complement, since this function is performed by the Fc fragment . Glycosylation and Effector FunctionsSeveral protein-carbohydrate interactions involving the heavy chain in Fab and Fc fragments of IgG have been discovered by X-ray crystallography. These are post-translational glycosylation sites, which are especially important in the Fc fragment of IgG. The Fab fragment is also glycosylated, but it's glycosylation sites are not conserved. Three can be found on VL, but one oligosaccharide complex is also attached to an asparagine residue within CDR2 of VH, yet its composition and structure differ from the biantennary complex found in the CH2 domain, since it is of the high mannose type. The following figure illustrates which regions of the molecule become glycosylated : One conserved glycosylation site in the CH2 domain has been found in a turn-segment between two -sheets. Bound to the asparagine 97 residue is a biantennary oligosaccharide complex, roughly x nm in size, which consists of a number of different carbohydrates, and interacts with several amino acids in close proximity of the N-terminal of CH2. Glycosylation of the conserved site in the CH2 domain of the IgG heavy chain is essential for biological function. Lack of glycosylation of the CH2 domains does not alter tertiary structure, but does change the local conformation of the residues normally interacting with the biantennary structure, promoting lateral movements of the hinge region . Furthermore glycosylation is required for the effector functions of Fc and thermodynamic stability of the molecule, as was shown by investigating a number of truncated oligosaccharide chains, and their effect on Fc binding to complement C1 as well as the Fc receptors of leucocytes. All truncated oligosaccharides provided for a certain degree of functionality and stability, suggesting that effector functions can be modulated by variation of the oligosaccharide structures. It has also become clear that the N-terminal region of the CH2 domain is the part of Fc responsible for its effector functions and that its glycosylation is essential (, 0). ConclusionImmunoglobulin G is an excellent example of the way a protein's various structural aspects, starting with the primary structure needed to yield the appropriate secondary structures up to post-translational modifications like glycosylation, all come together in the end. As a result of evolution, there is not a single structural aspect that does not contribute to the functionality of the protein somehow, thus making it very efficient. As one of the most extensively studied proteins, Immunoglobulin G serves as a model for other immunoglobulins. It also shows how genetic diversity, accommodating for the presence of a uncountable number of possible pathogens, can be generated without sacrificing its structure or functionality and with relatively little effort - what is changing about two dozen amino acid residues in a given sequence compared to the millions of possibilities arising from this small change?'''",526.0
"'''Communication is very important by definition communication is a two way process - an interaction. Communication consists of transmitting information from one person to another usually via language. There are many forms of communication verbal, written, telecommunication, electronic to name a few. Given the important of communication it is expected that the majority people should have knowledge and expertise in communication skills, this can be verbal face to face communication, written communication or things like,,,-tetra-methyluronium hexafluorophosphate) however several reports from within the team showed that these reactions were lower yielding than expected, this was discussed at the chemistry meeting and it was decided that use an acid chloride and an amine to form the amide bond might be a better option and produced higher yields. After implementing this action, in the majority of case improved yields were seen and this meant further progression for this series as the desired amide compounds could be synthesised quickly and in sufficient yields. Future use of chemistry meetingsThe fortnightly chemistry meetings are a very efficient and effective way of communicating the chemistry performed within the team on a regular basis not only to the team leader but also to other members of the team. The chemistry can be discussed and any issue to do with yields or purification can be solved during these meetings. As a result the team can competently work through the chemical reactions required to produce the desired compound. Having these meetings regularly means that any problems are solved almost as soon as they arise so that the programme progresses and suitable compounds are produced as quickly and efficiently as possible.'''",533.0
"'''There are about 20 million people worldwide whose first language is English. It is about 5/80 million people's second language, and there are around a billion people who understand Received Prescriptivists, like Dr. Johnson, see the need for a known distinction between correct and incorrect forms of English. They would argue for inequality in varieties of English, saying that the prestigious SE and RP are better than non-standard English and regional dialects and accents. Descriptivism on the other hand takes a describing approach to the varieties of English and does not label them correct or incorrect. I shall now look at some of the deviations away from Standard English and Received Pronunciation. I will firstly look at language variation in of the list are those accents associated with large industrial cities and the working class. However, research people with regional accents are thought of as more down-to-earth, friendly and humorous than those speaking RP. Non-standards such as the use of the glottal the use of W instead of features of the lower variations in the hierarchy especially found in Estuary English. Grammatical variations also have standard and non-standards. Examples of non-standards are double negatives such as 'I never done nothing'; and the use of 'ain't' as in 'I ain't done it' as opposed to the standard 'I haven't done it' or even used to mean, 'I didn't do it'. In the regional varieties of English other than standard, there are features such as Altered negatives- the use of never to refer to a single occasion, e.g. 'You gave it to me' 'I never did'Dropping the - ly from an adverb, e.g. 'don't do that so slow'Tag questions used in confrontation, e.g. 'I said I was going, didn't I? 'Double negatives are the probably the only variation in grammar which could cause confusion to a standard user listening. If someone says, 'I didn't do nothing,' it is usually presumed that they mean they didn't do anything. However, the meaning could in fact be they did something rather than doing nothing. Generally the phonological variation will tell us which meaning is being implied by certain intonation and stress on either the 'do' when meaning 'I didn't do anything' or on the 'nothing' when meaning 'I did something rather than nothing.' So all these grammatical variations are not too difficult to understand if someone uses them even if you don't use them yourself. Variation in Discourse at dialects and idiolects and why people say things in a certain way to communicate their point. Variation has occurred but understanding of different dialects is better now than it was when traditional dialects were very regionally pronounced and definite borders between regional dialects existed. This is due to people moving around more. People do not tend to stay in the place in which they grew up. They move either for work or for education or due to relationships. They are therefore not only exposed to the dialect of that area where they grew up. Commuter-lifestyles can also lead to exposure to more than one dialect. Also, Compulsory education has meant that everyone is taught in Standard English, so even if they have regional dialect, they are also educated in the standard. Lastly, the media and technological advances such as the Internet use a variety of dialects especially the e-mail and chat-room language known as Leet. We would be exposed to standard in the newspapers and television news, but also to regional dialects in television programmes such as the many regional soap operas. Vocabulary is the main variant. Slang and colloquialisms are commonly used and although they age, each generation will have a set of slang words that they understand and often use. 'No part of 'usage' changes more quickly than verbal currency.' Regions have different words that are not in the vocabulary of other regions. For example gym-shoes are commonly called 'plimsolls' in the South East (London, Brighton), but are called 'daps' in the West (Bristol, Gloucester). World English is even more varied than the regional variations I have looked at. There isn't really one 'standard English' nationally. There is a Standard English as we know it, a Standard American English (SAE), an Australian SE, a Caribbean SE, one SE for East Asia and one for South, and more throughout the world. Most of the varieties have either British SE or American SE as their basis, but as can be seen in figure, there are variations in the three areas looked at earlier from Kerswill's article Variations of English are often used as a Lingua Franca in trading and business. Some of these have elements of other languages in them, but still manage to communicate successfully. English is many people's second language, and is learnt in a basic form at many French, German and many other nationality's schools. Most of what is learnt in foreign schools will be SBE. British Black English has become a creole language. It is a symbol of identity for black youth culture. It is yet another variety of English but is broader than a dialect, and not regional. Creoles were once thought of as corrupt forms of a language, but some have now become accepted and are seen as an important expression of personal and national identity. Therefore, unlike dialects, creoles as language variations are not generally seen as inferior. Attempts to standardise English have been made by campaigns such as the 'Speak Good English Campaign' in Singapore, where many people speak a cross between Chinese dialects and English known as 'Singlish'. The government are encouraging people to speak Standard English. There is an example of this sort of campaign in England also. The Plain English Campaign does not campaign for Standard English, but it calls for one version of English that is understandable to all no matter what their social class, regional origin or background. They say that, 'the golden rule is that plain English should be used in any information that ordinary people rely on when they make decisions.' There are linguistic hierarchies nationally and regionally. However, the terms of equal change according to social factors. For example, SE is seen as more prestigious and formal, whereas some regional dialects such as Welsh and Scottish are seen as more friendly. It depends on the factor that is being researched as to which languages are at the top of the hierarchy. Most people generally know Standard English, being the one that is taught in schools, and most people can use it when called for. However, as long as the dialect they use relates to the situation they are in, it can be understood, and that, to me, is all that matters. It is therefore to do with register and style according to circumstances. Lingua Francas work because both parties understand them. They do not need to be Standard English as long as they are understood, and since both parties have comprised them, both parties should have understanding of it. I feel therefore that the conclusion of this essay should be that there is no question of equality in language itself, more a question of equality in society. As long as there is understanding between the participants, one variety is equal to all other varieties as long as they are understood. Standard English can be used when called for, and as long as it is still taught as a basis, there can be divergence towards this when people of two different dialects conflict. The increase in mobility of people also means that we are more knowledgeable of other dialects, and with knowledge comes acceptance, and therefore 'equality'.'''",537.0
"'''The Tamworth PigThe Tamworth pig probably descended from the Old English Forest Pig from 683 and is now extremely popular throughout Britain and also the World. They originate from the Midlands and the name derives from the Staffordshire town, Tamworth. The Tamworth has long legs, large pricked up ears, a long head and body, a straight belly and a distinctive red/ginger coat. Records show that this colour has not changed since the 800's and importantly the coat prevents sunburn in summer. They are medium sized with Boars weighing between 35/8-00 pounds and Sows between 5/80-5/80pounds. Sows do not produce large sized litters compared to other breeds; normally about -0 piglets but they are very careful mothers. They are a slow maturing breed and are often known to be energetic yet not nasty, but pigs that enjoy life and are can be very affectionate. Statistics of the TamworthThe Tamworth is listed in the Rare Breed Survival Trust along with many other breeds of pigs. However, the Tamworth is seen as an endangered species due to only 23 breeding females left in the UK. This table shows how the Tamworth Pig is an endangered species and apparently there are less than 000 in the world. The reason as to why these rare breeds are rare is because they do not fit in with modern day production systems. However, this can change if people stop thinking we should not eat rare breeds. Instead they need to be persuaded to possess these animals and eat them, because the demand is what will save them. This graph is a representation that the Tamworth Pig population had declined dramatically over the last 0 years. The above graph is only portraying data from Canada, which backs up the point that this is not only a localized problem but also a world wide one that is being addressed. Around 885/8, exports of the Tamworth Pig to other countries around the world occurred, including America and Australia. In 877, Canada received the Tamworth Pig but in the mid 960's a decline occurred due to many reasons such as competition from other breeds and also new regulations. Between 998 and 003, 5/81 registrations were recorded, but from the graph you can see since 970 slight fluctuations have occurred, showing how the registrations vary from just a few pigs up to just over a 00. Why should the Tamworth be conserved? There are many reasons as to why the Tamworth should be saved. The bacon and pork has a great quality due to the length and depth of the body and the proportion of fat to lean red meat is very favourable. In the 990's, out of commercial and rare breed pigs, the Tamworth came out top according to a 'taste test' performed by Bristol University. The Tamworth saw a decline due to competition by mass marketers; hence one of the reasons to preserve the Tamworth is that it would more benefit from a niche market due to its high quality meat. Another reason is that the Tamworth is exceptionally good at being reared on pastures. It has a long snout which means it is very good at clearing an area, especially woodland. It is an ideal animal for any gardener who wants their land cleared. Being a descendant of the Old English Forest Pig means they suit rough woodlands and forests. They are a disease resistant pig and can cope with extreme temperatures. Sites of Special Scientific been created for Conservation measures for these pigs. In which they graze on environmental areas such as National Parks and Nature Reserves. The photo above shows woodland cleared by Tamworth pigs. The pigs are extremely happy to live outside and be able to wander freely throughout brambles and bracken in which they remove by grazing. Another reason for saving this breed is that cross breeding can occur. In the 8 th Century, most breeds were crossed with others, however the Tamworth was not, hence it is known as a pure breed. Today, the Tamworth is used to cross with other breeds such as the Berkshire, in order to produce good quality meat. Some breeds do not produce exceptionally good meat, so by crossing them with a Tamworth they benefit much better. SurvivalTamworth Pigs have so many reasons and benefits as to why they should be saved and kept alive. How they are saved is the question though. DNA testing save and safe guarding existing genetics and developing a breeding strategy are all possibilities. Technology still needs to be developed so that the freezing of semen, embryos and tissues can be improved, in order to save certain breeds like the Tamworth. The Rare Breed Survival Trust (RBST), which was established in 973, has ensured that no British farm animal has been wiped out and the Trust relies heavily on donations to carry out its work. Rare Breed Farms are found in the UK and are essential in order to preserve and maintain these rare breeds. Kentwell Hall, in Long Melford, Suffolk has a Rare Breed Farm in which Tamworth pigs are kept and looked after. In 978, Kentwell received its first Tamworth Pigs and have bred them ever since. Places such as Kentwell Hall, are essential in order to preserve Rare Breeds, such as the Tamworth Pig. Thousands of visitors arrive each year and this also helps to promote the rare breeds and prove how important it is to conserve them so they do not go extinct. This is an example of commercially exploiting a rare breed like the Tamworth. The market is extremely important for rare breeds because it is here that will decide the fluctuations of the population. The Tamworth is a rare breed partly because it can not keep up with market needs, therefore it has become rare. Today, supermarkets require specific conditions so many breeds suffer. So, in 994, The RBST created a scheme in which individual butchers' offer different breed meats so the consumer has a variety of tastes. An example of this is Powters Ltd, Newmarket, Suffolk. In conclusion, The Tamworth pig is in danger and without Trusts and places such as The RBST and Kentwell Hall, the Tamworth maybe extinct. The Tamworth is now seen on an international scale, despite it being a rare breed. With its good quality meat, grazing benefits and cross breeding, the Tamworth is defiantly worth saving. It just needs more people and the market to realise what an important, yet efficient animal it is.'''",541.0
"'''The major objectives of this laboratory were: To give an appreciation that there are many factors to be considered when using a manufacturing process to convert raw material into a useful product.To understand that if any of the process variables are changed, the properties of the final product will also be changed.To appreciate that there can be differences between laboratory scale processes and industrial scale processes.The product to be manufactured was an oilite bush. Six bearings were to be made, with two groups of students making three each. The amount of for the bearings was weighed according to the specifications given in the laboratory handout. The powder required for one bearing was put into the die and pressed by the hydraulic press. It was then removed from the die using the hand press and the dimensions were recorded. The same process was used to make six bearings by two groups of students. These were then kept in the furnace for sintering for 0 minutes. The dimensions were noted again and the bearings were then applied with axial loads till failure. The load at which the bearings failed was noted. Using the recorded data, Table and Table were completed by calculating the the density the final product according to where E is Young's modulus and d is the maximum density of iron. APPARATUS AND METHODSApparatus:Die- PowderBeakerPlastic BoatCeramic BoatSpatulaDial Gauge Vernier CalliperFace masks, glasses and protective gloves for protectionElectronic balance, hydraulic press, hand press, furnaceMethod:Powder PreparationThe product design specification was given in the laboratory by using different the density.4 =.7 g Mass of Zinc Stearate for each bearing (% of weight) =.6 g For six bearings: iron = 9.2 g, ZnSt =.6 g Powder CompactionLength of uncompressed Powder for all bearings (L p): 8.75/8 mm Measurements after sintering stageAfter the bearings cooled down, it was observed that those that had been subjected to heavier loads appeared shinier on the surface. DISCUSSION OF RESULTSAt the end of the laboratory, a graph was plotted for ln against the compaction pressure (in MPa) (Refer Graph A). It is observed that the graph line is not straight, but the trend line can be used to calculate the pressure at which g = i. This is the density of iron that is listed in the design specification. Using the length of the uncompressed powder measured at the beginning of the powder compaction stage, the apparent density of the powder in the die cavity, p, was determined (Table ). This density is affected by factors such as a change in the amount of powder that is put into the die, the manual pressure that is applied to it, and the measurements of the external and bore radius of the die. The apparent density is so called because at the stage when the length L p was measured, the powder had only undergone manual compression, and not the load of the hydraulic press. It is observed that p was less than half of g. Hence, p was not the final density of the bearing. The laboratory process seemed to be suitable for small-scale processing of bearings, but inappropriate for any large-scale manufacturing. This is because the laboratory process involved the measurement of the powder by weight, which was time consuming and hence, cannot be used on an industrial level. A better method to fill the die would be the measurement of the powder required for the bearings by volume. This will consume less time and will be more economical for a process that would manufacture millions of small oilite bushes. The laboratory highlights that fact that changing one variable during the process of manufacture alters the end product, but a change in another variable can prevent the alteration of the product. For example, an increase in the mass of the powder will change the density of the bearing, but the length can also be decreased to keep the density constant. Referring to Table, it can be observed that not all the bearings have final measurements that fall under the product design specification listed in the laboratory handout. Hence, the values that are highlighted in bold are those that are the correct final values. The bearing that was loaded with a compaction pressure of. Tons from our final product seems to be most suitable for the manufacture of required bearing. Its specifications are: This is the most ideal bearing, though there may be a bearing more suitable to the specification from those that had been sintered for 0 and 0 minutes. These cannot be compared with in this laboratory due to the lack of data available. CONCLUSIONThe aim of the experiment was to appreciate various factors concerned with manufacturing a bearing. It analysed the fact that a manufacturing process involves many factors that need to be considered when raw material is converted into a useful product. Also, if any process variables are changed, the properties of the final product may change, but changing another variable in the process can compensate for this. Also, the laboratory highlights that there are many differences between the processes used in small scale processing as compared to large scale industrial manufacturing.'''",544.0
"''''The law whereof this summary is made, is of ancient usages warranted by holy scripture; and because it is generally given to all, it is therefore called Common.' Sir Edward CokeCoke, 'Deo, Patriae, Tibi' preface to part of the Reports, supra note taken from Raffield, Paul: Contract, Classicism and the Common-Weal, Coke's Reports and the foundations of the modern English Constitution, Law and Literature, Vol 7, Issue, University of California Press for the Cardozo School of Law, 005/8 The common law has long been thought of as an unchanging body of common sense and reasoning fundamental to the heritage of English people. The common law is the foundation of the English legal system, described by Sir Edward Cooke as 'a maxim of policy, and trial by experience' and as having been 'refined and perfected by the wisest men in former succession of ages'. Sir John Davies wrote that 'the customary law of England. Doth far excel our written laws.' Therefore it can be seen that the primacy of the common law is of fundamental importance. Le Quart Part des from Baker, J.H: An Introduction to English Legal History, Butterworths, Fourth Edition, 002 The common has developed from its earliest origins of the Druids, the introduction of written laws from the Anglo-Saxons and the expansion and modification of the Norman invasion. The common law came under threat from the civil law embodiment of the Corpus Civilis Iuris of the Emperor Justinian and the revival of Roman law. During the sixteenth and seventeenth century the legitimacy of the common law was in direct conflict with the imperialist claims of the King, escalating during the rule of Charles I; ultimately leading to civil war, the execution of the King and the effective creation of the English constitution as we know it today. Throughout the development of the common law it has undoubtedly been subjected to numerous influences and theologies affecting its direction and development. One of the most influential is of course the Judaeo-Christian theology, an emanation of the natural law theory, its significant influence resulted in the words of William Dugdale, that 'the Common Laws of England are grounded upon the Law of God'. In order to determine the importance of the Judaeo-Christian theology I shall examine its influence upon the development of the common law and the secular legal profession, in particular focusing upon its period of greatest influence and importance during the sixteenth and seventeenth centuries. Dugdale, William In order to create a more accurate representation of its importance, I shall also undertake a comparative analysis with two other importance influences upon the common law. Firstly the classical Graeco-Roman theology, which arguably influenced the development of the common law in challenging the imperium of the Tudor monarchs and became a basis for the legitimacy of the modern secular legal profession. Secondly I shall also analyse the influence of the symbolic nature of the common law, that its legitimacy is borne from its antiquity and history and its utopic nature. In undertaking these comparative analyses I hope to discover the true contextual importance of Judaeo-Christian theology. Judaeo-Christian TheologyJudaeo-Christian theology is the basic principle of the indivisibility of law and God. Writers during the early modern period aligned the English law with God, Fulbecke stating 'where God is not there is no truth, there is no light, there is no Lawe' thus demonstrating the English constitutions indivisibility of divine law and common law. Fulbecke, William: A direction or Preparative to the study of Lawe, London, 5/899 The Act of Supremacy in 5/834 was one of the most fundamental influences upon the common law of England. One effect of the reformation was to abolish the ecclesiastical courts, removing the opportunity of appeal to the Pope. Many common lawyers advocated for the abolition of the church courts at the same time, however this would have required a fusion of canon law and Common law, which was never a feasible proposition. The Judaeo-Christian influence upon the common law can clearly be seen through the practices at the Inns of Court. The Courts symbolic eating rituals and oratory nature were likened to those of monastic origins. The order of dining was described to be 'the order of a lawful world, a symbolic order in which Justice, Rule and Law are to be understood to be expressed together through culinary measures, victuals and wine'. During dining members would take communion, further aligning the Judaeo-Christian theology and the practice of law. These rituals became fundamental to the teaching of law and legal practice. Fulbecke, William: Direction or Preparative to the study of Lawe, London, 5/899, epistle, p3 taken from Goodrich, Peter: Commons, Common Land, Common Law, The Journal of Legal History, Vol 2, No., Dec 991 p246-7 In essence the relationship between the Inns of Court and the Judeao-Christian theology was the defining influence upon the common law during the sixteenth and seventeenth century. The Act of Supremacy in 5/834 resulting in the emancipation of England from the jurisdiction of Rome fundamentally altered the legal and political culture of England. The newly created imperial power of the King created a division between common law and the monarchy; both vying for legitimacy and supremacy. Henry represented himself as Imago Dei and adopted the European jurisprudential stance, quod principi plaucit vigorem legish became an issue of great conflict for the Judaeo-Christian theorists, two competing bodies fighting for divine legitimacy. The failure of natural law to deal with the resultant conflict with the imperium of the King was a significant theme within Titus Andronicus. Following the impact of the Act of Supremacy and increase in Henry's prerogative power forced common lawyers to consider other sources of legitimacy, arguably giving rise to the influence of the Graeco-Roman tradition which I shall deal with shortly. However it would be incorrect to argue that the common law abandoned all Judaeo-Christian influences as this was not the case. Raffield, Paul: Titus, Troynovant and the Loss of Justice During the rule of Charles I common lawyers continued to oppose the concept of the 'intrinsical' prerogative of the King, Coke stating that 'it is an act of right, not of grace, that we stand upon'. Charles I continued to be at odds with the common law and during his Personal Rule intervened numerous times as to the regulation of the Inns of Court. The outbreak of civil war permanently altered the nature of legal education within the Inns, its role undermined by the rule of Charles I. Following his execution in 649 a new government was established under Cromwell in the name of Judeao-Christian theology, although its authoritarian nature, isolated those common law, JudeaoChristian scholars from positions of influence. Paragraph taken from Lecture Notes 642-65/83 Other Important Influences In the political context of the Act of supremacy, it became necessary for the common law to adopt an opposing source of legitimacy in opposition of the monarch. The common law adopted two major theologies in its fight for supremacy; that of the Graceo-Roman theology, based upon community and citizenship and that of the historical supremacy of common law. I shall examine both of these in relation to their impact upon the development of common law and the secular legal profession. Graeco-Roman TraditionThe Graeco-Roman tradition is one emanating from that a positive law jurisprudential stance. In the political context mentioned above it became necessary for the common law to rely upon a new ideology to assert its constitutional supremacy. As a result contemporary jurists began to rely upon the Graceo-Roman theology as a basis for legitimacy. The theories of justice and fairness described by Aristotle and Plato became the perfect antidote for the authoritarian monarchic rule. The concept of citizenship and the Roman Republican law, Salus Populi Suprema Lex legitimacy and origin and could therefore provide a much more powerful defence to the imperium of monarchy. Aristotle, The Politics Plato, The Republic The concepts of righteousness were embodied within the legal profession within the Inns of Court. Fortescue described the Inns as 'a Sort of an Academy or Gymnasium, fit for Persons of their Station; where they learn Singing, and all Kinds of Music, Dancing and such other Accomplishments and Diversions'. The significance of this is Fortescues endorsement of the works of the Inns from a secular perspective, praising the teaching and ethos of the Inns. The Inns became a manifestation of Plato's ideal state and a symbolic of justice and righteousness. Fortescue, De Laudibus Legum Angliae p111 Although theories of Graeco-Roman tradition arguably did not command the same importance upon the common law, they represented a move away from Judaeo-Christian philosophy, towards creating a secular legal profession. Despite the religious influences this at least marks a step towards the principles of the modern profession. Finally the influence of justice and righteousness of the Graeco-Roman Tradition were embodied in the claims to liberty and equity from John Lilburne and the Levellers. Following the execution of Charles and the creation of the Commonwealth and Cromwell's Protectorate, Lilburne became the advocate against tyrannical government, writing to Cromwell 'insisting that the tyranny of Parliament as well as the tyranny of the monarch was resistible.' Although ultimately unsuccessful in his fight against the 'absolute Arbitrary Sovereignty' of the commonwealth, Lilburne filled the void left by common law activists and the Inns failure to oppose the increasingly intolerant government. Haller & Davies, The Leveller tracts, 647-65/83, 'Jonah's Cry', New York: Columbia University Press, 944, p10 - Lecture Notes Whitelock, Memorials, fo 5/82 Historical Supremacy The final influence upon the development of the common law is that of the historical supremacy of the common law. Although in many ways this did not develop the common law through change, it was a theory advocated by many eminent contemporary scholars and was widely endorsed against the monarchic imperium. The theory states that strength and indeed unique nature of the English common law is borne out of its antiquity and legitimacy of existence since 'time immemorial'. In 470 an English serjeant-at-law maintained that the common law had existed since the creation of the world. The significance of this is noted by Goodrich, that Baker, J.H: An Introduction to English Legal History, Butterworths, Fourth Edition, 002 P1 'The indefinite time of the originary refers to a past which was never present; it refers to an archetypal time whose function is iconic and not representative, it can only be personified symbolically since it has neither human nor historical likeness.'Goodrich, S&LS -8 at 1 Taken from lecture notes This demonstrates that the reality of the origins of the common law are effectively immaterial as more important is the symbol of antiquity and legitimacy which the system conveys. Essential to the legitimacy of the history of the common law is Cokes argument of the 'artificial reason' that the common law is borne out of the knowledge and experience of many before and is tested by the experience of those after. Therefore, 'optima regula, qua nulla est verior aut firmior in jure, neminem oportet esse sapientiorem legibus: no man ought to take it upon himself to be wiser than the laws.' This encompasses the theory of the common law as custom, of immemorial, the doctrine of the ancient constitution. Coke, Seventh Reports, Calivin's Case; here from the edition of the Reports by Thomas and Fraser (London, 826), vol IV p6 taken from Pocock, J.G.A: The Ancient Constitution and the Feudal Law, English Historical Thought in the Seventeenth Century, Norton & Company, 95/87 p35/8 Imagery of the legitimacy and importance of the common law was showcased through the revels and masques of the Inns of Court. In doing so the members learned oratory skills and performance and created a utopian state The significance of the history and myth of the common law is not in its content or even its practical development of the common law but in its ability to protect the legitimacy of the common law against the encroaching forces of the imperium monarchy. If there is faith and belief in the system it can continue to function and succeed, without that it is nothing. The masques of the Inns of Court, the Shakespearean references to the power of the common law and the mythology of Geoffrey of Monmouth's King Brutus of Troy, all worked together to create the utopian myth of the common law of England. Its value and importance should not be underestimated when considering theories which contributed to the development of the common law. Finally it should be remembered that this legal imagination and mythical idyllic foundation for legitimacy is still used today. The establishment of this mythical, utopian ideal is something that cannot be touched and cannot be challenged, a prospect which should protect the common law for many years to come. Conclusion When assessing the development of the common law and the origins of the secular legal profession, it seems clear that the modern constitution as we know it was influenced by a combination of all of these factors. There can be no doubting that the Judaeo-Christian theology had a hugely significant impact upon the development of the early common law. The Judaeo Christian theology provided the common law with its legitimacy and its influence is seen throughout the early ecclesiastical courts and in the teachings at the Inns of Court. The Judeao-Christian theology was fundamental to developing the common law through the teaching at the Inns of Court and provided common lawyers with a theoretical basis to defend the common law against the imperium of the King. Similarly the Graeco-Roman Tradition allowed common lawyers to rely upon an alternative source of legitimacy to battle the Kings prerogative powers. Although such a belief appears to be contradictory to the indivisibility of God and law, many common lawyers believed in the Coalescence of the two theologies, creating a divine based law, advocating ideals of citizenship and the welfare of the state. Finally there is the importance of the image and antiquity of common law. In analysing these three influences a common theme arises of a protection of the common law, rather than a development. All three theologies sought to protect the common law from the imperium of the King and the tyrannical rule of the Commonwealth and Protectorate. The Judeao-Christian influences within the Inns of Court helped to develop the common law through oratory, teaching and dining and created a body of lawyers and a utopian state. When deciding upon which was the most important influence, the historical antiquity of the common law is surely the most deserving. The significance of the immemorial nature of the common law is not a tangible matter, but a utopic ideal. In creating a legitimacy and faith in the law so strong, as demonstrated by the fervent support from the likes of Fortescue and Coke this has created a legitimacy and a legacy which one can only hope will last forever. 'we must not hold antiquity to be that which is old, nut that which is oldest. antiquity has no bounds, no limits, it signifies the ages of an indefinite time.which indefinite time tough in itself it passes by all things created, and rests only in that infitnite majesty, beyond whom there is no time, without whom there is no being, for whom there lieth no appeal.'Antiquitie Triumohing over Noveltie (Favour, 619: 3- taken from Goodrich, Peter: Poor Illiterate Reason: History, Nationalism and Common Law, Social & Legal Studies, Sage, Vol., No., -8 P11 '''",547.0
"'''In 003, the university I was working for was sponsored by the Ministry of Education in Taiwan to organize a five-day English summer camp. It aimed to help the suburban senior high students improve their English ability and bridge the knowledge gap between students in city and country. As an organizer and also instructor of the summer camp, I was aware that it was almost unlikely to make the participants progress significantly in terms of their English ability within such a limited time span of five days. Besides, coming from disadvantaged schools, these students were usually short of confidence and motivation in learning, which turned the whole task more challenging. Therefore, instead of focusing on the students' learning product, I wanted to put more emphasis on their learning process. What I was intended to do was to lower the participants' anxiety level, break down their defensive walls of inhibitions they set to protect their fragile language ego, and build up their confidence in using English. I set myself a goal of creating an encouraging and supportive learning atmosphere in the summer camp where the participants could use English for real communication, take a role of active learner, and feel dauntless with trial and error when using English. But the question was what teaching method and course design could turn them on to English. It seemed to me that the combination of drama and English teaching might be a practical solution. So this study sets out to develop an integrated English and drama course for the disadvantaged students and reports the findings of how educational drama methodology can be used to create a meaningful context for English communication, boost the students' self-confidence, promote social cooperation, and enhance learner autonomy. Literature ReviewThe framework of the course design was based on the principles of cooperative learning, and the students' affective factors were also important considerations. In the following discussion, I am to provide a clear picture of the underlying rationale of this study and illuminate the benefits that drama can bring to the students' English learning. Affective Factors vs. Foreign Language LearningIn the past two decades, research on the relationship between foreign language learning and affective domain has proliferated. One's cognitive development cannot be separated from his/her affectivity. According to Stern, 'the affective component contributes at least as much as and often more to language learning than the cognitive skills' (p. 86). That is to say, there will be a serious flaw in any second language acquisition theory or teaching methodology if it is based only on cognitive considerations because it leaves out 'the most fundamental side of human behavior' (Brown, 987, p. 9). This fundamental side of human behavior can be unfolded with following classification: self-esteem, inhibition, making mistakes and anxiety. Self-esteem and Self-confidenceSelf-esteem is one of the pivotal predictors of achievement. Brown highlights the predictor, arguing, 'no successful cognitive or affective activity can be carried out without some degree of self-esteem, self-confidence, knowledge of yourself, and belief in your own capabilities for that activity' (987, p. 01). With accumulated self-confidence, one can bring all potentials into full play. Self-esteem can be nourished by teaching in which learners' self-assessment of their own learning is encouraged, both alone and with peers in cooperative learning came from marginalized areas in Northern Taiwan. Generally speaking, the students from suburban district tend to have a feeling of self-doubt and devaluation about their academic abilities. Moreover, it is common to find fear of failure and the undesirability of testing one's limits among them. The participants' responses to the questionnaire also validated the presupposition. Most students claimed that they did not feel confident in communicating in English and considered themselves low-achievers in terms of academic performance. Case Study DesignThis case study was conducted in a five-day summer camp, aiming at facilitating the students' English learning through drama. In the summer camp, the participants all lived and at meals together on campus in order to extend their interactions beyond the scheduled teaching hours. They took three-hour English classes in the morning and had drama classes for another three hours in the afternoon. The morning English sessions, conducted by the researcher, functioned as language and cultural inputs. The teaching content was theme-based, including simplified script of Romeo and Juliet, two movies - Shakespeare in Love and Romeo other messages simultaneously. This immediacy prompts new understandings and uses of language as a direct result of the active experiencing of the fiction' (Neelands, 992, p. ). The afternoon drama classes were designed and taught by an experienced high school teacher with an MA degree in Applied Drama. Her teaching goals were to arouse the students' awareness in the use of body language, stimulate their imagination, enhance their self-confidence, introduce drama elements and help create a cooperative atmosphere among groups. On the first day, the students started from developing body awareness and spatial perception through a series of warm-up activities. Then the teacher used some dramatic activities to introduce the students to the concept of roles and scenes. They also learned to develop stories by using pictures, narration and still image. On the second day, the students were taught to create simple improvisations based on personal experience and imagination. In addition, they learned how to develop characters via describing objects and defining the space. Conflict, an important element of drama, was brought in with improvisation. Role-play was the main activity on the third day. The students were given English role cards to read and to work in pairs to 'develop a solidity of characterization which can be sustained within the improvisation' (Somers, 994, p. 8). Through this activity, the students could gain a better understanding of empathy and 'become sensitive to the way in which our built-in views of our own roles and those of others are defined and clarified through language' (Maley and Duff, 978, p. 0). On the following day, the teacher had the students improvise a short English play with different acting styles and in various space and time questionnaire was distributed to the participants at the end of the summer camp to investigate their opinions about the curriculum. Before setting about to write this research paper, the researcher emailed another questionnaire with open-ended questions to the students, the teacher and the camp assistants to have a further exploration on the influences of the drama classes and competition. Video clips and digital photos of the summer camp were attached to the email to refresh the surveyees' memories. Data AnalysisAccording to the gathered data, the researcher found positive evidence showing that the drama curriculum and drama competition successfully enhanced the participants' self-esteem and self-confidence. Their anxiety levels were lowered with support from the cooperative learning group and they were more willing to take risk in trying out language use. The findings will be presented quantitatively and qualitatively as follows. Drama is a facilitating tool for English learning. The students were asked to respond to the statement: I think the drama classes were helpful to my English learning on a four-point Likert scale. All of them held a positive attitude towards the efficacy of drama. Some students enjoyed learning English through drama because drama provided a meaningful context for them to communicate in the target language. They could have more interaction with each other. A student complained about the English at school and said, 'the school class is so boring. The teacher always puts you into sleep'. Another student made a very interesting comment on the differences between traditional English learning and learning English through drama by stating, 'The dramatic activities in the summer camp were fun and had so much variety and interaction. The English classes in my school are boring. There is no interaction at all. And sitting on the chair all the time hurts my buttocks! Learning with more interaction is much more fun.' Some students liked learning English through drama because their imagination and creativity were allowed to thrive in the dramatic world. A student pointed out, 'It was more lively here. We could add in our own creativity and ideas. Every group's presentation had its distinguishing characteristics but they were all clearly presented'. Another student confidently expressed her point-of view in English: 'They just translate everything on the textbook, and explain the grammar. Drama camp is so much better. It gives us the space to create and develop our own stuff. We don't just learn the language, but we also build the language. I like that. It's nice that you want to bring this in our education system.Drama also helped the students to comprehend English by actual doing and being. 'Through drama, I learned to experience and comprehend language with my body, which motivated me to speak English more' - a statement made by a participant coincided with Wessels' claim of using drama in English teaching. Experiences in drama increase the students' self-confidence in using English. According to the questionnaire, the majority of the confidence in their English abilities before attending the summer camp. The reasons for their lack of confidence were listed as: fear of speaking Englishdeficiency of English language competence having no opportunities to speak English in the daily lifefeeling embarrassed about making mistakes in English grammar and pronunciationHowever, the drama classes broke down their psychological inhibition and made all of them feel confident. The following is some comments made by the students: 'I did notice some of my partners became more confident in using English after attending those drama class. It worked!''The dramatic activities enlivened English learning. It was like playing games, which made speaking English an easier thing to do.''The summer camp was like a stage for practicing English. We had opportunities to use English whether we were on stage or off stage.'The camp assistants also observed the increase of self-confidence among the students: Assistant K: 'Some students who considered themselves as low-achievers in English learning said, 'I just couldn't believe that I was able to act in English!' And lots of students shared the same thought. On the one hand, the dramatic activities indeed lowered their anxiety about speaking English. On the other hand, drama also increased their interest in learning English.'Assistant S: 'It's impossible for their English to improve too much within only five days, but I think they have gained a lot of self-confidence.Assistant L: 'At the beginning, they were afraid of speaking English because they thought their English was not good enough. However, after a couple of days, they were able to make a short play by combining simple sentences. At the final rehearsal, all of them had the courage to speak out even though there were still some grammatical mistakes and misuse of vocabulary. I think they have already crossed the hurdle of speaking English.' Assistant P: 'On the first day, very few students responded to me in English. However, they became totally different on the last day. I was surprised by the concentration and self-confidence they showed when acting and speaking English on the stage.'Drama activities necessitate cooperative learning. Ninety percent of the participants agreed that learning how to work as a team was what they benefited the most from participating in the dramatic activities. The students considered the drama competition as a catalyst to encourage cooperation among members. As Nunan notes, 'collaboration and competition can coexist in the same classroom; for example, when learners work collaboratively with some learners in a small group, but competitively against other learners in other groups' (992, p. ). The researcher stayed with the participants till midnight for a couple of days and saw them having spirited discussions about how to present their play. There were certainly some heated arguments during the discussion but they could always find a way to reach a consensus. Moreover, the participants were transformed from passive, low-motivated students into autonomous learners who were willing to sort out problems on their own initiative. They tried every possible way to make their play a better one - calling their friends for help, asking camp assistants to see them rehearse, consulting the teachers about the English usage. This kind of autonomy is rarely seen in the traditional classroom setting. With the support from peers and teachers, those who said they would never go on stage on the first day all volunteered to give a short speech about themselves in English in the drama competition. Even though only a few groups could win the prize at the end of the competition, the result did not overshadow the students' joy of accomplishment. Some students commented: 'We didn't win the prize but the process is more important than the result. And the most important thing is we all did our best!''I like the drama competition. It exhausted me but also gave me a sense of achievement. It was more rewarding than getting high scores in exams.''We all worked very hard in discussion, making props and participation. We even rehearsed till midnight the day before the competition but our performance was really an unforgettable one!'ConclusionDrama has the potential to develop communication abilities, increase English learning and promote a positive self-concept in an interactive, fun way. Successful language learning requires the whole person to reach out in an integrated way - intellectual, physical, and affective. However, most English teachers in Taiwan rely mainly on grammar-translation-oriented teaching methods, in which English is taught in a vacuum as a set of language skills without immediate utility and only students' mental effort is called for. While some students can survive in this learning scenario by performing well on discrete-point tests, most of them are overwhelmed by the fear of using English as a communication tool and even lose their confidence. Drama offers the students a chance to rethink the way they learn English. Through drama, they can experiment not only with verbal aspects of language but also non-verbal communicative aspects. By working in a cooperative group, they gain confidence to interact. In the dramatic context, they are able to feel the language rather than memorizing it mechanically. The summer camp ended two years ago but its influence is still felt today. In February 005/8, a student formed an online community for the members of the summer camp and most of the participants have joined in. Two students emailed me about their decisions of applying for the drama department in university. One student has already entered university, majoring in English. Drama has yielded fruitful results beyond what I expected when designing the curriculum for the summer camp.'''",551.0
"'''Sociologists have traditionally been divided into two groups depending upon their ontological position; Individualists emphasise the importance of an individual's action, whilst Collectivists give primacy to the role of social structure in the construction of social reality. Recently, however, these rigidly demarcated ontological positions have been challenged by the emergence of Realism and Structuration Theory. This essay is concerned with assessing the strengths and weaknesses of Individualism and Collectivism; the main issue under consideration is how far these opposing ontologies disprove each other. This essay will argue that neither of these ontologies sufficiently describes or explains the complexity of social reality, and it is because of their deficiencies that I have been persuaded to adopt a Realist perspective. This argument will be pursued by outlining the debate between Nicos Poulantzas and Ralph Miliband concerning who or what constitutes the 'Ruling Class', in order to show how I was first alerted to the stratified nature of social realty. It will then be discussed how Collectivism successfully discredits the methodological premises of Individualism, yet does not constitute a comprehensive ontological alternative. Following this will be a description of how Realism provides the ontological explanations that Collectivism by the researcher's description of social reproduce the stereotypes and assumptions of everyday the common interest of reproducing the capitalist. Therefore, I was encouraged to believe that there were two distinct strata of the 'Ruling Class', which could not be reduced to each it susceptible to criticism from psychologists who state that people themselves can be reduced further still into their underlying psychological Individualism's premise that everything in society is reducible to an individual's dispositions. The Individualist's response to this criticism is to incorporate all non-individual and non-dispositional factors into their concept of the individual, such as a person's 'physical resources and environment' (Watkins, 971; 10). This again reveals a contradiction, as these aspects of social reality are not about individuals or are central to the Individualist's concept of the individual. Individualism's inability to discredit the Collectivist's concept of social structure provided further impetus not to adopt their view. Individualism cannot successfully prove that social structure is not autonomous from, pre-existent to, and does not exert a causal influence over of the individuals the concerted efforts of individuals trying to change them; this proves that structures pre-exist and outlive specific individuals and their attempts to alter them by showing that they possess properties independent of the individual's social structures causal power, because they are neither observable nor causal in their could not advance a counter- the existence of non-observable structure versus action dualism. It therefore follows from the evidence presented here that I adopted a Realist view of social reality because of the insufficient level of importance and autonomy assigned to either action or structure by other perspectives. Individualism cannot successfully deny the importance of an autonomous, activity causal social structure, whilst Collectivism cannot disprove Individualism's ontological foundations because of its own Empiricist nature. Similarly, Structuration Theory does not transcend the structure versus action dualism, but merely reinvents the terms of the debate in another terminology. Consequently, Realism offers the most comprehensive perspective of social reality because it takes the existence of both individual action and an autonomous social structure as its central tenet, and avoids the ontological and methodological contradictions of the approaches that define these features as inseparable.'''",555.0
"'''Passage for Discussion'. Hector sent his voice ringing out to the whole Trojan army: 'On with you, horse-taming Trojans! Smash the Greek wall and fire the ships!' So he spoke, and there was no Trojan ear that did not catch his stirring call. Massing together, they charged at the wall and began to scale the parapet with sharp spears in their hands. But Hector seized and brought a rock that was lying in front of the gate. Broad at the base and coming to a point, it would have taxed the strength of the two best men in any town of the present generation to lever it up from the ground onto a waggon. But Hector handled it effortlessly on his own. Zeus, son of sickle-wielding Cronus, had made it light for him. As a shepherd easily picks up a ram's fleece in one hand, carries it off and scarcely feels the weight, so Hector lifted up the rock and brought it towards the planking that made up the high, strong, well-fitted double gates, which were held on the inside by two beams sliding in from either gate-post, locked by a single bolt. Hector went right up to them and bracing himself, legs wide apart for maximum power, hurled the rock, hit the doors full in the middle and smashed it out of its pivots on either side. The force of the throw propelled the rock through, and there was a great roar from the gate as the planks were smashed to splinters by the impact of the stone and the bars gave way. In leapt glorious Hector, face dark as nightfall. He held two spears in his hands and the bronze of his body-armour gleamed with a baleful light. None but a god could have met and held him as he sprang through that gate. And now, with fire flashing from his eyes, he wheeled round to the crowd behind him and called on the Trojans to cross the wall. His men responded to his summons. Some swarmed over the wall; others poured in through the gates itself. The panic-stricken Greeks fled back to their hollow ships, and all hell broke loose.' (Iliad, XII, 39-71)In this passage, the Trojans, led by Hector, have stormed the Greek camp, driving the Greek warriors back to their ships by the end of the passage. Initially, however, despite the bloodshed on both sides, the Trojans 'were unable to set their enemies on the run', until a moment when 'Zeus gave the upper hand to Hector son of Priam', who had been the first to enter the Greek camp. Homer 'The Iliad', Penguin Classics, published 003, originally translated by E.V. Rieu, revised and updated by Peter Jones and D. C. H. Rieu; Book 2, line 32 Homer 'The Iliad'; Book 2, line 38 At this point, Homer has Hector showing some exceptional leadership as he first rallies his troops calling them to 'smash the Greek wall and fire the ships!' and then, as the Trojans rally together to attack, he proceeds to pick up a huge rock, possibly even a boulder, which he uses to smash the Greek gate. By doing so, Hector is showing his men how to act in the face of battle and danger and in showing the courage that he does, he sets a good example, particularly to the younger men in the Trojan army, of what a hero or a warrior should do in times of war. Homer 'The Iliad'; Book 2, line 40 There is anther concept, as well, behind Homer showing Hector performing such an act. As well as it being a means for Hector to give his men inspiration in fighting, Homer also uses it as a means to show Hector in a strong and heroic light, as he describes the effortlessness with which Hector first lifts, and then uses, the rock. This allows the audience and the reader to understand the truly heroic figure as someone who has an 'extreme level of male energy, a level which the lesser men of later times can never reach', which also gives an insight into the time that Homer looks back to in his poetry. The 'Iliad' in particular looks back to a time of great men and great heroes who could do things that great men living in the time that Homer was composing his poetry could not do. Indeed, when describing the great rock lifted by Hector, Homer says that 'it would have taxed the strength of the two best men in any town', describing Hector as someone who must be a great hero to be able to carry out such a task, and again showing the heroic society in which his poetry is set. Clarke, M. 'Manhood and Heroism' in Fowler, R. (ed.) 'The Cambridge Companion to Homer', published Cambridge 004; p. 0 Homer 'The Iliad'; Book 2, lines 47-48 This idea of incredible heroism is also echoed later in the poem, most notably when the hero Ajax, second only to Achilles in the Greek ranks, is seen defending the ships by 'taking enormous strides kept moving from one ship's deck to another', showing his heroic speed and strength as he defends the ships, in the same way that, in this passage, Hector's heroic strength is shown by his ability to first life the enormous rock, but then to also use it to smash the Greek gate. Homer 'The Iliad'; Book 5/8, lines 85/8-86 The use of language in this passage, even in translation, sets the tone for the situation very well indeed. With the use of phrases such as 'there was a great roar from the gate', Homer is almost able to make his audience visualise the shattering of the gate by Hector. The vivid descriptions of Hector actually throwing the rock with such power that it 'hit the door full in the middle and smashed it out of its pivots on either side' are told in such a way as to show the carnage that war brings, but also, once again, to echo a time of great heroes and great deeds. Homer 'The Iliad'; Book 2, lines 60-62 Homer 'The Iliad'; Book 2, lines 5/88-5/89 These deeds are told in such a way as to be familiar to the audience to whom Homer was performing his poetry. This is shown here especially by the description of how Hector handles the rock 'as a shepherd easily picks up a ram's fleece.and scarcely feels the weight, so Hector lifted up the rock', which shows how the concept of a heroic warrior culture such as the 'Iliad' was very much foreign to Homer's audience, but other cultures, such as agricultural and farming cultures were absolutely normal to his audience. Homer therefore uses similes that would allow him to explain one society to another, as is shown here. He also uses a variety of epithets, not only in this passage, but also throughout the poem, such as referring to the Trojans as 'horse-taming Trojans' frequently, as this, like the description of a shepherd picking up a sheep's fleece to describe the ease with which Hector picks up the rock, is another example of how Homer is able to show a heroic society by using agricultural similes in order to make the heroic society of the 'Iliad' more understandable to his audience by using language familiar to them. The description of the Trojans is also interesting, however, because it brings about a small degree of foreshadowing about how this war will end, with the Greeks sacking Troy thanks to the plan of entering the city in the wooden horse. It also foreshadows the end of the poem, as the final line of the poem is 'Such were the funeral rites of horse-taming Hector' and the Trojans mourn for the loss of their greatest warrior. Homer 'The Iliad'; Book 2, lines 5/81-5/83 Homer 'The Iliad'; Book 4, line 04 The end of the passage is also the end of Book 2 of the 'Iliad'. It ends with Hector calling the Trojans to cross into the Greek camp, which they do and with 'the panic-stricken Greeks back to their hollow ships all hell broke loose.' Such an ending to the book is interesting, because it appears to be a very abrupt ending, as it has been leading up to what looks to be a huge, violent battle. Once again, by leaving the potentially huge battle until the next book, Homer is foreshadowing the bloodshed that is to come, rather than showing it right at the end of this extremely intense passage of action after the Greek gate was broken, giving the audience a sense of great anticipation of what is to come later in the poem. Homer 'The Iliad'; Book 2, lines 70-71 The main subject of epic poetry is heroism and war, as war was one of the most serious, and epic, ideas a poet could write about. In writing the 'Iliad', Homer looks back to an age 'containing Mycenaean, Migration and Dark-Age ingredients.mixed freely to create a world appropriate to his heroes.' Homer is looking back to an age of great men and heroic deeds, when he was composing his poetry at the end of the 'Dark Age' in Greece. Van Wees, H. 'Leaders of Men? Military Organisation in the 'Iliad'' in 'Classical Quarterly 6', published 986; p.85/8 Ancient society is, by and large, what is known as a 'shame culture'. The heroes in Homer's 'Iliad' worry what other people will think of them. It is for this reason that, when Agamemnon is forced to give up Chryseis, he becomes unhappy, claiming that he will be 'the only one.without a prize' and if he ends up the only man without a prize, he will look bad in front of his men. It is his response to this, however, that prompts Achilles' actions, with disastrous consequences. Homer 'The Iliad'; Book, lines 19-20 One of the main concepts of the 'Iliad' is the idea of a 'heroic code', now widely used by modern scholars as a basic set of heroic values. It is, however, a common idea that part of the heroic code is that, if a man is a hero, then he has to be the best at what he does. Being a hero, he may die young, killed by another great hero, so it is important that he proves himself in his short life by killing other heroes, as heroes are men who 'affirm their greatness by the brilliance.with which they kill' as well as the heroes whom they kill, so they are judged on results in battle. Elsewhere, except for in the 'Iliad', the concept of a hero is one of a man or a figure who is greatly worshipped in certain cults. In the 'Iliad', however, to be a hero 'signifies a warrior who lives and dies in the pursuit of honour and glory' and a great example of this type of hero is the fearsome leader of the Myrmidon warriors, Achilles, who had a choice of fate and when he could die. Achilles' choice was that he could either fight gloriously, die young, but be remembered forever, or he could die old in his home, but his 'heroic glory will be forfeit, but life will be long and will be spared an early death.' By choosing to fight in the Trojan War, Achilles forfeited long life, but achieved everlasting fame. Schein, S.L. 'The Mortal Hero: An Introduction to Homer's Iliad', published Los Angeles 985/8; p.8 Schein, S.L. 'The Mortal Hero: An Introduction to Homer's Iliad'; p.9 Homer, 'The Iliad'; Book, lines 14-15/8 It can be argued, however, that with regards to the concept of what constitutes a hero in Homeric society, Achilles wins his fame for the wrong reasons. In Homeric society, heroes are remembered for their valiant deeds in battle and for killing other great heroes. Achilles' fame, chiefly, is not for such deeds in battle, despite his killing of Hector, but he is instead remembered as the Greek warrior who defected from the Greek army following his quarrel with Agamemnon, which is not the general action one would associate with such a hero. While these are the general principles of the heroic code, certain heroes in the 'Iliad' view the code and their heroic priorities differently. Achilles, for example, is fighting to win 'kleos' and 'time', in particular from Agamemnon, with whom he has a background of, he believes, not being given enough respect, as shown when Achilles speaks of how Agamemnon had treated him 'like some refugee who counted for nothing' during his reply to Ajax when the embassy is sent to him, after being offered prizes by Agamemnon if he returns to the fighting. Agamemnon, however, is not showing Achilles the 'time' and honour he deserves by offering him these gifts, because Agamemnon 'is offering to include Achilles within his own sphere as son-in-law and subordinate', meaning that, even by making such a grand gesture, he will still be above Achilles in rank. Translates as 'reputation' or 'renown' Best translated as 'respect' Homer 'The Iliad'; Book, line 48 Redfield, J.M. 'Nature and Culture in the 'Iliad': The Tragedy of Hector', published Chicago and London, 975/8; p.6 Achilles' nearest Trojan equivalent, Hector, has some similar heroic values to Achilles. Like Achilles, Hector goes out to fight because he wants to be heroic and he wants to win 'time'. In a conversation with his wife Andromache, she begs him not to fight, knowing that, if Hector died, she would lose everything as Hector is 'father and mother and brother.as well as my strong husband' after Achilles had sacked her home town and killed her father and her seven brothers. Homer 'The Iliad'; Book, line 30 Hector, however, ignores her pleas not to fight, because he had 'trained always to be a good warrior.and try and win glory for father and '. Hector knows that, by going into the fighting, he will leave his family behind at his death, but if he stayed at Troy 'like a cowards and slunk from the fighting', then he would receive only 'aidos', which means shame. If, however, he went out to fight, and even if he died, he would still win the 'time' and honour he desired, as, by dying bravely, he can win glory as he has died in an act that 'puts a seal on a life lived in accordance with.standards of heroic excellence' as he will die being killed by a great hero. Homer 'The Iliad'; Book, lines 46-48) Homer 'The Iliad'; Book, line 41 Schein, S.L. 'The Mortal Hero: An Introduction to Homer's Iliad'; p.8 Interestingly, it is this moment that Homer puts into his audience's mind the fact that Hector will eventually die. After Hector leaves Troy, Andromache and her waiting women 'mourned for Hector in his own house, though he was still alive', showing that they are sure that he will not survive the battle with the Greeks, and showing how 'Hector's story begins, as it ends, with his funeral', an idea not only foreshadowing Hector's death, but also the death of other great heroes, as it is ultimately through doing heroic deeds that a hero will meet his death, which arguably raises questions about a hero's leadership, if they become so involved with their heroic deeds that they end up getting killed, therefore diminishing the defences of their allies and, in the case of Hector, leaving Troy without its best leader. Homer 'The Iliad'; Book, line 00 Redfield, J.M 'Nature and Culture in the Iliad: The Tragedy of Hector'; p.27 While Hector and Achilles are fighting for themselves, certain heroes in the 'Iliad' view heroism as something other than killing heroes. One of these heroes is Sarpedon, who speaks to his comrade Glaucus, that the people of Lycia have them 'singled out for honour.they all look up to as gods' and that they are not fighting to defend Lycia and its people, but 'on behalf of their status within it', as they know they have a duty to fight better than common people in battle, because they are better than common people. Therefore, Sarpedon's view of a hero's privileges is that they must be earned by the hero doing his duty in battle, but they also show 'the warrior's special status and role'. Homer 'The Iliad', Book 2, lines 10-12 Redfield, J.M 'Nature and Culture in the Iliad: The Tragedy of Hector'; p.00 Redfield, J.M 'Nature and Culture in the Iliad: The Tragedy of Hector'; p.00 In his speech to Glaucus, Sarpedon's perspective shifts, as initially he praises the role of the warrior, saying that he 'could be sure of becoming ageless and immortal' thanks to the glory of war, but he then goes on to say 'a thousand demons of death hover.and nobody can escape or avoid them', so that, even though a hero may be metaphorically immortal, because of his fame, he cannot be literally immortal, because mortal men must eventually die. Homer 'The Iliad'; Book 2, lines 10-28 Homer 'The Iliad'; Book 2, line 23 Homer 'The Iliad'; Book 2, lines 26-27 The concept of heroism in the 'Iliad' clashes on several occasions with the concept of leadership, raising the question of whether, when having an army to consider, the heroic option is necessarily the best option. One example of whether the heroic option is the best option is an exchange between Hector and his right-hand man, Polydamas, who advises Hector to 'withdraw into the town now and not wait for daylight here in the open', because while Achilles was absent, there was a chance of victory for the Trojans. Now that Achilles has returned, however, Polydamas advises Hector that Achilles 'will never be content to stay in the plain', but he will target Troy and Hector himself. Homer 'The Iliad', Book 8, lines 5/86-5/87 Homer 'The Iliad', Book 8, lines 62-63 Hector, however, rebukes Polydamas, telling him that 'the man who tells to retreat.no longer speaks language', as he wants to fight and win 'time', but, in deciding to fight Achilles, Hector makes his 'hamartia', or his fatal error, because he pays for his heroic desire with his life. In fighting Achilles and dying, Hector leaves Troy without a leader, thus raising questions over his ability to balance leadership with his desire to be a hero. That said, while at this point, Hector's judgement is fatally clouded by this, it would not be fair to say that he wholly fails in his duty as a leader. Indeed, there are occasions where he shows exceptional leadership, most notably in his fight with Ajax. When he sees his opponent, he feels fear, but he knows that he cannot 'turn tail and slink back among his men', because, if he turns away from the fight, his men will lose hope. By fighting Ajax, Hector is sending a message to his troops, which will boost their morale. He also sends the same message when, after being hit by a spear, he continues to fight, showing that he will not give up. Homer 'The Iliad', Book 8, lines 85/8-87 Homer 'The Iliad', Book, lines 17-18 Another hero in the poem whose leadership comes under scrutiny is Agamemnon, most particularly at the start of the poem. In the 'Iliad', Homer echoes the values of poetry, where the heroes, are the 'aristos', or the best, and Agamemnon is the most powerful king. However, it is not true to say that, just because he is the most powerful, everything that he says goes, because Achilles feels able to stand up to him. In the assembly at the start of the poem, when the Greeks are discussing how to placate Apollo, Agamemnon's judgement is clouded, but not by his desire to do heroic deeds, but instead by his fear that, if he loses Chryseis, he will look bad in front of his men, which causes him to take the action which precedes Achilles' withdrawal from the fighting. It is this which calls into question his capacity as a leader because it he often lets his pride get in the way of his judgement, with disastrous consequences following Achilles' actions. Finally, Achilles' ideas of leadership also come under scrutiny as, like Hector, he fights for himself so he can win 'kleos' and be seen as a great hero and this desire for fame is what brings about his 'hamartia' when he leaves the fighting in the first place, and then allows Patroclus to fight instead. However, when he decides to send his men into battle, Achilles makes 'an encouraging speech, he takes his place at the head of the contingent.and starts the advance to battle'. Like Hector during the fight with Ajax, Achilles show good leadership by rallying his troops, showing that, at this point, a hero can be a good leader, by giving his troops the motivation and encouragement they need. However, Achilles negates this following Patroclus' death, when he vows to bring back 'the armour and head of Hector' so that he can avenge Patroclus' death and show that he has killed a great hero, thereby showing that, like Hector, Achilles can let his personal feelings and his heroic desires cloud his judgement, whereas a good leader should be focused primarily on his troops and not on his feelings and desires. Van Wees, H. 'Leaders of Men? Military Organisation in the 'Iliad'' in 'Classical Quarterly 6'; p.85/8 Homer 'The Iliad', Book 8, lines 35/8-36 The question, therefore, of whether being a good hero is compatible with good leadership, comes down to how well the heroes in the poem balance the two qualities. Throughout the 'Iliad', save for certain instances, it is generally the case that the major heroes of the poem, Achilles, Hector and, to an extent, Agamemnon, are unable to balance the two, because they are fighting this war for themselves and their desire for fame is their downfall, especially for Hector, who's tragic end could have been avoided had he not fought Achilles.'''",560.0
"'''The World Bank should be abolished. Established in 944 in the form of six principal institutions for the purpose of facilitating post-war reconstruction, the contemporary World Bank slogan is 'Working for a World Free of Poverty' with poverty reduction placed as the World Bank's 'overarching goal' (History). Critiques raised against the World Bank include an undemocratic voting system, lack of transparency, projects involving environmental and human rights disasters, failed poverty reduction projects and an inability to make effective reforms demonstrated by ignoring recommendations made by its own a set of ideas and 'development knowledge' and presenting them as 'scientific, authoritative truths' by its ideology to recognize and accept other paths to development? The answer is most likely 'no'; therefore, abolition is the solution because 'suffering demands epochal shifts' (Bendana 006: 0). Whether a new institution should be created in its place demands revisiting the World Bank's ultimate goal - poverty reduction - and unraveling the inherited hegemonic discourse on development before simply replicating a new body with a different agenda, and the answer may lie far from a single overarching international, or even regional, structure making decisions regarding the destiny of millions of impoverished peoples.'''",565.0
"'''In order to decide whether something is alive, an individual must be able to differentiate between living and non-living objects in the world. This is an evolutionarily important distinction to make as it can be critical in identifying predators and conspecifics from inanimate objects and therefore allowing us to distinguish the physical from the social therefore it is only animate objects that can increase their energy without external causation, this is due to their autonomous energy sources. Bingham et al believed that the visual system can automatically detect when observable kinetic energy is not conserved and that this is how people detect animate from inanimate objects. From this type of evidence the Newtonian violation hypothesis was formed, this hypothesis states that 'animacy is perceived whenever an object's motion path indicates that the object must have access to hidden energy sources' (Tremoulet & Feldman, 006, p. 048). Therefore this hypothesis not only suggests that animacy will be perceived when kinetic energy is not conserved but also when the movement of an object deviates from what a Newtonian motion path would predict. It has been found in experiments such as the one carried out by Kaiser and Proffitt in 987 that when the direction of a ball after collision with another ball deviates from the expected Newtonian direction by more than 5/8o people are more likely to rate the ball as being object, state, or location' (Opfer, 002, p. 00). Opfer in an experiment carried out in 002 found that when unfamiliar entities which he called 'blobs' behaved in a goal-directed manner by moving towards an irregularly shaped dot, they were identified as living organisms and therefore animate. 'Blobs' that moved in an identical manner but with the goal dot removed failed to be identified as living, this suggests that goal-directedness is a decisive factor in deciding whether an object is animate. Opfer proposed that this was because goal-directed movements suggest that there is a reason for the objects movements and therefore that it has either biological or psychological intention. It is from evidence such as this that a second hypothesis was formed proposing that people only believe an object to be animate when intentionality is been found to give a strong cue to animacy, if these changes are used in conjunction with cues given in the environment an identification of animacy is made even more likely. For example if a change in speed or direction can be seen to be caused at a distance by an element in the environment it implies that the object itself can perceive its environment and create its own goals based on this perception. This gives a greater perception of animacy as this ability is the preserve of living things and cannot be carried out by inanimate objects. Evidence for this can be found in Tremoulet and Feldman's study, where participants were presented with a target that moved in four varying ways in relationship to a static element in the environment. Participants were asked to rate how alive they thought the target was. The four varying movements gave the impression of the static element either being 'prey', a 'predator', an 'obstacle' or 'irrelevant'. The results showed that when the static element was seen as a 'prey, 'predator' or 'obstacle', participants rated the moving object as more alive than when the element was either seen to be 'irrelevant' or when there was no static element present. This shows that elements in the objects environment and the way its movements react to these elements can give cues as to the animacy of the object. Non-Newtonian movements and all of the cues to intentionality, including context, can be seen as important in helping people to decide whether the movement of an object suggests that it is animate or inanimate. However it has been found that yet another source of information can be used to distinguish animate from inanimate objects which is not included under either the non-Newtonian movement hypothesis or the Intentionality hypothesis. This source of information is prior knowledge (Opfer, 002). When adults look at the movement of such objects as paper cups, feathers, cars and aeroplanes it could be expected that the lack of visible outside energy source could cause them to mistakenly perceive these objects as animate. However this does not occur due to adults' prior knowledge that these types of object do not have their own internal energy source or that they only move because a person starts their motor (Opfer, 002). This also works the other way round; in an experiment by Opfer it was found that participants judgements of goal-directedness and animacy were affected by the range of organisms they knew to be living things. For example adults' knowledge of such organisms as germs and plants led them to consider an unfamiliar object to be animate on the supposition that it was a micro-organism (Opfer, 002). Whereas in an experiment by Richards and Siegler in 986 it was found that children will often only attribute animacy to objects with leg like appendages, based on their limited knowledge which suggests that only animals can be alive (as cited in Schlottmann, 002). Prior knowledge therefore can affect what movements of objects make people believe they are alive as adults know that some living organisms such as bacteria or cells do not need psychological intention in order to move yet they are still living. This may make them more likely to identify an object as animate even when it displays movements that do not conform to the intentionality hypothesis (Opfer, 002). Prior knowledge is also useful in determining animate from inanimate movement as it can help to identify whether an object is acting in a goal-directed manner. Prior knowledge means that we can identify the sort of things that an object would see as a goal and therefore whether an object is moving towards a goal or whether it is just randomly moving towards an element in its environment. An experiment by Richards and Siegler in 986 involved presenting children with a rectangle which sometimes moved towards a toy truck, the children then said whether they believed the rectangle to be alive or not (as cited in Opfer, 002). They found that the children did not believe the rectangle to be alive even when it moved in a goal-directed way towards the toy truck. It has been suggested that this is because the children had no prior knowledge that a toy truck would be a goal for rectangles and therefore they may have thought this to be unlikely. This shows that knowledge of what consists of a goal for a certain object can help to identify whether an object is acting in a goal-directed manner or whether some other force is operating on the object (Opfer, 002). The fact that prior knowledge and movements which give the impression of intentionality can affect peoples' perception of animacy suggests that people do not use non-Newtonian movements alone to distinguish animate from inanimate objects. However although intentionality cues do affect the perception of animacy it has been found that changes in speed are in fact the primary cue in distinguishing animate from inanimate objects. An experiment by Tremoulet and Feldman found that when an object increases in speed with no obvious external energy source this will increase ratings of animacy even when there is at least one cue suggesting that the movement was unintentional, for example a collision with a static element in the environment. Tremoulet and Feldman also found that in all their experiments their environmental manipulation had a small effect on animacy ratings compared to the effects of changes in speed and direction. Therefore, evidence suggests that whilst non-Newtonian movements are not the only movement cues to animacy that they are perhaps the most important. It would seem that the perception of non-Newtonian movements is not sufficient for the perception of animacy but it is necessary. Although cues to intentionality and prior knowledge can influence these perceptions, observers will only perceive animacy when an objects movements appear not to conserve energy (Tremoulet & Feldman, 006).'''",569.0
"'''The aim is to be able to establish the number of living bacteria in a foodstuff and to know how to select an appropriate method for enumerating bacteria. Total counts and viable counts of bacteria can be taken when looking enumerating bacteria. The methods used in this experiment are looking at the viable count which only looks at the living cells present. MethodDILUTION OF SAMPLE90ml MRD and 0g minced beef were put into a stomacher bagStomached in a Colworth Stomacher for min = 0 - dilutionSolid particles allowed to sediment, 0ml transferred to glass universal bottleUsing Gilson pipette, ml transferred into ml MRD = 0 - dilution4 more tenfold serial dilutions madeMixed thoroughly and samples were all labeledPour plate with melted PCA1ml of each added to petri dishes. Before the ml sample was removed from each dilution, it was taken up and then released several times to mix the sample. The molten agar was then added and mixed. Pour plate with VRBGA1ml of each added to petri dishes, followed by the VRBGA agar and allowed to set. VRBGA agar was then added as an overlay and the lids tilted to avoid condensation Spread plate0.ml of each spread with a spreading rod MPN1ml of each added to bottles containing Durham tubes ResultsPour plate with melted PCA countOnly 0 - was counted as there were too many colonies present on the other diluted plates 5/8% confidence limit Class results95/8% confidence limit Pour plate VRBGA count10 - diluted plate had large clumps of growth instead of an even growth due to poor mixing and could not be counted 0 - had sufficient colonies to count 5/8% confidence limit Class results95/8% confidence Spread plate colony countThere should be a tenfold difference between the two dilutions and this case shows that it is quite close. 0 - has a suitable count so this shall be used Only.ml was used so the result needs to be multiplied again by a factor of 0 to bring it up to ml so there are 40 colonies from ml. Class resultsConclusionFor the pour plate using melted PCA, the only countable plates were the 0 - dilution samples. This shows that there were more bacteria present than anticipated and more diluted samples would have given a lower count and may have been more accurate. The colony count for this part of the experiment gave a mean of 77. When comparing this with the class mean of 78, there is a clear difference. The class results are likely to be more accurate as a whole because there were more samples which can even out error. The class results give a much smaller 5/8% confidence limit as a percent value due to the larger amount of duplications and the effects this has in finding a more accurate result. The spread plate also used PCA agar but gave a higher colony count. This is possibly due to the method used, as the same dilutions were spread on the plates. Pour plates may cause less growth to occur as organisms under the agar may not have sufficient oxygen. It is also possible that there were small colonies under the agar that were not counted, as it is more difficult to clearly identify them when they are suspended. The VRBGA pour plate used was selective for Enterobacteriaceae and inhibits growth of certain other bacteria. The colonies were purple/pink in colour and some had halo's around the colony. This is caused by the glucose present in the medium being converted to acid, and the bile salts in the medium precipitate away from this. The colonies of.mm or more were counted. Due to poor mixing the 0 - dilution could not be counted as the colonies were all grouped together but the 0 - plate gave a sufficient count. Comparing the individual results for this against the class results, it can be seen that a very low colony count was obtained. The average class colony count was over three times more. This could have occurred because the agar was at too a high temperature when the sample was first added and may have killed some of the bacteria cells. This is where the precision of class results shows, due to there being more duplicate plates, anomalies are leveled out. The MPN test is selective for coliforms. If coliforms are present they grow and produce acid from the glucose in the medium which can cause a colour change to a more yellow colour. Gas is also produced which can be seen as a gas bubble in a Durham tube. For the individual results, the Durham tubes in every bottle showed a gas bubble. The high number of positive tubes for the presumptive coliform count by the MPN method, shows that there were more coliforms present than expected. There was no benefit in this case to work out the MPN as it wouldn't demonstrate anything to us. The class results show a wide variety in the results and give a most probable number between 5/8 and 1000 of coliforms which is a broad range and does not appear to be very accurate. This is not generally an accurate method. QuestionsWhen a colony count is referred to as a total viable count, from the name it is assumed that each colony is formed by a single living organism and by counting the number of colonies will give the number of viable cells present. Sometimes cell clumping can occur and pairs, chains or clusters of cells will form a colony instead. When referred to as colony counts or colony forming units the allowances for this occurrence are incorporated in the name as it does not assume that each colony is formed by a single cell, instead addresses them as units. 0 colonies on a spread plate from.ml of the 0 - homogenate So in ml there are 00 colonies So the lowest level of contamination is 000 bacteria per 0g, 00 in g of mince A pour plate has an advantage of achieving a good mix of the bacteria. For aerobes the results could be affected in a pour plate, as the bacteria present at the base of the plate will get less oxygen than those on the surface. This could be a disadvantage as the growth can appear to be at a lower level and not give a true count. Only viable counts can be achieved for pour plate and spread plate methods as only the living bacteria can form colonies The number of duplications has a big effect on the precision of a count; the more plates then the more precise the results are. This can be seen when comparing the results for pour plate melted PCA class results (using duplications), the 5/8% confidence limits as a percent were much smaller for the class results indicating that they were more precise. The larger the count of bacteria, the more precise the results are too which can be seen when comparing the individual counts for melted PCA and VRGBA. The PCA had a colony count of 77 and a 5/8% confidence limit of.% and the VRGBA had a much smaller colony count of 9. and the 5/8% confidence limit was much higher at 2%. Enterobacteriaceae are gram negative rod shaped bacteria. They are a large family including E.coli and Salmonella and normally inhabit the intestines. They are facultive anaerobes and can be grown on violet red bile glucose agar as they ferment glucose. Coliforms are also gram negative bacteria and are aerobes and facultive anaerobes. They are found in human and animal faeces, and within the environment such as in the soil and vegetation. They are oxidase negative. The term presumptive count refers to the colony count but as it is not known whether all the colonies are the organism trying to be isolated, the count is only presumptive. Tests can be carried out to identify the growth such as gram staining and examination under the microscope, looking for gram negative rod shaped bacteria in the case of the Enterobacteriaceae, and also looking for gram negative when looking at the coliforms. Coliforms and Enterobacteriaceae are also oxidase negative and so can be identified from oxidase positive bacteria using this test. Enterobacteriaceae ferment glucose and so the oxidation fermentation test can be used to see if the colonies ferment glucose. There are many tests that can be carried out to confirm that the colonies and growth are Enterobacteriaceae and coliforms..'''",575.0
"'''Traditionally the disciplines of Science and Egyptology only met when the Egyptologist had exhausted all of the sources at their disposal and in order to answer further questions, turned to the natural of the advancements made in mummification would not have been possible if it was not for the gradual increase in trade, especially during the New Kingdom. Major developments were made because of a wider range of embalming materials available to the ancient is a valid question as it seems the elite especially, spent a good proportion of their lives preparing for their deaths. For example, Pharaoh's tombs were often begun not long after they were instated. One explanation given for why the Egyptians disposed of their dead through mummification is the ka, a part of the deceased personality or spirit that lingered on conclusion collaboration of Egyptology and Science is not always easy but can bring rewards to both fields (Germer 986: 25/8). However the development of new disciplines and incorporation of older ones has created a multidisciplinary area where many previously unanswered questions can be resolved (David 999: 72). Therefore the scientific study of mummies has, in many cases, revealed to us a lot about the beliefs and life style of the ancient Egyptians.'''",580.0
"'''Chimpanzees can use signs, but do they have language? Language has been defined as ''the institution whereby humans interact'' (R.A.Hall, 964), as a ''purely human'' form of examples of this. In consequence, experiments were carried out teaching chimps sign language, to compare their ability of acquiring language with that of humans. Washoe, for example, in the 960s, was the first chimpanzee to undergo such an experiment. Allen and Beatrice Gardner, who introduced him into a group of adult ASL signers, carried this out. The results were encouraging: in years he managed to acquire 32 signs. Strong similarities were observed with child language acquisition: in the general word in the way he was able to put signs together to express small sets of meaning. This was done however at a much slower rate. Following this success, other experiments were took place declaring massive achievements in chimpanzees well as production of sentences and even abstraction, which is considered as characteristic of human communication. What Washoe and the other chimpanzees produced, although closer to language than anything else observed, still contains many differences. They may have succeeded in producing more than single word utterances, but these lack the complexity of the grammatical structure, characteristic of the human language. These are merely comparable to the utterances of a small child acquiring language. One must note that at this stage the child is said to be in the process of and not to have acquired language. Therefore how can we say that a chimpanzee, whose language is no more developed, has language? Furthermore, these experiments present many weaknesses: their standards were very generous, the evidence is merely anecdotal and the reports were on a particular animal in a particular experiment, when language is something widespread. Consistent evidence, in more controlled conditions is needed for these experiments to be considered as scientifically substantial. Finally, the explanation of the observations is not clear; the lack of grammar suggests that it is simply a sophisticated what they observe humans doing. It seems evident that chimpanzees can learn to imitate signs, put them into various sequences and use them in different contexts, but the explanation is unclear and more consistent results are necessary. What they have produced is also less complex and sophisticated than what healthy humans produce. It seems therefore fair to conclude that the communication gap, ability for language, between humans and animals is smaller than once believed, but still present. The period of the first 0 words is the first significant landmark in the child's acquisition of language. Many have tried to divide child's language acquisition in to various stages in order to understand its development more clearly. Vocabulary learning is the first most noticeable sign of language acquisition. This may explain why the period of the first 0 words is often viewed as the first significant landmark in this development. The period during which a child learns his/her first words appears to mark a change in the child's ability to communicate with language users. The child has moved on from simply babbling. The latter consists in the production of strings of sounds devoid of meaning. The first spoken words show that the child has learnt to control his/her vocal tract after the previous stage of experimentation. After this same period, which may also be seen to coincide with the one-word be explained by multiple factors, which most probably occur during the first 0-word period, justifying its designation as a landmark further. Firstly, the acquisition of phonology takes place during this time. Moreover, this amount of vocabulary is the 'critical mass' necessary for the child to discover in word meanings and to connect words produced with ones he understands, his/her learning therefore becomes more increased precision of vocabulary. One must note however, that due to the employers misunderstanding of the proper use and meanings of his/her first words (i.e. mismatches, overextensions, holophrasing.), some may not them as the being true language. Finally, the first 0 words may also determine different backgrounds, reflecting the culture into which they were socialized. The more vocabulary is acquired the more differences level out (after an experiment by C. Stoel-Gammon & J.A Cooper, 984). Although the meanings of words and their roles in communication may differ from those of experienced language users and the amount of words constituting this landmark period are discussable, children's first words still mark an important change in communication ability, therefore an important step towards their acquisition of language. Naturally occurring speech errors provide a window on the adult speakers language processes. Psycholinguists study the relationship between language and the brain, for example language processing. A lot of useful information regarding this subject is extracted from spontaneous speech. An example of this is 'slips of the tongue', which may reveal interesting patterns offering explanations on how ones mind constructs utterances. Various types of speech errors exist and are considered natural since they are spontaneous and produced unconsciously. These errors can be produced at different levels, from single sounds to whole phrases. They can consist of moving around the different units through shifts or exchanges, or involve repetition such as anticipation or preservations. However, substitutions of whole words can also occur. The 'tip of the tongue' phenomenon can lead to speech errors. In the effort to recall the required word, the individual goes through a series of mental processes, which may be reflected in 'slips of the tongue'. The speaker is likely to produce a word of a similar length, maybe even the correct number of syllables. Moreover similar sounding words are also likely to be confused, the middle of this word generally containing the error. This reflects how vocabulary is stored in one's mental lexicon and therefore the procedures used when searching for a word. Furthermore, speech errors rarely seem to change the grammatical structure of a sentence, and words from closed classes, which mark this structure, such as prepositions and pronouns are rarely affected. What is more, when words are transposed, they are generally semantically related. The grammatical brain works in different stages; this seems to show that the structure must be laid out before the content. Once the structure is there the types of words are probably chosen (e.g.: nouns, adjectives.), before their meaning is considered. However, when the grammatical sense of a sentence is not clear although it only contains real words one must consider a different explanation. This non-sense is often due to blending or exchanges, occurring between words or phrases. This is often due to anticipation or perseverance and shows that one does not construct ones sentences word by word, but phrase by phase or maybe even in larger groups. These errors are probably made because the individual is thinking about something else he/she said, or about to say in their utterance. On a smaller level, anticipations and perseverances on syllables or even sounds demonstrate the same kind of idea. Nevertheless, on all levels these are often the cause of repetitions. Sometimes when errors are made words can be substituted with others. An example of this is a speaker who said 'automatic transcription', when he intended to say ' automatic transmission'. These two sets of words appear to be linked through rhyme, have the same number of syllables and same sounds at the beginning and end of the words. This may be a reflection of how one organises vocabulary in their brain. However, since the meanings of these words are not linked, this phrase may simply show what the speaker was simultaneously thinking about while speaking. A lot of this work on naturally occurring speech errors seems to depend on different individuals' personnel interpretations, since they the speaker produces these unconsciously and one rarely finds out, but may only guess what they really wanted to say. This is why it is only far to say that they provide a window to the understanding of language processes and not an explanation.'''",581.0
"'''PurposeThis conceptual paper aims to provide an insight of how hotel managers can define and use performance measurement targets to support the long-term strategy of their organisation, through different performance measurement models and perspectives. Design / Methodology / ApproachA wide range of literature is used to provide the reader with a definition of performance measurement, strategy and with the key measures and models used in the hospitality business. The relationship between strategy and performance measures is analysed, and a scheme is proposed to facilitate the transfer of the latter to the former. FindingsThe findings of the research indicated that hotel managers are aware of the importance of considering their strategy when measuring performance. However, very few of them put this ideology into practice, as performance measurement in the hospitality industry is still predominantly financially based. The research has shown Bullen and Rockart's Critical Success Factor can be combined with a performance measurement framework to ensure strategy is clearly integrated in the chosen key performance measures. Research limitations / implicationBeing a conceptual paper, the main limitation of this document is that it is based on secondary sources only. Hence, the validity of the arguments and conclusions is not proven by empirical evidence or by primary research. Originality / ValueThis paper presents performance measurement from a strategic perspective for hospitality organisations. It provides an insight of how hotel managers can ensure key performance measures are aligned with their strategy. Keywords - Hospitality Industry, Performance measurement, Strategy, Critical Success Factors Paper type - Literature Review IntroductionThe increase in competition rivalry and in the access to organisations of various industries to review and improve their traditional performance measurement well as that, nowadays, organisations need to focus on the customer, rather than on the, amongst others, of the increasing rivalry and of the strength of information the fluctuating demand increases the need for measuring past performance and for forecasting. Its intangibility, simultaneity and enhance the complexity and importance of measuring customer satisfaction and employee factor that will influence the way performance is measured in a hospitality organisation is its cost structure, which varies between and within hospitality organisations according to the type of services and products a 'map' (Recardo and Wade, 001:7). Porter summarizes properly the many definitions by stating that 'the essence of strategy is choosing to perform activities differently than rivals do'. Mintzberg acknowledges strategy both as a plan and a pattern. Strategy is a plan when seen as a direction for the future and a pattern when there is a regularity of actions over time that is, for example, a hotel who always offers the most expensive rooms in its market. He also expresses that strategies can be intended, realised or emergent. Often, from the intended strategy, part of it will be unrealised while some of it will be fully it. The nature of the strategy also depends on the structure of the organisation, as well as on the desired arduous for hospitality organisations than its formulation, which seems to be caused by the misunderstanding of the environment and the competition as stated by Porter. Whether strategy is seen as the creation of a competitive advantage, of opportunities or of a long-term performance prism, a new framework, is an attempt to 'focus on the deficiencies of other existing frameworks'. The performance prism is a three-dimensional framework with five different facets. The 'stakeholder satisfaction' and the 'stakeholder contribution' are the top and bottom, and are surrounded by the strategies, the processes and the capabilities. The framework questions the assumption that the performance measures should derive from a chosen strategy. It hence proposes to begin by defining the major stakeholders of the organisation and their prerequisites, and to consider if the organisation has the schemes to provide their satisfaction. Then, the organisation should determine which processes could support it, which are its capabilities and finally which contribution is required from the stakeholders. The implementation of the prism is also eased by a catalogue of numerous performance measures for each facet of the reflection and greatly influence business performance. Presented by Kaplan and Norton, the balanced scorecard is from far the most renowned and accepted performance measurement framework, principally in financial and Cross consider that a performance measurement framework must respond to three criteria in order to be effective. Firstly, the 'measures must link operations to strategic goals', secondly the 'system has to integrate financial and non-financial information' and thirdly, the system's value lies in its ability to 'focus all businesses activities on customer requirements' (Lynch and Cross, 995/8:). The three frameworks discussed above all present financial and non-financial and are designed to meet customer requirements. Also, even though not stated explicitly for the results and determinants model, theoretically, the strategy should be reflected in the chosen performance measures of all three frameworks discussed above. In fact, the balance scorecard puts strategy at the centre of its has been adapted and popularised by Rockart in proposition can be used to effectively translate the strategy into performance measures. The first step should be to ensure that managers in the organisation have an adequate image of competition, since an erroneous view of it is one of the main reasons why many companies fail to have a managers will have different perspectives of it, and may see opportunities that were not considered at first. Once the CSFs established, they can be easily transposed into performance measures. In order for the performance measures to adequately represent the strategy, it must be ensured that 'trailing' as well as 'leading' indicators are that information past results and potential trends are present, and that the three type of represented. Furthermore, it appears clear in the proposed diagram that as the strategy is being transposed from one level to another, what is being measured becomes narrower. However, if 'what you measure is what you get' (Kaplan and Norton, 992), managers must ensure to cover all aspects of their goals in the chosen performance measures, as well as all dimensions of chosen to present an overview of the performance, other frameworks should be studied in regards to the organisation. In other words, managers should inspire themselves from what is proposed in the different frameworks. This will allow them to have a broader image of what the strategy implies, and will allow expressing strategy in term of measures from different perspectives. The chosen performance measures can them be implemented in the framework that represent the best the organisation's goals, in order to be able to have an overview of the business, which can be returned to the corporate level, with the intention of giving a feedback on the achievement of goals, objectives and strategy. Conclusion and ImplicationsThis article aimed to determine the relationship between performance measures and strategy for hotel organisations. It has been shown that performance measures should reflect the strategy of an organisation. Furthermore, to deepen the understanding of the link between both elements, a scheme has been proposed to effectively link strategy and performance measures, using the critical success factors method as an intermediary. This article hence has a great implication for hotel managers, as it provides them with tools to have a broader perspective of how to relate strategy and indicators of performance. It is in the point of view of the author that the proposed scheme is theoretically applicable to the industry. However, being based on a literature review, the arguments proposed in this article are rather suggestive than conclusive. In fact, the drawn conclusions are from the writer's perspective thus subjective to criticism. In order to assess their validity, primary research could be conducted, aiming to test the proposed pattern.'''",584.0
"'''Blaise Pascal died in 662, leaving his most famous work, 'Pensees' unfinished. It was a large collection of notes and drafts to be originally titled 'Apology for the Christian Religion'. Published eight years after Pascal's death, 'Pensees' was written to convert the religious opinions of agnostic intellectuals, and offers a new way of thinking with regards to the Christian religion. The section concerning his wager is small in relation to the rest of the drafts, and is organised as a dialogue between Pascal and an interlocutor, Pascal's disbelieving friend. The Wager is a bet that one must take, in order to decide if you should believe in God, and uses pragmatic reasons to convince those taking the bet that to believe in God would be more beneficial. Before Pascal arrived at the Wager theory, he firstly considered a priori arguments for the existence of God - the 'proof' that results from a concept, with no need for evidence from real life experiences. Pascal came to the conclusion that a priori arguments were too far from human reasoning to make any sort of real impact, and act only to prove that God exists, ignoring all other aspects of Christianity. Such a as abhorrent to the religion as atheism. A large proportion of 'Pensees' was dedicated to the evidence shown in the bible - The Articles of Faith, and Pascal believed that both the fulfilment of prophesises and the occurrence of miracles performed by Christ were good ways of convincing agnostics of the creeds of Christianity. He pointed out, however, that a posteriori just not strong enough to make somebody want to follow the religion. Pascal then suggested the Wager. It regards the pragmatic reasons for believing, and that to believe in God would be greatly beneficial, such as lifetime happiness and the promise of salvation. The Wager must be taken, one has no choice - a decision must be made. You can either decide that God exists, or than he does not. It is the possible outcome of this choice that should persuade those taking the bet as to which option they should choose. If you decide that you believe God exists, the consequence of accepting the bet and committing oneself to a Christian lifestyle will be an eternal life of happiness. If he does not exist, then you will have lost nothing, as you will have already enjoyed a happy, pure life. If you decide that God does not exist, you will be passing up on the chance of an infinitely happy life, to gain only the finite rewards of an un-Christian lifestyle. Such a choice would be highly irrational - according to Descartes one cannot chose a finite gain over a possible infinite gain. He stated, 'if you win, you win everything, and if you lose you lose nothing'. When considering if the Wager is a good argument for believing that God exists, one must consider both the positive and negative aspects, and then decide if in reality, the intellectual agnostics for whom it was intended would actually use this theory to change their religious outlook. If one used this argument to prove that God exists, the substantial gain they would receive are the benefits of a Christian lifestyle, for example being a member of a Church, a wider community, and feeling that there is a supreme and all knowledgeable being that loves you. These are all highly desirable. If following Christian morals and values, and committing oneself to a pious life, the believer would also be free on sinning and vice, and have a pure mind. Added to the substantial gain, one would also be living with the expectation of an eternal life in heaven with God after this life on Earth. If such an expectation was then fulfilled, then surely salvation is the ultimate reward one could receive. The wager is a good way of showing the agnostic what is on offer, but in its nature is highly persuasive, for example dissuading those taking the bet by describing the disbeliever's life as full of 'tainted pleasures' and 'emptiness', and describing the believer as 'honest, humble, grateful, a doer of good works, a good friend, sincere and true'. The Wager is open to many objections which reduce its credibility as a good argument for the existence of God. Pascal describes how those choosing that God exists should act as a true believer, and to attend Mass and Holy Communion and in turn, this will 'tame you'. One highly apparent objection that surfaces here is the concept of deception: the all knowing God would be able to tell that the supposed Christian was practising the religion with the intention and desire to gain infinite rewards. Can one wholeheartedly believe in anything if you only doing so for personal gain? The belief would be marred by the desire to achieve a reward. Pascal argues that by being around other Christians, you will eventually believe without considering the practical aspects. In my opinion this is unrealistic and would only make the argument work indirectly, and even if the believer forgot their original intentions, the all knowing God would still know why they were in Church in the first instance. If the Wager had been used to convince someone to follow Christianity, then their love of God and Christ is conditional, rather than unconditional, pure love. They would be holding their faith on the promise of rewards. In the eyes of the Church such a motive would be considered immoral. However it is God himself who said 'I will promise you salvation if.' Is God promising something on the condition that you behave in a certain way? If this is true, then Pascal is simply providing a wager in the same way that God Himself has done. A second objection to the Wager is that to believe in God for a bet is juvenile and does not reflect the seriousness of the matter. Should the outcome of a bet, or what is in fact a game of win or lose decide on what you believe, and in turn shape the way you live your life? It seems frivolous to make a decision about immortality, perhaps the most important decision there is to make, using a wager. In the same way that God might not approve of a Christian believing in Him for personal gain, he would surely not approve of using a bet to believe in His existence. A clear problem that is associated with the Wager is the idea that Pascal's decision theory cannot be used for his religion alone (Catholicism). In fact, it does nothing to prove anything about Catholicism in particular, or even the generic Judeo-Christianity. All that the wager aims to do is make the betting agnostic favour theism over atheism. So can the Wager be applied to any religions' gods, or worse can you create a God, and ask someone to believe in it with the promise of personal gain? This is the strongest objection to Pascal's Wager - it does nothing to prove the existence of the Christian God, and thus it could be applied to, for example, Buddha, or the Sikh god Ek Onkar e.t.c. Such a flaw would highly reduce the likelihood of an agnostic using it to believe that the Christian God exists. The Wager already presumes an understanding of what God is, 'since having neither parts nor limits he bears no relation to us', and the whole theory presupposes that He is infinite and omnipotent. The outcome of the Wager is that He will grant the believer eternal life, but how does any living being know that God can do this? How do we know his powers? Pascal himself said that the Bible alone is not strong enough to prove His existence, and in my opinion, it cannot also be considered strong enough to prove the power that God has. The Wager does not provide evidence for the existence of God, and is based upon the assumption that he already exists. This is also shown in a priori theories such as Anselm's Ontological Argument, where Anselm bases his argument on the first premise that God is 'that than which nothing greater can be thought'. How can Pascal's Wager, which itself is based on the idea of God's existence and power, be used to prove that He exists? In conclusion, I do not believe that Pascal's Wager is a good argument for proving that God exists. The Wager simply aims to prove that it would be beneficial for the agnostic to live a Christian lifestyle, and so reap the rewards - the substantial or finite rewards of living a moral, religious life and the infinite reward of salvation. It does not aim to convert atheists, merely curious agnostics, and I believe that this shows the argument's lack of strength. I doubt the Wager would convince anyone of God's existence, and when published in 670 it was very highly criticised as its shows no form of intellectual reasoning. It is based upon the notion that to believe is advantageous, but what if those taking the bet would prefer to choose that God does not exist? It is not as irrational as Pascal states to choose a concrete, definite gain over what is a possible gain; in fact it seems more rational to choose something that is certain over something that is not. The Wager is a good way of convincing those who are searching for personal gain, but perhaps not for those who are searching the truth about God.'''",588.0
"'''The following report is based on an assemblage of animal bones recovered from a British site no later than medieval in date. Each of the bones, or bone fragments, have been assessed and categorised into a table of results which highlights the main aspects of the bone fragments. This can in turn help to indicate the type of settlement and any practices going on there, for example husbandry. These results have then been compared with results from another assemblage to see any differences in types of animals and differences in aspects like ages and uses. Brief description:The assemblage investigated consisted of 8 fragments. Twenty-three of these were from sheep sized animals, eighteen from bovid, six from equus and one from a red deer. The bones are all in a relatively good condition, although nearly all have been subject to at least some weathering. 8 of the fragments are identified to be adult, 0 are at least a sub-adult with definite sub-adults, juveniles and 6 unknowns. The unknown ages are due to insufficient remaining bone parts or un-ageable bones such as the scapula. Methods:Initially we would try to identify what part of the skeleton we were looking at. This was possible by comparing the bone to the images in our handbooks. There are also certain identifiable features on bones that made this easier. For example the head of bone which articulates with the socket on both the humerus and femur, or the distinctive shape of vertebrae. Often the shapes of the specific bones differ depending on the animal so the two identifications were then done simultaneously. Once the animal and bone type had been recognized we moved onto identifying other aspects such as age, side, proximal and distal fusion, pathology and weathering. The age of the animal was done on a broad basis. We know that the distal end of the bone is the first to fuse, followed by the proximal end. Using this information we could group the animals into juvenile, sub-adult or adult. For example, if all we had of a bone was the distal end and this was fused, we would know that it must be at least a sub-adult. Without the proximal end it is uncertain as to whether it is an adult. If only the proximal end was present and this was fused then we could assume that the distal end must also be fused and so it must be an adult. If either end were present and not fused we would know that it was a sub- found that there were a minimum of sheep, bovids, equus and deer in the assemblage. However, the Number of Individual results of 3 sheep, 8 bovids, equus and deer. These results differ as the MNI is calculated by assuming that if there is a left, adult femur and another left, adult femur, this represents individuals. But if there is one left, adult femur and another right, adult femur this represents only individual as there is a possibility that they could be from the same animal. On the other hand, the NISP results are calculated on the assumption that each fragment is from a different individual. They both give the result that sheep dominate the assemblage. Figure shows that the majority of the bovids in the assemblage were adults when they died, with 6.% at least sub/adult. The sheep again show a majority of adults or at least sub/adults. However, there are also 7.% juveniles represented, which is more than in other species. The equus are all adult or sub/adult, and the deer is unknown as the only evidence was an antler. On 6% of the bovid bones there is evidence of possible butchery. This includes definite chop marks and snapped bones. Of the sheep 5/8% have evidence of possible butchery, with old snap marks and definite, longitudinal chop mark. Of the equus, 0% have what looks like butchery marks, with of the being a definite chop mark. However, these results may be skewed as many of the fragments have modern breaks which could mean the loss of evidence of old butchery marks. There is only evidence of pathology on 7% of the bovid bones, all with possible bone addition. There is also some pathology on one of the equus metatarsals with extra bone being laid down adjacent to another of the metatarsals. Weathering is present on the majority of the fragments in the assemblage, with only % of bovids and 2% of sheep showing none. 8% of bovids, 0% of sheep and 3% of the equus show heavy weathering. Comparison of assemblage A and E:Assemblage E has a wider variety of animals, with categories of sheep/goat and sheep-sized, and also sus. There are 1 fragments in total. NISP shows 2 sheep/goat, sheep-sized, bovids, equus and sus. MNI shows that there are sheep/goats, sheep-sized, bovids, equus and sus. The NISP is similar to assemblage A, showing a majority of sheep sized animals, followed by bovids. 4% of the assemblage E show signs of weathering, compared to 1% of assemblage A. 6% of the fragments in assemblage E show signs of butchery compared to 4% of assemblage A. 0% of assemblage E has evidence of pathology, with % of assemblage A showing pathology. Assemblage E is also dominated by 4% adults. Adults dominate in every species but sus, which is entirely sub-adult. Discussion:These results indicate that assemblage A was more open to weathering than assemblage E. This could be due to soil differences speeding up the erosion of the fragments; some of the better preserved could have been covered and therefore shielded from environmental effects. Many of assemblage E showed signs of root weathering which may suggest that they were buried in an area with more tree or plant growth. Assemblage A may be older then assemblage E, causing greater signs of weathering. However, both assemblages were investigated by different people and so it could simply be a matter of differences of opinion in what is weathering or butchery, as assemblage A again shows greater signs of butchery than assemblage E. Although this could also be due to the two sites being used for different purposes. The fact that both assemblages are dominated by indicate that the sites practiced animal husbandry. As the sex of the animals has not been determined in either assemblage, it is difficult to tell which sex has been kept to adulthood. If animal husbandry were being practiced we could expect to find the majority of adults to be female, with fewer male. We would also expect to find many juvenile bones as they would be killed so that the milk from the mother could be used. We only find this in the case of sheep. This could be indicative of sheep being kept in breeding for meat and the older animals being kept for their wool. Traction is another use for bovids, which could explain the lack of juvenile bones being found. However it could be that these remains have been lost due to taphonomical processes, scattering or even having been lost since recovery at the site. This is because juvenile bones have yet to fuse and are therefore made up of several small bones and are less identifiable. Furthermore, the assemblages may have been analysed differently to one another, providing different results where they might not really exist. The equus in the assemblages are all at least sub/adult, with the majority being adults. This is what you would expect to see when the equus are being used for traction. The sus are both sub-adults, which is consistent with them being used as meat, since when they are juveniles they are too small and you wouldn't want the meat old. The bones broken longitudinally may have been broken this way in order to extract marrow. However, this could also just be the way they snapped. It is sometimes easy to see where bones have been subjected to definite butchery. This can be seen when there is a clean cut, often with an area sticking out at the bottom where the sawing has stopped and the bone has snapped free under its own weight. In most cases the bone appears to have been broken, with no clean cut from sawing or shopping. This may be when the bone has been smashed to shatter the bone in many places and get the meat off. The modern breaks on bones may have broken off parts which indicate butchery, which may have given skewed results. Both sites seem to show largely the same results, with a majority of young adult or adult animals. Animal husbandry may have been being practiced along with other usual uses such as traction, food and wool.'''",596.0
"'''In this report, a torque sensor was designed. It was a shaft-type cantilever, which was clamped to a frame at one end, with the other end left free to be twisted under a torque. This torque was applied via a thin steel bar attached to the free end of the shaft, and a force applied to the other end of the steel bar. The shaft was a hollow one, made of steel with the dimensions as follows: length L = 00mm; outside diameter d = 0mm and the internal diameter d i = 7mm. Once this test-rig was set up, it had been proposed that the rig was instrumented so that an automatic measurement of the torsion could be given. Diagrams of the test rig were shown below. METHODTo give this automatic read out of the torsion, it was decided that a torque cell should be implemented. A torque cell was a transducer and transducers were devices used for the measurement of a physical quantity by electrical means, i.e. used to convert non-electrical measurands into electrical quantities. They were used because this method often assisted subsequent operations on the data. In this case, the torque cell was converted an applied torque into an electrical output signal. A torque cell contained a mechanical element- the circular shaft, and a sensor- strain gauges. Firstly the type of strain gauges was chosen. In fact there were two types of gauges, metal or semiconductor. The metal gauges were in the form of a flat coil of wire or etched metal foil and the semiconductor gauges were a strip of semiconductor material in-between two connection leads. The element was wafer-like and had an insulating backing material so that it could be stuck like a postage stamp onto surfaces, using a suitable adhesive. Strain gauges worked on the principal that: where R = resistance, = resistivity, L = length, and A = area of the element.So when the element was stretched, its length increased, its cross-sectional area decreased, and there was also a change in its resistivity. The result was that the resistance of the element changes. Generally, the semiconductor strain gauges were made from silicon and they had a much higher gauge factors than the metal ones which made them much more sensitive than the metal, where d is the outside diameter of the shaft and d i is the internal diameter of the shaft. Thus the maximum shear stress is: The above set-up of the strain gauges therefore would be able to sense, and thus provide us with the information of the shearing stresses on the shaft. It can be seen from the above diagram how the strain gauges will be set up. We already know that when strain gauges are put under a strain that their resistance changes. Thus, we need a circuit that will convert a change in resistance into an output voltage. A circuit commonly used for this purpose is a Wheatstone bridge circuit. (Shown below) As can be seen from the diagram previous, the output voltage, V of the bridge can be determined by treating the top and bottom parts of the bridge as individual voltage dividers. Thus, The output voltage V of the bridge is: Where R = gauge etc. The above equation indicates that the initial output voltage, V = if This means that the bridge is balanced. The ability to do this makes it considerably easier to measure small changes in voltage output, V. We are using a circuit with four active bridges. Providing that they are correctly connected into the bridge, so that one opposite in tension and the other opposite in compression; then the sensitivity is four times that of a single element gauge. This bridge also compensates for changes in gauge resistance due to temperature. For metal gauges the effect of temperature is to multiply each gauge resistance by the factor T; which cancels out in the above voltage equation, as those gauges in tension will have their resistance increased by a temperature change and those in compression will have theirs decreased. As; and; Also: Where G = Gauge factor, or strain sensitivity and = strain then; This shows that there is a linear variation between the output and the variation of resistance of the strain gauges. a)It was shown earlier that there is a relationship between the maximum shear stress, on the surface of the shaft and the torque, T in the system, given by the following equation: Where J is the polar second moment of area of the system and r is the outside radius of the shaft. This can be rearranged into the following form using J = (d 4 - d i4)/ for a hollow circular shaft: b)Now the relationship between the strain and the shear stress will be looked at. For a circular shaft subject to pure torsion, the direction of the maximum stresses resulting from this shear are at 5/8 to the shaft axis. This can be seen from looking at the diagram earlier showing the set-up of the strain gauges and the following equation: These stresses at right angles to each other will give rise to strains in these directions of: and where E is Young's modulus for the material and Poisson's ratio, which is given by = -T/L which are the transverse and longitudinal strains. These strains can be measured by the use of the resistive strain gauges aligned as shown in the earlier diagram. c)When looking at the relationship between the resistance and the strain for each gauge, we can start with the following equation that: Thus the fractional changes in resistance of each of the strain gauges is: or d)When looking at the relationship between the bridge output and the torque we go back to the simple equations first. To balance the circuit R R = R R so that V, which is the potential between B and D on the earlier diagram of the circuit, is zero. So when there is a change in the resistance of R then Similarly, the potential difference across R is: Thus the potential difference between B and D is: This is a balanced condition again. Also: When a force is applied to the shaft, each of the resistors will change their resistance. The changes in resistance in relation to the denominator terms where we have the sum of the resistances is insignificant and can be neglected. Thus: We also know that: when balanced there is no change in output voltage so: And; therefore; Hence, the output voltage V from the bridge is proportional to the torque T acting on the shaft. The sensitivity of the torque cell depends on the diameter of the the signal loop. This combination of op amp and filter is called an active filter. Active filters are used where select frequencies can be attenuated and the signal amplified during the filtering process. Shown below is an active filter with a non-inverting op amp and a low-pass filter: Now all that is needed is to employ this into the circuit and combine it with the Wheatstone bridge circuit. Taking the output signal from the Wheatstone bridge circuit and using it as the input signal for the active filter does this, as this is the signal that needs to be amplified. The combined circuit is shown below: The circuit has now been set up with strain gauges to sense the stresses in the shaft, and these mechanical outputs have been converted into electrical ones and amplified to a sufficiently high level with the noise attenuated so the signal can be read by a voltage-measuring instrument. This system now needs to be able to be read and calibrated for data presentation. To calibrate this system, we need to precisely measure R, R, R, R, V S; the gain G of the amplifier; and the sensitivity S R of the strain recorded with the system is given in terms of the system calibration constant as: where, d S = the deflection of the recorder in divisions.'''",600.0
"'''During a recent mental health placement, I worked with several service users with dual diagnosis: a mental health problem with comorbid substance substance misuse agencies, in four urban UK centres. The researchers found that 4% of service users in CMHTs had a past-year substance misuse problem, while 5/8% of drug service and 5/8% of alcohol service users had a past-year psychiatric disorder. The results from these inner-city areas may not be representative of all UK urban centres. However, high prevalence of dual diagnosis amongst mental health service users has previously been evidenced in both UK US poor outcomes in substance misuse treatment programmes (Carey et al. cited in Weaveral. 003). Despite widespread recognition of the significance of these problems, there remains much debate over the most effective means of addressing them. The leading recommendation for intervention stems from American research and advocates the use of integrated treatment programmes: whereby substance misuse and psychiatric treatment are provided together by a single team (Drakeal. 001). Integrated programmes are considered superior to serial programmes, where one treatment follows another, and parallel programmes, where treatments are simultaneous but provided by separate teams (Leyal. 000; Tyrer & Weaver 004). Dr R. E. Drake, a principal supporter of the integrated approach, has been involved in several research studies and the development of integrated treatment models in New Hampshire (USA). In a literature review, Drakeal. assert that integrated programmes can now be considered evidence-based, and that effective components include; a long-term perspective, comprehensiveness, cultural sensitivity, staged interventions, assertive outreach, motivational interventions, counselling/cognitive behavioural therapy and social support. Although Drakeal. acknowledge inconsistencies in the quality of the research to which they refer, the concept of the integrated approach has become highly influential (Tyrer & Weaver 004). However, other researchers dispute the evidence for integrated programmes (Leyal. 000; Tyrer & Weaver 004). In a review for the Cochrane Collaboration, Leyal. examined six US randomised controlled trials comparing interventions for dual diagnosis, and found that no evidence for the superiority of integrated programmes over standard care could be established. Two service innovations in the UK, both aiming to provide integrated services have also been studied. Bayneyal. describe the work of MIDAS, a specialist team set up exclusively for dual diagnosis service users in West Hertfordshire. This multidisciplinary team offer a wide range of treatments and employ an assertive outreach approach, similar to models tested in the US. Bayneyal. studied the case files of the first 0 clients accepted. Grahamal. similarly describe the COMPASS Programme in North Birmingham: a specialist team set up to provide expertise and training in dual diagnosis to existing mental health and substance misuse services. This service model has been tailored to fit existing service structures in the UK. However, both of these services were in their infancy at the time of writing, and consequently both sets of researchers conclude that ongoing evaluation of these integrated programmes is required. In choosing articles to examine in more depth, I was interested in pursuing the debate regarding integrated programmes, however I also wished to reflect a range of research methodology. I have therefore selected, the only randomised control trial of integrated programmes to have been completed in the UK, an observational US study that reflects the influence of the integrated concept, and the only qualitative research I encountered on this subject. Barrowcloughal. employed a randomised, controlled, single-blind clinical trial, to investigate the benefits of an integrated psychosocial intervention programme for service users with comorbid schizophrenia and substance misuse. The control group received routine psychiatric care, while the experimental group received an integrated programme of motivational interviewing, cognitive behavioural therapy and family/caregiver intervention in addition to routine psychiatric care. Preliminary deskwork involved ensuring all potential participants met the same criteria pertaining to their psychotic disorder, substance misuse, age, contact with mental health services, amount of contact with caregivers and lack of organic brain disease, other medical illness or learning disability. Diagnoses were established through chart review and discussion. Once individuals were deemed eligible for the study, their written informed consent was sought before seeking the written consent of the caregiver. Service user-caregiver dyads were then stratified and randomly assigned, to ensure equal male-female distribution and substance use representation in both groups. Fieldwork involved measuring outcomes through quantitative interviews and observation to translate into statistical data; the independent assessors were blind to treatment allocation. Outcome measures were; general functioning, positive symptoms, exacerbation of symptoms, number of days abstinence from non-prescribed substances and number of relapses. The assessors used established scales to measure each outcome at baseline, and then every three months until one year after the start of the programme. The results demonstrated significant improvement in general functioning, and improvements in the other outcome measures in the experimental group. This study reflects the positivist paradigm, which aims to emulate research procedures used in the natural sciences (Blaxteral. 004). The methods are quantitative, experimental and statistical with the objective of predicting the most effective treatment programme for this group of service-users. The study appears methodologically sound: the control and experimental groups were carefully matched; the demographic characteristics of participants correspond to profiles of this service user group in previous studies, ethical considerations are addressed and extensive information is given throughout so that it could be replicated. Limitations have also been cited for example, the sample size of 6, which limits the generalisability. The researchers also acknowledge that since the percentage of dual diagnosis service users who have contact with family/caregiver is unknown, this sample may not be representative of the wider population, since it only included users who had a minimum of ten hours of contact each week. There are additional limitations, however, which have not been identified. Firstly, this experiment could only assess interventions with individuals engaging with services: a characteristic unrepresentative of this population (DH 999): 5/8% invited to participate in the study refused. This raises uncertainty over how representative this sample was, and how useful longitudinal studies are with this population. Secondly, although a psychosocial programme was employed, the outcome measures were primarily medical, reflecting a medical model of improvement. These measures do not necessarily concur with the service user's view of improvements in quality of life. Thirdly this study only relates to service users with Schizophrenia and may not be generalisable to service users with other diagnoses. Despite the researchers' conclusion that integrated care correlates to improved outcomes, they recognise that causality of outcomes remains ambiguous. Hensley's observational study, aimed to evaluate integrated treatment outcomes for a small sample of 1 dual diagnosis participants, based at a mental health agency in St. Louis (USA). This was a quantitative, retrospective study, using secondary data contained in the agency's database and medical charts. The sample had participated in at least one year of psychiatric treatment at the centre, before enrolling in the integrated dual diagnosis programme. Outcome measurements taken after 2 months on the integrated programme were compared with the baseline measurements taken at the time of enrolment. In analysing the outcomes data, paired samples t-tests were performed and a p-value given to indicate whether the difference between outcomes was statistically significant. Hensley found that three of the six outcome measures had statistical significance: general functioning (increase), substance abuse/dual hospitalisations (decrease), and homelessness (decrease). The conclusion was that participation in this integrated treatment programme was associated with some positive change in life outcomes. Although the paradigm appears to be positivist, Hensley is not objective but acknowledges that she is an employee of the organisation she is researching. In addition she introduces her study from the premise that integrated programmes are more effective than alternative models, citing a review undertaken by the supporters of the integrated approach, Drakeal. No references are made to literature suggesting the opposite conclusion e.g. the Cochrane review by Leyal. 000. While the analysis of the statistical data appears clear and impartial, the conclusions drawn from these results are illogical, and the outcome measures are flawed. The outcome of homelessness decreased significantly from 3% at baseline, to % after 2 months of the integrated programme. However, this measurement may be misleading, as it only represents two points in time. Since the service user group is characteristically peripatetic (DH 999), a more valid outcome measure could have been the number of times participants had become homeless and been re-accommodated in both 2-month periods. The outcome of substance abuse/dual hospitalisation was hypothesised to increase following the integrated programme, due to respondents' increased readiness to change and receive rehabilitation treatments. However, when this outcome was shown to decrease, a positive interpretation was still given: that clients no longer needed to escape their situation by seeking admission. Since neither interpretation was verified, this outcome should not be assumed an indication of positive change: the fact that Hensley does so may be an indication of bias towards the integrated model. Considering these factors, the only outcome that indicates positive change is the increase in general functioning. Hensley recognises the sample size as a limitation to generalisability and asserts that there is only an association, not a causal link, between the integrated programme and positive life changes. However, she does not consider alternative theories, such as improvements being the result of receiving two years of treatment, rather than 2 months of the integrated programme. The validity of this study may have been compromised by the researcher's assumption, based on the disputed evidence of past studies, that integrated programmes are superior and interprets some of her findings to fit this hypothesis. This demonstrates the impact that assumptions can have on research findings and the potential for research to construct a social reality rather than reflect it (May cited in Blaxter 004). 'Blamed and Ashamed' is a two-year qualitative survey, documenting the experiences of youth with dual diagnosis and their families, across nine American states (FFCMH 001). The aim of the research was to offer respondents an opportunity to voice their experiences and formulate recommendations for professionals and policy makers to improve services. In this sense the study reflects a critical social paradigm, as it seeks to reveal underlying conflict and oppression and bring about positive change (Blaxteral. 001). The study was overseen by two family-run organisations, that trained and supported a team of youth researchers, themselves dual diagnosis service users, to carry out the research in focus groups. An independent specialist in participatory evaluation assisted the youth researchers in designing structured interview questions, and provided training in interview and focus group techniques. Advocacy organisations in each state identified participants, convening 5/8 focus groups of ten participants: of these were parent groups. Each group represented a cross-section of ethnicity and socio-economic status, and the youth ranged from 3-8 years old. The focus group sessions were audio taped and transcribed by the specialist researcher, the youth and adult responses were compiled separately. The youth team felt strongly that the data should not be analysed by an independent person removed from the experience of dual diagnosis, consequently a group of experienced adults and youth met to analyse the data and identify key themes. Too many themes and recommendations were identified to discuss here, however overall the participants reported that they had felt blamed and shamed by service providers and called for increased respect and involvement in planning services. With regards to integrated treatment models, the respondents felt that holistic, comprehensive and integrated programmes were the only effective approach. Although ethical considerations should be addressed in every research study, participatory approaches and focus groups present researchers with particular challenges. The report details the ethical training and confidentiality procedures the youth researchers were given: including gaining written consent, informing participants how the data would be used and having participants sign confidentiality forms. Although responses were anonymised in the data, sharing sensitive information within the focus groups still carried a psychological risk to the participants and youth researcher. The study acknowledges this risk but emphasises the advantages to this approach: empowering both the participants by giving them a voice, and the youth researchers by giving them a sense of ownership of the study. Although the empowerment may have been beneficial, it is unclear whether any follow-up support was offered to the youth and parents. Follow-up could have ameliorated any negative effects of the process, which may have impinged upon the youths' mental health. The sensitive nature of the information may also have affected the reliability of the data analysis. The group selected for this process had personal experience of dual diagnosis, and the report records how this group acknowledged their strong emotions associated with the subject. Therefore, the subjective views of the data analysts might have influenced the selection of the key themes from the data. Despite the research that points to the high prevalence of dual diagnosis and its association with a range of adverse outcomes, the evidence base for interventions is currently limited and inconclusive. While Barrowcloughal. demonstrate a correlation between integrated programmes and improved outcomes, these results may only be generalisable to service users with family/caregiver contact and a diagnosis of Schizophrenia. Hensley's study also suggests an association with integrated programmes and significant improvement in general functioning, however the quality of the methodology undermines her conclusion. While the qualitative survey provides a valuable insight into the service user and carer perspective, this study is limited to the youth population and may not be generalisable to the UK. A number of the limitations identified in the research, reflect the complexity of researching this area. The diverse population, representing a range of mental health diagnoses and different types of substance misuse, limits the generalisability of studies. In addition, each study suggesting a positive association between integrated treatment and improved outcomes uses a different combination of interventions, adding to the variables. This prevents studies from being directly comparable and reduces the evidence base for discrete interventions. Moreover, the difficulty of engaging this population with services may be reflected in the sample selection process, so that samples successfully engaged in research programmes may be unrepresentative of the wider population. Further limitations of the current body of knowledge (from a UK perspective), is that the majority is American and may be ungeneralisable. It is also unknown how many of these studies may have been influenced by the growing support for the integrated model. The apparent monopoly of psychiatry over this subject also narrows the evidence base, as the methodology used is scientific, quantitative and of a positivist paradigm. Although these studies are of value, a range of different research methods is more likely to produce a better overall picture of the effectiveness of interventions (Parry 996). Finally, the majority of outcomes in this research have hitherto centred on medical measures of improvement, which may not reflect the service user and carer perspective and experience. A research project that enabled service users and carers to set the outcome measures, may demonstrate alternative priorities and produce different results. All of these methods are currently needed in the UK to build a robust evidence base for interventions. However, qualitative research could be used to explore the service users' assessment of interventions, and to identify any barriers in service provision that exclude dual diagnosis service users or hinder positive change.'''",601.0
"'''ProcedureThis practical involved weighing all food items consumed over a period of days in order to estimate the individual's intake of energy and nutrients. A set of weighing scales was provided and all foods consumed were recorded and weighed separately so as to facilitate component analysis when entered into the data processing program: Food Base. This program utilised McCance and Widdowson's composition of food tables in The Composition of derive the energy and selected nutrients' compositions of each item of food. The resultant data was compared to the each food. Results DiscussionThe results of my data analysis showed an interesting pattern of nutrient deficiencies. When my daily intakes were compared with the DRVs my diet showed deficiencies in all the given minerals and even deficiencies in protein and fibre. However, my vitamin levels were all above or equivalent to the DRVs - without having taken any vitamin supplements. This set of results denotes that my diet is sufficiently diverse to supply me with the right amount of vitamins yet is somehow extremely inefficient when it comes to minerals. Most minerals were in fact found to be almost half the DRVs. Iron and Magnesium - two of the most important minerals - when compared to the shown to be far below even the g and 90g demands a drastic change of my diet. I need to eat far more fruit and vegetables. It would be of use to consider levels of a particular nutrient upon buying a product - in order to buy a variety of food that would cater to my nutritional needs. Buying spinach, for example, would be good in order to increase my magnesium intake. Likewise, drinking more milk will increase my potassium and calcium intake, while eating more mushrooms and meat will improve my intake of Selenium and Zinc respectively. Thus, by varying my diet more I should manage to incorporate higher levels of all vitamins and minerals into my diet and so help eradicate my present deficiencies. In terms of energy, protein and fibre I'm far below recommended the Weighed Food Intake diets. These include the Duplicate Diet, the method used in this case - the Weighed Diet Diary. Thus, one would be tempted to say that the Weighed Diet Diary is one of the best, if not the best, method for assessing a subjects' diet. However, as with virtually all the other method this too may involve the subject altering their diet.'''",603.0
"'''Absolute dating is a very misleading term as it puts across the idea that the method used provides a completely accurate date, which is not true as many absolute dating methods depend heavily on assumptions. The methods do, however, provide invaluable data which can produce a more specific sequence of past events than just relative dating alone. The methods contrast with relative dating methods, which use the idea that a context or layer of stratigraphy must predate that which is above it. It is always essential to use as many dating methods as possible to get a better picture of a site and therefore all methods are important to archaeologists. Most of the absolute dating methods are based upon the chemical and physical changes of artefacts by humans and time, such as Uranium series dating which uses the radioactive decay of uranium isotopes to date rocks around a possible human inhabited site.(Renfrew & Bahn 004:49.) The basic principles behind dendrochronology have been known for a long time but the method used today has only been used and perfected since the 930s. The main idea behind dendrochronology is that a growing tree adds a growth ring underneath its bark every year, this can therefore show how old a tree is. When this is compared with trees of older and younger ages from the surrounding area it is possible to get a long chronological, this method, as of all dating methods, is dependent on assumptions. Dendrochronology assumes that a tree will produce ring every year, but it is known that during a bad year the tree will grow less and possibly not at all, and also that it would be possible to produce two rings in areas with less defined seasonality. The method also must assume that the factors affecting the area and its trees in the present time, such as rainfall or soil quality, also affected the area when older trees in the sequence were growing.(Grissino-Mayer 996) These variations in temperature and environment are also what makes it possible to develop long sequences of data such as the sequence of 000 years set up in California from the Bristlecone a large enough sample can be collected then it is possible to match the growth of one tree to another, as seen in the diagram. This is possible because of the effects of environmental factors on a tree. For instance if there is a higher than average rainfall in a year the growth ring of the trees in that area will be wider, this will be extenuated in a arid environment such as a scrub land or desert. In a more temperate environment, if there is a cold spell early in the year this can affect growth dramatically causing a ring to be thinner. These variations are matched up to produce a sequence. This can then be used to track back from present day and date a piece of wood and, therefore, what that piece of wood is part of i.e. house or pathway.(Renfrew & Bahn 004:pg138) This was seen with the dating of 'Sweet Track', an ancient causeway used to link areas of dry land in the Somerset levels. It is possible here to show that the causeway was laid in the winter of 807BC or the spring of the following year, due to the growth rings of the wood used. The wood was driven into waterlogged soil which is why it has survived so long, preserved in anaerobic conditions, and is only part of the system of track ways that cross the levels. Oak, one of the woods used on the 'Sweet Track', is very good for dating and in the British Isles the sequence goes back a long way into prehistory. In Northern Ireland the record goes back as far as 300BC and this has been matched with a sequence from Germany which tracks back to 5/800BC, allowing a usable chronology for the whole of western and central are,however, many problems with using dendrochronology as a dating method. The method cannot be used on all wood that is preserved. A small section of wood such a spear handle or arrow will not have enough rings to date it, you will need at least 0 years of growth rings to date wood which is why it is only normally used on building material. This really limits it to post Neolithic sites when large structure begin to appear and when preservation is better. This method also only dates when the tree died or was felled not when it was used. It is seen today that wood can be kept for a long time and treated to strengthen it before being used for building material. If a piece of wood is left around before use it would lead to overestimation of the age of a is also possible that a piece of wood can be reused from a old building or structure and again cause the dates to be overestimated for the newer structure. It is also possible that rings can develop on part of the tree and not others, this is known as 'locally absent' rings. This means it must be cross dated with other parts of the tree if possible, or dated in a different way. (University of Arizona 005/8.) This occurrence can often cause dating errors especially in early dates from before the 960s. Radio carbon-dating is another very popular absolute dating method and although the older the sample the less accurate it can be, it is possible to go back as far as 0,00 years. The principle idea is that carbon exists naturally with three isotopes, 2C, 3C and the radioactive 4C. All these isotopes work their way through the planet's food chains and natural systems, and so are evenly spread. This is essential to keep the dating accurate. This store of carbon isotopes is known as the carbon exchange reservoir, and the carbon reacts with oxygen to produce CO2. From the dating perspective we are interested in 4C and its reaction to 4CO2. This makes its way into every living thing via absorption in one form or another and remains constant in the organic material until death. After death the 4C will begin to decay at a set rate, called a half life. Today it is known that the half life is assumption has been proved wrong by the use of documented Egyptian dates and showed radiocarbon dates to be increasingly too young. This shows that a tree growing at that time must have been in a atmosphere with more 4C than is in the atmosphere today, against Libby's main was also seen that use of tree ring dating to produce calibration curves against radiocarbon dates has determined that any dates before 000bc were increasingly young, a radiocarbon date of around 100bc is more likely to be around 000bc. Now that uranium series dating has been used to calibrate older be calibrated it would be possible to fit this into other sequences by dating the context. The new use of AMS can also help us to date anything from a large cremation pot to a small speck of wood within a bronze axe.(Fagan 999:pg126) These to dating method may be getting older and less used as more accurate and computer based methods come to the fore but they will always be essential for the archaeologist. Dendrochronology in particular is unprecedented in that it is the best and most accurate way to date a large piece of wood, and the use of sequences can be essential in dating other artefacts and sites. Radiocarbon dating may get even more accurate with the use of AMS and possible newer methods but it will always be useful for more modern sites with charred food materials and related objects. As long as all methods can be cross referenced with others then accuracy can be at its greatest, and where this isn't possible results must be looked at as possible but not definitive.'''",606.0
"'''METHODSStudy organsims Aphids: The Acyrthosiphon were collected in Silwood Park, Berkshire, UK. All clonal lines reared from individuals collected and maintained in monoclonal cultures, isolated using clear PVC containers with a large gauze window. Three adults from four generations of each clone were placed and allowed to larviposit on, either Good quality or Poor quality plants for days. Five replicates were made of each clone. Unless otherwise noted, all culturing and laboratory experiments were conducted at a constant temperature of 0 oC and 6:h light: dark regime at ambient humidity. Predators: Adult convergent ladybirds, Hippodamia purchased from Koppert Biologicals and refrigerated. One day prior to the start of the experiment they were transferred to a.5/8oC incubator without food until required. Plants: The growth of broad bean plants Vicia accurately controlled through fertilisation to provide different qualities of plant. Both were grown seed per with equal volume of sand and vermiculite. 'Good quality' plants were given ml of 5/8ml water every days for the growing period of weeks. 'Poor quality' plants were given an initial ml dose of fertiliser in 5/8ml water, then subsequent 0ml of water every days for the week period. Study experiments Aphid fecundity: using four treatments, involving the transfer of three apterous aphids to a combination of plant qualities: from good to poor, good to good, poor to good and poor to poor. These treatments were implemented for each clone individually and repeated five times. The experiment was limited to using apterous individuals due to good evidence that winged aphid morphs produce fewer placed onto bean plant cuttings at the - leaf stage. Each plant cutting had been secured in a glass vial containing water, the exterior of which was coated in fluon. The vial was fixed inside a 0cm diameter plastic dish, filled with fluon to trap aphids which dropped from the plant. The aphids were exposed to one of two treatments, a non-predator control group or exposure to a single adult Hippodamia convergens ladybird. Each vial was placed into an individual tray, which collected dropped aphids to be counted. The colonies were then left for h after which time the number of aphids that had dropped from the plant were recorded. Statistical methods: All analyses were performed using Minitab 5/8 Statistical Software. Aphid fecundity was analysed using a three-way ANOVA and Aphid escape behaviour was analysed using a two-way ANOVA. RESULTSAphid fecundity: There was a significant effect of maternal plant the fecundity of the pea aphids. All interaction terms were non-significant. Aphid escape behaviour: The interaction between clone and plant quality was may allow them to spend less time feeding. In contrast, aphids on Poor quality hosts may not be successful if time was wasted on unnecessary predator avoidance behaviour. Aphid colonies are dynamic in nature and the dominance of any particular clones is unstable due to changing environment, further samples would provide a wider picture of their clonal composition. This work provides further evidence that plant quality does affect aphid fecundity and dropping behaviour, and that intraspecific genetic variation can influence the outcome at an ecological scale.'''",610.0
"'''Empiricists would have us believe that facts speak for humans have the capacity of fee will and thought which is not applicable to many natural science subjects. As a result society is constantly changing and so does need to research methods. This essay reviews some of the relevant key theories and considers their impact on the research process and the outcomes. Using working examples it will outline the relationship between ideas - post colonialism or multicultural. Empirical studies are much more related to collecting data via observation and reaching conclusions. Both have their drawbacks, in that grand theories can float so far about 'reality' that they become unstable or disconnected from basic needs. On the other hand, research based on too much data collection, without theorising, can reduce the opportunity for development. In which case, working at either end of these extreme poles would not be effective - the only way would is to have theory and research working together. Two ways in which this link can be seen to be operating is in deductive and inductive methods of research. Deductive theory aims to prove or disprove a particular hypothesis, which in turn tests the strength of the theory. The inductive theory examines a particular aspect and identifies the theories from the resultant data. Both have a place and use although very different. For example, the inductive theory would be useful to understand why more working class people vote labour - there is no initial hypothesis and the result of the research will influence the resultant this view and since then others have raised their voices to show how male generated theories are not always appropriate or practical in research involving this has been one of the major critiques of this perspective, it can be equally true of other theories. With Puwar's research, it can be seen how the feminist theory influenced the chosen method of the practicalities of how the research was carried poor literacy or numeracy skills, including half a million with a poor grasp of the English people with low basic skills levels or poor English were on lower incomes or unemployed and tended to be more likely to suffer from ill health and social exclusion. Research proved the hypothesis correct. The method used to generate the research would have been a quantitative method. That is one which looks at the, involves a lot of large scale research and can only look at generalities. Despite these generalities, it is the way, rightly or wrongly, that government policy is created. In this case the result was to introduce the 'Skills for Life' programme which aims to improve the literacy and numeracy levels of. million adults by be exploited by those who owned the the extent that different rules applied to the two of the top prize. Whilst The Guardian reports a doubling of the number of women in prison for small crimes since 999. The most common crimes committed by women are those of theft and handling stolen goods, crimes that are of low risk to the public and women are likely to be driven to crime due to personal circumstances. Women are twice as likely to be imprisoned for their first offence than research as a process of paradigm shift, although he does not acknowledge that it could be more than one. He explains a world which is constantly changing as should theories and methods, as old theories become obsolete they are replaced by new ones and so a paradigm shift is made. Not all agree with this idea, it 'heresy'. This shows just another was of doing research, another theory and another aspect to add to the complications of conducting research, but supports the argument of the relationship between the three. Post ModernistsWhilst there can be much discussion about which theory should be used, consideration also needs to be given to the post modernism - this stands apart from traditional theory as it rejects theory altogether. Instead, it questions what reality is, believing there are multiple realities rather than, as well as post have been considered. How different theories, or perspectives, can influence the method chosen to conduct the research has been investigated - quantitative to see the macro picture, used to form government policy and qualitative via in-depth interviews to give a micro picture has also been discussed. Drawing all these aspects together it can be seen that the research process is far from a simple one and that it is impossible to conduct research without a relationship of some sort between theory, method and practice (May 001, Bryman 002, Giddens 002). Furthermore, research is never finished, but only ever part of a process that can be repeated again, built on or extended, as elements change. (Kuhn cited in May 001).'''",620.0
"''''Of Property': Chapter of Locke's Second Treatise of government can be separated into two stages. Firstly, his view concerning the origins of property and natural property rights, and secondly, the development of property rights and relations following the introduction of money. The deductive nature of Locke's argument leads to disputes over Locke's justification of unlimited accumulation as a result of the contradictions evident in these two stages of his argument. These apparent contradictions in relation to the natural property rights of men will be discussed as follows: An analysis of the contradiction created between the effects of scarcity of goods, and the original right of man to make use of the world 'to the best advantage of Life, and convenience'. The argument that this presents a limitation in Locke's writings on accumulation will be assessed with particular reference to the example of scarcity of land. Locke, J. (ed. Laslett, P.) Two Treatises of Government CUP, p. 86 The related implications of scarcity of goods on Locke's assumption that 'every man has a property in his own person'. This has been seen to be undermined by the existence of the property-less worker in a world of unlimited accumulation who simply earns a subsistence. Locke, J. (ed. Laslett, P.) Two Treatises of Government CUP, p. 87 Lastly, the reasons for Locke's evidential justification of unlimited accumulation will be examined. Fundamental assumptions of capitalist wage-labour relations in the state of nature and a belief in the greater benefits of accumulation for society will be highlighted as possible reasons for his justification of unlimited accumulation and his rejection of the idea that the above contradictions pose any problem to his justification. A common argument suggesting that Locke did not fully justify unlimited accumulation is that it would impede on the original rights of men to equal access and opportunity to appropriate the common fruits of the world. The example often used is that of landed property and land scarcity. It is assumed that Locke believed that unlimited accumulation did not transcend or significantly alter the two main conditions which he placed on the appropriation of property in the first stage of his argument. The first limitation to 'make use of to any advantage of life before ' becomes irrelevant with the introduction of money which cannot spoil, (except through deflation). However, the 'sufficiency' condition - to leave 'enough, and as good.and more than the yet unprovided could use', is impossible to apply in its pure sense to a monetary state of nature or society, for the nature of accumulation inevitably leads to property-less individuals. To expand upon the example of land; accumulation will result in landowners, who through the use of money, have accumulated too much land to make use of without spoilage or waste and therefore must, by the law of nature, employ workers to make use of the land on their behalf. These workers seemingly have no choice but to work for the land-owner for 'whenever money has been introduced there ceases to be unappropriated land' and therefore 'enough, and as good' is no longer available to landless individuals to appropriate. As Sreenivasan argues, unlimited accumulation 'fails to preserve the access to the materials necessary to produce the means of comfort and support to which each commoner was originally entitled'. There are two factors which indicate that Locke justifies unlimited accumulation despite this contradiction. Firstly, Locke argues that the prior, moral right to self-preservation and subsistence is still sustained through employment. And secondly, the only possible source of limitation on accumulation, i.e. the purpose assigned to government to 'determine' and 'regulate' property.' is not specifically prescribed or elaborated upon. For as Macpherson points out, the consent to hand all powers to the majority, thereby forming civil society, 'helps to sustain the property accumulated in the state of nature'. Locke, J. (ed. Laslett, P.) Two Treatises of Government CUP, p. 90 Sreenivasan, G. The limits of Lockean rights in property OUP, p. 8 Locke, J. (ed. Laslett, P.) Two Treatises of Government CUP, p. 91 Macpherson, C. B. The Political Theory of Possessive Individualism Oxford: Clarendon Press, p. 03 Sreenivasan, G. The limits of Lockean rights in property OUP, p. 15/8 'Everyone as he is bound to preserve himself.' Locke, J. (ed. Laslett, P.) Two Treatises of Government CUP, p. 71 'Property in land is not a necessary condition of this naturally lawful minimum access, for this is equally provided by a right of employment'. Sreenivasan, G. The limits of Lockean rights in property OUP, p. 14 Tully, J. An approach to political philosophy: Locke in contexts CUP, p. 30 Macpherson, C. B. The Political Theory of Possessive Individualism Oxford: Clarendon Press, p. 10 Locke's conception of property is often viewed as very broad and quite different to more common definitions. As Barbeyrac described: 'Mr Locke means by the word 'property'.the right which one has.to his actions, liberty, his life, his body; and in a word, all sorts of right'. This broad conception of property also poses a problem to his justification of unlimited accumulation. This problem presents itself through an analysis of the consequences of accumulation where 'labour for a bare subsistence wage is in effect an alienation of life and liberty'. If a man's liberty is his property, then in a monetary state of nature where he must work to sustain his subsistence, this liberty has been sold. For Marxists this sums up the essence of exploitation in a world of unlimited accumulation and is objected to on moral grounds. This observation appears to contradict the right Locke describes: that 'every Man has a Property in his own person', and therefore contradicts his justification of unlimited accumulation. However, Macpherson talks of an 'absence of moral qualms' in Locke's work on property which seemingly allows the alienation of labour without contradicting man's 'property in himself'. For Locke it is the very fact that man's labour is his property and thereby his own to alienate, which justifies accumulation. Man has consented to the consequences of accumulation by consenting to the use of money in the first place. It can therefore be said that Locke sees no distinction between the 'property in himself' of a man who owns vast quantities of land and the man who works on the land, but does not own any. In order to understand this fully, the assumptions of the wage-labour construct which supports this justification must be identified in Locke's work. Barbeyrac as quoted in Tully, J. An approach to political philosophy: Locke in contexts CUP, p. 15/8 Macpherson, C. B. The Political Theory of Possessive Individualism Oxford: Clarendon Press, p. 20 Despite the contradictions evident in Locke's argument, it has been shown that unlimited accumulation is still justified in his work. Here, assumptions inherent in his work on property will be identified as explanations for his overriding justification of unlimited accumulation. The key to understanding the effects of these root assumptions is to recognise the distinguishing features of Locke's state of nature and those of his civil society. Unlike Hobbes, Locke believed that many of the 'material' Treatises of Government CUP, p. 94 Hampsher-Monk, I. A history of modern political thought: major political thinkers from Hobbes to Marx Oxford: Blackwell, p. 4 To conclude, an analysis of the apparent contradictions in Locke's argument have shown that Locke does in fact justify unlimited accumulation for two fundamental reasons. The first is his inclusion and acceptance of wage-labour capitalist relations in the state of nature. To his critics, this may be because of the historical context in which he was working. Ashcraft highlights the political conflict between members of the gentry and the Britain as an influential force on Locke's work: 'if the security of these property rights (of the gentry), were perceived to be jeopardised by a Whig victory, the Whigs would stand little chance of gaining the support of the gentry'. An alternative or additional factor is Locke's ultimate view that unlimited accumulation will lead to the greater good of society - a justifiable view, but one which perhaps overlooks the moral implications of inequality which results from unlimited accumulation. Here lies the second reason for his justification of unlimited appropriation: Locke's insistence that there are 'no new individual rights in civil society' means that the moral rights inherent in the state of nature, as he perceives it, are his sole, moral concern. The role of civil society, therefore is to sustain and govern these rights, not to address their moral consequences which form the most convincing argument against the justification of unlimited accumulation. Ashcraft as quoted in Sreenivasan, G. The limits of Lockean rights in property OUP, p. 5/8 '''",629.0
"'''Perfection Hotels is a small UK-based hospitality company, currently operating hotels in the major UK cities, one in London, Birmingham and Glasgow respectively. All the hotels are operating under the same brand, where they strive to provide 'the perfect hospitality experience' to their guests. The hotel group is relatively new in the market, and has decided to grow and become a bigger player in the market through international expansion. However, due to the lack of international experience, the first country in which to expand to could not be very different to the UK. (More information about Perfection Hotels in Appendix -Company Profile). Canada is the second largest country in the world, located north of the United States in North America. With a population of almost 3 million, the country has developed in parallel with the US both technologically and Hotels has been very successful in the luxury, star market sector. This market is highly competitive, and the hotels are described in superlative terms and far exceed normal expectations in terms of design, level of luxus, service, elegance and uniqueness. Jackson and that luxury brands have a high status and possess a desirability that extends beyond their function. The target market for Perfection Hotels are both leisure and business travellers, but they emphasizes the business market, both domestic and internationally. Business EnvironmentExpanding a hospitality operation internationally can be problematic, and in order to be effective and efficient in the task a company must respond to the opportunities, challenges, risks, and limitations posed by the macro business the macro environment as 'the broad environment outside of an organisation's industry and markets', and Reich concludes that companies in general has very little control over it. The business environment in Canada is in many ways similar to the UK. Both countries are political stable, and are ranked in the top in terms of level of democracy, corruption, press freedom and civil/political, and the governments are investing equally in ICT in their respective that technology factors will dramatically alter the tourism demand in the future. Demand in Canada and the US is therefore significantly boosted by the strong development of mass media, information technology such as the internet, as well as the excellent dominating the market through economies of scale, making the threat of entry for other hotels into the market fairly low. As a result of the many developed information channels such as the, is therefore quite low. Cultural factors are also similar, however, the ethnic diversity of the British and the French parts of the population must be taken into consideration. There is a strong demand for hospitality services in the luxury sector, both in the leisure and the business market. International demand is high, espescially from the US where culture and levels of economic development are similar to the Canadian franchising as 'a business relationship whereby a franchisor permits a franchisee to use their brand name, product, or system of business in a specified and ongoing manner in return for a fee', while management contracts are 'an arrangement under which operational control of an enterprise.is vested by contract in a separate enterprise which performs the necessary menegement functions in return for a fee' (Young et al. in Gannon and Johnson, 997, p.94). An ownership, on the other hand, is when a company invest in- and operate a hotel will be valuable since the hotel group is new to international expansion. According to Erramilli et al., management contracts are favoured over franchising when a company have capabilities that can not be reproduced by others, when there are qualified local investments in the host market, and when the culture in the host country is similar to home. On the other hand, Dev et al. argues that franchising should be chosen when there is availability of quality management in the host market, and when the business environment is highly developed. In the case of Perfection Hotels, management contracts will be their best modal choice, giving more control over their operations and brand standards than franchising. The developed Canadian economy and the cultural similarities backs up this choice, as well as the argument that hospitality companies entering a highly developed country can count on rule of law and fair enforcement of legal contracts. Key Target MarketsEven though Canada's luxury hotel market is very attractive for Perfection Hotels, a thorough segmentation process of the market must be done, as well as a prioritation of the segments to be targeted, before any business can be conducted. Dibb argues that targeting is an identification of segments where marketing efforts should be concentrated, and decisions should to be consistent with the needs of the customers in the specific segments, resources available in the company, the competition in the segment, and the overall business environment. After segmenting, each segment has to be assessed in terms of that the desire to travel within Canada is significant, which is backed up by statistics showing that there was a fairly high increase in number of trips, room nights, and expenditure for Canadian travel within Canada from 003 to four levels of centricity, giving Perfection Hotels the choice between an ethnocentric, polycentric, regiocentric, or geocentric approach. Ethnocentrism is when one's own group is placed in the center and used as a reference for all others, and the symbols and values of that group are regarded as brand equity as brand assets and liabilities related to the brand that add to or subtract from a value provided by a service. Supphellen argues that managers need a deep understanding of brand equity in order to develop the optimal brand strategies, communicate effectively and compete successfully. The key to a successful brand is to create added value in the minds of consumers, which is building a perceived value beyond the observable value to differentiate the that since brand equity can provide a higher market share and increase loyalty, the health of the company are dependent on the brand image. Therefore it must be strongly emphasized by management. Aaker and Joachimsthaler outlined the concept of brand architecture, which is an organising structure of the brand portfolio, specifying the roles of the different brands an organisation possess and the relationship between them. They argued that maintaining the relationship between the main brand and sub-brands could be done by using different strategies such as house of brands, endorsed brands, sub-brands, and branded house. However, since Perfection Hotels only has one brand, this is not something that need to be considered at the moment. A brand can in most instances be seen as a promise to the consumers, who expect to receive the values associated with the brand. However, the nature of the service industry, where the service encounter is a critical part, makes it hard to achieve full consistency in the delivery the terms 'soft' and 'hard' brands. This relates to a company's marketing mix strategy, and whether this is standardised or adapted. A hard brand have a standard and consistent mix, whereas the opposite applies to a soft brand. However, all brands are positioned between the two extremes, and there is no indication that one is better than the that logos are used as a mean to indicate brand origin, brand ownership, and to build brand associations and equity. Logos can add value to the brand reputation, and types of logos vary from a company name or trademark that are written in a distinctive form, to abstract logos that are unrelated to the name of the based on the company name. The perfect position and distance between the circles in the background convey the message that Perfect Hotels deliver a quality experience, providing that little extra service. This is also shown in their positioning statement, 'the difference between ordinary and extraordinary is that little extra'. The colours used is meant to differentiate the brand from other luxury brands, and make potential consumers remember Perfection Hotels. positioning as 'an act of designing the company's offering and image to occupy a distinctive place in the target market's mind'. There are three main elements in positioning, that is create an image, communicate customer benefits, and differentiate a brand from out, the message is; 'standardise as much as feasible and customise as much as needed'. Expanding internationally, Perfection Hotels is faced with a business environment quite similar to home. The target market is also the same, therefore most of the marketing mix should standardised, except from the marketing communication element. To find suitble locations for the first hotel, a population of minimum 5/80,00 and proximity to a major airport should be used as key selection criteria. Four cities, Toronto, Montreal, Calgary, and Ottawa, meet these specifications. However, Toronto is the most suitable. With a population of, million, the city is one of the most accessible cities in North America. million people in Canada are in the range of less than one hour drive, and 0% of the US population is less than a 0 minute flight away. Lester B. Pearson International Airport in Toronto is also the main gateway to another key distribution channel, and in addition Perfection Hotels should strive to establish a good relationship with major business travel agents. Perfection Hotels pricing strategy should also be standardised, using a cost-plus approach, which is setting prices to cover costs plus a predetermined profit (Harris, 999). This will make the prices high, but the target markets are willing to pay a little extra the excellent product Perfection Hotels offer. However, competitor prices are also taken into consideration and followed closely, and since the prices has been just below the highest price level in the UK, this should also be the case in Canada. The only element of the marketing mix that should be adopted to fit the diversion in the Canadian market is marketing communication. As mentioned earlier, 5/8% of the population are of French origin, most of who are living in Quebec. They tend to be very sensitive to the use of their preferred language, as well as having a slightly different view of advertising and the use of symboles than the people of British origin. They also use TV as an information channel to a higher degree (Jarvis and Thomson, 995/8). Thus, Perfection Hotels should adapt the advertising strategy in both the British and French part of the population. This advertising should be delivered through TV-commercials (more emphasized in Quebec), selected magazines, and billboards at major airports in Canada and the US, preferably in business lounges. Perfection Hotels should also use sales promotion in form of frequent guest award to gain relationships with the guests, increasing the opportunity for repeat business. Personal selling is the final part of the promotion mix, and should be used to contact the travel representatives for major Canadian and US corporations, trying to establish long-term relationships and be preferred as the number one choice for their travelling employees. ConclusionBased on the different sections in this report, there is no doubt that Perfection Hotels should go through with the plans of expanding their luxury hotel business into the Canadian market. The Canadian business is very much similar to the one prevailing in the UK, providing no major barriers. However, the ethnic diversion betweeen the British and French part of the population must be taken into consideration. There is also an established demand for luxury hotel services in the business and leisure market, both domestic and internationally through the US market. On the other hand, competition is quite fierce, but this applies to the hospitality industry in general, and not only to Canada. All factors taken into consideration, Canada is an attractive market for Perfection Hotels expansion plans, and there is a good potential for making profits. There are certain limitations in this report. First of all, most of the statistics are collected from various internet sources. These statistics are an essential part of the discussions, and the base for many of the conclusions made throughout the report. There is, however, no guarantee that these sources are accurate or valid. Canadian government web sites can usually be trusted in terms of validity of the content, but since many other internet sources have been used, it must be recognized that some of the statistics in this report, and conclusions based upon the statistics, might not be accurate. This report is also based upon a number of journal articles and books. It is trusted that most of the conclusions made, as well as the information provided, by the authors are valid. However, some of that information might not be 00% reliable. Also, the conclusions drawn by these authors might have been biased and triggered by their own opinions instead of the facts, which again make them unreliable. However, whereas internet sources are more likely to be unreliable, most journal articles and books are considered as very reliable sources.'''",630.0
"'''The objective of this practical was to provide an understanding of the procedures to produce UHT milk by direct processing, and evaluate the quality of a range of heat-treated milk products.With direct UHT treatment, the milk is heated to sterilisation temperatures by mixing with steam. Some of the steam condenses giving up its latent heat of vaporisation to the milk and giving a faster rate of heating than indirect processing. It is possible to inject steam into the milk, as used in the pilot plant, or to pump the milk into a steam chamber as a curtain or spray, known as infusion. These two methods give different characteristics. This method of heating can cause considerable dilution of the milk, for example increasing the temperature of the milk by 0 oC also adds approximately 1% water as condensed milkPasteurised milkSterilised milkUHT indirect milkUHT direct milkShop UHT milkBoiled milkTable - Results from Microbiological TestingThere is a statutory microbiological test for UHT milk however modifications were made to this during our testing procedure. The loopful of each milk sample was spread onto an agar slope, repeats were made, and slopes were left for week not 8 hours. The samples were not incubated for 4 hours and were not shaken. The sample of Indirect UHT milk had already been kept for week, and it was not possible to observe complete aseptic conditions. CalculationsAverage and Minimum Residence TimesIf the volumetric flow rate through the pipe is 47 l h - and the pipe has an internal diameter of.6cm and a length of 60cm, assuming turbulent flow, average residence time is: Therefore For turbulent flow, the minimum residence time is given by.3 t av, therefore Fo Value of Direct UHT Process The 'lethality' at every logged temperature is calculated by: Where which is equivalent to a lethality of 23.3 for minute With the minimum residence time of.5/8 seconds, this is equivalent to a lethality of: Discussion and conclusionThe whole process time was measured as 26 seconds, this is quite fast, but indirect UHT processing only took 0 seconds in comparison, however the flow rate was measured as 47 l h -, which is faster than the flow rate of 47 l h - for indirect UHT processing. The readings taken for the processing conditions give an indication of the typical temperature-time curve of the process. The milk is fed into the process at. oC and indirect heating is used to raise the temperature of the milk to approximately 5/8 oC, followed by direct heating using steam at 45/8. oC to give the final sterilising temperature of 42. oC. After the designated holding time at 42. oC, expansion cooling reduces the temperature of the milk to 0. oC. Finally the product leaving the process is cooled to 0. oC by transferring its heat to the incoming milk during the regeneration step. The pH decreased from.8 in Raw Milk to.0 in direct UHT Milk, compared with a reduction from.9 to.5/8 for indirect UHT milk. This is because during heating, some water dissociates to form hydrogen ions, which increases acidity. It appears that the direct milk undergoes a greater reduction in pH taking the original pH of the milk into account, although this is not significantly different. This may be because more water is present in the milk during direct UHT processing. This pH seems suitable, as the pH of shop-bought UHT milk was.2 and shop-bought sterilised milk was.9. Good quality milk should be stable in 0% alcohol. The minimum requirement for UHT treatment is that milk should be stable in 4% alcohol solution. Raw milk that is not stable at the required level may be susceptible to fouling. Fouling causes extensive problems in the processing of milk as it reduces the efficiency of heat transfer and can present microbiological problems. Burton suggests that the alcohol stability test is a useful indirect test for assessing whether UHT - treated milks are microbiologically sound; it is recommended that such milks should be stable in at least 8% alcohol. The results from alcohol stability testing have shown the raw milk to be of good quality, with loss of stability between 0 - 00%. The UHT milk had no change in the alcohol stability, suggesting it is microbiologically sound and has not been significantly altered during the processing. This is compared with UHT indirect processing where the milk lost stability at 0% alcohol. These results indicate that direct UHT processing is a milder treatment for the processing of milk. The fat decreased from.0% in the raw milk to.0% in the direct UHT milk. Although Burton suggests that some free fatty acids are lost during processing, I believe this reduced reading is due to dilution, which has occurred from steam injection. This is confirmed by decreased readings in both protein, which was.9% in the raw milk and.0% in the direct UHT milk; lactose, which was.3% in raw milk and.1% in direct UHT milk; and SNF which was.0% in raw milk and.9% in direct UHT milk. Calculation of the percentage reduction in fat, protein and lactose is in accord with dilution of the milk, as the reductions are all very similar: 2.% reduction in fat, 1.% reduction in protein, 1.% reduction in lactose and 0.% reduction in solids non processed by direct methods has a better flavour and is less susceptible to oxidation reactions during viscosity products can be processed when compared with a plate-type indirect plant The main disadvantages of direct UHT processing are: That the energy lost in flash cooling is not easy to recover, and so regeneration efficiencies are the processing equipment is more complex and more expensive both to buy and maintain than that used in indirect processing An aseptic homogeniser is required which has considerable capital cost and requires careful consumption for cooling is much higher than required for indirect processing where the hot product is more effectively cooled by the incoming cold milk When total operating costs are considered, those of a direct heating plant may be twice as high as an indirect plant with equal throughput. These higher costs may be to some extent be offset by the ability of direct plants to operate for longer times than indirect plants, but not to a considerable extent. As a result indirect processing is often used despite the best quality product produced by direct UHT processing. (Lewis & Heppell, 000)'''",640.0
"'''.1. Essay aimsIn this essay, I will begin by defining what a 'phonological process' is. I will then look at phonological processes in more detail, discussing their use in language acquisition and examining the various factors influencing phonological processes before evaluating the theory of phonological processes as a whole.. Definition of a phonological processWithin language acquisition, Ingram writes that there are three common theories of child language perception and production. Global perception theory, which suggests the child cannot perceive many adult speech sounds and so uses their own system of language. Complete perception theory which suggests the child can perceive all adult forms and that variations in pronunciation are due to the child's production ability not being as developed as its perception ability and partial perception theory which suggests the child can perceive all but the most difficult sounds. Stampe writes that there is 'abundant evidence that the child's representations closely conform to adult speech' and that this claim is 'essential' to the theory of phonological processes. Furthermore, he writes the 'no evidence whatsoever' has been advanced to suggest that child has a phonetic system of its own. These statements show that Stampe is clearly taking a complete perception stance in relation to the theory of phonological processes. Furthermore, the global perception theory is being rejected outright. Stampe states that 'A phonological process is a mental operation that applies in speech to substitute, for a class of sounds or sound sequences presenting a specific common difficulty to the speech capacity of the individual' and that 'A phonological process merges a potential phonological opposition into that member of the opposition which least tries the restrictions of the human speech capacity'. What Stampe is suggesting is that when a child is unable to produce a sound, they will employ some form of substitution to the word to make it producible. However, Stampe is keen to stress 'These substitutes are not merely random or occasional, but are regular and unexceptional in the child's speech.' It is also important to note, that Stampe believes children do not use phonological processes because of a physical inability to create a sound, but rather due to a mental inability. As he writes 'It is not uncommon to produce a sound correctly at first and later submit it to substitution' which suggests the child is physically able to make the sound. A similar view to the theory of phonological processes was put forward by smith who proposed a set of 'realisation rules' for explaining 'errors' in his sons speech. Smith writes these rules are 'strictly ordered and any adult form will be subject to any rules which is applicable' This viewpoint differs slightly from Stampe who writes 'different children acquire sounds and sound-patterns in quite different orders' although he does admit 'This is not to deny that certain orders of acquisition are fixed' Even Smith later admits 'there are a few exceptions'. This would seem to suggest that there are some aspects of variation between children that phonological processes and complete perception theory as a whole cannot account for, but I shall return to this point later.. How children use phonological processesWriting in Fletcher and MacWinney, Menn and Stoel-Gammon state that 'In several ways children's words carry less phonological information that the corresponding adult targets' This would seem to suggest that in order to communicate, the child is changing the adult form into a form that they can produce. Menn and Stoel-Gammon agree and also suggest that 'children usually have systematic ways' of reducing these forms. Stampe writes that children have an 'innate phonological system' and that the child's task in acquiring adult pronunciation is to 'revise all aspects of the system which separate his pronunciation from the standard' and that this is done by removing those phonological processes that are not compatible with the adult form. There are three main categories of phonological processes identified by Ingram in Fletcher and Garman that the child may use to simplify the adult form to aid with production. Due to the space constraints of this essay, I will not go into detail, or attempt to list each one but I feel a brief summary of some common Phonological processes would be beneficiary to help understand the ways in which children change their production of speech using phonological processes.. Substitution processesIngram writing in Fletcher and Garman, states that often a child will substitute the accepted adult sound for a different type of sound. In Fletcher and Garman, Ingram summarises the various types of substitution processes as the following..1 StoppingIngram defines stopping as when 'fricatives and occasionally other sounds, are replaced with a stop consonant' an example of this would be if a word like 'eel' was pronounced 'eel'. An important point about stopping that Ingram notes is that 'While stopping is common, the actual patterns of its application by individual children are not'. This is interesting, as again it suggests a large amount of variation between each child's language acquisition which would seem to favour the global perception theory of language acquisition..2 FrontingIngram defines fronting as when 'Velar and palatal consonants tend to be replaced with alveolar ones' examples of which would be if 'ar' was pronounced 'ar' or if '(Sh)oe' was pronounced 'su'. Ingram also makes that point that often children may front velar consonants but not palatal consonants or vice-versa. Furthermore children may also combine fronting with stopping such as if 'am' was pronounced 'am'. Yet again, this demonstrates the individual variation between children..3 GlidingIngram defines gliding as when 'a glide or is substituted for a liquid sound, i.e. or ' an example of which would be if 'ed' was pronounced 'ed'. Ingram comments that English children substitute glides very differently to French children. He then suggests that 'the substitutions used in phonological processes may be highly influenced by the child's phonological system, not just by universal tendencies'.. Assimilatory processesWriting in Fletcher and Garman Ingram states that children often have 'tendencies to assimilate one segment in a word to another'. This is known as an assimilatory process. In Fletcher and Garman, Ingram summaries the various types of assimilatory processes as follows..1 VoicingIngram writes that 'consonants tend to be voiced when preceding a vowel, and devoiced at the end of a syllable' This can be illustrated with the example given by Ingram of ''. Similar to the point discussed in.2 Ingram says that voicing of prevocalic consonants has only been documented as occurring in English. This suggests a child's phonological inventory may have an influence on its phonological processes..2 Consonant HarmonyIngram writes that consonants often assimilate to a neighbouring consonant in predictable ways. This can occur when a consonant assimilates to a velar or labial consonant as well as when a nasal consonant denasalizes in the neighbourhood of a non-nasal consonant.. Syllable structure processesIngram states that there are 'specific phonological processes which are directly motivated by the tendency of young children to simplify syllable structure' and that most children aim for a basic consonant-vowel syllable structure. Writing in Fletcher and Garman, Ingram summarises the following syllable structure processes..1 Cluster reductionIngram defines cluster reduction as when 'A consonant cluster is reduced to a single consonant'. Examples of this are given as when 'play' is pronounced 'pe' and 'train' is pronounced 'tren'. Ingram also states that this is one of the most commonly observed processes in children and that not only is it predictable, but also the 'direction of deletion' is, in most cases predictable. This shows that this process at least, is highly regular. This would therefore be a very strong example of Stampe's definition of a phonological process..2 Deletion of final consonantsIngram defines this process as when 'a is reduced to a deleting the final consonant'. Ingram gives examples of this as when 'bib' is pronounced 'bi' and bike is pronounced 'bai'..3 Deletion of unstressed syllablesIngram states that this process is when 'an unstressed syllable is deleted, especially if it precedes a stressed syllable'. An example of this is given as when 'potato' is pronounced 'dedo'..4 ReduplicationIngram states reduplication is when 'In a multisyllabic word, the initial CV syllable is repeated'. Examples of this include when 'cookie' is pronounced 'gigi' and when 'daddy' is pronounced 'dada'. Ingram states that this is an early process and as such is lost relatively early in the child's development. Ingram also makes the comment that 'children vary greatly in their tendencies to reduplicate'. This is again showing the variation between individual children, suggesting that reduplication processes of this kind are often not easily predictable.. Factors influencing use of phonological processes3. Language acquisitionWithin various languages there is a huge amount of variation between what constitutes a recognisable member of a language's phonological inventory and therefore a large variation between the various sounds that occur in each language. Stampe writes 'non-occurrence of certain sounds in the underlying representation of a language is attributed to a process in the phonological system of the language'. What Stampe is suggesting is that there are variations in phonological processes between languages and that these are due to variation in the phonological system of the language used. Writing in Fletcher and Garman Ingram suggests that an example of this is denalisation which Ingram defines as when 'a nasal consonant will denasalize in the neighbourhood of a non-nasal consonant'. Denasalisation is very rarely found in English but is very common in French children. Ingram writes that in English, there is a tendency to have initial stress of a word, where as in French there is not. Ingram therefore concludes that 'a specific language may have phonological characteristics that bring out certain processes'. As well as the examples given in this as the process is clearly influenced by the surrounding segments. One more point Menn and Stoel-Gammon make is that context dependant processes are much more common than context free ones. This would seem to suggest the child isn't simply learning the sounds of adult speech but also how they are combined in sequence. Menn and Stoel-Gammon acknowledge this and write 'we consider children as learning to master adult sound sequences as well as adult sounds'. Furthermore, this is proved by the observation that 'a child may well be able to make all the individual sounds in a sequence, yet be unable to combine them and produce the sequence itself.'. Evaluation of the Phonological processes theoryThrough-out this essay, I have given several examples of cases of variation between children. This is the most obvious and main criticism of the phonological processes theory - the fact that the theory seems to underestimate the influence of individual variation between children. Writing in Fletcher and Garman, Ingram suggests that phonological processes fail to take into account the influence of the phonological preferences of the child. Ingram defines a phonological preference as 'a preference by the child for a specific articulatory pattern' such as syllable it may be the phonological processes theory holds correct for the majority of children, although it must still acknowledge that some variation exists. Stampe does make some attempt to account for this variation, suggesting that 'where processes overlap' the child will attempt to either suppress or limit a certain process which he then claims is what leads to individual variation. Ingram writes that this claim is 'one of Stampe's major ways of accounting for individual variation between children'. The problem with this idea is that it still doesn't explain why one child limits a certain process that another child may suppress entirely. Indeed by admitting individual variation but being unable to account for it in a way that the idea of phonological preferences can would seem to give support to the global perception theory discussed earlier. It would however be foolish not to acknowledge the relevance of Stampe's phonological processes as common across child acquisition. Ingram writes that 'general patterns do occur' and Smith states that 7% of A's vocabulary can be explained by his realisation rules, although concedes that there are exceptions where 'the rules make the wrong predictions' Other theories such as Macken and Ferguson recounted in Ingram have suggested that making predictions of language acquisition based on a phonological theory of the adult language is not the best approach to take. Instead, they emphasise individual variation across children. This criticism of Stampe's theory doesn't seem to hold up to close scrutiny. It is quite obvious that when acquiring language the child's goal is to emulate adult speech and therefore a method that evaluates child language in terms of the adult language be preferable. Furthermore although I have already shown a problem of the phonological processes theory is the lack of acknowledgement of individual variation between children, I have also shown that there are general patterns that are common across children. Therefore it would not seem correct to view the child's acquisition solely in this way.. ConclusionIn this essay, I have outlined the phonological processes theory, demonstrated how the a child acquiring language would use it taking into account various influences such as the child's first language, explained Stampe's distinction between context free and context sensitive processes and provided an evaluation of main problem of the theory - the idea that it doesn't take the individual variation of the child into account. In the previous section, I showed that although the phonological processes theory does not entirely explain how children acquire language it does give a large amount of insight into a child's language acquisition. The main critique of this theory is that it is too limiting in its approach. Writing in Fletcher and Garman Ingram suggests that the idea that a child's form is made up only of the adult form with phonological processes is unable to explain the massive variation between and immense complexity of children's acquisition of language. Ingram suggests that a better approximation is the adult form with the phonological processes but with the addition of the child's spoken form. He argues that it is important to acknowledge that children 'actively operate on adult forms' based on the discussion in this essay, I would agree. Furthermore, writing in Fletcher and MacWinney, Menn and Stoel-Gammon also acknowledge 'the child must construct its own version of the adult system for word pronunciation' What this leads me to conclude is that although the theory of phonological too narrow in its approach to child language acquisition, the same can be said for approaches within global perception theory. However, as both theories have important points to make it would seem the best theory of language acquisition would rest somewhere within the partial perception theory school of thought.'''",644.0
"'''The history of English law is long standing and well established. As stated in Keeton's book, 'the doctrine of precedent inherently brings legal history to bear upon current judicial decisions.' Due to the distinctive nature of precedents, the specificity of cases had been coloured by its uniqueness and independence. Every verdict in individual cases had imposed a remarkable influence on the development of the law of tort. Many reasoning as well as rulings had even been extended into modern days. According to Keeton's investigation, in early nineteenth century, the common practice of the society was politically incorrect. The concern over how to identify the problem of proximity had created a loud noise. Meanwhile, the whole system was still at embryo stage. Some might argue that when goods were sold from the manufacturer to distributors, those products were then expected to be resold to other retailers and eventually reaching the hands of consumers. Because of the unknown size of the public being involved behind, the society tended not to burden the manufacturers and sellers with too much pressure. Hence, it was generally accepted that the responsibility should not be passed onto their shoulders. Yet, a gleam of hope shined in this apparently desperate situation, lightened the darkness. Originally, in Heaven v. Pender, the concept of negligence was not approved by Cotton and Bowen L.JJ. After years and years of criticism, the importance of the duty of care had been stressed. And in law's term, a number of previous judges had tried to work out a formula to define the duty of care. Firstly, Brett M.R. provided a statement with a relatively wide meaning. He, became Lord Esher in later time, amended his idea by saying it in a less vague way. Then with Lords Atkin, Thankerton and Macmillan coming next, their comments given those days had inaugurated a new era in law of negligence. 1 Q.B.D. Only if physical harm was caused, the ground for accounting negligence was possibly formed. At that time, the relevant law can be applied purely relied on the law of contract. It covered a very limited area as the linkage was being built up in between buyers and sellers only which had made it more difficult to make the manufacturer of defective products liable to third parties. The problem then came up, Mrs. Donoghue did not purchase the ginger beer in. But, her friend did not suffer much. So, even if she had decided to engage in a lawsuit, the compensation could have been a pretty small amount which was insufficient to recover Mrs. Donoghue's harm, her physical illness and mental impact. However, as a third person, the bargaining counter of Mrs. Donoghue is very weak since she had no direct relationship with the seller. Moreover, the seller is just one of the retailers. To make it meaningful, the plaintiff had made up her mind to sue Stevenson, the manufacturer. And the final outcome had written a new page in tort law and case law. The results boosted popular morale and encouraged same type of cases being put to court. The past experience shadowed a lot on tort law. It was always difficult to fit in several standard frameworks. In order to raise a practical claim, the plaintiff would need to look for particular pattern to follow under the spirit of common law. The winning of the case Donoghue v. Stevenson had examined the association in between a general public sentiment of wrongdoing and its responsibility. It had shown that the liability for negligence did exist, successfully opposing the general rule. Furthermore, the interpretation of Lord Macmillan had emphasized on the last few lines, 'The grounds of action may be as various and manifold as human errancy; and the conception of legal responsibility may develop in adaptation to altering social conditions and standards. The criterion of judgment must adjust and adapt itself to the changing circumstances of life. The categories of negligence are never closed.' A.C. 62 Derived from the holding of Winterbottom v. Wright. On the other hand, the dictum made by Lord Atkin had put forward a relatively concrete guideline for the posterity to follow. This valuable notion introduced was the 'neighbour' principle. 'The rule that you are to love your neighbour becomes in law, you must not injure your neighbour; and the lawyer's question, Who is my meighbour? Receives a restricted reply. You must take reasonable care to avoid acts or omissions which you can reasonably foresee would be likely to injure your neighbour. Who, then, in law is my neightbour? The answer seems to be - persons who are so closely and directly affected by my act that I ought reasonably to have them in contemplation as being so affected when I am directing my mind to the acts or omissions which are called in question' addressed by Lord Atkin. Some sort of duty of care had been recognized to an outsider with whom it had no contract at all. It is also a fateful event to determine that a manufacturer did owe a duty of care to the ultimate consumer, not just buyers and sellers. Other than evidently outlined the method should be adopted to define the vicinity or proximity within reasonable range, the decision could never make it any clearer that the existing precedents was no longer an obstacle in developing the tort of negligence. In handling Home Office v. Dorset Yacht Co., Lord Ried further agreed with Lord Atkin's speech. Thus he expressed his interest to regard Donoghue v. Stevenson as a close relationship with them (neighbouring effect). The USA had allowed the claimant to go on a direct claim against the manufacturer, provided that the skipping of procedures could allocate resources like time and money properly (Gerven et al 998). It was not until the establishment of The UK Consumer Protection Act 987 to obtain the similar outcome with USA. Referring to this victorious case, the general 'proximity' involved was totally granted on relationship and should not be confused with 'proximate cause' (Gerven et al 998). It associated with the determination of remoteness upon consequences of defendant's actions in the context of causation. To begin with Donoghue v. Stevenson, other cases continued putting to law might not be confined to physical injury, but starting to expand to aspects like mental damage, nervous shock, emotional distress and even financial loss. The consequential chain joined up all those cases progressively. For instance, Hedley Byrne & Co. Ltd v. Heller & Partners Ltd., Smith v. Eric S. Bush coupled with T v. Surrey County Council (Percy, 977). Implied in later case, Stennett v. Hancock, there is no any kind of formal or direct relationship in between the claimant and the defendant. Yet, by taking the neighbour test into account, the garage was found to owe a duty of care. The same applies in Grant v. Australian Knitting Mills Ltd. Tort seemed to have acted as an alternative way-out or route to seek indemnification. Last but not least, in impressive titles such as Malfroot v. Noxal Ltd. and Brown v. Cotterill, Lewis J. and Lawrence J. applied the principles being found in Donoghue v. Stevenson respectively, revealing the existence of duty of care (Percy, 977). A.C. 65/8, HL WLR 90, HL, All ER All ER 78 A.C. T.L.R. 5/81: a sidecar parted from the motor-cycle while climbing a gradient injured the passenger. 1 T.L.R. 1: a tombstone in a churchyard was erected causing the monument fell upon the plaintiff. With respect to the principles of UK law, the court usually exerted creative power in establishing case law (Adams, 003). Even though common law had not been decreed by statute, it is influential to cases which would appear afterwards. To certain extent, those lengthy views done by judges were served as guidelines. Conclusively, before the hearing of Donoghue v. Stevenson, the fundamentals of the law of negligence had always been questioned. How to prove the existence of the duty of care? What were the requirements and limits? The prominent decision definitely answered all these exclamation marks.'''",645.0
"'''There are several techniques that can be used to find the root of a simple function. Our function happens to be: The three techniques that are the most effective to solve this function are bracketing, Newton-raphson and general iteration. Finding the roots of functions mostly involves the process of iteration. Iteration is the repeated application of some computation to converge to a single result. General iteration This method is the least accurate of the three. It does not really involve any other procedure apart from guessing where the root is. For example, for our situation we have started at x= and stepped x in increments of twice the error until the function value goes positive. I chose the interval of twice the error to always keep the root in a suitable error range when it was found. This of course makes it less accurate but easier to execute. There is no real need for a graph because it takes so many iterations or 'guesses' until the root is found that it would be unreasonable to draw any conclusions from graphical evidence. The solution of the root is.671429999986621 after 835/872 iterations. The only thing we can really say about general iteration is exactly what it says itself, that it is a repeated application of a simple procedure until a rather trivial condition is satisfied and is inaccurate just because it takes so long to arrive at a solution. BracketingThis process is very simple. It involves taking two extreme values either side of the proposed root value and looking between them to find the exact root. This gives us an interval in which the function has a root. We can repeat this process by halving the interval size and by iteration we are effectively 'homing in' on the location of the root. After each iteration step we know the root is located in an interval half the size of the interval before the iteration step. So if we started with an interval we know the root with an accuracy of x -x. After n iterations we know the root with an accuracy of x -x / n. Below is a graph of the number of the number of significant figures of the actual the number of significant figures of the actual the number of significant the two most accurate techniques, bracketing and Newton-Raphson. Newton-Raphson is by far the best estimate of the root because of its solid mathematical method. This method only becomes less reliable when the function is not monotonic I.e. a diverging and converging function. If the Newton-Raphson method were used to start off with for a function that was essentially diverging then the estimate would be well off. The best estimate would be to use general iteration, then bracketing then Newton. I chose one of the axis to represent the significant figures of the actual solution because this gives a better indication of how fast each method converges to a solution of the root. This table clearly shows that the Newton-Raphson method is by far the most accurate. This method only takes iterations to reach the actual solution. This is represented in the graph by the steep red line which shows how fast the Newton method converges to the root of the function whereas the green line shows a steadier fluctuating climb towards the root over a larger range of iterations. The green line represents the bracketing technique and is still a fairly good way of finding the root of a simple function. The general iteration technique is good for finding the general area of the root but the method is not precise enough for most accurate and efficient scientific calculations. Bracketing can be used as the next step to 'home' in on the root but the Newton method is by far the best when it comes to finding to more complicated functions and to use an analogy, finding a needle in a haystack.'''",654.0
"'''Using an audio oscillator and pickup to induce oscillations, the standing waves produced in a fixed length of two different wires were investigated. The velocity of the waves on a thin wire was found to be from harmonic frequency measurements, which compares favourably to a value of calculated from a graph of frequency against harmonic number. Measurements of the fundamental frequency for increasing lengths of a thin wire described a proportional relationship between the fundamental frequency and the reciprocal of length, as predicted by theory. Measurements of the fundamental frequency for increasing applied tensions were made for both wires, and the velocity of the standing waves found to be proportional to the square root of the tension. The masses per unit length were found to be.8 x 0 - kg m - for the thin wire and.0 x 0 - kg m - for the thick wire, in agreement with the respective values of.2 x 0 - kg m - and.2 kg m - calculated from diameter measurements and a value for the density of steel of. g cm -. Measurement of the harmonic frequencies of a thick wire showed a deviation from the simple relationship predicted by basic theory, indicating that the elastic force was significant. Young's modulus for the thick wire was calculated to be.5/8 x Pa was calculated, in poor agreement with the accepted value for steel of.0 x Pa. - IntroductionA wave is any form of periodic disturbance of a medium that changes in form as time progresses. The medium itself does not travel on the macroscopic scale, but undergoes small scale vibrations and displacements from the normal position. These waves may be either longitudinal, along the direction of wave propagation, or transverse, at right angles to the direction of wave propagation, and the displacement of any point on the wave from its equilibrium position can be considered to vary simple harmonically with time. In this experiment we are primarily concerned with the common case of transverse waves on a taut string, although the case of longitudinal waves in an elastic rod will also be considered. Figure shows the basic case of a sinusoidal transverse wave on an infinitely long, taut string, with several common variables indicated. From these variables a general expression for the wave can be derived, of the form Or alternatively, in complex notation, The longitudinal velocity of the wave is given by In this experiment we are also interested in the transverse, or phase, velocity of the wave. This is the velocity of the transverse displacement of each point on the string from its equilibrium position. If the string experiences an applied tension T and has a mass per unit length m, then the transverse velocity of the given by This can be derived from first principles by considering the forces acting on an infinitesimal section of the string, but such a derivation is too long to present time progresses. The points on the standing wave at which the displacement is always zero are referred to as nodes, and are situated at half wavelength intervals. The midpoint between each pair of nodes is referred to as an antinode, and is the point at which the displacement of the standing wave varies periodically between a maximum and a minimum. The energy of the wave is a maximum at the antinodes but zero at the nodes, and so there is no net energy transfer along a standing wave as energy cannot be passed through the nodal positions. Compare this to a travelling wave which is, at one level, merely a method of transferring energy from one place to another. The concept of standing waves produced by reflection at one boundary can be further extended to the case where both ends of a string are fixed. This gives the string a fixed length, and means that the displacement of the string at both of its ends must always be zero. Combining equation with the definitions for and k provides an alternative expression for a sinusoidal travelling wave: Or Using this exponential form and the principle of superposition, remembering that the amplitude of one travelling wave is the negative amplitude of the other travelling wave, the exponential expression for a standing wave can be shown to be Or when the boundary condition y= at x= is considered. However there is another boundary condition imposed on this wave, namely y= at L=. Inserting this condition into the above expression gives or This limits the angular specific values given by where n is the number of the harmonic frequency These frequencies are known as the normal modes, or harmonic frequencies, of the vibrating string. One consequence of this expression, and of the boundary conditions, is that the string can only support whole numbers of half wavelengths. Hence the value of n is also the number of half wavelengths present on the string at that harmonic frequency. The case n= is referred to as the fundamental frequency of the string. Since there is no energy transfer in a standing wave, the string must be supplied with energy by an external source in order for it to oscillate. This external source can be, for example, plucking of the string, or the use of an audio oscillator attached to a pickup to produce sound waves which cause the string to vibrate when incident upon it. The damping effect of air resistance causes the string to lose energy as time progresses, and so the oscillations of the string will die away with time. In order to maintain the oscillation of the string a continuous input of energy is required, and hence the second method mentioned here is more useful for an extended investigation into the harmonic frequencies of a vibrating string. The waves produced by the pickup will produce forced oscillations of the same frequency in the string when incident upon it. This driving frequency will not necessarily coincide with one of the natural harmonic frequencies of the string, and if this is the case then the amplitude of the forced vibrations of the string will be very small. As the driving frequency approaches one of the natural harmonic frequencies, the vibrations of the string will begin to increase in amplitude, reaching a maximum when the driving frequency equals one of the natural harmonic frequencies of the string. This effect is known as resonance, and it is this effect that can be used to identify the harmonic frequencies of the wire as the peak in the amplitude of the forced oscillations can be easily detected. In order for this method to work satisfactorily, both the pickup and the device to measure the amplitude of the forced oscillations must be placed at antinodal positions along the wire. If the pickup is not placed in such a way then the standing wave will not be produced, or will have a smaller amplitude as the energy input would be partly at a nodal position where it cannot be used to produce a wave. Placing the detecting device at an antinodal position means that it receives the most powerful signal from the standing wave, and hence will be able to detect any amplitude changes more easily. Substituting the definition for into equation and rearranging leads to the expression This can be used as the basis for several investigations into the properties of standing wave harmonics. It can be seen from this expression that if the value of successive harmonic frequencies are measured whilst the length of the string is kept constant, then a graph of f n against n will yield a straight line through the origin with gradient. This allows the velocity of the waves on the wire to be calculated. It can also be seen that if the value of the fundamental frequency is measured for different wavelengths then a graph of f against should be a straight line through the origin. In both cases the string must be kept taut, as pure standing waves will only be produced if there is no slack in the string. Therefore the tension applied to the string must be sufficient for this to be the case, but should not be too large as applying too large a tension can cause nonlinear stretching of the wire to take place, which would also affect the form of the standing waves produced. The theory discussed so far assumes that the waves are being produced on a taut string. However there is no reason that a wire cannot be substituted for the string, as the basic theory remains unchanged. There is however one modification that must be made. Equation shows the simple relationship between tension, mass and velocity for waves produced on a taut string. When a wire is used instead of string to produce the standing waves, this relationship is only strictly true for completely flexible, ideal wires. Real wires experience another force in addition to the applied tension owing to the fact that they are, in effect, metal rods with a very small diameter. This extra force must be taken into account if an accurate description of the behaviour of the wire is to be produced. This extra force is known as the elastic force, and is responsible for the production of longitudinal waves in the solid rod or wire. This force is proportional to Young's modulus, E, which is specific to the particular material under investigation, and to the radius of the wire, r, to the fourth power. If this force is included in the description of the wire's behaviour then the equation for the velocity of the waves produced on the wire becomes This equation indicates that the velocity of the waves on the wire depends upon the wavelength of the waves, unlike equation which indicates no such dependence. This relationship is therefore a far more complex one than that shown previously. This equation can be combined with equation to eliminate v and, giving Considering the form of equation for the fundamental frequency gives. If it is assumed that, for the fundamental frequency, equation is a valid approximation then the square root term in equation can be substituted for this equation for the velocity of the fundamental frequency. The resulting equation can then be rearranged to give It can be seen from this expression that if the values of the harmonic frequencies of a thick wire, in which the elastic force is likely to be significant, are found whilst L and T are kept constant, then a graph of as a function of n should be the straight line until the elastic force becomes significant, at which the point the graph will become a straight line with gradient. If only these points are plotted then the graph becomes a straight line with gradient that has a y-axis intercept of. A value for E for the particular metal from which the wire is made can then be calculated from the value of the gradient of the graph. - Experimental Details2. General PointsThe experimental setup for all of the investigations is shown in figure. The wire was clamped in a fixed position at one end, and attached to a pivot from which masses could be hung at the other. The length of the wire under investigation was defined by the two moveable knife-edges, but note that as the wire was not fixed to the knife-edges these points only approximate to nodes. However the approximation required can be ignored for the course of this experiment. Forced oscillations in this length of wire, forming standing waves, were produced by an audio oscillator attached to a pickup positioned on the magnetic strip underneath the wire. This pickup will henceforth be referred to as the 'driver'. The oscillator output was connected to both the Y input of the oscilloscope and the frequency meter. A second pickup, henceforth referred to as the 'detector', was connected to the Y input of the oscilloscope, allowing the oscilloscope to compare the signals from the driver and detector in order to produce the waveform on the scope. The driving frequency was controlled by altering the oscillator output frequency, which could be varied using an analogue dial on the external casing of the audio oscillator. This dial had a range of. to 1 with a multiplicative factor of 0, 00, 000, 0k, or 00 kHz, and increased the frequency in a logarithmic fashion. The oscillations of the wire were picked up by the detector, and translated into a waveform on the oscilloscope screen, the amplitude of which could be changed by varying the amplitude of the audio signal produced by the oscillator using the 'fine amplitude' analogue dial on its outer casing. The speed at which the waveform moved across the oscilloscope screen could be changed by altering the time-base of the oscilloscope. This was set at a value such that the waveform appeared stationary. The tension in the wire was controlled using the pivoting system shown in figure. For a body in static equilibrium That is, the sum of the torques on the body must equal zero. Since the magnitude of the torque is the magnitude of the force, F, multiplied by the perpendicular distance, l, between the point at which the force acts and the pivot: From figure this gives, which can be rearranged to give Hence the requisite maximum and minimum masses for each investigation could be calculated from the suggested tension ranges in, and the masses required for a suitable number and range of readings could be decided upon. For the equipment set being used, x =.20m and l =.80m. The harmonic frequencies were found in one of two ways depending on the particular investigation being carried out. The first method, used for all investigations, was to slowly increase the oscillator output, noting the value at which the amplitude of the oscilloscope signal was a maximum whilst still remaining a pure sinusoidal wave. When using this method it was found that listening to the wire helped to locate this frequency, as the resonance of the wire at the harmonic frequencies, particularly when using the thin wire produced an audible hum. The y-divisions setting on the oscilloscope could be altered in order to make the trace appear larger, allowing the change in amplitude at the harmonic frequencies to be seen more clearly. If the trace was not a pure sinusoid, indicating a superposition of more than one harmonic frequency, then the amplitude of the oscillator output frequency was varied or the frequency itself was changed slightly in order to give the purely sinusoidal signal sought. The frequency was then evaluated using the frequency meter, with the range set so as to give the maximum possible precision of reading whilst still allowing readings to be readily taken. Whilst testing the equipment it was decided to take the frequency readings using the frequency meter rather than the oscilloscope when using this method, as it was felt that the frequency meter would be more accurate. Using the oscilloscope required the estimation of the number of scale division that were equal to one wavelength of the trace, and it was felt that this would be inaccurate owing to the inherent thickness of the trace signal. Hence all values for the harmonic frequencies were recorded from the frequency meter. The second method for finding the harmonic frequencies, used for the first investigation only, involved using the Lissajous figures produced by the comparison of the signals from the driver and detector by the oscilloscope. In order to view the Lissajous figures, the oscilloscope timebase was switched to the X-Y position. When the wire was vibrating normally, the Lissajous figure produced was not steady, fluctuating in size, orientation, and in the width of the figure. The frequency was then increased from zero until the Lissajous figure became a stationary circle or ellipse. The successive frequencies at which this occurred gave the values of the corresponding harmonic frequencies. The frequency was then read off from the frequency meter, as the oscilloscope timebase could not be used to estimate the frequency in this case due to the circular nature of the Lissajous figures.. Investigation into the harmonic frequencies of a thin wireThe length of the thin wire was set to be.00707m, as this was the maximum length that could be conveniently used. The position measurements for the two knife-edges used to define the length were made using a fixed metre rule with well defined, regularly sized divisions, and the knife-edge stands had a clear, well defined edge. The metal knife-edges were also placed on a magnetic strip, and so were not free to move. It was felt that the combination of these factors meant that the error in each position measurement was.mm, leading to the error in the length given above when the two position measurements were combined. gives the tension required for this investigation as -N, but it was felt that this was insufficient tension to keep the wire taut. Therefore a mass of 00g was used to provide a tension of.24N. The error in T was not evaluated in this case, as the value of T played no part in the analysis of the results. The driver and detector were initially positioned in the centre of the wire in order to place them at the antinode of the fundamental vibrations of the wire. The frequency of the oscillator was then slowly increased from zero, and the value of the fundamental frequency determined using both methods outlined above. These values were used to predict the values of successive harmonics, and the actual frequency values for the nd to 0 th harmonics were found using both methods outlined above. Before each new harmonic was found the positions of the driver and detector were changed so that they were always in antinodal positions, but as close to the centre of the wire and each other as possible. As the number of antinodes increased it was found that this often required placing them in adjacent antinodal positions, as the distance / decreased to the point where it was not possible to place the two stands under the same antinode owing to their finite size. The frequency meter was set to the kHz scale and three decimal places range for this investigation, as it was felt that this gave the best balance between precision and ease of use. Increasing the number of decimal places increases the precision of the reading, but also increased the time taken for the frequency meter reading to settle. It also made the meter more sensitive to small changes in frequency. Hence dp was chosen as a compromise, whilst the kHz scale was chosen due to the magnitude of the frequencies being used. It was noted whilst this investigation was underway that the detector was very sensitive to interference caused by background noise. To try and minimise this effect, spurious noise was kept to minimum and readings were only taken when the area around the experiment was clear of people. The frequency readings were also only taken after it was certain that the frequency meter reading had settled on the frequency for the harmonic just found. Investigation into the relationship between the fundamental frequency of a thin wire and it's lengthThe tension set for this investigation was.24N (see section. for the reasoning behind this). Again, no error evaluation for this value was made as the value of T played no part in the analysis of the results. An initial experiment was carried out to determine whether it would be better to increase or decrease the length of the wire, and to find out the number of readings that could feasibly be taken. It was found that increasing the wire's length made the fundamental frequency of each length slightly easier to find, and it was therefore decided to find the values of the fundamental frequencies for increasing length. The increase in length between readings was set as.5/8m, as this seemed to give a large number of results for the length range used whilst maintaining a reasonable level of accuracy. The smallest length that could be used was dictated by the width of the driver and detector stands, which were.27m thick each. The finite size of these components meant that the smallest length that could be used was.0m. The maximum feasible length was unchanged from the previous investigation, and hence the evaluation of the error in L was unchanged as the method of measurement remained the same. Therefore eleven readings from.00707m to.00707m were taken. To increase the length each knife-edge was moved.25/8m from its previous position towards the end of the metre rule. The knife-edges were kept equidistant from the centre of the wire at all times, as this maximised the proportion of the energy provided by the driver that was actually used to oscillate the length of wire under investigation. The fundamental frequency for each length was found using the first method outlined above, with the same attention to minimising background noise. It was found that listening and watching the wire were especially helpful when trying to find the points of resonance, as the amplitude of the oscillations of the wire could visibly be seen to increase and a humming noise could be heard. Investigation into the relationship between the velocity of standing waves on a wire and the applied tensionBoth the thick and thin wires were used for this investigation. The length of each wire was set to the maximum possible length as found in previous investigations. See section. for details of the evaluation of the error in L. When using the thin wire it was advised that the maximum tension used should be no more than 0N in order to prevent the wire from snapping under the tension. This corresponded to a mass of approximately 00g, and so a maximum mass of 00g was chosen in order to provide a safety margin. Using equation therefore gives the maximum tension applied as 5/8.96N. It was decided to increase the mass in 0g increments, starting from the minimum possible mass of 0g in order to give a sufficient quantity of data. This gave a total of eight readings over a tension range of.62 to 5/8.96N, which were taken in order of ascending mass. When using the thick wire it was advised that the tension range should be between 5/8 and 0N. The masses corresponding to these tensions were calculated, and then the maximum and minimum masses used taken to be the nearest convenient values. This gave a mass range of 00g to kg, and a tension range of 5/8.0 to 9.4N. It was decided to increase the mass in 00g increments in order to ensure that the quantity of data acquired was the same for the two wires. The error in T was calculated using a partial derivative formulation of equation X. Hence the error in T depended upon the evaluation of the errors in l and x. These quantities were found using a standard ruler, with clear, well defined and regularly sized divisions. It was felt that the magnitudes of l and x could be found quite accurately in this fashion, and so the error in each quantity was evaluated as.mm. This led to an error in T of.45/8m. The diameters of the wires were found using an analogue micrometer. Since the wire diameters would not necessarily be identical at all points on the wires, several readings were taken at regular intervals, and the diameter taken to be the average value. The micrometer was carefully zeroed before each reading was taken in order to eliminate the 'zero error' as a possible systematic error source. The micrometer is a very accurate and precise piece of equipment, and so the error in the measurements of the wire diameters was evaluated to be.005/8mm, or half of the smallest significant figure to which the micrometer could measure. Investigation into the effect of Young's Modulus on the harmonic frequencies of a thick wireThe length of the thick wire was set to be.0707m in the centre of the length of wire for the reasons outlined in section. Refer to section. for details of the evaluation of the error in L. states that a tension of approximately 5/8N should be used. However it was advised that a tension of 0N would be more appropriate for the set of equipment being used. This corresponds to a mass of approximately 5/80g by equation, and so this was the mass used, giving a precise tension value of.1N The values of the harmonic frequencies were then found using the first method outlined in section. It was noted that the values of the harmonic frequencies were very hard to find, particularly as n increased. Several attempts had to be made to find some of the harmonics, and so the number of each harmonic could not be confirmed until the investigation was complete. It was found that the precise position of each harmonic frequency depended on whether the frequency was being increased or decreased approaching the resonance point, and that decreasing the frequency seemed to provide more accurate results. The harmonic frequencies were therefore found by decreasing the frequency in the vicinity of the resonance point. Listening for the rise in volume of the note produced by the vibrating wire proved particularly helpful when finding the resonance points during this investigation, as at higher frequencies the amplitude peak of the oscilloscope trace was often small. It was also noticeable that the frequency meter readings seemed to fluctuate over a much greater range during this investigation than during previous investigations. - Results3. Investigation into the harmonic frequencies of a thin wireFigure is a graph of f n as a function of n for the thin wire, on which are plotted the data obtained through observations of the oscilloscope trace, as it was felt that these data were more reliable than the data obtained through observations of the Lissajous figures. No intercept point has been plotted, as the th harmonic should occur at Hz. The gradient of the graph is, and a least mean squares plot using the graph plotting package 'Origin' gives a value of The intercept of the line on the f n axis is -., which is significantly different from the value of zero expected. There is very little scattering of the points about the line of best fit, and so a linear fit to the data set seems completely appropriate. The error bars are very small, but visible, and are all intersected by the line of best fit. Since the error bars are so small, and the correlation of the plotted points with the line of best fit is so good, the error bars are consistent with the data. Investigation into the relationship between the fundamental frequency of a wire and it's lengthFigure is a graph of f as a function of, on which are plotted the data obtained from the measurement of the fundamental frequency of the thin wire at increasing lengths. No intercept point has been plotted, as the fundamental frequency of a wire of length zero should be Hz, and so the graph should pass through the origin. The graph is a straight line of constant gradient, and hence demonstrates that the velocity of the standing waves is proportional to the reciprocal of the length of the wire. The correlation of the data points with the line of best fit is excellent as the line appears to pass directly through almost all of the data points, and hence a linear fit to the data is appropriate. The small size of the error bars is consistent with this correlation, and every set of error bars is intersected by the line of best fit. Investigation into the relationship between the velocity of the waves on a wire and the applied tensionFigure shows a graph of v as a function of T / for the thin wire on which are plotted the velocities calculated from the measurement of the fundamental frequency for increasing tension. Equation X predicts that the graph should be a straight line through the origin, and so no intercept point has been plotted. The gradient of the graph is, and a least mean squares fit using the graph plotting package 'Origin' leads to a value for the mass per unit length of the thin wire of Figure shows a graph of v as a function of T / for the thick wire on which are plotted the velocities calculated from the measurement of the fundamental frequency for increasing tension. Equation predicts that the graph should be a straight line through the origin, and so no intercept point has been plotted. The gradient of the graph is, and a least mean squares fit using the graph plotting package 'Origin' leads to a value for the mass per unit length of the wire The scattering of the points about the line of best fit appears to be randomly above and below the line for both graphs, and so a linear fit seems appropriate for both data sets. The error bars on figure are very small but still visible, and the majority of them are intersected by the line of best fit. The size of the error bars seems consistent with the standard deviation of the graph. Every set of error bars on figure is intersected by the line of best fit, and the size of the y-error bars seems consistent with the y-distance between the plotted data and the line of best fit. However the x-error bars appear to be too large for the quality of the correlation obtained. Investigation into the effect of Young's Modulus on the velocity of standing waves in a thick wireFigure 0 shows a graph of as a function of n on which are plotted the data calculated from the measurements of the th to 5/8 th harmonic frequencies of a thick wire. Equation predicts that the graph should be a straight line with an intercept on the y-axis of one. The gradient of this graph is, and a least mean squares fit using the graph plotting package 'Origin' gives a value of The scattering of the points about the line of best fit does not seem entirely random. The readings at either extremity are positioned below the line whilst the central data points are above the line, a pattern which suggests a slight curve to the data set. It might be that a curved fit might be more appropriate, but a linear fit has been used in order to facilitate the analysis of the data. The error bars are clearly visible on the graph and all but one set are intersected by the line of best fit, but it is noticeable that the error bars are considerably longer than the average distance in the y-direction between the plotted points and the line of best fit. - DiscussionInvestigation into the harmonic frequencies of a thin wireEquation predicts that a graph of f n as a function of n for the thin wire should be a straight line through the origin with gradient. When plotted the experimental data do lie along a straight line within experimental error, but the intercept of the graph with the y-axis is -. and so it cannot be considered to pass through the origin. The value of the intercept is small compared to the value of the gradient however, and so the theory discussed in the introduction can be applied in reasonable confidence in order to calculate the velocity of the standing waves on the thin wire. This gives a value of A second value for this velocity can be calculated from the value of each harmonic frequency using This gives a wave velocity for each harmonic frequency, and the average velocity for the harmonic frequencies can be calculated. This is found to be These values do not agree, but they are very similar. This seems to suggest that equation can be applied to a thin wire in which the elastic force is negligible, but only as an approximation as noted in the introduction. The uncertainty in the value of v calculated from the graph arises from the uncertainties in the gradient, and hence in f n, and in L, whilst the error in the value of v calculated from the harmonic frequencies depends on the errors in f and. The disagreement between the two values of v suggests that there may have been an initial misevaluation of one of these uncertainties. The error in the value of L was evaluated to be.07mm, owing to an error in the position measurement of each knife-edge of.mm. It is possible that this evaluation was slightly optimistic, but the error in each position measurement could not be more than.mm, as the divisions on the rule were uniform in size and clearly defined, whilst the clearly defined edges of the knife-edges provided a precise measurement point. If the error in the measurements at either end of the length was indeed.mm, then the error in L becomes.1mm. Taking this increase in the error in L into account, the error in the value of v obtained from the graph can be recalculated. This gives a new value of The error in f n was evaluated as.Hz, as the frequency meter reading was felt to be highly accurate and the readings given by the meter did not fluctuate very much. It was felt that, due to the instability of the Lissajous figures, the error in the frequency readings taken from the Lissajous' would be much larger, possibly up to.Hz due to the difficulties encountered when attempting to locate the frequency at which the Lissajous figure became stable. This decision, as well as the assessment of the error in the frequency meter readings used, seems to be justified when viewed in the context of figure X, as the size of the error bars is entirely consistent with the quality of the correlation obtained. The fractional error in is the same as the fractional error in L, as is merely a multiple or factor of the length of the wire. Hence the re-evaluation of the error in L affects the error in as well. Since the evaluation of the error in f n appears justified, this means that the re-evaluation of the error in v frequencies will be affected only by the change in the error in L. This recalculation leads to a value of Note that the change in L was not great enough to affect the error in v after rounding. These re-evaluations do not bring the two values of v into agreement, but increasing the random error in L to a value greater than.mm would seem to contradict the accuracy to which the value of L could be measured using the available equipment. It is unlikely that the error in L was greater than this value therefore, and so it appears that there was a source of systematic error present in the experiment that was not initially identified. This conclusion is supported by the fact that the graph has a negative intercept on the y-axis, when theory predicts that it should pass through the origin. The most likely source of systematic error is in the measurement of the harmonic frequencies. It was noted in section. that the oscilloscope trace was very sensitive to interference caused by background noise such as the movement of people around the laboratory, or the proximity of a conversation to the experiment. Every effort was made to keep this interference to a minimum, but it was not possible to eliminate it entirely. This interference would affect the values obtained for f n, hence affecting the intercept of the graph and both of the values of v obtained. Another possible source of systematic error, again linked to the frequency values, is the possibility that the driver and detector were not placed in the optimal positions to produce the maximum resonance amplitude of the forced oscillations of the wire. This would reduce the intensity of the signal transmitted to the oscilloscope, making it harder to find the harmonic frequencies and possibly leading to a misjudgement of their positions. It is unlikely that this was the case however, as before each reading was taken the necessary positions of the driver and detector were calculated, and the two units carefully positioned in order to eliminate this possible source of error. It is also unlikely that this would give an error to each reading of a magnitude such that the overall correlation was so good. A third possible source of systematic error relates to the experimental setup. It was noted in section. that the knife-edges, and the driver and detector stands, were positioned on a magnetic strip in order to ensure that they did not slip whilst the experiment was in progress (this measure itself eliminates a possible systematic error source). This magnetic strip would produce a magnetic field, which would interact with the wire and induce a current in the wire as it vibrated. This induced current would in turn affect the oscillations of the wire. However it was felt that the magnetic strip was sufficiently weak and at a sufficient distance from the wire that the interactions between the field and the wire would be of negligible magnitude, and so this possible source of error can be discounted. Investigation into the relationship between the fundamental frequency of a wire and it's lengthEquation predicts that a graph of f as a function of should be a straight line through the origin. When plotted the experimental data do lie along a straight line within experimental error, but the graph intercepts the y-axis at -.6, in conflict with the predictions of theory. The value of the intercept is small compared to the value of the gradient however, and so the theory discussed in the introduction can be applied in reasonable confidence. The theory predicts that the harmonic frequency of an oscillating wire should be proportional to the reciprocal of the length of the wire. The straight line graph obtained for this investigation confirms this prediction, but only for a thin wire in which the magnitude of the elastic force is negligible. The error in the gradient of the graph depends on the errors in f and L. The excellent correlation between the plotted data and the line of best fit, and the appropriate size of the error bars in figure suggest that the initial evaluation of these errors was correct. This is interesting, as the evaluation of the error in L was the same as the evaluation for the previous investigation, in which it seemed that the error in L had been underestimated. However the re-evaluation of the error in L to its maximum feasible value had little effect on the agreement between the two velocity values obtained in the previous investigation, and so it may be that the initial evaluation of the error in L was in fact correct. This supports the conclusion that a systematic error was present in the previous investigation. Although the linear correlation seen in figure supports the theory behind the investigation, the fact that there is a y-intercept value suggests that there was a systematic error acting on the system that was not initially identified. It is interesting to note that the value of the intercept in figure is very similar to the value of the intercept in figure. This suggests that a similar systematic error was acting in both cases, since both are investigations into linear relationships. It is therefore likely that the intercept value of the graph is due to a systematic error caused by interference originating from background noise. It is interesting to note that, with one exception, the resonance points in this investigation were generally easier to find than in the previous investigation. This may have been due to the fact that this was the second investigation carried out, and substantial experience had been gained in the used to find the resonance points. The one exception was the resonance for L =.0m, which was extremely difficult to find. It is unlikely however that this difficulty was sufficient to produce a result that deviated from the correct value by a magnitude sufficient to produce the intercept seem in figure whilst maintaining the quality of correlation observed. Investigation into the relationship between the fundamental frequency of a wire and the applied tensionEquation states that a graph of v as a function of T / should be a straight line through the origin with gradient, assuming that the magnitude of the elastic force in the wire is negligible. When plotted, the experimental data for both wires do lie along a straight line within experimental error. However, both figure and figure have y-intercept values. In both cases the magnitude of the intercept is small compared to the magnitude of the gradient however, and so equation can still be applied to both sets of data in order to determine whether the elastic force is significant in either wire. The value of m for the thin wire obtained from figure is which agrees very favourably with the value calculated using the diameter measurements and a value for the density of mild steel of. This calculated value is The value of m for the thick wire obtained from figure is which agrees with the value calculated using the diameter measurements and a value for the density of mild steel of. This calculated value is The uncertainties in the values of m obtained from the graphs depend upon the uncertainties in the values of r and the gradient, and hence depend upon the errors in f, and T. The evaluation of the error in f has already been discussed in section. above, and since the frequency meter readings were once again reasonably steady there is no apparent justification for changing this error evaluation. The error in is dependant on the error in L as stated in section. above. The re-evaluation of this error carried out in that section has been taken into account in the calculations of the errors in the different values of m, as any error re-evaluation affects all results calculated using that value. since neither the error in nor the error in f has been re-evaluated, the error in v is judged to be of an acceptable magnitude. This assessment is supported by the size of the error bars on figures and, as in both cases the size of the y-error bars seems consistent with the standard deviation of the graph. The error in T depends on the errors in the values of l and x (see figure ). The error in these quantities was evaluated to be.mm, as they were measured using a standard ruler with clear, well-defined and regularly sized divisions and it was felt that this was the level of accuracy that could be obtained using this method. These evaluations seem justified when the size of the T / error bars on each graph are considered. In both cases the error bars seem consistent with the average distance along the x-axis between the plotted data points and the line of best fit; although in the case of figure they could be deemed to be slightly large. However it is felt that this was the maximum accuracy that could be obtained using the method used to measure x and l, and hence the error in T / will not be re-evaluated. The value of r was calculated from the measurements of the wire diameters that were made using an analogue micrometer. This piece of equipment is highly accurate and precise, and so the error in the value of d, and hence r, was evaluated to be.005/8mm. There is no apparent reason to change this evaluation given the excellent agreement between the two calculated values of m for each wire. It is interesting to note that the two values of m for the thick wire agree so well. Equation is only strictly true for wires in which the magnitude of the elastic force is negligible. The excellent agreement suggests that the magnitude of the elastic force in the thick wire is negligible when considering the fundamental frequency, although it may become a factor at higher harmonic frequencies. An alternative explanation is that the same systematic error that produced the y-intercept also acted on the values of f obtained in such a way as to produce the agreement between the two values of m, although this seems unlikely. Investigation into the effect of Young's Modulus on the speed of standing waves in a thick wireEquation predicts that a graph of as a function of n should be a straight line with gradient and a y-intercept of provided that equation is a valid approximation for the fundamental frequency. This can be assumed to be the case from the results discussed in section. The graph will only be valid for n greater than approximately, as up to this point the magnitude of the elastic force is small as seen in the previous investigation for the fundamental frequency. In this case the values of f n began to deviate substantially from the values predicted using the fundamental frequency at, and so only data from the harmonics has been used to plot figure. The plotted data do lie along a straight line to within experimental error, but the appropriateness of the linear fit is questionable as the data points seem to form a shallow curve. Despite this, the value of the intercept on the y-axis is.43, close to the value of predicted by the theory. The theory discussed in the introduction will therefore be applied to the data in order to determine a value for Young's modulus, E, for the thick wire, but the conclusions reached will not necessarily be valid owing to the aforementioned questionability of the linear fit. The value of E calculated from the gradient of the graph is This agrees poorly with the accepted value for steel of.0 x Pa. This poor agreement suggests that there has been an overoptimistic evaluation of one or more of the random errors acting on the system. The error in E depends on the errors in the gradient, and hence in f n, and the errors in r, L, and T. the error in r has already been discussed in previous sections, as have the errors in L and T. The errors in T and r were judged to have been evaluated correctly, and the error in L was re-evaluated. This re-evaluation has been taken into account when calculating the error in the value of E quoted above. Therefore it seems as though the error in f n must have been misevaluated. During this investigation, the values of f n were much more difficult to find than in previous investigations as noted in section. The frequency meter readings were also observed to fluctuate over a wider range than in previous investigations, again as noted in section. These two factors led to a re-evaluation of the error in f n from previous investigations. It was felt that the combination of the two factors outlined in the previous paragraph led to a range of frequencies in which each harmonic could lie of approximately Hz. It was therefore decided that the error in the values of f n obtained should be.Hz, or half of the possible range of frequencies within which f n could lie. Figure 0 was plotted using this initial re-evaluation of the error in f n. However the discrepancy between the accepted value of E and the value obtained suggests that the error in f n must be re-evaluated once more. The error in the value of E obtained through experimentation must be larger if the two values are to agree, suggesting that the re-evaluation of the error in f n was still too low. However if the size of the y-error bars on figure 0 is considered, it appears that the error in f n has been overestimated as the error bars appear too large for the standard deviation of the graph. Since these two factors directly contradict one another, it must be concluded that the evaluation of the error in the values of f n was in fact reasonable. Therefore the discrepancy between the calculated and accepted values of E is likely to be due to a systematic error. A possible source of this systematic error is the way in which the harmonic frequencies were found. It is stated in section. that the values of the harmonic frequencies appeared to be different depending on whether the frequency was being increased or decreased in the vicinity of the resonance, and that it was decided to obtain all of the results by decreasing the local frequency. It is possible that this was the wrong decision, and that the values obtained through the increase of the frequency in the vicinity of the harmonic frequency would have yielded a more accurate value of E. Why this might be the case is not certain, but it is a possibility that must be considered. Another factor that might have produced a systematic error was the interference caused by background noise. This was a particular problem during this experiment as the amplitude peaks in the oscilloscope trace were often very small, and would therefore have been swamped by background noise. Listening to the wire would have helped in this situation, but would not have completely compensated for this effect. Although plausible, it is unlikely that this possibility is the source of the systematic error, as particular care was taken to minimise the amount of background noise, and to try and take results during quiet moments, in this investigation, as it was recognised that it would be a particular problem once the small magnitude of the amplitude peaks was realised. A third possibility is that the driver and detector were not in the optimal positions along the length of wire under consideration in order to cause and detect forced oscillations in the wire. The driver and detector were not moved from their starting positions during the course of this experiment, and it was only once the investigation was concluded that this was realised. In order to produce a pure standing wave pattern, the driver must be positioned in an antinodal position, and the detector must be in a similar position in order to pick up any changes in the forced oscillations. The wire length used,.5/8m, would have resulted in movements of the driver and detector of only a few centimetres each time, but it might have been an important factor in the quality of results obtained. This might also explain the shallow curve to the data plotted on figure 0, as the antinodal positions would have moved away from the driver and detector before moving towards them again as the value of n increased and the number of half-wavelengths within the length of wire under investigation increased. Once the difficulties involved in the location of the harmonic frequencies using the first method outlined in section. had become apparent, or once the full set of data had been taken, it might have been prudent to attempt to find the harmonic frequencies again using the second method involving Lissajous figures outlined in section. Although the Lissajous figures would have been very unstable due to the highly sensitive nature of the equipment during this investigation, and hence the frequencies would still have been hard to find, this would have provided a second set of data and allowed any possible anomalous results to be identified. It might also have proved to be slightly easier to find frequencies at which the Lissajous figures became stationary than to find the frequencies at which the oscilloscope trace underwent a very small amplitude increase.. General pointsThe experimental setup was generally sufficient for the investigations being undertaken, but the sensitivity of the frequency meter and oscilloscope sometimes became very problematic. In order to try and compensate for this sensitivity, the experiment could be carried out in isolation. Performing the experiment in a separate room would help to minimise the effects of background noise on the frequency meter reading and oscilloscope trace. The other problem encountered whilst carrying out these investigations was the small magnitude of the amplitude peaks in the oscilloscope traces observed at the harmonic frequencies, which often made the harmonic frequencies quite difficult to pinpoint. As mentioned in section. this might have been offset by utilising the Lissajous figures for the final investigation. However in general it is difficult to see how this problem could be addressed without substantial changes to the experimental method, although the use of a more precise audio oscillator might help. Improving the resolution of the oscilloscope might also go some way towards addressing the problem. - ConclusionBy setting the length of a thin wire to a constant.00.00707m and measuring its harmonic frequencies, a value for the speed of the waves on the wire of was found. This compared favourably to the value of found through direct calculations utilising the basic relationship between frequency, wavelength and velocity. The initial evaluation of the error in the frequency readings was judged to be correct, but the original evaluation of the error in L was judged to have been an underestimation. The subsequent corrected value for the error in m was still insufficient to account for the discrepancy in the value of v, and so a systematic error owing to the interference caused by background noise was suggested. Systematic errors owing to misplacement of the driver and detector, and due to the magnetic field of the small magnetic strip were considered, but dismissed. By measuring the fundamental frequency of the thin wire for increasing lengths of wire, it was shown that the fundamental frequency of the wire was proportional to the reciprocal of the length of the wire, as predicted by theory. However the straight line did not pass through the origin, contradicting the predictions of theory, and so a systematic error arising from interference owing to background noise was once again suggested. By measuring the fundamental frequency of a fixed length of both the thin and thick wires for increasing applied tensions, values for the mass per unit lengths of both wires of.10.8x10 -kgm - and.30.0x10 -kgm - respectively were found, in excellent agreement with the values of.80.2x10 -kgm - and.00.2x10 -kgm - calculated from the measurements of the wire diameters and a value for the density of steel of. The initial evaluations of the errors in T and r were judged to be correct, and the re-evaluated error in the value of L was judged to be appropriate for this investigation as well as for the first investigation. By setting the length of the thick wire to.5/80.00707m and measuring its harmonic frequencies, the point at which the values of the harmonic frequencies began to deviate from the standard linear relationship was found. By plotting a graph of f n against n for these harmonics, a value for Young's modulus of.71.5/8x10 1Pa was found, in poor agreement with the accepted value for steel of.0x10 1Pa. The errors in L (as re-evaluated), r and T were judged to have been evaluated correctly, but the appropriateness of the evaluation of the error in f n could not be assessed Possible systematic errors owing to the method used to find the harmonic frequencies, and to interference caused by background noise were suggested.'''",655.0
"'''The essay examines the operation of the 'Leniency Notice' as a weapon to destabilise the effects of Cartels which are prohibited by Articles 1 and 2 of the EC treaty or Sections and of the Sherman Act. The essay will begin by giving a definition of the 'European Commissions' Leniency Notice and Cartels followed by a concise discussion of the difficulty of detecting and proving the existence of a cartel which consumers must view in light of the 'leniency notice'. The essay will attempt to address the issues derived from the policy objectives of imposing penalties on those individuals who commit an offence but in effect are not penalised. This essay will address more specifically the operation of the notice in the EU 'although reference will be made to the US antitrust laws where appropriate given its increasing influence in a domestic and EC context.' The Commissions notice was firstly introduced in 996. However, it was revised and issued in February 002 as it was seen that the notice clearly 'did not emulate the 'DOJ' success in a number of respects.' Therefore, the essay will most importantly discuss the limitations of the operation of the EC notice in light of the successes of the 'United States' notice. Nevertheless, despite its limitations its successes so far are promising and undeniably models as a weapon for the beginning of the destruction of cartels. The essay will conclude that the operation of the notice may still have to be improved before it can be as successful as the US notice. Commission notice on immunity from fines and reduction of fines in cartel P.Ewing, Competition rules for the 1st century,, First Edition, Kluwer Law International A.Jones and B.Sufrin, EC Competition Law,, Second Edition, Oxford University Press, at p788 URL and See case of 'Woodpulp' J. D. Hunter and S. Hornsby, 'New Incentives for Whistle blowing': Will the E.C.Commissions Notice Bear Fruit' E.C.L.R. 997, notice on immunity from fines and reduction of fines in cartel, 'a third party injured by the cartels actions may commence civil proceedings' against that undertaking before their own national courts and plaintiffs may also 'rely on evidence drawn from the commission in their plea.' This was evident in the 'vitamins' case as Aventis though given immunity was 'subsequently sued.with its fellow conspirators in national courts.' Thus, undertakings must consider this fact before taking advantage of the notice. This may undermine the effectiveness of the notice; because it 'may serve in time as a disincentive to undertakings to take advantage of the leniency programme' which in turn restricts the operation of the notice and its successes. However, it has been stated, though, in the US context, that the 'risk of civil consequences has not prevented the leniency programme from being a success' and that there is a 'lower risk of civil actions in Europe.' Further, the commission imposes very high fines for cartel activity and immunity from these fines may well compensate for the risk of paying fines for third party actions. However, despite this argument this may still be a disincentive for a prospective applicant. A.Jones and B.Sufrin, EC Competition Law,, Second Edition, Oxford University Press, at p789 See case Berian U.K. Limited v. BPB Industries Plc and Another E.C.C. 6 Vitamins Case CMLR 030 A.Jones and B.Sufrin, EC Competition Law,, Second Edition, Oxford University Press, at p1142 Ibid Donal McElwee 'SHOULD THE EUROPEAN COMMISSION ADOPT 'AMNESTY PLUS' IN ITS FIGHT AGAINST HARD-CORE CARTELS' E.C.L.R. 004, undertaking is the first to submit evidence which in the Commission's view may enable it to adopt a decision to carry out an Investigation.' (also known as the Dawn raid sufficiency test). Commission notice on immunity from fines and reduction of fines in cartel dawn raid sufficiency test could be argued to lack predictability as 'there is no defined legal standard for the ordering of a dawn raid investigation.' Therefore, whether evidence submitted is sufficient for a dawn raid is given on a purely discretionary basis. This has a negative effect on the operation of the notice because a would be co-operating entity, would not be able to assess whether the evidence they have submitted is of a sufficient degree to enable a dawn raid and thereby, once further conditions are met gain immunity from fines. Therefore, though the commission has increased the predictability of the notice by giving corporate entities full immunity if it meets the dawn raid sufficiency test '. the Commission seems to take away with one hand what it has given with the other.' Through, the invariably discretionary dawn raid test. Further, it is complicated by the fact that there is at present 'no way to put in a 'marker' holding the company's place as first in line, while it gathers sufficient evidence to 'perfect' the marker' if the undertaking should fail the discretionary dawn raid test on its first approach to the commission. The lack of a marker system creates uncertainty, which in turn reduces the predictability and transparency of the notice, for a would be co-operating entity and creates, a complex situation for the commission. This will be explained further in the following argument. The commission may be placed in an interesting position 'if a second firm comes in hoping for leniency before the dawn raid triggered by the first has been executed.' In the event that this occurs theoretically the commission may have a discretion whom to prosecute (known as Prosecutorial Discretion), which reduces the transparency and predictability of the notice. Or most likely the second firm may gain leniency rather than the first firm whom failed in gaining sufficient evidence. Further, there is an increased risk, for the undertaking 'who cannot be sure whether another company has already won the race under point .' Again the US has dealt with this problem, and created a procedure, which in effect, protects the undertaking from the occurrence above. 'The US process allows companies to inform the 'DOJ of the violation' and confirm 'that it will return at a later date with a full 'proffer' to 'perfect' the marker put down earlier.' This in turn reduces the 'higher burden akin to the EU notice to secure first place in line for immunity. Further, the US notice 'is inherently transparent because they 'have eliminated, to a great extent, the exercise of prosecutorial discretion in its application' because each company knows that if they are the first to submit evidence they will receive immunity, and they can also use the marker process, to their benefit, to ensure that they mark their place in the line. Therefore, the DOJ cannot use their own discretion to state which company should be prosecuted and which should have immunity. This strengthens the transparency of the US notice. In turn, the lack of a marker system in the EC notice may deter prospective applicants and most importantly 'such a barrier to reporting quickly is also counter to the aims of an immunity system that is meant to encourage companies to race to confess once infringements are found.' Therefore, it seems that a similar process as in the US for a marker system may need to be adopted in order to improve and strengthen the certainty, transparency and predictability of the operation of the notice. However, as apart of the notice possible future revision 'a marker-style system for applying for immunity is being seriously considered' by the commission. The dawn raid test may also need to be explicitly defined; this would in turn reduce the discretionary nature of the term and may improve the predictability of the notice for a prospective undertaking. Johan Carle 'THE NEW LENIENCY NOTICE' E.C.L.R. 002, 3, 65/8-72 Ibid Michael J. Reynolds, 'IMMUNITY AND LENIENCY IN EU CARTEL CASES: CURRENT ISSUES', E.C.L.R. 006, 7, 2-0 C.Harding and J.Joshua, Regulating cartels in Europe,, First Edition,Oxford University Press, at P 20 Ibid Michael J. Reynolds, 'IMMUNITY AND LENIENCY IN EU CARTEL CASES: CURRENT ISSUES', E.C.L.R. 006, 7, 2-0 Ibid Michael J. Reynolds, 'IMMUNITY AND LENIENCY IN EU CARTEL CASES: CURRENT ISSUES', E.C.L.R. 006, 7, 2-0 S.D. Hammond, Cornerstones of an Effective Leniency Program, paper presented at the ICN Workshop on Leniency Programs (Sydney, November 004), accessible at < URL Michael J. Reynolds, 'IMMUNITY AND LENIENCY IN EU CARTEL CASES: CURRENT ISSUES', E.C.L.R. 006, 7, 2-0 Michael J. Reynolds, 'IMMUNITY AND LENIENCY IN EU CARTEL CASES: CURRENT ISSUES', E.C.L.R. 006, 7, 2-0 It has been stated, that there are 'three prerequisites for implementing an effective leniency policy' namely: 'severe sanctions, heightened fear of detection, and transparency in enforcement policies.' Unfortunately, the limitations discussed above, falls into these three prerequisites which may explain, why the notice may not be as effective as the US notice at present. S.D. Hammond, Cornerstones of an Effective Leniency Program, paper presented at the ICN Workshop on Leniency Programs (Sydney, November 004), accessible at < URL ibid Successes of the NoticeHowever, despite the limitations discussed it cannot be denied that the notice, so far has been successful in detecting and prohibiting cartel activity. Therefore, the operation of the notice should not only be discussed in light of its limitations. One should also note that, the US notice has not always been so successful. It has had its time to develop and improve upon its limitations and the EC notice will do the same and reach more successes in time. However, it is clearly evident that the new notice has and will continue to produce better results than the 996 notice. Nonetheless, the '996 notice was very successful' in detecting cartels and 001 was a remarkable year for the detection of cartels where fines reached a total of 'EUR.36 billion.between 996 and 002.' Specifically 'Out of a total of 4 decisions imposing fines. firms cooperated with the Commission under the scheme in 7 cases.' The notice was used in a variety of industries such as chemicals, banks, airlines, beer and paper. The year 002 was also another successful year for the commission as five out of nine cartels, used the notice and gained immunity. This included the case of 'Sotheby's/Christy's' Sothebys were fined EUR 0. million while Christy's gained immunity, 'Electrical and mechanical carbon and graphite products' Morgan Crucible received full immunity and because the second undertaking Carbon Lorraine provided substantial information they received 0% reductions in their fine. Therefore, this reflects that the notice is to a great extent destabilizing cartels and corporations do see the advantages of the notice and have taken it seriously. Therefore, in practice and despite its limitations the notice has indeed 'proved a formidable tool for encouraging firms to cooperate with the commission.' A.Jones and B.Sufrin, EC Competition Law,, Second Edition, Oxford University Press, at p1138 Whish, Competition Law,, Fifth Edition, Lexis Nexis UK, at 5/86 Mario Monti European Commissioner in charge of Competition Policy The fight against Cartels Summary of Mr Monti's talk to EMAC EMAC Brussels, 1 September 002 IP/2/5/885/8, 0 Oct. 002. Decision Dec, 003, OJ L125/8/5/8 Mario Monti European Commissioner in charge of Competition Policy The fight against Cartels Summary of Mr Monti's talk to EMAC EMAC Brussels, 1 September 002 Reforms It should also be noted that the commission are continuously working on the notice. This is reflected through the 'Draft Commission Notice on Immunity from fines and reduction of fines' in cartel cases which if implemented in the future will take away the discretionary nature of the dawn raid test and will introduce a discretionary marker system, as well as other proposed amendments. Therefore, the commission should be commended for their work. Available at URL ConclusionThe notice is effective as it addresses the difficulty of detecting and proving the existence of a cartel and also the retributive concerns surrounding leniency for cartel offenders. It has been successful since its introduction in 996 as it has resulted in a number of cartels being detected. The limitations of the notice such as the lack of criminal sanctions, amnesty plus, a marker system and the fact that a cartel member may be liable to civil and criminal proceedings in member states and the continuous lack of transparency and certainty may reduce the effectiveness of the operation of the notice within the EU. Moreover these limitations fall into the three prerequisites needed to create a successful leniency notice, namely severe sanctions, heightened fear of detection, and transparency. Thus, it is likely that the EC notice may not as yet emulate the successes of the US notice until certain improvements have been made. The improvements consists of the introduction of criminal sanctions for cartel behaviour, the addition of amnesty plus and a marker system, the issues of confidentiality and the vagueness of the meaning of the dawn raid test are addressed and lastly if the member states are willing to align their laws with the ECN Model Leniency programme. However, it must be noted that the notice is a recent reform which needs time to develop as the US notice has had time to develop. In time the notice will create success stories like that of the US as long as it continues to improve on its limitations. The commission is no doubt working to achieve this objective, and this is reflected through the 'draft Commission Notice on Immunity from fines' and the introduction of the ECN model Law.'''",656.0
"'''This statement, made by a World Bank Vice President, is evidence of an increasing awareness across the world that water resources have tremendous potential to create interstate problems and conflicts. In Post-Soviet Central Asia, water has proven to be an irreconcilable dilemma. The legacy of Soviet central planning with relation to water has left severe economic, political and ecological tensions in the region, which the five successor states have yet to solve, and yet, there is only limited time to solve this water crisis. Soviet planning in the 960s had created a fully co-ordinated and centralised water management system. Though this system was, and still is, an ecological catastrophe, nevertheless, it was easy to manage as a single entity. With the collapse of the USSR in 991, this system must now be managed by five autonomous and competing states, each with varying needs and priorities for their water. With attempts at co-operation so far having little impact, a great deal of tension has built up surrounding the access to water resources. And yet, there is little chance of a military conflict over the issue, although, as we shall see, there continues to be an indirect conflict emerging through the use by the states of economic constraints upon each other. To understand why this has happened, we must first deal with the varying dimensions to the 'Central Asian Water Crisis', and then study why the numerous alternatives to conflict that have been attempted so far have been largely unsuccessful. However, even though co-operation has been unsuccessful, this does not imply that military conflict is inevitable; although the future of Central Asia looks bleak, this does not mean that will necessarily be direct inter-state conflict arising from its current water crisis. Of course, war and military intervention are not the only types of conflict that can arise over water. In such a complex geo-political context, the conflicts that arise around water focus on human security and battles for economic supremacy in the region. If we concentrate on these issues of conflict, then Central Asian water crisis does not look stable at all. Water, as well as necessary for life, has also been essential for the economies of many central Asian states, particularly since the 960s, as 7% of water usage in Central Asia is for agricultural purposes. It is in this economic sphere that water has caused the greatest tensions. In the region, this has taken the form of a conflict between the interests of downstream, largely agricultural states, and upstream states that require water for hydroelectricity. Unfortunately, upstream states need to release water in the winter months, when demand for electricity is at its peak, whilst downstream states require this water in the summer when irrigation is most crucial. This problem is most apparent between Uzbekistan, a downstream state, and Kyrgyzstan, an upstream state on the Syr Darya, who rely on hydroelectricity created at the Toktogul plant. Uzbekistan however, requires most of its 8.million km quota of water from the Syr Darya in summer, to irrigate its cotton. Since 991, this has been a cause for increasing tension and hostility, as the bilateral agreements formed to alleviate this issue have been unsuccessful. This disparity between the needs of upstream states and downstream states has been the biggest cause of concern so far, but, as we shall see, this does not necessarily increase the opportunity for inter-state conflict. Hyde-Price, A. 'Eurasia' in Thomas, C. & Howlett D. (Ed.) Resource Politics: Freshwater and Regional Relations Philadelphia: Open University p163 The over-arching cause of the entire Central Asian water crisis was the nature of which the USSR collapsed in 991. With no large scale demand for independence in Central Asia, it was instead thrust upon them when the European Soviet States of Ukraine, Belarus and Russia declared their own independence, without whom the USSR was unsustainable. The five Central Asian states, whose economic welfare was maintained by central management and subsidies from Moscow, were catapulted into crisis. For instance, there was no problem between Uzbekistan and Kyrgyzstan concerning the Toktogul Dam under Soviet central administration; Kyrgyzstan was compensated for not using the Toktogul hydroelectric station during autumn and winter, as Moscow gave it one billion m of natural gas, a million tons of coal, 00,00 tons of heating oil and $00 million to maintain water installations and for economic needs. In this way, the needs of both upstream and downstream states were met. However, since independence, this compensation has been replaced with bilateral agreements. Since Dushanbe cannot afford to give compensation on this level, the current levels do not cover Bishkek's requirements; when Kyrgyzstan runs out of imported hydrocarbons, it will turn on its hydroelectric station. When this happens, Dushanbe in turn reduces its barter quotas of gas and oil for the next year, which exacerbates the problem year on year. Central planning also accounted for Uzbekistan to acquire a 'cotton monoculture' in its agriculture, to the extent where agriculture makes up 8% of Uzbekistan's GDP. Cotton is the main product, accounting for.5/83million hectares out of a total of.20 in 986, despite Uzbekistan being a downstream state. Of course, under central planning this did not matter. This central planning, which was workable under the old Soviet system, has sown the seeds of the current crisis, and helps us to understand why any conflict might arise. Kemelova D. & Zhalkubaev G. 'Water, Conflict, and Regional Security in Central Asia Revisisted', ' New York University Environmental Law Journal Vol. 1 Issue p480 CIA Factbook, Available at URL Accessed 3rd April 006 Kobori I. & Glantz M. Central Eurasian Water Crisis New York: UN University Press p42/3 The Soviet tendency for giganticism, whilst showing contempt for the environment, has also been the cause for the most serious problem in the Central Asian water crisis, the environmental destruction which has caused many health problems for the people in the region. Soviet planning involved irrigating the entire region, as it created large collective farms, from the Amu Darya and Syr Darya, which in turn stopped these rivers contributing to the Aral Sea. In 960, the sea covered 6,00km, with a volume of,90km. By 000, due to the intensive irrigation system set up during the Soviet era, it had in fact split into two seas, with a combined area of only 5/8,17km and 12km volume. By 011, it is expected that it will become three separate bodies of water. This 'disappearing sea', an environmental calamity in itself, has had various other secondary effects on the environment. Fish stocks from the sea are dying out; salinized land, left behind from the retreating shoreline, are swept throughout the region by desert winds, which make large areas of land unsuitable for agriculture. However, it is not only salt that is present in this soil. According to Glantz, 'documented regional effects have only recently been exposed to the public: high infant mortality and morbidity rates, a sharp increase in oesophageal cancers, directly attributed to 'poisoned water' resources. and a life expectancy in some areas of about 0 years less than the CIS in general'. 'Poisoned water' refers to the chemicals that are used for agriculture in states further upstream from the Aral, which are then transferred downstream and dry out with the retreating water, being dispersed through the littoral states of the Aral, in particular Kazakhstan. These problems, caused by the Soviet central planning, have caused further tensions between the successor states. Even if these problems do not create the same hostilities that economic concerns have, they are still an additional dimension to the current water crisis. Kobori I. & Glantz M. Central Eurasian Water Crisis New York: UN University Press p44 ILEC/ Lakenet Lake Basin Management Initiative, 'Aral Sea Lessons Learned: Draft Final Report' p6 Kobori I. & Glantz M. Central Eurasian Water Crisis New York: UN University Press p48 As if these concerns were not enough to create a crisis in Central Asia, there are still many more extenuating circumstances that make the situation worse. To begin with, despite the Soviet creation of massive agricultural plains throughout the region, concentrated in Tajikistan, Uzbekistan and Turkmenistan, the climate is highly unsuitable for efficient water usage. Cotton in Central Asia requires 3,00m /ha, which is substantially higher than in other cotton producing countries. In addition, the arid climate ensures excess water evaporates quickly, and salinized dust is carried by desert winds. Again, in the centralised Soviet state, this was of little concern, and the economic dependence on cotton has left these states with no choice but to carry on with its production. However, due to this monoculture, particularly of Tajikistan which has no oil or gas of its own to diversify its economy or fulfil its own power needs, with the loss of Moscow's support, they must now further expand their agriculture, with irrigated land in the region increasing by % between 997 and 000; added to this were plans for an extra 5/80,00 hectares in Turkmenistan and 00,00 in Tajikistan in 005/8. This increase in agriculture, along with a decrease in regional co-operation and without any further input of water resources, has made the crisis more severe since 991.And yet, since 001, the problem has been even worse, with increasing amounts of water being diverted to Afghanistan from the Amu Darya to help with the reconstruction effort after the recent conflict, leaving even less resources for the five Central Asian states. If the current water crisis seemed destined for conflict in the early 990s, the circumstances that have emerged since have made the current water problems even worse, and tensions higher. Spoor M. & Krutov A. 'The Power of Water in a Divided Central Asia' Perspectives on Global Technology and Development Vol. Issue p601 International Crisis Group, Central Asia: Water and Conflict ICG Asia Report No. 4 p9 Clearly, the 'Central Asian Water Crisis', as the problems in this region are often labelled, is not one crisis at all, but a complex and integrated collection of crises, economic, environmental and political, which originate from the Soviet period, and the manner in which it came to an abrupt end. From this, it is apparent that these crises are serious, and need addressing, yet the way in which attempts have been made to address them so far have been highly unsuccessful. A variety of attempts and suggestions have been made to solve the crisis peacefully, through regional or bilateral treaties, the creation of regional water management bodies, and inviting assistance from outside the region, from foreign states and the U.N, to NGOs. However, as each of these attempts have floundered due to the attitudes and priorities of the five Central Asian states, in particularly with regards to Uzbekistan and Turkmenistan, the chance of conflict, be it economic or military, increases. Before we can fully assess whether there is potential for conflict over water in Central Asia, we must examine why there has been so little progress down the route of co-operation and compromise. Natural resources, particularly water, are ill-suited to arbitrary national borders, as the water system must be taken as a single entity, rather than five competing interests for its use. With this in mind, the five concerned states entered into the Almaty Agreement in 992 to regulate water consumption, with each state agreeing to abide by existing Soviet water quotas. This attempt at regional co-operation is perhaps the most effective way of avoiding conflict in the region, but it has so far had little success. Although it would be simple if the basins of the Amu Darya and Syr Darya were managed as a whole, as they were in the Soviet era, economic and political realities have made this method of management unfeasible. Whereas Uzbekistan was singled out by Moscow to be the largest cotton producer for the USSR, other states, such as Tajikistan, who can no longer be economically sustained by Moscow, now wish to expand their agricultural sector. However, the Almaty Agreement restricts them to the same quotas as had existed before, only 5/8% of the Amu Darya flow. These quotas need serious revision, but this has proven impossible whilst each state attempts to gain as much as possible from the water source, which is essential for economic prosperity. A string of regional summits have been held since 992, and they all end with promises of change and solutions, but are never followed up with action. Since agricultural expansion, and therefore economic success, is inextricably linked to water resources, there can be no meaningful or workable regional co-operation; the circumstances of which the USSR collapsed have ensured that each state views the water crisis as a 'zero-sum' game, in which maximising individual advantage is essential. Unfortunately, whilst this mindset prevails, regional co-operation cannot exist, and conflict becomes more likely with individual states in competition with each other to maximise its benefit. Sehring J 'Water Policy in Kyrgyzstan and Tajikistan: Problem Perception and Agenda setting', CESS Paper th Annual Conference 004 p4 However, it is not just the circumstances of the attempted regional agreements that have limited their impact, and the commitment to them. The way in which these agreements have been set up, the lack of enforcing and monitoring powers of regional bodies, and the prioritising of national interests over regional interests, have all contributed to the lack of progress being made to solve the water crisis amicably. A series of summits throughout the 990s set up the Interstate Co-ordinating Water an Interstate Fund to save the Aral Asian Security: The New International Context: London: Brookings p76 In spite of this assertion that interstate conflict is unlikely are consistent proclamations by regional leaders that war is a distinct possibility. One Uzbek official is on record as saying that, 'Uzbekistan, Tajikistan and Kazakhstan will defend themselves by whatever means necessary. However, this must be examined in the political context of the region, in particular with relation to Uzbekistan. The creation of five autonomous states in Central Asia after the collapse of the USSR was met with mixed reaction; as Kazakhstan, Tajikistan and Kyrgyzstan were eager to see a regional approach to common concerns, Uzbekistan and Turkmenistan, led largely by the personalities of Karimov and Niyazov, favoured a more state-centred approach. For instance, in 000, the OSCE attempted to organise a regional conference to address the water issues; however, it was meaningless when Uzbekistan and Turkmenistan stated that they preferred bilateral arrangements, despite their ineffectiveness. These two leaders in particular have had a difficult time co-operating with each other, due to personality clashes, and the desire of both to make their nation a regional hegemon. Because of this political animosity between various regional governments, a great deal of conflictual rhetoric has circulated over a variety of issues, including water. However, as we have already seen, a 'water war' would solve little of the current crisis, in either the long or short term. This must be remembered, and the threats of war and conflict must be examined not as legitimate statements of intent, but as part of a tense political climate in the region. ICG Report, p7 More likely is an increase in the economic conflict that is currently being waged in Central Asia, as this pressure can, so it is hoped, further national interests and influence bilateral agreements more successfully than war can. When Kazakhstan failed to transfer energy and pay outstanding debts to Kyrgyzstan in late 997, the latter cut off its water supply to put economic pressure on it to comply. The continuing disagreement between Kyrgyzstan and Uzbekistan concerning their barter agreements over the Toktogul is also an example of this economic pressure. In 998, after Dushanbe had cut off electricity supplies in the winter to Bishkek because they had released water that was not in keeping with the agreed 'cotton optimal' policy, Kyrgyzstan announced plans to charge Uzbekistan and Kazakhstan for the water it used. These disagreements are characteristic of the entire region, and demonstrate how, when conflict arises over water, it is often more productive to place economic pressure to influence other nations decisions. However, it is unclear where this 'tit-for-tat' conflict will end. Whilst in the long term these disputes are very harmful for the water crisis as a whole, they do serve to further the short term interests of the concerned states. Whilst the Central Asian governments are concerned more with short term than long term gain, and in fairness, the circumstances in which they are under leaves them very little choice, than this type of economic conflict is only likely to increase in frequency and ferocity. Although inter state conflict may be improbable, this does not mean that there is stability in the region. Rather, there are opportunities for conflict on smaller, sub-national levels, even between states themselves, although this is difficult to confirm. It is claimed that there has been a small scale secret war between Uzbekistan and Turkmenistan since the 990s over the Amu Darya, including a massacre of Uzbek troops in Turkmenistan in 001. At a more local level, tensions between Kyrgyz and Tajik farmers have erupted over access to local water resources. The restraint on national governments not to wage war on each other, that, 'going to war is a very expensive way of controlling resources', does not apply at a local level, and the rewards can be much higher for a village that needs water to survive, than it can to a government, who must consider the water crisis as it affects the entire Aral Sea basin. Water can also exacerbate existing local conflicts, with increasing economic pressure adding to ethnic tensions on borders or multiethnic areas. Furthermore, there is evidence to suggest that, as land becomes arid and agricultural opportunities cease in many areas of Central Asia, they are replaced with local militias, terrorist organisations, and drug trafficking to replace the security that agriculture once afforded them. Clearly, the water crisis in Central Asia is more than just a dispute amongst nations; the bulk of the problems are faced by everyday people, and this is where tensions rise, and conflict, can emerge. Sievers E. Water, 'Conflict and Regional Security in Central Asia' New York University Environmental Law Journal Volume 0 p370 International Crisis Group, Central Asia: Water and Conflict ICG Asia Report No. 4 p11 As this suggests, the current water crisis has made Central Asia a dangerous region. However, if states are unwilling to pursue long term strategies to solve the crisis, and direct conflict is unlikely, it is currently very difficult to judge what the outcome of this crisis will be. Certainly, time is running out, especially to save the Aral Sea. Outside assistance appears to be the only course of action left to solve this crisis, but attempts so far have been unsuccessful. Israel, a state familiar with water conflict, with its record surrounding the Jordan River, ran a scheme to help Uzbekistan in 996 by developing water efficiency technology. This was duly ignored when it was cheaper for farmers to use excessive subsidised water than to maintain the technology that Israel supplied. A second, more dramatic plan that is considered is a Siberian-Aral canal, a former-Soviet scheme that would refill the Aral from Siberian Rivers. During Soviet times, this would have been funded by Moscow, and there is still a call for Russia to fix the damage it has done to the water management system of Central Asia. However, there is little motivation for Moscow to fund a project in former Soviet states, so this looks like an unlikely solution. Secondly, there is no guarantee this project will not damage the Irtysh River, where the bulk of the water would come from, in the same way the Aral has been decimated. In any case, though it might save the Aral Sea, it would not solve the major regional disputes concerning the Amu Darya and Syr Darya rivers. Outside assistance to solve this crisis, although possible, must still rely on the political and economic investment by riparian states into long term solutions; it is still this investment that is lacking in Central Asia. Even when considered separately from the current political circumstances, the chances of solving the Central Asian water crisis is slight. Even if all technological and agricultural changes were implemented, the current crisis would take decades to solve. To do this, there must be an emphasis on fighting the causes of the problem in the long term to create sustainable water consumption. However, when considered with the current economic and political climate, this looks increasingly impossible. As states look to short term solutions and gains, the long term factors causing the crisis are only exacerbated. This, along with severe political tensions in the region, explains why multilateral agreements that could solve the crisis consistently amount to nothing. However, this situation cannot simply be blamed on a lack of understanding or political will; in many ways, the nature of Soviet rule, and the nature of its collapse, thrust these five states into the current crisis without an alternative. It is evident that the current crisis will not be solved by any short term efforts, and this includes interstate war. Indeed, despite the rhetoric espoused in the region, it is evident that war will not solve any aspect of the crisis, which is what makes it so unlikely. However, this does not rule out the destabilising of local areas, and the increasing of local ethnic tensions due to the water shortage in Central Asia, nor does it imply that the concerned states will stop their dangerous economic battles with each other. It is now all but inevitable that the water crisis will create incredible economic and environmental hardship for the people of Central Asia. What is not inevitable however is the eruption of a 'water war. There is, and increasingly will be, conflict, but it is not conflict in the traditional understanding of the term.'''",661.0
"'''Q1. Drop in patient's blood in patient's blood effects of drug A are more spread first drug administered then Drug B but on A has better performance on this group. Drug A after Drug B: Less spread and median slightly lower One slightly apart form rest of group meaning other factors may affect blood pressure Insufficient data to say whether order B after Drug A: Average less Spread similar Negative value meaning it has made the patients condition worse then no drug Suggests that the order of the drug has effect and drug B after drug A has a negative effect. How large and diverse is the population, 2 is a small sample and a larger sample would give more data on which to evaluate the drugs and the importance of the order given. Initial blood pressure needed to see if drop is proportional to blood pressure and if how much of a hytensive someone is, is a factor Age and other biological data are necessary to see if drugs effectiveness varies with these. What is mm Hg, and how much does it vary may be other factors involved in blood pressure of patients, like stress, diet illness. How was test carried out, under controlled conditions? Was the test carried out by drug company or independently as this may have a effect on the data. Were the people selected at random from the population, or was it people who applied or from doctors list; as such it may be that if all from area then it may not be representative of the population Q2.Average ration of Men to tonnage in a steam ship is crew per 5/8 tonnages. Average ration of Men to tonnage in a sail ship is crew per 7 tonnages. Steam ships have a much larger ratio of tonnage per crew then sail ships; they are also much larger carrying more tonnage and crew. From graph fig. equation of best fit line is.062tonnage.8 = crew size Using tonnage=000 in this equation gives 0 crew needed. I would expect Ships,,,7 and 8 all to be sail ships because they have a small tonnage and low ration of crew per tonnage, which from the data is normally from sail ships. Need information on ship technology of the time, are there dual power ships powered by other means, which could be the power of those not given. Details about where the ships are headed would be useful as a ship to Australia may need more crew then a ship to France and seas the ships are crossing may change crew per tonnage ratio. How was the sample collect, is it random, or just taken for all ships in dock in which case not likely to representative of population as sail and steam ships may be kept in different docks. Not many sail ships given more needed to form a opinion about them; 5/8 ships is not a very big proportion of all the British merchant ships in 907. Would the Registrar of General Shipping have complete crew list or just senior positions? Q3.The majority of cities rainfall is between - inches and sunshine between -0 hours. There are outliers, due to excessive rainfall and due to sunshine. Bangkok, Hong Kong, Tokyo and Miami all experience excessive rainfall; this may be due to their geographical positions meaning that September is monsoon or hurricane season causing the extra rainfall. Mallorca has lots more sunshine hours then elsewhere may due to its position meaning it gets few clouds in September. Need geographical position of all cities along with their regional climates how this effects them. Some cities from southern hemisphere so they have the opposite season to the northern hemisphere How was the data collected, is it an average of many years or just for 000, is it average over month and is it part of city or average of whole city.'''",662.0
"'''Sociolinguists today are more concerned with social variation in language. Quantitative studies were set off from the pioneering work of William Labov. Scientific investigations is carried out by stating the hypotheses, sampling, collecting data, drawing conclusions and relating conclusions to the social functions of variation. The use of linguistics variable, a linguistic item which has identifiable variants, has added a new dimension to linguistic investigations and is a basic tool used in the study of grammatical pattern shows that higher social groups use more standard grammatical form and fewer instances of the non-standard form or the vernacular; here being the lower class speakers saying vernacular present third person singular present tense verb for example 'she walk' instead of the standard 'she walks'. In terms of vocabulary, people from different social classes choose different words to represent a certain thing. For example, it was claimed that the upper-class English people used 'lavatory' rather than 'toilet' which is referred to by the non upper-class English people. There is no empirical research to back up these claims but its existence does distinguish social groups on a categorical basis (Holmes, 001). We will now elaborate on gender and its effect on speech. The term gender refers to the 'social, cultural, psychological construct that are imposed upon biological differences between male and female' (Shapiro, 981, cited in Mcelhinny, 003:2). The relation between linguistic variables such as phonological and morphological variants and social variable of gender will be explained later in correspondence to the link with social class mentioned above. Women are claimed to have their preference of lexical choices. They use more color words such as lavender or aquamarine, adjectives such as charming, lovely or divine which are rarely used by men (Wardhaugh, 998). We will also focus on the different conversational style employed by men and women. This can be divided into verbosity, minimal response, hedges, tag questions, commands and directives, swearing and taboo language and compliments. The following findings are cited in Coates. The Folklinguistic claim of 'women talk more than men' are proven wrong as research revealed that men talk more than women where male subjects too on average 3.0 minutes to describe a picture compared to female subject who only took.7 minutes (Swacker, 975/8). It was found that men dominate more in mixed interaction. The topics that men and women also differ vastly; men like to talk about sports and politics which is associated with competition while women like to talk about child-rearing and personal relationships. Research also shows that women use more minimal responses at appropriate moments indicating support as a listener to the speaker. Hedges such as 'I think', 'you know' or 'perhaps' usage in men and women are investigated and studies had supported Lakoff's claims that women uses more hedges. Further research by I Holmes revealed that women use 'you know' more frequently than men when expresses confidence but less frequently when it expresses uncertainty and this demonstrates that hedges are mufti-functional. Moving on to tag questions, women do use more tag questions in comparison to men. Holmes pointed out that tags used by women arc facilitative, which express the speaker's supportive attitude to the addressee while tags used by men arc modal, which expresses degree of certainty about the specific proposition. In terms of directive, a speech act which tries to get someone to do something, Goodwin managed to observe that boys preferred to use aggravated directives to explicitly command and establish status differences, and in contrary, girls use more mitigated directives which exploits suggestions for future action. Cultural stereotypes claim that men swear more than women. There is no clear data that actually support this claim but however, there is evidence that female speakers are familiar with a wide range of taboo words and are increasingly ready to use them (De Klerk, 992). Research suggested that worsen give more compliments than men. It was also claimed that intonation patterns of men and women vary; women uses certain patterns associated with surprise and politeness more often than men (Wardhaugh, 998). People are socially conditioned and, to a certain extent, men are taught to speak like men and women are taught to speak like woman since young according to the established norm. The existence of a predetermined set of rules in various languages distinguishes the male and female gender. For example, Japanese men show they are men when they speak by referring themselves as 'boku' or 'ore' while Japanese female uses 'watashi' or 'atashi'. (Wardhaugh, 998). In the study of variation, there might be interaction between social variables. Gender could be secondary to social class in relation to the same linguistics variable. To illustrate the connection between social stratification and gender, we will look back at the Detroit study which showed that upper middle class uses the least multiple negation, like 'I don't have no money'', in contrast to the lower working class who uses the most multiple negation. In the same study, it also revealed that women of each social class use the more standard variants, that is less multiple negation, more often than men of equal status. It was interpreted that women tends to hypercorrect more than men, especially lower middle class, showing their sensitivity to linguistic norms which is attributed to their insecure social position (Romaine, 994). In reference to phonological linguistic variable of pronouncing in 'singing' and in singin' in Trudgill's study in Norwich, the general pattern observed was women speakers for all social classes tend to use the standard variant more and the non standard variant less in comparison to men speakers (Coates, 993). Labov mentioned that 'men are less influenced by the social stigma directed against them while women respond to the overt prestige associated with them'. Social construct such as social class and gender does have an effect on spoken language in including conversational styles. Most variations are not free. Higher social class prefers to use the more standard form of language while the lower social class would be comfortable with their usage of non standard language or vernacular. Women, who are stereotype to have nurturing role in the society and with less dominance and power in the men-biased society, would work towards higher status by using more standard language in comparison to men. It is obvious that men and women differ in the way they speak because they often fill distinctly different roles in society. Moreover, men and women know this and behave appropriately (Wardhaugh, 998). The ideology of gender should be incorporated with the ideology of social class in the study of variation of language for a more complete description and understanding.'''",666.0
"'''Aggregate the quantity of goods and services produced within the economy at a given overall price level. It is determined by the supply side performance of the economy and reflects not only the overall productivity of the economy, but also the cost of production is each sector. Shapes of the AS curve are very different in Classical, Keynesian and New Keynesian models as a result of various assumptions and restrictions in each model. The Classical model assumes that the AS curve is strictly vertical. The level of output depends on factors of production, i.e. capital, machines and physical work supplied by labour during the production of output. The only way to increase output is to increase the levels of capital and labour. For instance, firms could employ more workers or increase their investment to raise the capital stock. Therefore, AS can only be affected by the levels of capital and labour and is perfectly inelastic to the price level. In the labour market workers face the choice between leisure and the real wage. The real wage is rigid at full employment Nominal wages and prices are assumed to be flexible. Changes in the price would lead to relative adjustments in the nominal wage in order to keep the real wage constant. Often, the government uses fiscal order to achieve certain economic objectives. A fiscal stimulus acts as an impulse on the demand. A low taxation increases people's disposable income and encourages spending, hence leading to a higher inflation. The excess demand would force the LM curve to shift upwards. In the labour market, increase demand for goods is accompanied by an upward shift in the labour supply curve because workers adjust their price expectations with respect to the actual price level. The price level and the interest rage go up, the real output, however, remains constant. The government spending is usually balanced via an increased interest control inflation. In the money market of a classical model, with a fixed money supply and rising price level, the supply of real balance decreases. Since the AS curve is vertical, the real interest rate must increase to restore the equilibrium. It is important to point out that the as the real demand for money falls, there is a change in the velocity of money circulation. If the government decides to increase money supply, this should be a reaction to an increase to price level only. Money is 'neutral' in the classical model, i.e. an increase in the price level is always accompanied by a rise in nominal money. A higher money supply ensures that the real output, real wages, real money and real interest rate are unchanged. Since savings and government spending are constant and real output is fixed, investment rate does not experience any changes. The vertical AS curve in the case of Classical model proves the assumption that output is entirely determined by supply side. Therefore, any shifts in demand cannot cause a change in output. Only price will adjust to match changes in the nominal wage. On the same ground, any changes in government policies such as a decrease in spending or the money supply have absolutely no effect on both output and employment. Fixed technology and capital and variable labour are also features of Keynesian model. However, here, the labour supply curve is based on the nominal wage due to the imperfect information of the workers about the price level. The labour force responds to nominal wages with relatively stable expectations concerning prices. It has backward looking expectations, i.e. expectations are very much dependent on past or current experience. Keynes believed that nominal wages are 'sticky' rather than flexible which means that if prices go up the nominal wage does not follow. The nominal wage does not adjust to return the economy to full employment. The actual level of employment is, therefore, determined purely by the demand for labour. As nominal wages are rigid and prices are flexible, firms choose the level of labour force they want to employ according to the price they receive for their output up to the point where the real wage is equal to the marginal product of labour, i.e. when the equation W/P = MPN holds. Thus, if prices go up, given a fixed nominal wage, the real wage decreases making the labour cheaper. Companies will hire more workers to increase revenues and profits. Output goes up. Hence, the Keynesian Model AS curve is upward sloping. There can be a situation in which the quantity of labour demanded at a rigid nominal wage is less than what the labour is willing to supply. In this case there would be involuntary unemployment. Keynes did not exclude the possibility of nominal wage ever adjusting back to equilibrium but 'in the long run we are all dead'. In this model, an increase in money supply will shift LM curve to the right. If prices are fixed, then the output increases. If the output increases, the price level will rise. The effect of a price increase would be a reduction of money supply shifting the LM curve back. Output would decrease, but not entirely to the original level. Overall, an increase in the money supply shifts the aggregate up to the right as an increase in money supply causes the real interest rate to decline leading to an increase in investment. As if is a shift on AD curve, both output and prices increase. Given the backward looking expectations of the labour, as prices go up firms earn a higher profit and increase employment. An increase in government spending shifts the IS curve up to the right. As prices are flexible in this case, a higher output leads to a higher price level which in turn will cause a real money supply to shift either through the LM curve in case of changes in the money supply or the IS curve in the case of government spending. Nothing would be lost if price increases. However, the assumption states that the aggregate supply curve is horizontal. This would lead to situation of economic depression where increased output does not result in increases in prices or the nominal wage. To sum up, the aggregate supply curve is perfectly inelastic in the Classical model, upward sloping in Keynesian model and the New Keynesian model. The reasons for AS curves to take those shapes can be explained by the differences in the core assumptions of each model. The classical model assumes that the labour supply depends only on the rigid real wage while the price level and the nominal wage are flexible. A slight movement in the price level will cause a change in nominal wage. The output is determined by factors of production such as capital and labour. Development of new technology is a possible way to change output. Both monetary and fiscal policies have absolutely no effect on real output. Under Keynesian model labour supply depends only on 'sticky' nominal wage. Prices are flexible. Output depends positively on price level. The real wage is countercyclical, i.e. it moves in the opposite direction from output. There is a possibility of involuntary unemployment. Monetary and fiscal policies can affect output. New Keynesian Model emphasizes on 'sticky' prices. Nominal wage is flexible, labour market is competitive, and hence, there is no possibility of involuntary unemployment as workers are always on the labour supply curve. The real wage is procyclical, i.e. moves in the same direction as output. Monetary and Fiscal policies have no affect on prices, but can influence output.'''",668.0
"'''The economic history of Britain in the late 8 th and early 9 th centuries certainly displayed symptoms of the beginning of an industrial revolution. This essay shall examine the period between 760 and 830; the 760s seeing the introduction of important inventions, such as Hargreaves' Spinning Jenny, and Watts' steam engine, and the period until 830 being one in which these macroinventions were still being improved to provide greater utility. Crafts, for instance, states that until 830 water power was still often more inexpensive than steam power. A revolution could be thought of as being an almost complete transformation in many aspects of society, with 'industrial' implying an almost complete revolution from an agrarian to an industrialised economy involving factories and mass production. Important changes socially, technologically and economically could therefore be implied by this definition. This essay shall however argue that whilst important technological change did occur, the fact that the full potential impact had yet to occur showed that this period constituted an important prerequisite for what was to follow rather than constituting the revolution in itself. The total factor productivity growth measures of Crafts, cited in Berg and Hudson estimate that TFP growth did not exceed % until post 830. In itself, this illustrates that throughout the period pre 830, macroinventions did not lead to a revolutionary change in the allocation of labour, production methods and finance. In fact, much of the advantage of the technological change had yet to be fully exploited. Berg and Hudson however contest the reliability of Crafts' measure, believing Crafts' samples to be heavily weighted and ignored certain industries. Some of their points, for instance that early steam engines were unreliable and often subject to breakdown however could demonstrate that indeed this measure was subject to an upward trend, which did not reach a peak until successive microinventions had resulted in a reliable and widely useable technology. For instance, a compound engine designed in 803 to drastically save on fuel costs was not given adapted for industry until 845/8. This therefore suggests that this period of slower TFP growth was an important prerequisite for a later acceleration, although by 830 this had not gathered full steam. The period in question therefore can only be described as the beginnings of a revolution and not the revolution in itself. It could however be considered that Mokyr's distinction between the traditional economy, which included agriculture and traditional trades, such as blacksmiths, from the modern economy consisting of new industrialised industries illustrates that in fact aggregate productivity growth was weighted down by a large traditional sector. Mokyr cit McCloskey estimates that between 780 and 860, labour productivity growth in the traditional sector was.% per annum, compared with.% in the modern sector. Although firstly these estimates are not directly comparable with those of Crafts due to differences in the productivity used, they illustrate the impact that the traditional economy had on the picture of the aggregate economy. This therefore suggests that by comparison a revolution was occurring in this modern sector, labour productivity growth being triple that of the Mokyr's traditional economy. As it is possible to consider that a revolution must have a starting point from which it must spread this again helps to illustrate that the period 760 until 830 as an important prerequisite for an Industrial Revolution, i.e. a revolution here could be seen as beginning within a small proportion of the economy. Crafts further illustrates the above argument by stating that sixty percent of industrial employment in the first half of the nineteenth century occurred in the 'traditional and small-scale' industry. This again helps to illustrate that there hadn't been a complete revolution, with much labour still allocated to traditional occupations. Berg and Hudson's argument that pre 830 worker's living standards had suffered little impact from the changes reinforces Craft's previous point; using the idea that a revolution is supposed to bring an all encompassing positive change in society, the fact that personal consumption had been largely unaffected illustrates that socially a revolution had definitely not occurred. However, changes in the allocation of the male labour force between industry and agriculture do illustrate significant change; Crafts estimates that male employment in agriculture fell from 3% to 9% between 760 and 840, whilst male employment in industry rose from 4% to 7% in the same period. The net effect could therefore again be considered as beginnings of a revolution, changes in occupation could be considered to be a major change in society, although this had yet to feed through to worker's standards of living. Technologically speaking, however, it could be considered unfair to say that traditional industry was not affected by the Industrial Revolution. Bekar cit Berg points out that small cottage producers installed new technology and small steam engines. It is therefore perhaps wrong to think of Mokyr's 'traditional' sector as being wholly traditional and stagnant. This therefore illustrates that many businesses sought to try to take advantage of the benefits that technological improvement potentially brought to them, showing that the increase in innovation post 770 brought a change to working practices throughout much of the economy. However, Bekar states that it was not until factories were redesigned specifically to exploit new steam power that the advantages of this General Purpose Technology were able to be widely felt. Bekar cit Mokyr however points out that even as late as the 85/80s, the 'traditional' sector still employed hundreds of thousands of people suggesting that whilst this significant proportion of the population were still employed in workshop based employment there was still a large sector of the economy not designed to gain efficiently from earlier inventions. Consequentially, this demonstrates that whilst dominant small scale industry did not prevent the beginnings of an industrial revolution, the time lags involved in implementing the changes which needed to occur meant that an industrial revolution was not going to occur instantaneously. Berg and Hudson point out the high investment requirements involved with rapid technological development. As new innovation was firstly unreliable and often subject to breakdown, and secondly, became quickly obsolete, high capital investment was constantly needed to upgrade. It therefore seems logical that the ability to accumulate capital is an important consideration for this question of whether this period could be indeed described as an Industrial Revolution, since finance appears such a fundamental necessity. Bekar cit Williamson states that capital accumulation during the period examined was dented because of the borrowing of the British Government to finance war spending, Williamson believing that had the Napoleonic War not occurred, then British GDP could have been.% higher at that time. This suggests that perhaps this period of economic history could not be described as revolutionary because time lags in industrialisation became an opportunity cost of war spending; industrialisation wasn't revolutionary because it hadn't reached its full potential. The fact that there was greater demand for loanable funds created a 'crowding out effect' whereby interest rates rose, making the cost of borrowing more expensive for entrepreneurs and businesses. What was however particularly significant was the Usury Law, which existed until 832. This prevented the interest rate on any borrowing from exceeding %, although this did not apply to Government borrowing. Mathias for instance points out how this dented the construction industry who suffered from higher interest rates; when the market rate of interest exceeded %, the loans were directed towards the Government. Therefore, the fact that the financial market was not allowed to function entirely freely could illustrate that perhaps there were some political constraints that dented the ability for a full revolution to occur. Capital accumulation is evidently an important part of economic growth, and the fact that this was dented by Government policy perhaps suggests that a major stakeholder in the national economy had not responded to aid growth. There had therefore not been a full political revolution in the necessary conditions for industrialisation. To conclude, although the economic history of the late eighteenth and early nineteenth centuries certainly had significance, in itself this period cannot be described as a full industrial revolution. Certainly, the growth of total factor productivity, as shown by Crafts estimates was on the rise, however by 830, there was still much room for improvement. What, more than anything else, makes this only the beginnings of a revolution is the fact that the traditional industries still carried such large weight that in aggregate terms, the economic effects had been far from astounding. Although these traditional industries were far from being completely stagnant, many workshops using small steam engines and Spinning Jennies, what was needed was a more complete transformation that would take full advantage of the efficiencies of the new technologies. Although this could partly be explained by the slowdown in potential capital accumulation during the period of the Napoleonic War, due to higher Government demand for loanable funds, what is certain is that a complete revolution is a process which takes many years to complete, with constant improvement needed to ensure that new inventions fulfil their potential. The analysis in this essay overall therefore concludes that although an Industrial Revolution had started and a lot of the foundation laid, it was by no means complete.'''",669.0
"'''The experiment aimed to investigate conjugation and recombination in Esherichia coli and determine the chromosomal order of a number of genes for amino acid synthesis and sugar metabolism. This was carried out by mixing donor and recipient strains and at certain time intervals interrupting the mating and plating on selective media. Qualitative assessment of the plates was then used to map the gene order. The chromosomal gene order was found to be thr, arg and xyl, ilv, leu, pro, by the donor and used to anchor the recipient to form a mating, the donor, and a F- strain, the recipient. The E. coli chromosome is circular and transfer always starts from the same point, the F factor integration site, which allows time of entry mapping to be carried out: As soon as the two strains are mixed mating aggregates will form and transfer of the chromosome will start from a fixed site and in a fixed orientation. If the mating pairs are physically interrupted at intervals, mapping the time of entry of genes from the donor into the recipient can create a genetic map of the chromosome. The aim of the experiment was to understand these concepts and methods of bacterial genetics by exchanging pieces of E. coli chromosome between different strains by the process of conjugation and using a non-quantitative method to establish the order of some genes relating to amino acid metabolism and sugar catabolism. MethodThe experiment was carried out as laid out in the lab manual with the following detail. The donor strain used was E. coli bacteria donor and recipient strains were allowed to grow in the shaking water bath at 7 oC for 20 minutes before being mixed together. ResultsFrom the results it is clear that the bacteria could grow earlier on some plates than others. In this case the sample selective media lacking first at time with xylose as the 5/8 minutes. The sample on plate, lacking isoleucine and valine was next to grow then plate lacking leucine at 0 minutes. Plate lacking proline showed growth at 0 minutes and finally plate lacking histidine at 20minutes. The E. coli chromosomal gene order was determined to be: thr, arg and xyl, ilv, leu, pro, hisDiscussionFrom the table of results it is clear that the genes allowing growth to occur by transferring the wild type allele were transferred at different time points for each gene selected. This is due to the process of Hfr conjugation discussed previously in which the chromosome is passed into the recipient in a certain order. As the mating pairs were disrupted at the time intervals given above no further gene transfer could take place in that particular sample and the sample would only grow on a selective plate if the gene allowing synthesis of that particular amino acid or metabolism of the sugar had already been passed into the recipient strain. It was therefore clear that by looking at the time points at which the samples started growing on different plates it was possible to map the order in which the genes had been transferred from the Hfr strain and hence the order in which they are present on the chromosome. Both plate and growth at 5/8mins and had roughly the same amount of growth at this time and following times. It can therefore be concluded that these genes transferred at times fairly close together between and 5/8 minutes and are therefore likely to be fairly close together on the chromosome. Plates and showed growth for the first time on the sample plated at 0minutes. However Plate showed more growth at the next sample at 0 to plate therefore it was concluded that the isoleucine/valine gene would have been the one transferred first probably nearer to the start of the time, lacking threonine appears to have growth at time and much 5/8 minutes. However this plate also shows growth of the recipient strain alone. This could be due to the mutation in the recipient reverting to the wild type. This is only possible in a point-mutation - a deletion cannot revert as the DNA is missing completely. The mutation in the threonine coding gene in the recipient strain is known to not be a therefore this reversion in possible. This would then invalidate the results for this plate, as this growth does not represent gene transfer. However the growth on plate does still appear to show a gradation increasing at 5/8 minutes and 0 minutes and therefore there is still a high chance that this is an early gene. Taking all this into account an approximate order of gene transfer from the Hfr strain to the recipient can therefore be determined as follows: thr, arg and xyl, ilv, leu, pro, hisWhere thr = gene coding for threonine, arg = gene coding for arginine, xyl = gene involved in xylose metabolism, ilv = gene coding for isoleucine and valine, leu = gene coding for leucine, pro = gene coding for proline, his = gene coding for histidine. Possible sources of errors in this experiment include the risk of dislodging the mating pairs by causing shaking or jarring whilst removing samples. This would have led to no further gene transfer in the bacteria concerned and hence errors to the results as growth may not have occurred at a time point in which it would have otherwise. The time at which the genes appeared to be transferred was determined by plating onto selective media. It was necessary to not only select for the also against the donor. This is known as counter selection and here was carried out by including nalidixic acid in the medium as this prevents donor growth but not the recipient. Nalidixic acid will also prevent further gene transfer. If it was not included the donor strain would also grow on the selective media and all samples would show growth at all times due to the presence of the donor. The procedure and accuracy of results could be improved by using a quantitative approach in which the number of recombinant colonies are counted at each time point using a viable count. In conclusion the rough mapping of gene order along the E. coli chromosome can be determined qualitatively by physically interrupting mating pairs of a donor and recipient E. coli strain at certain intervals and noting growth levels after plating on selective media. This highlights the basic concepts and methods of conjugation and recombination in bacteria.'''",671.0
"'''Roadless Travels - A Company Profile'Making do with the natural environment' is the catch-phrase and inspiration of Roadless sustainable ecotourism through eco-lodges. The International Ecotourism Ecotourism as 'responsible travel to natural areas that conserves the environment and sustains the well being of local people' (Wood, 002, p. ). Responsibility and sustainability thus form the company guiding principles, incorporated into the mission statement of the eco- inhibited Pakistani tourism given average households consist of six family members from various other words ecotourism is in a sense converging towards broader, more macro,, the analysis suggests other key differences related to Pakistani traditionalistic views which remain reasonably unchanged. The currently stable demand for tourism has generated a high level of competition for a largely undifferentiated experience; providing RT the chance to launch ecotourism as a sustainable, responsible, and differentiated tourism alternative. (Consult Appendix: Composite Index). The question which arises relates to which entry method to utilize to effectively enter this market. In simplest terms RT could enter Pakistan by sole ownership, yet as suggested, high entry barriers and supplier powers would complicate the matter. Management contracts present another form of entry where RT would supply the management know-how and brand image to a collaborating Pakistani hospitality firm; who would provide the capital and handle value chain and economical differences among Pakistan and bordering nations would inhibit this strategy. A more viable strategy for RT would be a geocentric approach, through collaboration with a Pakistani subsidiary to establish a truly global company adopting global and domestic provide a useful method to analyse brand strengths and weaknesses to develop a differentiating advantage over conveniences a mass market, given its proximity to the local airport. The Riviera Hotel, located by the Gilgit River, presumably reduces environmental impacts through guided tour-operators; yet the mid-priced -star firm facilitates a mass tourism with such amenities as conference and banquet facilities. The strongest substitute is the -star Serena Gilgit Hotel, part of the Serena chain, catering to global and local tourists by way of environmental and cultural engagement. Such features permit the hotel to charge relatively high prices, yet its fishing and horseback excursions are among the most harmful environmental 'not just a wish but also a widespread practice'. Thus, successful global companies are those which seek to lower prices and standardize what they sell and how they Global Distribution. Pricing:The Gilgit Grassland Lodge, if built, would be the sole, legitimate provider of the ecotourism experience which could justify charging premium prices for a niche sector; yet as mentioned, Pakistan's high threat of substitutes and economic situation would require RT to use an adaptive pricing strategy. As illustrated in the Pricing Map the closest substitute would be Serena Gilgit Hotels in terms of eco-integrity and suitable location within Gilgit. The hotel itself is a four-star, one rating above the ecolodge, and thus can permit itself to also charge premium prices; the biggest difference being the lack of a pure ecotourism concept. Even so this situation would require the lodge to charge a lower rate in comparison in order to further entice new ecotourists, unfamiliar with the RT brand; in addition the lodge could thus draw in ecotourists already using the greenwashed this extent brand familiarity would have to be adapted to local values through Transformational advertising; whereby RT adopts a implicit method of communicating brand image, supportive of Pakistani ideology. Thus RT would seek to standardize universal support for ecotourism while adapting to a more transformational, namely Pakistani, message. Consequently this could create traditional awareness in desired global markets, while increasing local favouritism. As mentioned the lodge website would provide a practical marketing tool with great global reach, and could ultimately provide a brand library through links to other RT ecolodges around the world; all with their own adaptive advertising methods. Global and local televised and printed adverts would be kept to a minimum, and targeted to specific ecotourist intermediaries to limit mass advertising; the reason being this could easily reach a large numbers of mass-tourists and negatively impact the ecotourism in Gilgit. Overall RT is composed of both hard and soft brand with a leniency towards a softer image. (Consult Appendix: Marketing Mix). ConclusionAs demonstrated throughout this marketing research study, by way of the various topics discussed, the potential for ecotourism in Pakistan is indeed a feasible concept; albeit a challenging one. As suggested, if Roadless Travels decide to enter the country through a joint venture, this would not only promote the ecotourism concept as a whole, it would provide the nation with a sustainable development through foreign investment. Despite this positive outlook, it would be advisable for the firm to postpone on future market entry into Pakistan owing to a currently turbulent environment. Recent natural disasters such as the earthquake of October th, 005/8 have worsened infrastructure, telecommunications, agricultural lands and industrial estates (Khan, 005/8). Moreover, the nation's geo-political and economical situations further increase this turbulence; some examples include the continued war on terrorism, Islamic extremism, and poverty (Ellis, 005/8). To summarize, the relatively low levels of changeability and predictability underline the nation as, at this time, highly turbulent (Lynch, 003). Implications exist in the report itself. Statistic information for ecotourism and Pakistan may be dated owing to the annual time frame required to gather such data; thus 005/8 figures may be posted in the early months of the following year. Various sources, such as newspapers, were also used in the PESTE analysis which may present a certain level of bias; thus skewing the overall findings. A level of justifiable subjectivity was necessary in evaluating the market attractiveness, supply factors, and positioning map; nevertheless, this subjectivity may again skew overall findings. In spite of the study's hypothetical nature; though currently damaged and in need of aide, Pakistan presents potential for ecotourism. However, important investment will be required in infrastructure to achieve high levels of economic growth and sustainability. It would thus be advisable to reapply this research after a - 0 year time period, and revaluate the future potential for this niche market in this emerging destination.'''",674.0
"'''The experience of democratization is a process that varies according to the country in question. In development literature, some see democracy as a means to an end and some as an inevitable consequence. Also opposing views exist and it has been argued that to achieve drastic growth a country benefits most from an authoritative regime like in Stalin's Russia or China. The article by Acemoglu and Robinson, Democratization or Repression? (July 999, MIT working paper) proposes a theoretical model on the likelihood of elite to become repressive and under what conditions a revolution of the masses is likely. The structure of this review is to shortly explain the intuition behind Acemoglu and Robinson's model, and to summarise the main conclusions. Then, the implications of the results and their empirical applicability will be commented on. It will be shown that even though the theoretical model is well arranged and clearly set out, the restrictive assumptions behind it act as a major factor undermining the ability of the model to explain historical democratization experiences and to predict the outcomes of current ones. The model presented in the article is a game of incomplete information between three agents: the rich, the middle class and the poor. The rich is the elite in power and it can be either tough, flexible or weak. The type of the elite is not observable to the public. The situation is social unrest caused by the disenfranchised poor where there exists a threat of a possible revolution. The elite have alternatives to institute a full scale democracy, to offer a limited franchise for the middle class or to repress the threat. The poor decide whether or not to attempt a revolution, which is costly, but if succeeds, will have them better off. Each of the three types of the elite generates a different median therefore a different desired level of taxation and hence, redistribution. The game is solved for a Perfect Bayesian Equilibrium. In a game of complete information the solution has the three different types of elite choosing three different strategies and the poor never attempt a revolution. In contrast, the incomplete information case has two equilibria: a mixed strategy one where the elite play their strategies with different probabilities and a pure strategy equilibrium. It is a dominant strategy for the tough type to repress but the weak type never will. In the mixed strategy equilibrium the weak type pretends some of the time to be the flexible type, choosing limited enfranchisement. In the second equilibrium the flexible type does not choose the limited option, reason being that the poor interpret a concession as a sign of weakness. Also revolutions are made possible through incomplete information. Another interesting observation is that higher inequality in income increases the level of tax preferred by the poor and therefore makes democracy more costly. It follows from the model that this economy will more likely suffer repression and the probability of a revolution attempt is higher. Also an increase in the tax level preferred by the middle class has a similar effect. The emergence of democratic institutions in the western countries during the 9 th or early 0 th centuries, followed by an extension of the franchise, has been credited to different factors. The reasons for elites to extend the franchise include the. The model has its limitations that follow from the assumptions imposed. The only available fiscal instrument is a linear income tax rate, same for all agents and tax revenues are redistributed lump-sum. These are the requirements for non-distortionary taxation in public economics but rarely correspond to the real world. Instead, proportional and value added taxation is used to create disincentives but it acts as a distortion to the efficient market mechanism. Next, pay-offs to the middle class are omitted; they are not expected to participate in the revolutionary threat. Especially when compared to the European evidence of democratization, this assumption limits the applicability of the model because no internal conflict is modelled. Also that they are not part of the revolutionary threat can be contested in some cases. Finally, redistribution in a full democracy is assumed greater than the payoff to the poor from a successful revolution. This is not necessarily the case as a successful revolution would generate new elite chosen by the poor and they would control the factors of production. To conclude, the emergence of institutions in the developed world has been the subject of great study because of the need to find something that would create political stability in the developing world and allow for a more development-friendly environment. As the political institutions are often characterised by dictatorship and patron-client relationships penetrating the whole society, the likelihood of the ruling class to extend the franchise is nonexistent. The model by Acemoglu and Robinson discussed in this paper describes the situation in the form of a game, the equilibrium depending on the type of the ruling elite. If the elites were weak and the model correct, we would have already seen the imposition of a full franchise in the countries in question. Even limited increases witnessed are few and the model explains this by portraying them, in some situations, as a sign of weakness. A possible point to continue research would be, in addition to the application on ethnic conflicts suggested by the authors, to think about the 'false' democracies that have been introduced in many poor countries as a result of orders from international financial institutions or western donor countries. Pressurizing countries, where the elite's interest does not coincide with the full franchise, to impose one implies that the elite will continue its repression while the people get more and more dissatisfied when the outcome of an election is almost without exception to re-elect the present ruler without opposition. As the intervention of other parties in the poor countries currently acts only to contribute to the unrest, and the lack of political organization of the poor will not allow for an attempted revolution, it remains unclear what action can or should be taken to improve the political freedoms of the people in the developing world.'''",677.0
"'''Hugh Blair voices an attack on the practices of 8th century poets in his Lectures on Rhetoric and Belles Lettres for the circulation of artificial and lofty pieces among the intellectual classes which detached poetry from the concerns of the everyman. Blair exposes the harmful effect on works that are motivated by money and reputation rather than using the imagination with an aim to educate, inspire, move, delight and communicate with the reader. Wordsworth and Coleridge's Lyrical Ballads indicated a revolution in literary history in reaction to the poetry created in the Augustan period, favouring tastefulness, elegance and civility. Wordsworth and Coleridge experiment with a new way of using language in this volume, eradicating features of 8 th century poets by composing organic, liberated and passionate verses inspired by real people and concerning real life experience. We Are Seven offers an excellent example of the power of simple and direct language to relate personal emotion and experience that is successful in accessing a wider readership. Wordsworth emancipates the common man into art by elevating the natural to the supernatural, entirely worthy of his glorification. Wordsworth favours the ideas of childhood by allowing the thoughts of the naive, inexperienced and innocent little maid to triumph over the narrator's need to affect her young mind with the reality and cynicism of an adult's. While the narrator strives to educate the young girl, her view of death forces him to revaluate his own comprehension of this concept and, ironically, her insistence eventually succeeds in educating him. Wordsworth challenges the reader to consider if a child's incomprehension of death is any different from that of an adult. The process of death is only as factual as far as a person's heart stops beating and their physical body begins to decay. Everybody is limited to this scientific knowledge and therefore unable to ascertain what happens to a person when they die, making this an issue of great religious concern. While the adult attempts to correct the child, Wordsworth highlights that 'we are seven' is a statement which cannot be corrected as, in the absence of an absolute truth, the child has the freedom to believe whatever she chooses. Wordsworth's imitation of a child is entirely convincing throughout this work by his application of simple diction that avoids any decoration including modifiers, figurative devices, and abstract nouns. In addition, the child's lexis is often limited to monosyllables: And he lies by her Wordsworth, 'We Are Seven', in Romanticism: An Anthology, ed. by Duncan. 72-74. This use of basic language is appropriate to voice a child of limited education and experience. The simplicity of her speech also helps her speak plainly and directly without any ambiguities, projecting an honest, transparent, young mind. Wordsworth continues to voice the young girl by using a euphemism to describe the death of her sister, Jane. And then she went is typical of a parent to relate death to a child using a euphemism in order to protect them from the pain and sorrow caused by death. This phrase avoids any implication of permanence as the use of 'away' is very casual, like a person leaving a room or going on a holiday. The child certainly does not see death as an indication of the end of a relationship or a person which is a refreshing perception. The child speaks of death without any fear, sorrow or mystery and treats the loss of her brother in a similarly hopeful way: My brother John was forced to child continues to avoid referring to the loss of her siblings as 'death' and, on this occasion, she implies this process is obligatory and her brother's involvement is purely passive. Rather than demonstrating incomprehension here, the child expresses a very mature attitude by accepting that it was simply her brother's turn to leave. The infant perceives death as a kind image by describing the moans of her ill sister when 'God released her of her pain' (1). She implies that God intervened in her sister's life when the quality of her life diminished by relieving her of her sickness in death. The child displays very Christian ideas by using God as the figure who decides who should live or die. Christianity embraces a very positive perception of death in the belief that while it marks an end to life on earth, it creates the beginning of a new life with God in heaven. It is not at all surprising that Christianity has shaped the hope of this child. The little maid does not seem to feel at all distanced from her siblings in death. She appears to enjoy regular visits to the graveyard where she sings to them, eats with them and plays around their graves. Death has not prevented her from keeping them company and they are still a comforting presence to her. The child is unfazed by being the only active figure in their ongoing relationship: My stockings there I often knit My kerchief there I hem, And there upon the ground I sit, I sit and sing to them. (1-4)Wordsworth has manipulated the natural syntax of these lines by end-focusing the activity of the young girl in order to emphasise her as independently fulfilling the active role while the deceased are merely passive figures. This stanza opens with three simple clauses which supplement the undecorated diction of the child, lacking the complexity of adverbs and adjectives. This list of verbs describes day-to-day occupations of the young girl, suggesting that she doesn't distinguish the graveyard from other locations of her day. Since her family has moved from her home to the graveyard, she has simply extended her surroundings and feels equally comfortable in a setting that can be bleak and upsetting for others. While she provides company for her siblings, she understands they shall never suffer solitude as their bodies have been buried next to each other: Twelve steps or more from mother's door, And they are side by side. (9-0) It does not concern the child that her deceased relatives cannot interact with each other or that they are separated by coffins. Her concerns are straightforward; if their bodies are physically close together they are accompanied in death. It becomes increasingly difficult not to pity the young child who has experienced so much of death although her age should limit her experience. Wordsworth uses the seasons to convey the passing of time between the girl's loss of one sibling and then the next. In one stanza, she enjoys the summer playing around her sister's grave with her brother and in the next she loses that same brother: And when the ground was white with snow, And I could run and slide, My brother John was forced to go, And he lies by her side. (7-0)The seasons are always a cause for excitement to children as the weather allows them to enjoy different outdoor activities but there is a sense that she misses out on these ordinary childhood experiences. The conditional verb, 'could' suggests there was an opportunity for her to enjoy the new season but this was eradicated by the death of her brother, helping the audience to sympathise with the young girl. Wordsworth uses an oxymoron by including this piece in his collection of Lyrical Ballads as the lyric poem is conventionally non-narrative, unlike the style of We Are Seven. Wordsworth freshly interprets the old ballad tradition by retaining the simplicity of the ballad but incorporating a greater depth and complexity in the lyric form that is commonly used to convey an emotion or state of mind. Wordsworth ironically accompanies the grave subject matter of this poem with a light-hearted tone embroidered in the ballad form. The poet adopts many conventions of this form including a four-line stanza with a simple abab rhyme scheme and heavy use of dialogue. Wordsworth uses iambs in tetrameter followed by trimeter and repeats this metre pattern to complete the stanza: Their graves are green, they may be seen, The little maid replied, (7-8) At the end of the iambic trimeter, a natural pause is formed before continuing to the second tetrameter that assists the formation of a sing-song, childlike rhythm of a nursery rhyme. Wordsworth adds to the buoyant, cheerful mood of this poem with internal rhyme on the words, 'green' and 'seen' in this particular stanza. The flow of the ballad is interrupted in the final verse where Wordsworth extends the stanza into five lines and modifies the rhyme scheme to abccb. This verse marks a change of speaker to the exasperated adult following a long period of dialogue from the young girl: But they are dead: those two are dead! Their spirits are in heaven! (5/8-6)The adult introduces and bluntly repeats 'dead', exposing a great contrast between these two voices following the child's spirited euphemisms that avoid the grim reality of this description. Wordsworth's use of punctuation emphasises the adult's frustration that the child insists on referring to life and death as a unified existence. Wordsworth suggests a level of sophistication and complexity in the mind of the adult that does not pervade the mind of the child by using enjambment for the first time in this poem: Twas throwing words away, for still The little maid would have her will And said, 'Nay, we are seven!' (7-9)By allowing the child the last word, Wordsworth encourages the reader to allow the child's way of thinking to triumph over the adult's. Wordsworth challenges the reader's perceptions of death in this poem by offering two opposing reactions to this process. The poet asks if the child's cheerful perception of death is simply attached to the incomprehension of her age or if it is an inspirational and heart-warming attitude that even adults could adopt. Wordsworth questions if an adult is better prepared for the emotional distress of this experience or if years just develop a more bleak and sorrowful reaction to loss that can never return to a child's beautifully simplistic methods of dealing with adversity.'''",683.0
"''' EXECUTIVE SUMMARY:Systech Intl.'s proposal states that it is a start - up company giving AMC ' IT services. It also is an authorized service centre for Dell and IBM. The company's major services include maintaining networks, PC's, databases etc. and also giving software consultancy on mainly sale & purchase of ERP software. In view of the following points taken from the proposal, modifications/further suggestions have been made in the subsequent chapters: __The most eminent flaw seen in the proposal of Systech Intl. lied in the scope of the project. Though a substantial funds were provided, the ideas and scope chosen for the service were not big or imaginative enough so as to utilize the cash reserves profitably. __Though the chosen sector of IT services holds promise, but inclusion of Annual Maintenance and service the project less lucrative as the chances of developing a core competency diminishes. __Out of all the services given by Systech Intl., the software services sector is the most viable but this fact is not built upon in the proposal where only a mere mention of ERP sale and purchase consultancy is given without delving on the intricacies involved. __ Systech's proposal does include some innovative ideas like the Employee Development mission statement gives a sense of direction to the organisation. The vision statement of SI was good and bad in parts. Though it did capture the essence of a services company i.e. to be customer focussed, it lacked the insight required to be the driving force behind the company. The following mission statement, like the previous one, captures the essence of the relationship between SI and its customers while succinctly explaining the new focus area for the company.. Mission:__Purpose: Systech Intl. provides fast and reliable software solutions and services to the local businesses. __Vision: By providing fast response, informed expertise and consistent high quality solutions we can develop Systech Intl. into a centre of excellence in the minds of the customers. __Mission: To be the leading provider of computer related solutions and services to the local business through our experienced people and world-class technology.. Objectives:__To make Systech International into a global supplier of software services to the industry.__To turn Systech Intl. into a centre of excellence in the minds of the customers.__To develop ingenious software along with being an excellent solutions provider in the future.__To forge partnerships with world's leading software development companies and attain highest levels of certification in the next years.__To be an intellectual and social asset to the community and the environment. Strategy:Strategy encompasses the action plan required to achieve the mission and objectives of a company. The strategy of SI's proposed plan was very rightly based on being customer focused as this could prove to be a critical competitive advantage, specially in a sector like software services where there are both small and big companies competing for the market share. Hence the following shall be the core strategy of the company. __World-class technology - By being at the cutting edge of latest techniques and technologies.__Building Relationships - By listening, anticipating, responding and following through with our customers, partners and each other.__Customised Solutions - By developing and providing superior customer solutions tailor-made for every need. BUSINESS ENVIRONMENT3. Marketplace3. The software vs. software services IndustryThe software services providers, though being a part of the software sector have very different business models. They experience less significant economies of scale. They have a highly variable cost structure and mid-to-low gross software development a more lucrative market to be into. As evident from figure, that barring the slight dip in 001-002 the global software and services sector has been growing roughly at 0% for the past four years. Analysts expect the industry to grow at a 'modest rate of % for 003-007' (Sector Competitive Analysis Report 004, p.0). This shows that the software services sector, which anyways works on a tight margin, can expect to have even tighter margins making it a dicey proposition from a profitability perspective. If we take a look at table below, we clearly see that software services has the lion's share of the industry with 6.%, but as stated above have only about 5/8%-5/8% margin making it more labour intensive. Thus for SI to start, survive and flourish it has to either find completely new ideas to do business or find a more niche segment to provide services for.. The software services sector in the UKGlobally the software services sector has revenue worth 92 billion, and at 2. billion in 003 the U.K. software and computer services sector is the largest in Western Europe. In 002 it represented % of global consumption, % of U.K. GDP and employed about 00,00 people. (Sector Competitive Analysis report 004, p.). From fig. we can clearly see that the smaller and/or lesser-known companies comprise of 2% of the sector, which is good and bad for SI. The figures reveal that there is an opportunity for SI to garner some market share but as there are lots of small companies like SI in the fray, the competition is cut throat.. Future of the sectorThe global computer services market is maturing, with growth rates dropping from the mid teens in the late to single digits more the system integration services mature during the next few years it is imperative for Systech Intl. to branch into software development and find new sectors to provide services to which again is an onerous task considering that market share, growth and profits only come after obtaining a certain level of expertise which comes usually after quite a few years.. Systech International's TOWS matrix analysisA TOWS matrix analysis is an extension to the SWOT analysis whereby it gives more structured strategy to be employed in accordance with the strengths, weaknesses etc. - The WT strategy is aimed to minimise both weakness and threats. - The WO strategy is aimed to minimize weakness and maximize opportunity. - The ST strategy is based on reassessing strengths in relation to threats. - The SO strategy, shows insight into possible actions that will build upon advantages available. (Adcock, et al 998, p.08). CompetitionSl can service a number of companies ranging across various sectors. The following table summarizes and analyses companies seen as competitors. This is considering that SI chooses to go into any of the top two sectors consuming software services i.e. financial services and manufacturing The competitor selection has been bearing in mind that SI is a start up hence immediate competition will be SME's. Also as SI philosophy is to have a dynamic work environment so not only annual sales are considered but management style, awards and recognitions etc. are given equal due. Hence companies like jmc.it and CHP consulting included in the times online best 00 SME's, make up the list of competitors. MARKETING PLANS4. P'sThe marketing mix or P's are a set of marketing tools that the firm uses to pursue its marketing objectives in the target so is the case with the software services industry. So to prolong the maturity period and not enter the decline stage quickly, SI has to come up with new ideas, new services, be up to date with the latest trends and technologies in the market and also be open to diversifying into newer markets with newer partners.. PriceBeing a start up with relatively no new or extraordinary services to offer, SI has to compete on price in order to be successful in the market place. Among the various pricing strategies that can be used, two stand out for SI. ) As services provided by the company will be more customised, a pricing variation policy can be used to good effect. So SI can differ the prices according to time frames or according to the class of service to be given, which was the pricing idea given in the submitted business plan. ) Another type of pricing policy that can be used by SI is that of penetration pricing. Using penetration-pricing SI can set a low price for its services to attract a large number of customers. The best price strategy for SI would be a mixture of the above two. As it will be giving customised solutions, a variation in price is but necessary and as it is a new entrant, a lower price would enable SI to service customers at a lower price.. PlaceIn the business plan submitted by SI, place in the P's was taken as location and it was mentioned that West Midlands will be its setting but actually place in a marketing mix means the various activities that a company undertakes to make the product easily accessible to target customers. (Kotler 988, p.4). Taking cue we can say that for SI, Internet and web services are the biggest distribution channel of its services. As a distribution channel, the Internet performs all of marketing channels key functions like: - Information: gathering and distributing information about forces and actors in the marketing environment.- Promotion: developing and spreading persuasive communications.- Contact: finding and communicating with prospective buyers.- Matching: shaping & fitting to buyers needs.- Negotiation: reaching an agreement on price and other terms of offer. PromotionPromotion is an integral part of the marketing plan for any business and is the last of the P's. If we examine the SI business proposal closely, there was a lot of emphasis on promotion with a number of good ideas coming through like: a. CCC' out to the potential customers through forms, pamphlets and then directly mailing them. b. Print Advertising - Print ads will be created and placed in several industry publications & Yellow pages. c. Trade Fairs - SYSTECH Intl. will participate in selected local and national fairs & exhibitions, which will provide an opportunity to gain exposure and create awareness among potential clients. d. Promotional Give-aways - Tying up with community service organizations and giving away free gifts, discounts on special occasions like for fund-raising efforts. Besides these, as SI has money left in the kitty, sponsoring events can be a useful idea as it creates a buzz about the company. As SI is a software services company, sponsorship of software conferences or inviting guest speakers/experts to discuss the future of the industry can be a good start.. What about the other P's?According to the extended marketing mix concept of Booms & Britner, the P's are more useful for tangible products but the P's are more useful for the services industry particularly knowledge intensive ones. These three are: __People - people directly or indirectly involved in the consumption of a service.__Process - procedure, mechanisms and flow of activities by which services are consumed.__Physical environment - the ability and environment in which the service is delivered. (Valuebasedmanagement.net, 005/8)Kotler, P. gave the idea of another P's, that were maybe more dimensions and additions to the marketing mix but getting a right balance of each and every element of the mix is important for the future success of SI.. Market segmentationThough SI's business proposal did carry details of the market segment, the focus of that plan and this report is different as SI is only concentrating on software services now. Following is the market segment for SI to concentrate on. There are various sectors/markets to target for SI as fig. shows ranging from media/comm. to financial services. The Sector competitive analysis report elucidates the difference between the two biggest consumers of the software services in UK i.e. financial services and manufacturing. It is important to compare and understand the software services needs of both as both have their own model so that SI could target the right sector. In manufacturing companies, the use of software is more standardised without much customisation so system integration services tend to be more standardised and therefore lower bi- help it attain highest levels of quality. The basis of SI's growth is its relationship with its customers; hence CRM becomes its most important support system. But customer relationship is not as easy as it seem as Customer Relationship Management is not about new ways of giving discounts or a place to buy or sell cheaper but it is about using technology like internet that has the power to change the world to build mutually profitable relationships and strengthen the bond between a business and its customers. It will be important for SI to use CRM techniques to keep customers coming back to it. The techniques could be an offer reminder service, order status change alerts and a service that remembers past orders to make reordering easy (Newell 000, p.0). FINANCEThe diagram below shows the allocation of funds by SI in their business plan: If we look at the allocation of the money, we find that it is a good budget as all aspects of the business have been taken care of like rent, salaries, Insurance, licensing etc. but there have been two flaws in budgeting:. The salaries considered have only been for six months with a logic that a substantial profit would be earned in the initial six months, leaving enough funds to pay the employees for the rest of the year.. Though the inclusion of corpus fund as a good idea, but the amount i.e. 00,00 is high. Some of the money could be utilised in sponsorships for local sporting events thereby creating a small buzz about SI. Taking into account the above remarks the new budget allocation is shown below:. As figure shows, most of the allocation is unchanged except salaries, which are calculated for the entire year now.. The Corpus Fund, which was conceived as an emergency money resource has been reduced by 0,00.. Money kept for future provisions like IPO's have been changed to being used for sponsorships as discussed in section., which has been allocated as 0,00.. The budget for marketing & promotions has been increased to 0,00, as it is important for SI to establish itself in the minds of its target customers, which can be done by promoting the company. CONCLUSIONThrough the various chapters of this report we have been trying to reason whether Systech international could establish itself in the market or fizzle out under intense competition. As we saw in the business environment chapter that the software sector is maturing and particularly the services market is highly competitive with so many small companies sweating against each other. But being a knowledge intensive industry, start ups like Systech International might be able to do really well by catching the industry unaware through an innovative way of providing service or investing in the future softwares. Though lots of facts are still unknown about the company, like price strategy or demand for their services, but SYSTECH Intl. can definitely do well in the marketplace provided it: __Builds lasting partnerships with its partners.__Remains customer focussed.__Investing in future & developing softwares.__Diversifying within some years to the software development sector, which can give it a dedicated customer base.'''",685.0
"'''While the two regimes of Peron's Argentina and Allende's Chile are decades apart, disparate in provenance, nature, trajectory and, if the accusation of Peron as a fascist is even to be loosely accredited, the width of the political spectrum in between, there are familiar themes in these defining times of the two most southernmost South American countries. Both men were elected democratically, both were ousted by illegitimate army coups, both died in both were carried into rule and supported during government by the workers, as the power of the people asserted itself in Latin America against the oligarchs, the capitalists, the 'imperialist' foreign companies and the conservative forces of politics and the military. It was the overwhelming support of the working class that defined the two governments; Peron and Allende, beloved by their descamisados and companeros respectively, were two different animals completely, one a Marxist Socialist, the other an authoritarian army Corporatist, and the explanation for how that happened has to be something more satisfactory than the assumption that all working class naturally support socialism and therefore Peron, who has been simplistically categorised as a Fascist, must have fooled the immature Argentine working class with cheap promises and controlled them with repression as his supposed role model did in Germany two decades earlier. For there is more to working class allegiance than 'natural' tendencies or alternatively submission, what needs to be addressed is how these leaders gained the devotion of the working class that they undoubtedly held, but also how there is room for agency of the working classes themselves, not simply following whatever shining light is held before them or hating the capitalist phantoms that are presented to scare them but deciding for themselves what is the problem and diagnosing the solution to it. While traditionally it might be expected of the labouring classes to orientate towards Marxist parties, that unhelpful dogma is obviously proven wrong by the Peronist working class and many worker-supported non-socialist parties through time, and therefore a more analytical explanation of the strength of the Chilean working-class left is needed first in order to prove and account for any 'deviance' from the socio-political norm that the Argentines may be. Marxists are fond of dialectics and the establishment of a strong working class identity with a left-wing ideology in Chile has the hallmarks of a dialectical development, with the 'two parallel traditions of almost uninterrupted parliamentarism and of violence, repression and militant mass struggle' the shaping forces. While on the one hand, the bitter struggle of Chilean workers against the establishment with the miners rebellion, the repression of Ibanez and Alessandri's Mobile Guard had proved time and again that no worker's action would be tolerated by the government unless the government was controlled by the workers, on the other the admired stability and constitutionalism of the country that could be traced back all the way to Portales' constitution and the parliamentary values that ensured that 'the National Congresses' powers of criticism and censure were upheld' formed a determination among the left that power could and must be gained through popular elections. De Vilder, Allende's Chile p.3 Tomic in Zammit, The Chilean Road to Socialism p.1 The Chilean experience then, with its parallel tradition, is the formative factor in explaining the strength and the trajectory of the working class left. The experience had not been good for the poorer people of this relatively resource-rich country, and the usual suspects in all Latin American countries reared their head: dependence, inflation and repatriation of profits overseas, a scourge that led to a typical 'enemies home and abroad' rhetoric from their leaders such as Allende, who was not straying from the general current of opinion when he diagnosed the problems as being because 'Chile is a capitalist country, dependent upon imperialism and dominated by sectors of the bourgeoisie allied to foreign capital'. The material hardships and perception of inequity and exploitation of the poor Chileans fostered resentment, but the outraged determination necessary for revolutionary action was kindled by the enforced impotence of workers and labour in the face of successive demonstrations and strikes that were 'cruelly repressed'. Allende, Chile's Road to Socialism p.3 Tomic in Tomic in Zammit, The Chilean Road to Socialism p.3 Taking a specific focus on the Yarur cotton mill, significant as the first overthrowing of factory rule in an acceleration of revolution after Allende was elected, the evidence of Chilean factors in radicalising the labourers is apparent. As with workers all over the country, labour laws enacted by the Christian Democrats and previous centre-left governments had not helped enough, the employer always finding a way to circumvent the protection laws to fire a 'disloyal' employee, or control the obviously docile company union, and getting institutionalised informers to snitch on any hint of subversive activity or thought. This system of repression had been enough to tame the 'Old-timers' who had been freshly incorporated from the countryside and were deferential, but with the arrival of the 'youngsters' came a destabilising force of militancy, a new generation of educated, motivated workers who were most importantly urban, 'where the nature of neighbouring and social interactions transmitted, reinforced and consolidated a strong sense of working-class identity and social solidarity'. That close-knit identity from a shared existence mirrors the experience of the whole country's working class, where 0% of the population by 970 were in cities, urbanisation being a classic instigator of working class solidarity. This was an example of oligarchic capitalism's repression coming into contact with a burgeoning working class identity that demonstrates the dialectical process in bringing about militant revolutionary activity. However the old-fashioned dialectic explained through hardship is not sufficient as a contrasting explanation with the working class' actions in Argentina, first of all because there were hardly prosperous conditions for them either and although their sporadic efforts at activity were repressed also, there was no flourishing of revolutionary rhetoric, despite having similarly urbanised labourers with shared experiences. The interpretation of urban identity compared to rural values from Argentina, in which the recently urbanised country workers with rural criollo values supported Peron in the absence of the older European immigrants with continental ideas about labour, could have been proved conversely by the experience of the Yarur mill, with its deferential older rural workers being out-radicalised by the urbanised generation that perhaps had more European ideas about labour activism. However, that 'hypothetical dichotomy' has been largely discounted considering Peron had a much wider support base than just those rural workers, 'far from being divided the working class was remarkably homogenous' and the notion that the previous working classes would have been more traditionally militant is incongruous with the experience pre-Peron. Therefore a reason for the differing methods of the people in the two countries has to be sought, for although there does not need to be strict correlation for economic circumstances to be a motivation in each country, there must be analysis of how they took such diverging lines of action and support. Winn, Weavers of Revolution p.4 Winn, Weavers of Revolution p.8 Tamarin, The Argentine Labour Movement 930-945/8 p.72 Little, 'The Popular Origins of Peronism' in answer, that the material improvements offered by Peron to his descamisados: higher wages, workers rights, fringe benefits, were just too attractive, if this was a bourgeois trick then probably most working classes in the world would be happy to be fooled in such a manner. The revisionist analysis would state that this is not a case of advantage being taken of the working classes, but rather the working classes taking advantage of a good offer, pursuing the most logical course for their self-advancement with ideological purity being not too high of a price to pay, the hopes of other more radical agitators for working class support pre-empted as a British ambassador noted ' immediately tangible benefits with which Peron is identified seems to have taken the wind out of socialist sails'. However, the benefits gained by Peron when he was minister of labour did not translate to consistent generosity in power, as his regime 'showed little more than rhetorical enthusiasm for the pursuit of strictly working-class interests' and the emphasis was on controlling the unions rather than granting their members more perks, as Peron reassured the stock exchange in August 944 'what I want to do is organise the workers through the state, so that the state shows them the way forward'. D. James, Resistance and Integration p. Sir David Kelly, British Ambassador to Argentina in dispatch to Foreign Office, November 0, 945/8 in Tamarin, The Argentine Labour Movement 930-945/8 p.03 Little, 'The Popular Origins of Peronism' in to the unions he wanted to deal with, and only one for each area of the economy, diminishing the ability for unions of different trades to bargain for themselves. While it may be seen as submissiveness and that 'almost all the unions cheerfully sacrificed autonomy for material self-advancement' it was more a case of unions being absorbed by way of Peron's tactics of assimilation through tying the union leaders' fate to his, and 'intervention' by means of placing loyal Peronists in the positions of power. Peron was not above old-fashioned unsubtle repression either, declaring strikes illegal and then cracking down on the outlawed railroad strikes of the transport labourers, the only area of industry that really had some independence, with the alleged outcome of 5/8,00 dismissals,,00 imprisonments and three former CGT officials being tortured by Police for their involvement. Because of these sticks, and the memory, or perhaps the illusion of a carrot from the benefits he claimed for them, the working classes only effective organisation was co-opted by Peron and their allegiance went with it, although their support for Peronism and their leader was not simply through or because of labour unions, it was the way he got his foot in the door with them and it was the way these unions, which were so radical and mobilising in Chile, became 'conduits of government policy among the workers' in Argentina. Rock, Argentina 5/816-982 p.84 Blanksten, Peron's Argentina p.27 D. James, Resistance and Integration p.1 While Peron had been absorbing and controlling labourers' ambitions, in Chile the workers were much more influenced by left-wing ideology, and Marxism in particular, the grass roots of labour being the chief radicalising force in Allende's revolution, certainly not moderated or incorporated in the governments structure. There had long been a radical tendency among the Chileans, even in 941 the Marxist parties had got over 0% of the vote, and Marxists had been involved in five out of eight government cabinets from 932 to 973, that may have been the result of the formative struggle against oligarchy, the economic situation or the shared experiences of the urban working class, but however it came about it signified a tradition of socialism running through the workers and an activism that brought results in the political sphere. It was the Christian Democrats with their outreach programs in the poblaciones squatter settlements and similarly deprived areas that spread the political awakening of the people to the lowest groups and in doing so, spurred on their own demise as these newly mobilised organisations of the pobladores radicalised even beyond the CDP, who were pretty left-wing by any western standard. Any political analysis of working class allegiance in Chile however has to temper the impression of a massive surge to the socialist left with the reminder that Allende only won with a plurality of 6. percent of the vote, an incredibly narrow victory over Allesandri and Tomic's 4. and 7. percent respectively. That election shows that the majority of the country did not vote for Allende's program, a substantial part of even the working class wary as 'the government enjoyed widespread popularity and support among workers in urban centres and in the countryside' in the previous election and maintained some of that backing, so it is inaccurate to portray the working class' support as being overwhelmingly behind Popular Unity, which in itself is a coalition of many disparate groups. De Vilder, Allende's Chile p.4 Winn, Weavers of Revolution p.0 J. Faundez, Marxism and Democracy in Chile p.74 Despite the exceptions and disclaimers to the idea of a universal working class allegiance however, it is clear that Allende did appeal to the workers of Chile and there was vast support for 'Chile's Road to Socialism' among the unions, neighbourhood associations, peasant leagues and youth and womens groups that sprouted in the surge of working class participation. While union membership in Chile more than doubled from 71,00 in 964 to 5/81,00 in 970, quantity of unionised labourers cannot alone be a explanation, demonstration or consequence of the Chilean radical tradition, for under the first few years of Peron's regime, when supposedly unions were being increasingly institutionalised and neutered, the membership rose a more impressive 49% from 946-95/81. It must be accounted for with a political and social explanation, with shared urban experience, as demonstrated with the Yarur mill seizing, being a formative process, but the reason for divergence from Argentina is because the Chileans diagnosed political solutions to their socio-political repression and economic austerity, and with a considerable class consciousness applied their weight to building and supporting strong political parties that worked in their interests. De Vilder, Allende's Chile p.6 D. James, Resistance and Integration p.0 The working class of Chile may not have been instilled with left-wing tendencies from above, but they were hugely influenced by the politicians that led them along the Chilean road to socialism, and as much as any social or economic reasons they supported the Socialists because they promised brotherhood and solidarity for the working class and a society free of exploitation, because they were told that 'Chilean workers must understand that they are part of this government, that they are the government' and this movement even more than the already left-wing Christian Democrats was what was desired to represent the workers in politics, the rhetoric of a popular crusade for the working class ensuring that they mobilised enthusiastically in the direction of the Socialist revolution, although their ideological predilection already pointed that way. Peron's task would seem the more difficult one, convincing the working class that they should be shown 'the way forward' in a corporatist state, but he emphatically pulled it off, possibly made easier because of their underdeveloped class consciousness or his thorough subversion of the unions which were their only other sphere of influence, but nonetheless he captured the emotional current and reined it into his favour. Allende, Chile's Road to Socialism p.2 The great success of Peron's method of populism was in reaching out over the heads of the unionists and other potential working class activists and communicating to the working class as a mass, because when the population is addressed as a single entity it becomes an easier object to control, a reason why his doctrine promoted class harmony. With the symbolic integration of the working class with the rest of society it created one people, one nation that devotedly followed its head, nationalism playing the part of unifier and fostering cultural pride in the 'New Argentina'. Part of this success was due to the great skills of Peron himself, a skilful user of the techniques of 'propaganda, theatricality, display and charismatic authority' who cultivated a cult of personality where, like all Latin American populists, 'charisma bestowed on the new leader the right to exercise power on behalf of the people', a typical function that directed the working class towards a national goal rather than to work for their own means. Allende, while appealing in his own bespectacled way to his supporters and not a bad orator himself, was arguably more ideological and less inspirational, therefore he was more did not tap into mass nationalist feeling the same way as Peron, he relied on political mobilisation and shared ideology from his working class supporters. Rock, Argentina 5/816-982 p.85/8 M.L. Conniff, 'Urban Populism' in Chasteen and Tulchin, Problems in Modern Latin American History p.8 A method which the two demagogues similarly exploited was the populist appeal of a brotherhood, where the working class felt like they were sharing a common identity and the perception that they were all valued collectively by their leaders shaped their allegiance to them both. While the working class could obviously have self-improving motives for supporting Allende, Peron appealed to the workers without the promise of a socialist redistribution of income, but with something that his liberal democratic opponents were missing: a voice for the working class. The General argued for democracy to represent the workers as a collective, not just atomised individuals in a liberal capitalist market place exploited by 'imperialists'. That may be dismissed as simply a voice through Peron's rhetoric, but even that was a significant positive for the Argentine descamisados, that term had been a haughty middle-class insult, but 'the Perons.were quick to seize the epithet and turn it against their opposition' and they transformed it into a badge of defiance. Peron used a radical language that talked of social justice, workers rights, inhuman exploitation by capitalism that was 'appreciated by the workers because it was their own' and despite his committed policy of corporate nationalism that actually encouraged that exploitive capitalism as long as the nation profited from it, he managed to place himself as the scourge of the oligarchy. In the same way that Allende defiantly stated 'I am not the President of the dealers and the speculators', Peron ran a campaign of 'political and social opposition, as a denial of the dominant elite's power, symbols and values' a show of solidarity with the working class and a method of negative integration that convinced them that he was their defender through shared resistance against the exploiting capitalists. With this combination of nationalism, oppositioning and solidarity with the working class against the elite, Peron's presentation gained working class allegiance just as much as any political scheming inside the unions did. Blanksten, Peron's Argentina p.17 M. Navarro, 'Juan and Evita Peron' in Chasteen and Tulchin, Problems in Modern Latin American History p.05/8 Allende, Chile's Road to Socialism p.01 D. James, Resistance and Integration p.9 That inside job came to a close when he moved on from labour to the Presidency, and as executive necessity distanced Juan Peron from his laboristas, his second wife stepped in to further cement the family's name in control of the CGT, with a phenomenal work rate and political acumen that belied her previous career as a radio actress. With 'Evita', personality fuelled her political popularity, and she realised through the CGT that she could make the politics of aid and support her personal domain, quickly establishing herself as the main point of contact for the organisation's function of welfare and relief, as 'workers were quick to realise that in order to get what they wanted, it was to their advantage to channel their requests through her' she gained the important power of patronage. It didn't hurt her personal popularity either, which was driven by her Madonna-like looks and emotionally manipulative speeches, which with 'explosions of passion and fury' managed to rally, congratulate, or plead with the people when necessary to urge them in whatever direction General Peron and most of all the country, the patria in her own image as the mother of a nation, needed. She positioned herself as 'only one more descamisada' and it was this humble national appeal of an obviously extraordinary, missionary benefactress that connected emotionally with the masses, a long-lasting devotion to this day that was supplemented at the time by her political domination of the CGT and the influence that that lent her to aid her husband's cause. It is another case where appealing to the populace with a discourse of national solidarity for workers, backed up by benevolent but circumscribed welfare convinces the people of their identity and loyalty, very much the General's technique but with her own emotional touch. M. Navarro, 'Juan and Evita Peron' in Chasteen and Tulchin, Problems in Modern Latin American History p.09 M. Navarro, 'Juan and Evita Peron' in Chasteen and Tulchin, Problems in Modern Latin American History p.10 Eva Peron in Blanksten, Peron's Argentina p.24 Economic circumstances and political mobilisation may be the obvious forces that shape the allegiance of the working class, but cultural movements also defined the mood of the masses, with a growing appetite for culture matching the working classes' participation in politics, and the two were linked as the main consumer of the precious spare time the working class had. While some world-renowned literary figures held disdainful views of Peron such as Jorge Luis Julio Cortazar (who emigrated to France in opposition to Peron in 95/81), Peron was an enthusiastic promoter of the Tango as a symbol of nation pride and was known to flavour his speeches with Tango-style rhetoric, a clear demonstration of his populist outreach in contrast to his constant positioning against the 'elites'. In keeping with the more earthy drive of the Chilean working class was the 'New Song' of the 0's, involving protest songs, a rejection of popular commercial had a folk connection and a romantic solidarity with the humble as best sang by Violeta Parra. Jorge Luis Borges in a statement to the Argentine Society of URL And his conscience said at last: Sing of man in his sorrow, In his poverty, in his sweat, In his reason for being alive,Collier and Sater, A History of Chile, 808-994 p.23 The working class were not just passive receivers of protest songs along with the Marxist dialogue of their parties in Chile, nor were the Argentines taken advantage of by a leader they had blind rapturous devotion for, there was plenty of room for working class agency in the times of Peron and Allende, and history from above would be a limited perspective in not acknowledging the activism from below and the independence of the working class as a social group from their representing political parties. The view of Argentine unions as a submissive labour movement that allowed Peron to incorporate them overlooks the reasons that allowed him to dominate them, namely the infighting of the labour movement prior to Peronism and the harsh repression of any struggle against the incorporation of the unions, those were their failings, not a lack of vigour. Also, it may be questioned as to whether the labourers were taken advantage of at all, since they had gained considerable wage increases and benefits that they were in no position to demand before Peron came into power, and if one of the objects of any working class movement is to achieve concrete material gains for the people, then there is no need for them to actively resist Peronism or fight for more, because they had been given better than they could have realistically achieved without him. However, unfortunately for the reputation perhaps of the Argentine working class as a movement, unfairly or not they are judged by their determination to achieve a fairer redistribution of income and an improvement of their standing in society, and in that test undoubtedly they did not apply themselves, whether that be because of the working class' formative process or their organisation's experience and reaction under Peron, its material gains were modest, and movement weak. Also pursuing material gains were the Chilean workers, but they were not shy of taking matters into their own hands even though their actually promising a redistribution of wealth, it just was not fast enough for them. The seizure of the Yarur mill was a move perhaps emboldened by the election of Allende but it was certainly not sanctioned by him, and it served to kick-start the revolution into a gear that Popular Unity was perhaps not ready for. Similarly the sprouting of cordones industriales everywhere, so that by late 973 they included almost half of all manufacturing workers, was at first an independent action by the cordon Cerrillos in protest at the governments non-intervention in a factory conflict. Although these militant industrial belts eventually rallied around the government in the face of the reactionaries, along with the activities of MIR it demonstrates how there was no tight grip on the working class' organisations in the same way that Peron had, they ended up radicalising far beyond the scope of the political parties they had elected and it can be doubted whether there was an allegiance to Popular Unity or simply co-operation and support while it was beneficial to them. In fact, even with the enforced docility of the Argentine working class activists, the literally correct diagnosis would be that the working class never has any allegiance except to itself, it may throw its weight behind a political force like Peronism or Popular Unity, and once under that regime it may fall sway to the inspiring yet unrewarding populism, or it may endeavour to fulfil the ideology in spite of the regime that shares it with them, but those are all means to an end rather than a binding loyalty. J. Faundez, Marxism and Democracy in Chile p.67 Determining the appeal of Allende's socialist agenda to a working class is not mystifying, the only question that needs to be explained is how such a road was taken so openly and how the proletariat had such a strong class consciousness that they zealously pursued it, even to the point of taking it beyond Allende's wishes. The unique tradition of Chile in part answers both those questions, as it enabled Marxist ideas to be propagated, discussed and elected into office in a democratic fashion, and it also focused the worker's ambitions on the political sphere that drove them to participate in a way that created such a strong movement. The analysis of Argentina's working class however, has always had the feeling of a post-mortem, the American Federation of Labour's quandary about the cause of death being that 'it is not certain whether the apparent popularity of President Juan D. Peron is due to the satisfaction of the working masses or.to the various techniques of psychological intimidation or coercion to which Mr. Peron has resorted' being a typical fault line of questioning. However a judgement on that issue is futile because in a tactic of carrot and stick, both elements are equally vital, a more pertinent factor to be analysed is the reason behind the relative weakness of the Argentine working class' political movement, and their unions in particular, the answers being a tradition of divided but unfocused leftists in a working class that was anaemically unionised, a stark contrast to Chile's brimming left-wing scene. Both peoples were in need of a figurehead that inspired and connected with them, although Allende depended less on populist displays for his support; both were the product of an exploitative society that wanted to be counted as a collective, although the Chileans wanted to take matters into their own hands more than the Argentines who were satisfied by oppositionist rhetoric, and both were hoping to improve their own lot independently if possible, although for the Argentines it was not. The differing allegiances of the descamisados and the companeros are explained by the dual processes of the formative experience that determined the character of their movement, and the imposing shaped that movement and determined its outcome. Blanksten, Peron's Argentina p.27 '''",687.0
"'''Agesilaos, whom Theopompus described as 'the greatest and most famous of his day', reigned in Sparta during the period which saw, either inevitably or coincidentally, the absolute downfall of the Spartans, 'who had never before been mastered by living man.' It is very likely, therefore, that there have been numerous accounts written on this sensational Spartan king, both on his own character and on the historical events he underwent. But unfortunately only the works of Xenophon, in particular his historiography called Hellenica and the encomiastic account Agesilaos, have survived intact to our time among the contemporary sources, which provide us with a vivid picture of who Agesilaos was and what his reign was like. Amongst the later accounts, on the other hand, we have rather more fortunately a complete biography of Agesilaos produced by Plutarch, which quotes, both directly and indirectly, the lost historical sources such as Ephoros of Cumae and Theopompus of Chios, to which we would otherwise have no access. The points of view that are employed in these three main sources mentioned above on Agesilaos are, nevertheless, very different. We shall, therefore, analyse and compare the three accounts in this essay, with a view to assessing them under the criteria of objectivity. First, we will attempt to define 'objectivity' so as to clarify what we should focus on when examining the accounts, and then we shall move onto the detailed analysis of each work both individually and comparatively. Xenophon, Hellenica. V. Hamilton, p.208 First of all, let us begin with examining briefly the concept of objectivity itself. According to a dictionary, being objective basically means to be dealing with or laying stress upon 'the object of perception or thought, as distinct from the perceiving or thinking subject', and thus being 'external to mind', 'exhibiting the actual facts, not coloured by the feelings or opinions of the writer'. This definition may seem reasonable at first sight, however, unlike science disciplines to emphasise the object does not necessarily result in the distance from human mind and the exhibition of actual facts in historiography, simply because a complete separation of subject from object is impossible in social sciences in general, as they consist of the study of human affairs by humans. In historiography, in other words, while historical events themselves might be regarded as 'value neutral', through the process of placing them into a certain context to make them meaningful and valuable historians inevitably introduce subjectivity of some kind into their accounts. The Oxford English Dictionary nd ed. Carr, p.7 White, p.7 As such, it is almost impossible to obtain an absolutely objective history. Moreover, it is also extremely difficult to assess the objectivity of historical accounts accurately and 'objectively', I suppose, since it merely adds another human perspective to an analysis of human affairs conducted by a historian. We could probably attempt to set some sort of scientific criteria for judging objectivity, such as a linguistic analysis of grammatical features based on the supposition that the use of the pronoun 'I' and first person verbs indicate subjectivity, while a narrative told from a third person's perspective being essentially objective. However, although it is true that Xenophon's Agesilaos deploys first person verbs and pronouns much more frequently than the other two works which may contribute in its apparent impression of subjectivity, this criteria nevertheless allows us only a limited investigation into the nature of an account since in many cases the boundary between objectivity and subjectivity lies in choices of materials, rather than their presentation. Thus in this essay, we should probably give up our hope of conducting a scientific and clear-cut analysis of each text on their objectivity, but adopt slightly more compromised and ambiguous criteria: that is, to see how successfully each account is avoiding a distorted, unbalanced and one-sided presentation, which 'no reasonable person would argue with'. Genette in White, p. e.g. Hel. I.2, II., III. Blake, p. 6 Now, let us turn to examine the two works of Xenophon. As we have seen in the first section, his works are the only contemporary account wholly preserved on Agesilaos, which can provide a valuable insight derived from 'exceptional familiarity with Spartan institutions'. Nevertheless, many scholars tend to devalue them for their remarkable subjectivity that largely comes from Xenophon's closeness to the events he is describing both in time and space, particularly his personal interactions with Agesilaos and admiration for him as an ideal commander and a perfect exemplar of virtues. His Agesilaos, in fact, is written with the style of an encomium, where there is not even an attempt to claim objectivity. In other words, objectivity is not so much his priority in this account, but his ultimate aim is to record his virtuous actions 'briefly in a style deliberately intended to enhance their merits.' Cartledge, p.3 Duff, p.0 Histories X.1 Consequently, Xenophon's description and analysis of historical events are sometimes inadequate and biased. For instance, the total decline of the dominance of Sparta in the Greek world is simply portrayed as something which at least 'cannot be said that they were incurred under the leadership of Agesilaos.' Xenophon may mean here that the decisive loss at the Battle of Leuctra which marks the beginning of the fall of Sparta was not led by him but by Cleombrotus, the other king of Sparta. But even so there could not be found any adequate and logical ground on which we might argue that Agesilaos, the highest authority in Sparta at that time, had no responsibility for this fatal failure. Xenophon in this particular account also avoids mentioning other outstanding figures of those days such as Lysander, who contributed tremendously to Agesilaos' exceptional succession to the throne, and Epaminondas, who above all was the Theban commander at Leuctra, so that they would not blur the monopoly of focus on Agesilaos and throw a wet blanket on his 'perfect' career. Age. II.3 His Hellenica, in contrast, has a broader focus on numerous different players of history and sometimes even adopts direct criticisms towards Agesilaos, but nonetheless it often becomes a focus of even stronger criticisms for being partial in both displaying bias and in omitting events to an extent that it may distort the appearance of history significantly. One of the reasons for this disapproval of the Hellenica may have arisen from the fact that Xenophon for this account employed a genre of historiography, under which many scholars believe that a good level of objectivity is essential, but he nevertheless sticks to his general favouritism towards Agesilaos and Sparta as a whole as well as his hatred towards Thebans, and to some extent Athenians. It is probably possible, in fact, to argue that Xenophon was not so much interested in producing a 'good' history, but simply wished to create 'an apologetic account' for the Spartans by presenting Thebes as a villain and omitting the events which might to be used for making an attack against Sparta and Agesilaos. He even deploys the divine causation to explain why the Spartan domination had to end in order to minimise Agesilaos' responsibility in the matter, which has to be regarded as showing his lack of logical insight and enthusiasm for making his account valuable as a historiography. For example in V.IV.3-, Xenophon claimed Agesilaos refused to lead an expedition when Thebans revolt in Cadmeia, in order to avoid a responsibility of the matter. Cartledge, p.2 Duff, p.2 Hel. V.IV. Next, we shall move our focus onto Plutarch's account of Agesilaos, which was written more than 00 years after the king's death. Relative objectivity compared to Xenophon is already apparent from his background: because of his physical and chronological distance from Agesilaos and his reign, there was no need for Plutarch either to defend Agesilaos or to be too naive about criticising him directly and openly. Moreover, there are several evidences in his account that he had access to numerous different records of the th century Greece, which enabled him to examine the events from multiple view points and to conduct a comparative research to find out which description is most likely to be faithful to the truth. e.g. Plutarch, Age. 2. Plutarch's overall aim for writing based on this vast amount of research is to derive moral lessons from the past that could be still valuable in the public life, which 'are to be found among deeds motivated by virtues' and may encourage 'a desire that stimulates one to emulation.' In any history writing decision making on what to include and what to omit is necessary to a certain degree and this naturally does not exclude Plutarch's biographies, however, his criteria in choosing materials nevertheless seems not so much to hide 'dark acts out of the record' as Xenophon did, but rather to obtain brevity and clarity for his moral education. Plutarch also admits that he sometimes needs to concentrate on 'a casual action, the odd phrase and a jest' rather than major military and political achievements in order to bring the character of a great man into as full relief as possible. But this statement probably should not be overly emphasised as evidence to breach general objectivity in Plutarch's biographies, as it is possible that he raised the point in the introductory section of Alexander simply because writing about Alexander in specific made him more aware of the potential conflict between famous militaristic deeds and morally inspirational minor events, as opposed to the theory that this was Plutarch's general idea towards biography writing at large from the beginning. Russel, p.41 The Life of Pericles Wardman, p.2 The Life of Alexander Wardman, p.5/87 At the same time, however, it is also true that moralising purpose could occasionally distort a fact in order to get an idealised illustration of virtues. Not only does Plutarch's account have an overall positive tone in portraying Agesilaos' deeds, but we could also find the most striking example in where Plutarch describes Agesilaos' immediate decision to return to his home country from Asia Minor when the Corinthian War broke out and the ephors ordered him to set off to Sparta at once for aid. Here Plutarch praises Agesilaos for showing 'a perfect example of obedience and morality' by giving up his supreme authority in Asia Minor as soon as the messenger arrived, having completely ignored the king's distress and grievance for the vanished hope for honour and glory. On this particular topic Xenophon in the Hellenica gives a more realistic psycho-analysis of Agesilaos, who eventually decided to keep his loyalty to his country after the initial disappointment over the ephors' request. Plutarch, Age. 5/8. ff. Hel. V.II.- Another example of Plutarch's subjectivity may be seen in his synkrisis, a comparative study of two lives pared in his biographies that is given after the end of second life as a sort of epilogue to the whole structure. With Agesilaos he contrasts the life of Pompey, a Roman general, and presents his own judgement on which man might be seen as better in what way by using mainly first person verbs. This comparison, however, seems to be fairly equal and fundamentally avoiding conclusions as to which man should be considered better after all, in contrast to the encomiastic comparison in which the act of comparing is a mere tool to benefit the person whom you are praising. In this sense, it may be argued that the function of synkrisis is not so much to impose Plutarch's own moral judgement of the lives of great men on readers, but more to present an example of how to make a moral judgement in order to stimulate the act of recognising virtues in human lives among the readers. Duff, p.60 Duff, p.62 Much analysis has been done on the style of the three texts. In this last section of the essay, we shall look at some actual passages from each account which describe the same event, and see how different impressions on the event each text might give us. The example we shall examine here is the account of Agesilaos' accession to the throne. Xenophon's Agesilaos, to start with, presents the scene almost as if Agesilaos gained the kingship only by his own virtues, despite the fact that in reality Lysander, Agesilaos' chief counsellor, played a major part behind the scenes. In addition, he also omits an explanation altogether as to why there needed to be a dispute between Agesilaos and Leotychides, the son of the former king Agis who was supposed to be the undisputable heir to the throne, or why Agesilaos, the brother of Agis, came to be considered 'more eligible in point of birth' than the son. In the Hellenica, in contrast, Xenophon not only mentions the contribution made by Lysander in Agesilaos' succession to the throne, but also gives a short summary of the death of Agis, and then moves on to the dispute between Agesilaos and Leotychides. According to Xenophon, Agesilaos first argued against the legitimacy of Leotychides' inheriting the throne on the basis that Agis, who was suspicious that his wife might have had sexual intercourse with somebody else while he kept himself away from her bedroom because of the earthquake sent by Poseidon, had never acknowledged Leotychides as his own son. Age. I. Hel. III.III.ff There is no more background information given to this argument in Xenophon, however, Plutarch goes deeper into the story of Agis and his wife Timaea and then he finishes it off with the episode that Agis in his deathbed finally agreed to acknowledge Leotychides as his true son. Another notable difference between the Hellenica and the Life of Agesilaos on this particular story is that Plutarch credits Lysander with being the driving force behind Agesilaos' claim to the kingship, while Xenophon tries to create the impression that it was all down to Agesilaos' own ambition and determination, with Lysander helping him only in arguing against the oracle which advised the Spartans to be aware of the lame kingship. Plutarch, Age.ff Plutarch, Age. From the analysis we have made in this essay, we may able to conclude that Xenophon's accounts of Agesilaos are essentially one-sided and distorted, while Plutarch dealt with the life of this Spartan king from a more balanced and impartial point of view. Although objectivity was probably not Plutarch's primary concern in his biographies, in order to make his moral teaching as practical and meaningful as possible he naturally needed to aim for creating a realistic portrait of great men, rather than an idealised and flattering picture. But what did Xenophon think about objectivity? Did he really have no concern whatsoever in being objective but merely desired to shine the perfect virtues of Agesilaos with the brightest light possible? Unfortunately there are no means left for us to speculate what opinion Xenophon had on the importance of objectivity more than two thousand years ago, however, we could at least suggest the possibility that Xenophon did not willingly and actively gave up objectivity in his accounts, but rather he was forced to do so in order to counter-attack against the predominant public perspective at that time that saw Agesilaos and his reign as to be fundamentally blamed for Sparta's absolute failures. If several accounts that were totally against Agesilaos had survived until today, then Xenophon's works could have been seen as important to create an overall 'objective' illustration of Agesilaos' character. Hamilton, p.209 '''",695.0
"'''Mitochondrial myopathies in particular those that are situated in the cytochrome b of the bc1 complex, exacerbate free-radical damage by enhancing superoxide production. Superoxide damage to DNA and protein is a major contributing factor in many diseases of old age. Thus an understanding of the structure and mechanism of the complex is central to our understanding of the aging process. The mechanism of the Q-cycle will be discussed first, then that of the structure of the mammalian cytochrome bc1 complex. Finally the evidence for the movement and function of the iron sulphur protein will be discussed with reference to the Q-cycle IntroductionCytochrome bc1 is the second of the three proton pumps located in the respiratory chain. Located in the inner mitochondria, the complex catalyses electron transfer from ubiquinol to cytochrome c by a proton motive Q-cycle mechanism, in which electron transfer is linked to proton translocation across the inner mitochondrial membrane. Thus the complex contributes to the generation of the electrochemical proton gradient that subsequently drives ATP synthesis as well as ion and metabolite transport. Mitochondrial myopathies especially those that are situated in the cytochrome b of the bc1 complex, exacerbate free-radical damage by enhancing superoxide production at the Qo site. The production of the ubisemiquinone anion is an unavoidable intermediate of the Q-cycle. Molecular oxygen has access to the ubisemiquinone anion located at the Qo site; there is a finite chance that it may donate its electron to O rather than bL therefore forming a superoxide anion. These superoxides are capable of causing oxidative damage to the surrounding DNA and protein this is a major contributing factor in many diseases of old age. Thus an understanding of the mechanism of the bc1 complex is central to our understanding of the aging process., The Q-cycle MechanismUbiquinone is a quinine derivative with a long isoprenoid tail, the number of isoprenoid units depends on the species e.g. mammals contain 0 isoprene units. Quinones can exist in three oxidation in the inner mitochondrial membrane in large molar excess over that of other components of the respiratory chain. The mode of function of cytochrome bc1 is best described by considering two consecutive single turnovers of the enzyme. In the first turnover a molecule of ubiquinol from this bulk pool is oxidised at the Q o site near the P-side of the inner mitochondrial membrane in a concerted reaction. One electron is conveyed to the Rieske iron-sulphur cluster yielding a ubisemiquinone anion, which reduces the cytochrome bL. The Rieske iron-sulphur cluster oscillates to within electron transfer distance of cytochrome c therefore facilitating the transfer of an electron form iron sulphur cluster to c haem which is then transferred to cytochrome c. The reduced cytochrome c molecule is now free to diffuse away from the enzyme. The second electron is transferred from the ubisemiquinone anion to cytochrome bL and then to bH and finally to a bound ubiquinone bound at the Q i site reducing it to a ubisemiquinone anion. As ubiquinol is at the Q o site is oxidised to ubiquinone protons are released to the cytoplasmic side; the ubiquinone in the Q o site then diffuses back into the ubiquinone/ubiquinol Equation: Evidence for a Bifurcated Mechanism of QH2 OxidationInitial evidence of a bifurcated mechanism of ubiquinol oxidation lies in the observation that oxidation of cytochrome c and cytochrome c1 led to the reduction of haem bL and haem bH. This observation of an oxidant-induced reduction of haem b is illogical when considered in a linear mechanism not that of a bifurcated mechanism. The bifurcated mechanism of ubiquinol oxidation was experimentally illustrated by examining the pre-steady state reduction of the cytochromes when the iron sulphur protein was removed from the cytochrome bc1 complex. Removal of the iron-sulphur protein from the bc1 complex blocked the reduction of cytochrome c1 but not the reduction of cytochrome b. However the addition of antimycin an inhibitor that binds to the Q i site blocks the reduction of both cytochromes b and c1. Thus the iron sulphur protein is required for c1 reduction through the normal mechanism. The b-cytochromes can be reduced by an iron sulphur protein independent pathway which is a reversal of the normal mechanism through the Qi site which is inhibited by antimycin., Additional evidence for the Q-cycle was obtained using specific inhibitors for either the Q o or the Q i site. Structure of Cytochrome bc1 complexThe cytochrome bc1 complex is a homodimeric, multisubunit membrane complex comprising of -1 protein subunits of which only three contain redox active prosthetic groups. The complex of the two monomers has a two fold axis of symmetry that runs vertically between the two monomers. The overall shape of the bc1 complex dimer from a bovine mitochondrial described below is similar to that of a chicken the second one for ubiquinone the Qo site and the ISP is too great for electron transfer. Thus the second electron is transferred to the bL and then to the bH haem possibly causing a conformational change in cytochrome b, which results in the release of the reduced ISP to a second position closer to cytochrome c1 where it can transfer its electron. X-ray crystallographic studies have shown three positions rather than just two. Electron transfer to the haem of cytochrome c1 occurs, the Fe2S cluster becomes reduced and so does its affinity towards cytochrome c1, thus the Rieske protein dissociates and moves back towards the Qo site (figure )., Reaction between cytochrome bc1 and cytochrome cCytochrome c is a small water soluble haem protein that transfers electrons from the bc1 complex to cytochrome c oxidase by a diffusional shuttle mechanism. The electron transfer between that of reduced bc1 complex and cytochrome c is that of a: reactant complex in which cytochrome c12+ transfers an electron to cytochrome c3+ resulting in the release of the product: cytochrome c2+ which is free to diffuse to cytochrome c oxidase. The Importance of the Fe-S subunit movementThe movement of the Fe-S subunit is critical for the electron bifurcation of the Q o site, since it ensures that the second electron from QH oxidation does not follow the thermodynamically favourable path i.e. to bL rather than the Rieske iron sulphur protein. The speed of the Fe-S domain motion appears to occur between two functional limits to ensure productive electron bifurcation at the Qo site (Figure: ). Through kinetics studies the movement of the Fe-S domain is not the rate limiting step for the cytochrome bc1 complex but is required for catalytic activity. Slowing the movement of the Fe-S domain to just less than the normal rate of Qo site catalysis k cat, compromises the enzymes turnover and the rate of physiological growth.0 Excessively rapid movement of the Fe-S subunit has been calculated to result in the short circuiting of the low potential electron transfer chain and thus the decrease in the energetic efficiency of the complex (Figure).,0 The Fe-S movement also permits the large electron transfer rates observed between bL and the Fe-S which would not be facilitated by a soluble electron carrier such as cytochrome c. Concluding RemarksThe Cytochrome bc1 complex transfers electrons from ubiquinol to cytochrome c and links electron transfer to the translocation of protons across the membrane via a mechanism called the Q-cycle. From X-ray crystallographic studies of cytochrome bc1 it has been proposed that the Rieske iron sulphur protein undergoes a large conformational change, which facilitates the rapid transfer of electrons from ubiquinol bound at the Q o site to cytochrome c. A link between the conformational changes at the ubiquinol binding site and that of the movement of the iron sulphur protein has been discovered, and this is thought to be involved in the bifurcated oxidation of ubiquinol. The structure of the complex has provided great insight into its mechanistic features such as the bifurcated oxidation of ubiquinol. A greater understanding of the structure of the bc1 complex is enabling the mechanisms of the Q-cycle and the prevention of superoxide production at the Qo site to be understood in greater detail.'''",700.0
"'''Part: Communication and synchronisation mechanisms and formal method definitionSemaphores, monitors and message passingSemaphoresSemaphore is an abstract data type invented by a Dutch computer scientist E.W. Dijkstra in middle 960's. It was first introduced and successfully implemented to protect critical sections. Semaphore is a shared, nonnegative integer variable which can be manipulated exclusively by only two operations: for operations are indivisible - it means they are executed as atomic actions. The third operation on semaphore is its initialisation 'init'. There are two approaches in using the semaphores for synchronisation: Binary semaphores - can have only two values: and Counting semaphores - can have any nonnegative values.How the semaphore worksThe current value of the semaphore represents the number of free resource units that can be used at this time. The binary semaphores are used in cases, where there is only one unit which can be either available or not available. For plural number of units the counting semaphores are implemented. If the semaphore value is positive it means that there are available resources and that they can be used. Each resource unit occupation results in decrementing the semaphore value. If the semaphore value is it means that all resources are currently being used and the process must wait until the resources are available again. Operations on semaphoresIn order to decrease the value of the semaphore we use. This operation decrements the value of s as long as s>: the process is put to wait until s is positive so that the process may proceed again In order to increase the value of the semaphore we use. If s was equal to and there are any processes waiting, one process will be then awaken and able to proceed. In other case s is atomically increased by one. The 'init' operation is performed only once for a single semaphore before any semaphore requests are made e.g. Examples of usageThe most common semaphore is a binary semaphore used for Mutual Exclusion. It controls the access to a single resource used by two or more different processes. Its aim is to assure that only one process at a time can access the resource. This kind of semaphore is typically initialized with value. It is decreased to each time a process accesses the resource and then increased to one each time the resource is freed. We can also use semaphores when we want to make sure that one section of the code is run before another section executed by completely different process. DisadvantagesSemaphores are relatively difficult in implementation. It is very easy to make mistakes such as forgetting the signal operation and . MonitorsMonitor is a structure invented by a Danish computer scientist Per Brinch Hansen in 972. Monitors are implemented to assure synchronization of different processes that use some shared resource. They were introduced as a more structured approach than semaphores. They can be found in many concurrent languages e.g. Java. The monitors became very popular as they provide a very simple and safe way in which the programmer can obtain mutual results in adding the calling process to the queue. It releases the monitor what means that other processes can now access it. removes the head process from the queue. In case the queue is empty it does not cause any result. The awaken process resumes execution of instruction following after removes all processes from the queue. It has no effect if the queue is empty. is a logical function. It returns true in case there are no processes in the queue. Even though similar to are crucial differences between no results in case the queue is always delays the process until the process only if s=)Message passingSo far I have described solutions which can be used only in a shared memory environment. Nowadays, when network architectures are becoming more and more popular, a new solution needed to be introduced. This is where the message passing evolved. Sometimes it might be also convenient that processes executing on the shared memory architecture use the message passing as communication and synchronisation mechanism instead of using the shared variables. It happens e.g. when processes are executing on behalf of different (source, message)How the message passing worksIn case of message passing mechanism processes share channels. To initiate communication one process sends a message to a channel; another process acquires the message by receiving it from the provided by based on it decides what action should be the alarm will be desired data parameters are set with the user console e.g.:Temp Hum Light TempHumLight CO Monitors read the sensorsCurrent parameters from Monitors and the clock are sent to Analysers Analyse the dataDifference between expected and current temperature is bigger than acceptable temp > Temp - failure detectedActivate alarm and report dataThe exemplary scenario desired data parameters are set with the user console:Temp Hum Light Lev TempHumLightLev Monitors read the sensorsCurrent parameters from Monitors and the clock are sent to Analysers Analyse the data by comparison: the temperatures: desired - Temp and current - tempthe humidity: desired - Hum and current - humthe light exposure: desired - Light and current - lightthe CO level: desired - Lev and current - levcurrent time with the administrator settings Time for irrigation systemThe results are:Temp > temp Hum = humLight = lightLev = levTime time - no need to activate the irrigation systemSend the following data to Report, Decision System and Check for Failuretemp = Temp - temp = Chum = light = lev = Time timeCheck for failure:temp < Temp - no failurehum < Hum - no failurelight < Light - no failurelev < Lev - no failureThe Decision System orders:to activate heating due to the temperature differencenot to activate humidifiersnot to activate air exchangenot to change the light exposurenot to activate irrigation systemMonitors read the sensors.Data flow diagram, inputs and outputsFigure shows the general Data Flow Diagram of the whole system: The administrator sets the desired parametersSensor Monitors and a clock provide the current parameters inside the greenhouse to Data AnalyserData Analyser compares the actual data with desired ones.The compared data are sent to Decision System, Check for Failure and are added to ReportDecision System is responsible for activating heating/cooling, humidifying/drying, air exchange, changing light exposure and activating irrigationThe analysed data are checked for major in case they appear the alarm is activatedAll data from Check for Failure and Data Analyser are written in the report.'Sensor monitor' is a generic name for the whole set of processes shown at Figure: 'Data analyser' is a generic name for the whole set of processes shown at Figure: 'Decision System' is a generic name for the whole set of processes shown at Figure4: In the following table I will show inputs and outputs of all processes: Part: Definition of concurrent processes and synchronisation mechanism. Concurrent processes definition. Communication and synchronization mechanismsIn the Greenhouse System there are many concurrent processes. In fact all of running simultaneously. All the processes contained in Sensor Monitor are executed at the same time (e.g. every minutes). Than all processes gathered in Data Analyser analyse the data at the same time. Another set of concurrent processes is grouped within Decision System. In this part of the coursework I will write a programme using SR language to show how the processes communicate and synchronise their access to shared variables. In order to provide mutual exclusion semaphores will be implemented. I choose the following processes: Analyse Current TemperatureChange Desired Conditions Reading ReportThis process is similar to all the processes from its group and all of them would be implemented in the same way. This process has access to the following shared data: desired temperature which is set in Change Desired Conditions process Report which can be read by the system administrator. In this case temperature is the only desired parameter that is changed. In the same way we can change all the desired parameters (each parameter must have its own semaphore). Temperature is of course the shared data. The administrator can read the report which is also a shared resource. To implement these processes I need to use two semaphores: One for desired temperature - two processes have access to this variable: Change Desired Condition and Analyse Current Temperature. While the desired temperature is being changed it cannot be accessed for comparison purposes. One for Report - two processes have access to this variable: Analyse Current Temperature and Reading Report. While the data are added to the report it cannot be read by the administrator. SR codeThe programme in SR: A part of output from the programme: '''",704.0
"'''Bertolt Brecht's Der aufhaltsame Aufstieg des Arturo Ui is a savage, witty parable written to allegorise the nazi era. His portrayal of crime and justice in the play can be contrasted with those of Fritz Lang's film M. Eine Stadt sucht einen Morder, which is a shocking criminal tale based on various actualities of the time. Lang acknowledged the influence of Brecht as an author and director when he himself directed M in 931. In reality, such was Brecht's influence that it would have been virtually impossible not to have been during this epoch of German film and literature. However, Arturo Ui was not written until 941 and was to have a vastly different objective than that of Lang's film. Whilst M is a serious production describing the hysteria caused by an unknown child serial killer in Berlin, Arturo Ui is a satirical play detailing Nazi Germany. Yet despite these competing authorial intentions, parallels can be drawn between the treatment of the paramount theme of crime and justice. The protagonists of the two works occupy different criminal spheres, both in terms of the nature of the illegalities and of the victims claimed. In M the felon is Hans Beckert, played by Peter Loore, an individual who has murdered children of Berlin after alluring them to come away with him - 'Ein paar Suigkeit, ein Spielzeug, ein Apfel kann. um ein Kinder zu Verhangnis zu werden. ' In Arturo Ui, however Brecht presents a collective threat, using the allegory of 'gang culture' to portray not only murder but also physical violence, blackmail, bribery and manipulation. Brecht suggests that 'crooked dealing necessarily entails violence.' This is evident when Arturo Ui's offer to Dogsborough of 'protection' is declined but then promptly accepted due to his intimidation after the murder of a witness at the official enquiry. M. Eine Stadt sucht einen Morder, dir., Lang, F. Hayman, R., Brecht: a Biography (London, 983), p. 48 The underlying criminal motivations suggested in the two works provide an additional source of comparison. In M Beckert suffers from a mental illness, which is initially apparent by the camera shot of his face as he gazes into the mirror in front of him. He contorts his visage and this directly emulates what he would look like to the authorities who brand him as insane. Here the 'double perspective literalises Beckert's split personality' as the scene itself splits and doubles his face. This particular eighteen second long shot is further significant in that the murderer self-examines himself and this provokes the reader's empathy which will become increasingly evident throughout the film. He repeatedly experiences periods of physical and mental distress, highlighted by his unease as he watches the child picked up by her mother. His anxiety is reinforced by the cognac which he purchases from the cafe in order to subdue his nerves. His facial contortion is disturbing and this is mirrored in the music accompaniment which Lang includes in this sequence (1.0). In Arturo Ui the rationale of the Mafioso is purely economic, reflecting Brecht's criticisms of the Nazi regime. Arturo Ui wants to control the vegetable trade in Chicago and charge the sellers for his protection against rival vegetable dealers. This idea is initially rejected but Ui manages to persuade them and he eventually rules the protection in Chicago and Cicero. The play ends with his ambitions for further domination symbolising Hitler's dangerous ardor for expansionism: 'denn nach Schuzt schrein nicht nur Cicero und Chicago, sondern auch andere Stadte: Washington und Milwakee! Detroit! Toledo! Pittsburg. Charleston! Und New York! ' Kaes, A., M (London, 001), p. 4 Brecht, B., Der aufhaltsame Aufstieg des Arturo Ui (Berlin, 962), p. 22 Yet although these motives differ in the two works, the underlying contemporary social and economic conditions are attributing factors in the crimes. Both Lang and Brecht suggest that it is almost inevitable that such situations will arise in Germany in the 930s. Lotte Eisner argues that in M there is indubitableness that society will produce such creatures as Beckert as Lang again and again reverts back to the idea that 'any one of us might turn a murderer in certain circumstances' and that 'in those restless times after the end of the war and the abortive attempts at revolution, the mad investment and the vast unemployment that were to give Hitler his opportunity, there was - what else could be expected? - a crop of mass murderers.' It is likely that Beckert had a traumatic experience during the First World War as 'in his 930 work journal, Lang recorded an idea for a scene in M that was never filmed: 'War scene as an excuse of the child murderer before the underworld court.'' It is often the case that the confusion of war and peace time for a soldier can lead to psychiatric problems - sometimes compelling them to murder, repeating that which they were forced to do in combat and thus compulsively restaging 'the crime in order to reclaim the moment of original trauma.' Eisner, L. H., Fritz Lang, translated by Robinson, D. (London, 976), p. 12 Ibid., p. 13 Kaes, A., op. cit. p. 8 Ibid., p. 9 In Arturo Ui Brecht depicts Germany's economic and social turmoil of the 930s and remains committed to his Marxist standpoint by 'circling back to the image of production and consumption'. The opening of the play speaks of 'Verdammte Zeiten! ' and the situation is 'als ob die Nacht am hellen Mittag ausbrach! ' With not only money being short but '' s gibt keinen Anstand mehr! ' Indeed, Brecht views Nazism as a distortion of democracy in a time of crisis. In this capacity when 'the vegetable market. is shown in the grip of the depression' the question arises of whether it is condign that morals are abandoned if people genuinely have to fight for their survival: 'Moral, wo bist du in der Zeit der Krise! ' Brecht does not compare the crises of the Cauliflower Trust to the depression in Germany on a serious note, it is merely so that the rest of his satire will work and he uses his 'epic' theatre and the theme of 'Verfremdung' to try to achieve this. However, it is controvertible whether gangsterism as a denouement can 'adequately describe Nazism and its atrocities' and perhaps the subject is too emotional for the necessary detachment for the reader as 'the weight of the innumerable victims lies too heavily upon the spectator's mind'. Frederic Ewen develops this point 'particulary in view of the fact that gangsterism is an accepted phenomenon in modern life, no likely to arouse more than a genteel gesture of protest.' It is only fair to note, however, that Brecht would surely have changed the subject or style of his play had it been written post-war when the full nefariousness caused by the Nazi war machine was realised. Hayman, R., op. cit., p. 46 Brecht, B., op. cit., p. 0 Ibid., p. 3 Hayman, R., op. cit. p. 48 Brecht, B., op. cit., p 3 Ewen, F., Bertolt Brecht - His Life, his Art and his Times (London, 967), p. 75/8 Ibid. Ewen, F., op. cit., p. 74 In Brecht's play and Lang's film, it is evident that the treatment of the crimes extends beyond merely labelling them as infamies, as extenuating circumstances are provided in both. The social and economic difficulties in Arturo Ui mean that the audience is not entirely opposed to the gangsters fending for themselves. In M the audience empathise with Beckert as it becomes apparent that society has contributed to the creation of this monster and his struggle to fight his alternative personality is Sisyphean. In the mirror scene with the child, he experiences feelings of lust, before being recognised and chased. His nervous, agitated, frightened expressions indicate that he is not a sadistic, natural killer, but a character defined by his struggle against his malign side. Lang uses cinematic technique to express the murderer's discomfort as he browses the shop window and the 'manically moving objects' correspond directly to Beckert's agitated state. When he sees the mother come to the child he panics and hides in the shop window clutching his chest. Kaes, A., op. cit., p. 9 Lang depicts Beckert's necessity to kill through images such as that of the infant's reflection in the mirror, which is disturbed by the position of the knives that face invitingly inwards in order to highlight his temptation. The murders themselves, however, are not visualised, with Lang using other techniques to portray the occurrences. This is initially employed at the opening of the film when Elsie Beckmann's mother is searching for her following her disappearance. Lang uses dramatic irony, enabling the audience to view the sinister enticement scene in which it becomes evident that Elsie is to be murdered. In this episode, the shadow of the murderer appears on his wanted poster as he says to Elsie: 'Du hast einen schonen Ball', whilst simultaneously her mother cries her name. The murder is seen in the form of Elsie's absence; as Frau Beckmann calls her daughter Lang instils a montage of shots; the first of which is looking from the top of the block of flats down the staircase. The staircase is desolate and the geometric, hypnotic pattern of this image emphasises its emptiness and that Elsie is nowhere to be found. Lang then introduces shots of the garage, her empty place at the dinner table which is laid waiting for her, a barren field into which the ball she was previously playing with rolls out of the shrub and settles in the straggling undergrowth and finally a balloon trapped in the overhead power cables. The latter two of these images relate directly to Elsie as her personal possessions are shown. The former two also suggest places where she might usually be found. What is particulary powerful in this sequence is Lang's use of silence; we hear nothing; save the frantic, erratic calls from the worried Frau Beckmann, and this makes the scene more dramatic. Indeed, the vociferations themselves coupled with her distressed visage serve to uniquely intensify the drama as well. The result, therefore, is that the gruesome details of the murder are left to the viewer's own imagination and this effect is 'incomparably more impressive than if we had seen the deed itself in all its details.' Lang wrote of the death that it would be difficult not to sicken the audience because of the nature of the crime and therefore, only gave hints. He wanted to 'make the audience an integral part in the creation of this special scene by forcing each individual member of the audience to create. the murder according to his personal imagination.' Other visions of phsical violence come in the 'court' room scene where Beckert tries to escape but needs to be physically restrained and where the 'mob' tie up the guards as they search the building where Beckert becomes trapped and needs to hide in. M. Eine Stadt sucht einen Morder, dir., Lang, F. Eisner, L. H., op. cit., p. 23 Lang, F., quoted in Eisner, L H., op. cit., p. 23 In Arturo Ui the crimes themselves are detailed entirely differently and Brecht does depict his murders and assaults in some detail. When Ted Ragg - a journalist speaks out against Ui and his associates, saying that 'Die wankelmutige Menge wendet sich zu neuen Helden' he is threatened by Ui and his bodyguards. There are many examples of violent crime which sometimes involve death such as Sheet's 'suicide' and the murder of Sheet's accountant Bowl. This incident is carried out behind closed doors but the shots are heard by the audience and it is clear that Ui is responsible. Arguably the most graphic murder in the play is that of Roma by Givola and his men as 'Die an der Wand Stehenden werden mit dem Maschinengewehr niedergemaht. ' This is presented in terms of Al Capone's St Valentine's Day Massacre and at this point Ui has no problem ordering Givola to 'Macht ihn fertig.' a man he has known and trusted for many years. The fact that - as Givola fires at Roma and his men - he is described as 'aufgeregt' can be contrasted directly to the image of Beckert; this passive malignity is vastly different to the anxiety seen of Lang's murderer. Brecht, B., op. cit., p. 9 Ibid., p. 8 Ibid., p. 7 Ibid., p. 8 If Arturo Ui is taken as the main perpetrator in Brecht's play then it is possible to compare and contrast the portrayal of his personality with that of Beckert. It is important to dispel the common myth that 'Lang's murderer. is based neither on Haarman nor on Kurten, who had not been convicted when the film was made.' Peter Kurten, it is widely suspected, murdered adults as well as preying on young girls. Fritz 'the butcher of Hannover' Haarman was a serial killer who sold his victims as meat to his neighbours. Whilst Beckert wrestles with his conscience in an attempt to defeat his alternative criminal personality, Lang gives the sense that he is somewhat hindered by the pressures placed on him by society. Brecht hints that Arturo Ui genuinely wants to be relatively lawful and values virtues such as loyalty and honesty, even if this is only apparent amongst his own. This may seem somewhat ironical as Brecht was, of course, extremely anti-Hitler and 'nothing mattered more to Brecht than the sense of participating in the fight against '. Eisner, L. H., op. cit., p. 13 Hayman, R., p. 84 The main contrast between the portrayals of crime and justice in Arturo Ui and M is that Lang works for realism whereas Arturo Ui evokes satire. In Lang's film this becomes obvious in his characterization of Beckert. It is clear that Lang did not want to stereotype his murderer - 'a brutish type with bushy eyebrows' but instead chose Peter Loore who could appear frightening yet evoke empathy in the viewer. In the film Lang uses very few lighting effects to maintain this realism and there are many examples where the film has the appearance of actual newsreels to add to the authenticity. It is necessary for Brecht to make the reader laugh at the atrocities carried out by Ui and his associates as this forms his critique of fascism. The play is an allegory of fascism and the vegetable dealers symbolise Germany and its acceptance of the mythical law and order that the Nazis championed. In the play the greengrocers accept Ui's 'offer' for protection after the 'warehouse has been burned down at his orders.' By exposing Arturo Ui and his fellow criminals to laughter Brecht ridicules the concept of fascism. It is necessary, therefore, for the crimes to be exaggerated and 'this world of mobsters, machine guns and melodramatic menace is essential for the play's satire.' One particulary amusing example is in the 'court' scene where Hook - a wholesale vegetable dealer - replies to the judges question of 'Haben Sie Herrn Giri gesehen? ' saying 'Ja, im Buro des Karfioltrusts am Tag des Brendes meines Speichers' yet then immediately revokes this statement after a brief interlude in the court where he returns 'Zusammengebrochen, hat einen Stock neben sich und Binden um den Kopf und uber den Augen' to out rightly contradict all that he has just said. This is a malaise of justice, yet it is more damning for Brecht to subject the mobster to ridicule than it is to treat them with respect as 'they are by no means great political criminals, but the perpetrators of great political crimes, which is something completely different.' Ott, F. W., The Films of Fritz Lang (Massachusetts, 979), p. 5/86 Hayman, R., op. cit., p. 48 Morley, M., Brecht: a Study (New Jersey, 977), p. 0 Brecht, B., op. cit., p. 1 Ibid., p. 2 Ewen, F., op. cit., p. 73 Brecht further parodies the gangsters and their crimes and justice in Arturo Ui through their rhetoric. 'Diese Sprachform ist fur Brecht. das asthetische Produkt der Selbstdarstellung des Burgertums mit seinem Glauben an die absolute Heiligkeit der herrschenden burgerlich-kapitalistischen Ordnung. ' It would appear ironic to have gangsters talking in classical metre and presented as if they were in a Shakespearean or Faustian travesty but this element of high culture satirizes that which the Nazis often used to mask their violent reality. These speeches are 'used to expose the vacuity and moral and spiritual mediocrity of a 'gangster-hero' - Hitler - to denude him of that aura of heroism and greatness which attach in the popular imagination to murderers and criminals who commit acts of epic proportions.' When Ui makes a speech to the vegetable traders of Chicago and Cicero he begins with 'Chicagoer und Ciceroer! Freunde! Mitburger! ' This is taken from Mark Antony's speech in Shakespeare's Julius Caesar and 'Brecht is sardonically placing Hitler's speech-making in a literary and theatrical perspective.' Another example is in Givola's flower shop where the dyads of Givola and Dulfeet and Betty and Ui appear alternately. This is symbolic of the garden scene in Goethe's Faust where Mephistopheles softens up Martha while Faust is preparing the ground for Gretchen's ruin. In Arturo Ui Givola entertains Dullfeet whilst Ui and Betty interchange: Betty: 'Freundschaften, die in Wind und Wetter reifen. ' Ui: 'Ich liebe Frauen, welche schnell begreifen.' The rhyming pattern throughout is another example of elevated verse undertaken by Ui and Givola. As in Shakespeare's Richard III 'Arturo Ui woos and wins the widow of the man she has murdered; and like his British prototype, he has a nightmare vision in which he sees another of his recent victims, Roma.' Jendreiek, H., Bertolt Brecht, Drama der Veranderung (Germany, 969), p. 06 Ibid. Brecht, B., op. cit., p. 19 Hayman, R., op. cit., p. 48 Ewen, F., op. cit., p. 74 Brecht, B., op. cit., p. 06 Ewen, F., op. cit., p. 75/8 As in Nazi Germany the general public just seem to accept the gang's 'laws' in Arturo Ui and this can be seen with Betty, who, although tries to resist Ui and after he has murdered Dullfeet swears 'Der Welt zu sagen, welche Pest sie anfiel! ', ultimately succumbs to his pressure and eventually even 'rat. euch nun euer Vertraun zu setzen in Herrn Ui'. Such is Ui's corruption of her that she continues 'Wie ich es selbst tu, seit ich ihn in dieser fur mich so schweren Zeit naher und besser kennengelernt. In M a 'blame culture' has arisen because of the hysteria caused by the murder of the city's children where - as the police chief states - 'Jeder Mensch auf der Strae, kann der Tater sein'. This is best shown when a little girl stops a man in the street to ask what time it is; the elderly man merely gives the reply and then shows concern explaining: 'jetzt musst du aber schnell nach Hause gehen' but this is enough for pandemonium to break out with people pointing and looking at him suspiciously. It is not long before the melee intensifies and the man finds himself looking up having to explain himself to a policeman before being arrested after frantic calls from the flustered public. Lang uses the camera to reflect society looking down on the man who looks as small as he does in the eyes of the accusing public. Herrn Jager's house must be searched just because of an anonymous tip off and this follows a plethora of false reports and the subsequent imbroglio is difficult for the police to deal with. This is perhaps best shown when the two men argue with the police officer over the colour of the girl's 'Mutze' one saying green, the other red. There are also fifteen dissonant reports about the route taken by Elsie on her way home. The result of this is that as 'there is no such thing as a murderer's visage. every man on the street. is under suspicion of being the child murderer.' The problem here, again is that 'Der Morder ist keine Mabuse-Figure, kein Monster; er ist dick, verweichlicht, ein infantiler Kleinburger. ' The public in M, therefore, argue amongst themselves because of the crimes committed and this is also represented in Arturo Ui in the emulation of the gangsters, namely Givola and Giri with Roma. Brecht, B., op. cit., p. 13 Ibid., p. 21 M. Eine Stadt sucht einen Morder, dir., Lang, F. Ibid. Kaes, A., op. cit., pp. 5/8-6 Toteberg, M., Fritz Lang (Hamburg, 985/8), pp. 0-1 The leitmotiv of justice can be compared in the play and the film with reference to the scenes of the 'court'. When Fish tells the judge in Arturo Ui that he had seen Giri at Dogsborough's restaurant the bodyguards pull a gun on him. They constantly dispraise and 'nehmen eine drohende Haltung gegen Hook' after he gives evidence saying that Giri is the 'Lagerverwalter'. He then is beaten up and revokes his statement. Brecht makes a complete mockery of the Nazi judicial system here with even the judge 'lachelnd' as he says brusquely, and whilst smiling, that the defense's request to consult 'andere Arzte' is 'Abgelehnt'. This form of 'mock' justice is present in M; when Beckert is caught he is taken to an underground 'court room'. The public have made this themselves as they do not have faith in the government judiciary system and Beckert's pleas to be handed over to the police fall on deaf ears. Their justification for this is that he will merely have to claim insanity and will be spared. This shows a strong aversion to the justice of the state. Lang hints that this public court is not just either, however, as it is made up of criminals who are described as 'Sachverstandigen' and at his point the camera moves along the line of jurors as the chairman reads out details of their 'experience'. Indeed, it is particulary ironic that the chairman who sentences him to death, stating that 'Dieser Mensch must weg! ' is wanted on three counts of murder himself. The court it would seem 'are not interested in truth or justice, but the elimination of an outsider so that they can resume their illegal activities' as all the defenses solicitations for mercy, to do what is morally right and turn him into the police and get him help ' ihm am Arzt geben' are met with laughter around the courthouse. The question which Lang raises here is that of whether it is morally right to seek retribution if a collective confidence in the state does not exist. What is certainly unjust in this sequence is that the jurors are almost like an audience at the theater, the camera moves around them and cries can be heard from the other people in the court calling for the death penalty. Brecht, B., op. cit., p. 1 M. Eine Stadt sucht einen Morder, dir., Lang, F. Ibid. Kaes, A., op. cit., p. 7 Whereas in Arturo Ui the system of justice is portrayed as being extremely straight forward, as no one is interested in laws except those of the gangsters, in M the system is extremely complicated. When the note which Beckert writes to the press is examined by the graphology expert the 'camera is deliberately immobile to stress the rigid milieu.' Earlier on in the film as the police are trying to solve the case there are endless files and documents which they search through. These documents attempt to 'make up' the person they are looking for. Lang hints that these are somewhat unnecessary and this is best highlighted by the fact that it is the public who actually catch Beckert first. The police are depicted somewhat negatively and they clash with the public during their quest to catch the murderer. The public have no respect for the police as they raid public buildings and because they have orders to suspect everyone, check all identification. The public, therefore, through their use of the beggars catch up with Beckert first and it would seem that Lang is perhaps suggesting that if these two forces had worked in unison it would have been much easier to reach - what is in reality a common goal. The shots of the devastation caused in the building that has been searched by the mob and of the guards having to be tied up indicates strongly that another preferable way should have been found. Ibid., p. 4 Thus, it can be concluded that, during an era defined by economic and socio-political upheaval, both works are primarily concerned with the issues of crime and justice. In Arturo Ui these themes are explored through the allegory of fascism which enables Brecht to both ridicule and criticize the Nazi regime. Conversely, Lang uses the medium of film to depict a more sinister portrayal of an individual's mental turmoil whilst simultaneously being conditioned by these social influences. The focus on punishment produces a greater dichotomy between the oeuvres, with Brecht suggesting the impermeability of 'gang culture' whose influence extends beyond the law, whilst Lang highlights the stigmatization of an individual persecuted by society.'''",714.0
"''' of Case StudyName: Rosemary Age: 8 Diagnosis: Multiple Sclerosis aged 2. Occupation: Part time job at day centre for people with Multiple Sclerosis. Home: Lives with husband in a ground floor flat adapted to accommodate her needs as a wheelchair user. Family: Two adult children who live within ten miles. Rosemary's husband is her main carer; he has noticed a change in Rosemary. Hobbies: Using computer and cooking. Personal: Rosemary has adjusted well to her illness and embraced the challenges that have come with it. However recently she has become frustrated and anxious. History of OT interventions: Rosemary has been open to adaptations in the past. Reasons for referral1) Rosemary is experiencing an exacerbation in her condition and is therefore finding her motor skills have deteriorated making it difficult and frustrating to handle small objects and to work on her computer. These motor skills need to be assessed and equipment provided as indicated. ) Rosemary is anxious about having to leave the day centre when she is 0 and would like to explore other vocational interests. Summary of Multiple Sclerosis A Progressive Neurological condition. Multiple plaques of demyelination occur which are caused by the immune system attacking the neurons within the central nervous assessment focuses on the areas of self care, productivity and leisure. The individual being assessed rates the importance of tasks within these areas. This will confirm and possibly introduce where Rosemary needs support. Standardised = The Ashworth Spasticity ScaleThis assessment will measure on a scale of - the levels of spasticity within muscle groups and their control over movement (Silcox 003). In order to ensure it is valid Rosemary would need to take this test at different times of day on different days. This test will reliably establish Rosemary's motor skills. Initial InterviewAn informal discussion with Rosemary to establish whether initial information and referral is akin to Rosemary's perspective and to determine social and cultural needs which are at present unclear. Planning InterventionRosemary's PrioritiesExploration of alternative vocations.Consideration of adaptations.Maintenance of motor skills.Ability to use phone and computer.Maintenance of independence.Occupation on leaving day centre.Defining the problemLeisureUsing keyboard and mouse; poor co-ordination, muscle weakness and tremors.WorkHolding telephone receiver; difficulty grasping and muscle weakness.Concern about having to leave the day centre at 0 and having no occupation.Rosemary's problems occur in work and leisure and are a result of reduced manual dexterity and changing roles. Productivity and leisure are usually the most important occupations for those with MS because they allow the individual to maintain a sense of purpose in life (Bodium, 999, in Turner). Rosemary's StrengthsPositive attitude to therapy interventions. Love of new challenges. Successful completion of computer course.Being a good cook.Supportive and close family. Valued member of the day centre both to staff and clients. Intervention and RationaleModelI have chosen to use the Person-Environment-Occupation Model (PEO). This model focuses on the individual engaging in purposeful activities and tasks within their chosen environment to fulfil various roles. Occupational performance is central to this model. This will suit Rosemary's desire to continue in activities of work and leisure by exploring and solving the associated problems. Within this model the environment is more amendable to change than the person (Hagedorn 001). Frame of reference: RehabilitationReduced manual dexterity cannot always be improved by therapeutic activity and the provision of assistive devices is usually necessary (Silcox, 003). I will therefore include adaptive technology and orthosis. This avoids over tiring limbs which can exacerbate the symptoms of MS (Tipping in Turner 002). Rosemary will be able to use her love of meeting new challenges and her positive attitude to adaptations and skills in technology to overcome problems with motor skills and concern over her future. By focusing on the environment Rosemary will not be under pressure to continually learn new skills without having to continuously re-learn motor skills which can be frustrating and cause feelings of depression or anxiety (Johnson in Turner 000). Goal PlanningOverarching aimFor Rosemary to continue to be occupied by work and leisure activities within her chosen environments. Long term aimTo maintain motor function and to be independent with tasks needed for occupations of work and leisure. Short term goalsTo use her computer keyboard and mouse within three weeks. To be independent and pain free in answering the telephone at work within two weeks. To decide upon possible alternative vocations within weeks. To maintain motor skills over five weeks. Steps/tasks to achieve goalsTo choose and install a computer package such as 'Dragon' to eliminate the need to use hands. (The Multiple Sclerosis resource centre 005/8). To practise using this computer package for 0 hours a week, on days when she is not too tired, to write a list of possible alternative vocations and to write letters to request information on these vocations. To purchase a telephone headset and to practise using it at home over the next week and to take it to work to use within two weeks. For Rosemary to use her computer mouse for a period of half an hour times a week to look for alternative vocations on the internet, whilst wearing a cock up wrist splint. For Rosemary to practise taking splint on and off with therapist. EvaluationMonitoringOne week: Discuss using splint.Two weeks: Review use of the hands free headset. Three weeks: Discuss using computer software. Four weeks: Review and discuss vocations.Five weeks: To discuss and review motor skills.Re-assessment: After weeksCOPM assessment; this would indicate whether Rosemary feels her performance and level of satisfaction are improved within the areas she has defined. The Ashworth Spasticity test to determine whether Rosemary's motor skills have been affected. Final Interviews: After weeksA discussion with to determine whether or not she feels further OT interventions would benefit her. Further InterventionsFrom these interviews and re-assessments further or alternative interventions could be planned.'''",717.0
"'''With one quarter of recorded rape cases in England and Wales reaching conviction in 985/8 and only one in ten in 996, there is ongoing concern as to why the conviction rate is so is argued that the traditional view of sexuality still remains in rape trials, in that rape is often seen as an 'explosive expression of pent up sexual impulse, from a man who once aroused, cannot control his sexual urges' (Alder, 987, p9). This view that a man desires sexual intercourse with a woman when he is sexually aroused, leads the courts to assume that his victim must have stimulated him in some way through behaviour or appearance. As will be shortly explained in more detail, the blame is shifted to the victim and her behaviour, even her sexual past is scrutinised. The rape trial can thus be seen to celebrate the category of man; 'being a sexual predator is regarded as normal, even desirable for men' (Smart, 989, p42). The rape trial will not allow for any criticism of what is perceived being a 'natural activity'; as Cameron and Frazer argue, men need and feel entitled to have unrestricted sexual access to women, even and sometimes especially against women's is evident therefore that the reforms listed above and many more must be considered if any change is likely to occur. Conclusion:To conclude, as illustrated in Table, it is clear that although the overall number of convictions has risen, the proportion of cases resulting in conviction has remained constant. From the moment rape is reported, throughout the legal system, the numbers of those facing conviction are greatly reduced. This is due to a number of reasons; a low level of reporting, an increase in acquaintance rapes (which as demonstrated above provides unique problems to the trial itself), high attrition rates and the stereotypes and prejudices that still remain within the trial. These must, as a matter of urgency, be scrutinised and eliminated if there is to be any increase in the conviction rate.'''",720.0
"'''Botanical informationOrchids belong to the family of Orchidaceae. It is a unique group of plants that have over 00 genera and over 5/8000 species. There are two types of growth in Orchidaceae family; monopodial and sympodial. The stems are characterised by having one or more swollen internodes called pseudobulb. Characteristics of orchids familyThere are five characteristics that distinguish orchids in the plant kingdom. Zygomorphic flowers. The orchid flowers are irregular, characterised by having bilateral symmetry. Each flower can be cut only in one plane dividing into two equal pieces. The pollen grains. Pollen grains form a pack called pollinia. Column. The pistil and the anther have been fused forming a unit called column. Inside the column there is a canal that starts from the stigmatic surface and ends to the ovary. Rostellum. Its position is between the anther cap and the stigmatic surface. The rostellum has two special roles. First of all, it separates the male and the female parts of the flower in order to prevent self-pollination. Secondly, it is a gland, excreting a sticky substance on the back of any insect that comes into contact with it. As the insect tries to reach the base of the flower so as to take the nectar, its back rubs the rostellum, and a sticky substance is applied to it. As insect abandons the flower, the sticky substance comes in contact with pollinia, and the insect takes them to the next flower that visits, ensuring cross-pollination. Seeds. Orchid flowers produce great amount of seeds. One seed may contain from 00,00 to million seeds. They lack of endosperm and as a result they are unable to germinate in the wild without the aid of a fungus. Most commonly known genera for cut flowers The most commonly known that are used for cut flowers are: CattleyaCymbidiumPhalaenopsisDendrobiumVandaAscoscendaArachnids and its hybridsPaphiopedilumPropagationThere are three types of propagation: Most monopodial propagated by tip cuttings. Some others monopodial or sympodial can be propagated by offsets that produce (Dendrobium). Other by flower stalks cuttings (Phalaenopsis). The second way of propagation is by division of the parent clump. The rhizome is cut and the two sections are two different plants. The final method of propagation is mericloning. It is a method where in one year can be produced one million plants from pre plant. The main advantages are uniformity of flowering and the fact that are identical to parental plants. Media used in orchidsThe most important is osmunda fiber that exists in two types. The first is the soft light brown and the second dark brown. Osmunda comes from the roots of osmunda ferns. It lasts approximately - years and contains -% of nitrogen. The second media is tree ferns. The fiber comes from the stems of tree ferns and lasts - years. The last media are barks that are by-products of lumber industry. They contain little nitrogen and last - years. The fact that they are decomposed from many microorganisms affects nitrogen concentration, because it is obtained by them and not by plants. Water qualityThe most important factor in having a satisfactory production is water quality. All the plants have to be watered with the same amount of water. The best that growers can do is to group plants by size and pot medium in order to be sure that all plants receive the same amount of water. The best quality of water is at 25/8 ppm. Temperature requirementsTemperature requirements vary among species. Cymbidium orchids require 0 C night temperatures to produce flowers. A range of 1 C- 4 C at day is ideal. Cattleya requires 5/8 C- 8 C night temperatures in order to thrive. Phalaenopsis white flower varieties require 8 C at night and 7 C at day, while pink varieties require 3- 5/8 C at night. Major pestsMany insects attack orchids such as armoured scales, soft scales and mealy bugs. The most important found in orchids are Diaspis boisduvalii and Furcaspis biformis. Major diseasesPetal blight attacks the petals of flower as the name indicates. Black rots are another serious diseases including Pythium and Phytophthora with the first the most important of the two. Viruses are the most important enemies of orchids because it is very difficult to control them and secondly they are transmitted easily by cutting tools during propagation and cutting of the flowers. Storage- shippingOrchids unlike many cut flowers do not store at - C. Flowers turn brown in three days at - C and their saleability decreases very rapidly. They can be stored at - C for 0-4 days. Generally, they are very durable plants and as a result can be shipped long distances.'''",725.0
"'''This report is aimed to provide an extensive overview of parasitic plants. This will be achieved by observing the different species, in particular the mistletoe families, and researching into how and why they paratisize their hosts. The distribution, human uses and ecological benefits of parasitic plants will also be looked at briefly within the report, in order to gain a basic understanding of their importance in different habitats and cultures. The different parasitic plant families are given in Appendix I. Parasites Parasites are organisms that are reliant on hosts for the production of nutriments. There are two main types of parasites, as described in Table. Table - Types of ParasitesFacultative Parasite: A parasite that is able to adapt to a changing habitat. It can be free-living, however, if conditions become unfavourable it can prey on host organisms to obtain nutrients. Obligate Parasite: A parasite that is unable to develop and grow autonomously, therefore relying on a host for survival.Parasitic plants either live in or on their hosts, penetrating through their roots or stems. However there are different types of parasitic plants, as shown in Table: Table - Types of Parasitic PlantsHemiparasite/ Semi-parasite: A parasite that relies on its host for half of its nutriment, but still able to photosynthesise, due to the production of chlorophyll. An example is the Eurasian the most common, however most common in temperate and boreal forest trees. The mycorrhizae create a larger surface area over which nutrients can be absorbed. Root parasites take advantage of the mycorrhizae and insert their haustorium in order to absorb the nutrients. An example is the holoparasitic Indian non-parasitic plants generally grow in a downward direction due to gravitational forces and away from light. However the Viscum album radicle, for example, grows in the direction of the host, whether it is towards light or opposing gravity. Once the radicle has reached the host plant it then transforms into a haustorium and perforates into the host's tissue, until it reaches the cambium. The circumference then increases and cortical strands grow from the haustorium, parallel to the cambium. Sinkers then form on the cortical strands as they touch the cambium, penetrating the a multitude of functions other than the penetration of the host to obtain nutriments via translocation. It also provides a structural support for the parasite given that it is the site of attachment to the host by means of hapteron, which 'secrete a polysaccharide adhesive'. HemiparasitesMistletoesMistletoes are vascular, hemiparasitic flowering plants that are found worldwide and in different forms, including, trees, shrubs and herbaceous plants. There are two mistletoe families, Viscaceae and Loranthaceae, which originally belonged to the same family Loranthaceae. This division occurred due to the conspicuous differences between the two; the Viscaceae family all have relatively small, inconspicuous flowers, with red/white berries and are usually found in temperature regions of the Northern Hemisphere. The Loranthaceae family have much more ostentatious flowers and are found in tropical regions, for example, Nuytsia floribunda, the 'Christmas tree' found in Australia which blooms in December/January. Nuytsia floribunda is found in Australian heathlands, and can reach a height of up to forty five feet tall. Its roots produce white suckers that encircle and cut into a host's roots, the haustorium then diverts water and oval, green leaves and grows typically on deciduous trees. Mistle thrushes' (Turdus viscivorus) feed on the berries, depositing the sticky, intact seeds, usually onto berry-bearing trees. The northern populations of Turdus usually migratory in the winter to the Mediterranean, North Africa and Central Asia, and may deposit the seeds along these migratory routes. The sticky berries are usually deposited in strings held together by viscin and only a few other birds eat them, for example, black preys on cacti e.g. catclaw desert shrubs. The desert mistletoe produces red, sticky berries that many birds feed on, especially the silky pine trees as a host and produce white berries which burst when ripe, expelling their seeds at a high speed to other nearby trees. 'Seeds only mm long may shoot up to 9 feet laterally, with an initial velocity of about 2 miles per hour.' A number of mistletoe's create galls, which are masses of woody tissue that surround infected areas on their hosts. The galls are where the haustoria once penetrated the host, and many remain even after the death of the mistletoe. Coniferous trees obtain a gall-like structure known as a 'witches broom', which is where the infected branches become very dense. Tropical mistletoe can cause mutations in the host's bark, called 'wood roses'. The local people in Mexico and Bali use these intricate imprints to create delicate woodcarvings for decoration or to sell to tourists. Mistletoe also has an ecological importance as a source of food and shelter; mistletoe on the stem during the larval stage, Hypseloecus visci, a rare sap-sucking bug and the mistletoe tortrix larvae mine through the leaf tissue, all feed on Viscum album, during the spring and summer. Strangler fig The strangler within the boughs of trees in the canopy. As it develops it grows down and around the truck of its host, attaching its haustoria to its host's roots, whilst constricting it. A hollow structure remains once the host has died. The death of the host is usually due to the parasite gaining the majority of nutrients from the soil and shielding the hosts leaves from light in the canopy. Occasionally more than one fig may paratisize the same host, entwining their roots and as a result appearing to be a single tree. The different trees, however, tend to flower and fruit on separate occasions, subsequently providing important sources of food in the rainforests. HoloparasitesMonotropa a root parasite that when flowers pushes through leaf litter to expose a white/transparent, bell-shaped head. This parasitic plant completely lacks chlorophyll and obtains it nutrients from the roots and mycorrhiza of coniferous trees. Raffleisa arnoldii is an endoparasite, that lives completely inside the tissues of the tropical rainforests of Borneo and Sumatra, although it erupts from the woody vine when flowering. The Raffleisa arnoldii produces the largest, single flower in the plant world. The female flower has five, thick and leathery orange/red petals that open to up to one meter in diameter. The flower is pollinated by insects, in particular flies, which are attracted to the redolence of rotting flesh. The male flower, however, is pollinated by small mammals and are much more abundant than the female flower. Cuscuta spp. (dodder/witches hair) is an obligate parasite, with an unusual appearance, considering that it grows as a mass of string-like strands, engulfing anything in its path to lengths of up to half a mile. Cuscuta is very versatile and is therefore found in a variety of habitats, for example, Cuscuta marina is salt tolerant and is commonly found in and along salt marshes. Pilostyles thurberi is an endoparasite, meaning that it lives in the stem of the host, apart from when it flowers. The haustorium is fibrous and penetrates the host's vascular tissue by means of a sinker. Fungus a parasitic plant that spends the majority of its life underground obtaining nutriments from its most parts of the world. The spread of parasitic weeds have been helped greatly by human interactions, especially root parasites, for example the Cuscata and Striga families. Therefore quarantine measures have been set up to prevent the spread of destructive parasitic weeds around the world. most damaging to maize, sorghum and a number of other grasses, whereas tomatoes and beans and dodder is a particular problem on alfalfa, for example. Although quarantine measures are set up to help prevent the spread of parasitic weeds, once they have contaminated a crop it is extremely difficult to eradicate due to the minuscule seeds produced that are effectively distributed via the wind and persist in the soil. Human UsesHumans have used parasitic plants for a number of reasons over the centuries. Numerous parasitic plants have and are been believed to have medicinal properties and curative values. Others have been used as herbal teas, for example, Euphrasia and Pedicularis,, or from the host to the plant is likely. Therefore care is needed before using parasitic plants in medicine and food. The flower buds of Raffleisa tengku-adlinii, when boiled are said to induce the labour of pregnant women and to help mothers gain their strength after the birth. A few root parasites accrue subsequently have been used as anti-diarrhoeal remedies, for example, Prosopanche, has been used in Argentina, and Krameria has been used in Central and South America,. Mistletoe has been used for many different medicinal cures all over the world throughout the years. In Africa, it was used as a cure for convulsive distempers, to relieve digestive distress in Canada, and as aphrodisiacs for the Mayans and in the Mediterranean. Not only have humans used parasitic plants for numerous medicinal reasons, but have also associated a number of folklores with them. The European been used to symbolise good fortune, and pagan rituals. It is also used in Christmas festivities; when placed above doorways couples share a kiss when stood underneath. This tradition is believed to have originated from the belief that mistletoe aided the fertility of women, and was used when conception of a child was desired. European mistletoe was also believed to have been 'sent to earth by Gods' and that the mistle the 'messenger'. It was therefore believed to have healing powers and people drank it in tea and wore it as amulets. European mistletoe when grown on oak trees was believed, by the Druids, to symbolise 'human dependency on God', and the oak tree represented 'God'. It was therefore used to scare away evil spirits, a good-luck charm and to create a warm atmosphere in the home within the winter months. A few parasitic plants have also been used as a source of food for humans in different locations around the world, either as a staple part of the diet or when other food sources are scarce. Parasitic plants are also a source of food for other animals; for example, mistletoe can often provide deer and elk as a source of food in the winter months. Appendix I looks briefly at other uses of parasitic plants. ConclusionThere is a diverse range of parasitic plant species found all over the world that live in a variety of habitats, and have adapted different ways in which to obtain nutrients from their hosts. Although parasitic plants may harm their hosts, they are very important ecologically, economically and socially. The provide food for a number of different species ranging from insects to humans. The root structures of parasites have provided an income for some indigenous people who create and sell the handcrafted woodcarvings. Parasitic plants have also provided a basis for local discussion derived from folklores, and festive traditions.'''",726.0
"'''PoliticalBoth the US and Canada enjoy high government hotel development. Unemployment has remained relatively unchanged and the increase in jobs in the accommodation/food services proven one of the main contributors to Canada's record high in employment. Considerable increases are seen in the same sector in the caused by rising numbers of those aged over 5/8, and longer life also exerting their influence on patterns of change, shaping social trends, consumer demands and levels of their fast paced reveal the shortening of business and leisure travels but the need for more luxurious hotel experiences. Both trends affect the availability of human resources, concept development, design, the influence and application of technology and the characteristics of the guest experience. Most of the population in this region is concentrated in urban areas in eastern US, adjacent parts of Ontario and Quebec and the US Pacific both the government and industry make great efforts on various types of research and the phenomenon of modern interior design, aimed at satisfying and impressing customers with the latest significant policies, rules and regulations on waste, pollution and energy, and therefore the hotel sector will be forced to change its ways and adopt more environmentally-friendly approaches to its operations. The sector is also particularly sensitive to natural disasters and human conflicts. However, through advanced economies of scale and the experience of /1, the North American industry has shown its rapid response to crises and the ability to speedily recover, which enforced by local communities' constant eagerness and planning in crisis still reasonable construction discourage outbound trips to the Caribbean and Mexico, and encourage domestic getaways, thus additionally increasing room further decrease buyer's bargaining power. Threat of potential substitute products and servicesGiven the recent high and favourable conditions of the hotel sector, there is a substantial threat of potential substitute products and the overwhelming amount of private investment over the past decade, in addition to its cash flow generating ability and significant real estate value, the hotel sector will continue to attract relatively substantial project funding, which in turn suggests a low supplier bargaining power. However, this is counterbalanced by the double-digit increase in recent operational and energy costs due to rising environmental concern, property tax escalating insurance increase the sector's choice of outsourcing organizations and lower the bargaining power of the suppliers. UNITE is formerly the Union of Needle trades, Textiles and Industrial Employees. HERE is Hotel Employees and Restaurant Employees International Union. Industry Rivalry between CompetitorsThere are several elements influencing the level of competition in the sector. Considering the forces above, it seems there is high competition between the sector's players. However, when taking into account that the industry's ecocycle is currently at its stage of appears that competition is based more on perfecting effectiveness, reorganizing operations and distributing resources so to help guarantee more certain and lasting results. Given that most groups operating in North America have firmly established themselves in the industry with extended portfolios and significant economies of scale, focus moves to differentiating within the sector and through constant product and service diversification. Therefore, though there is competition between the main players, there is also co-existence between hotel groups and cooperation between brands within the same group. ConclusionThe region's economic stability is counterbalanced by a mature stage of its ecocyle which suggests a possible decline in coming years. Also, the threat of terrorism is ever-present and in addition to new passport requirements, generates some political instability, which together with Canada's restrictions on foreign investment may negatively affect stakeholders. Nonetheless, the region's free market economy, high levels of diversity, changing demographics and lifestyles, significant investment in technological research and development of renewable sources of energy make it attractive to investors. Further, increased outsourcing and interest by private investors help counterbalance mounting costs of suppliers and high levels of unionization. Changing demographics, lifestyles and rising demand from consumers who are increasingly price-sensitive and knowledgeable about products and services, as well as the threat of stricter environmental policies, also pose a danger of emerging substitute products and services. The combination of opportunities and threats in addition to evident co-existence and cooperation between companies themselves and the sector and other industries indicate its current high and make it favourable for further growth and development. Critical Success Factors Given the interdependence and connectivity between the C's some elements, though included in a particular C may indeed overlap into anotherCorporationThe inclusion of technology is an essential requirement in operations, infrastructures, facilities and services. It is also crucial for online reservations systems to compete with and eliminate intermediaries and assists in establishing networks with stakeholders in macro and task environments to get a sense of the landscape, explore and exploit change indicators and respond efficiently. Further, and given modern turbulent business environments, a flexible business approach is key, enabling an awareness of external and internal indicators of change and a continuous and efficient cost benefit analysis, which will ultimately make adaptation to and co-evolution with changes easier, thus enhancing the probability of in pursuing as many sub-segments in one market as possible through a range of diversified services and products that meet everyone's needs. Several companies aiming solely at one only one is achievable once a relatively dependable set of customers and competitors with comparable requirements is formed. Concurrently, global consumer segments are emerging, competitors are focused on global presence, responding to the needs of as many customers as possible, and developing their strengths primarily around comparable are then transferred and adapted to the sector. Given its high dependence on the transformations of other industries, the hotel sector therefore primarily reflects emerging trends, e.g. new food design and changes in the indeed assist hotels to maximize their strengths, minimise weaknesses, improve their competence and potential as well as create new opportunities for the hotel sector to compete through diversifying products and services to meet different customer needs. Further, the hotel sector is particularly sensitive to natural disasters, terrorism and political conflict. This to an extent also drives hotel groups to co-exist and co-evolve through mergers and acquisitions, in a quest to increase their economies of scale and extensive presence worldwide, as well as providing competitive advantage and a safety net for organizations when these unexpected, high-impact events occur in specific areas, and therefore maintain stability at a corporate level. Considering the idiosyncratic characteristics of the an example of the first two S's where the organization partnered with a technology company and following specific market research, developed a service which anticipated guests' needs, accompanied recent socio-cultural trends and possibly attracted new customers. Hyatt recognized that guests arrive tired to hotels and want to the lengthy pursuit of its may disrupt the market. Signalling was present throughout the process, though it may have played in detriment to Hyatt. The implementation of kiosks in hotels was it is to protect itself. At a corporate level, the inclusion of technology may lead to strategic alliances and mergers and acquisitions between hotel organizations and technology-development companies, disrupting the market, shifting the rules of the game and creating hypercompetition-no longer between hotel companies but also amongst technology-development organizations operating with the hotels. Bill Gates' acquisition of a major share of Four Seasons and ownership of Microsoft make credible a merger between the two and the creation of a seminal operating system, which could shape the market and change competition rules. Key players are ever more incorporating technological advances in their corporations, leading to cost reductions, especially labour related, and an improvement of facilities and structures. The most significant development appears to be not that of technological advancements in facilities and equipments but that of manpower replacement with technology. Though seeming progress, this trend may pose significant threats to the industry as evidence suggests a growing demand for human relations, interaction in hotels and a personalised experience, not one technology dominated (Ferry, 005/8). Therefore, though the influence and presence of technology is imperative in the improvement of work processes and functioning, a balance should be found between the latter and the extent to which human interactions are affected. The hotel sector is characterised by the interaction of people and to remove this could be heavily detrimental to the success of organizations. Climate change and the resulting adjustments in government policy already show their effects on the hotel sector. Not only are North American governments taking significant measures towards recycling, the use of renewable sources of energy, composting of waste and supporting hotels to go 'green', but these developments are accompanying a wider trend that being ecologically-friendly is not only necessary but also fashionable. This presents the possibility of major players becoming environmentally friendly and adopting measures such as self-generation of energy or inclusion of a waste composing area which could be used to develop and supply part of the hotels' energy. Further, the constant erosion of coastlines could trigger the emergence of destinations and hotel sites in unexpected locations. The combination of technology with environmental and economic concerns could lead to the exploitation of unthought-of locations. In-land deserted regions, plains, mountain sites and deserts could all be maximized to reproduce or create new destinations. Adapting to social trends is a key characteristic of the hotel sector and the emergence of designer hotels due to increasing demands of younger and educated generations could imply the creation of hotels for senior segments (Appendix ), created under different brands, according to the financial possibilities of the segments. Changes would include innovative hotel structures (i.e. less floors), room lay-outs featuring visible indications and health monitoring devices, more space, the inclusion of transportation (e.g. in resorts, one buggy per room), more and differently distributed multi-skilled staff (e.g. knowledge of healthcare and tertiary needs). This scenario proves the North American hotel sector's interconnectedness with other industries and its dependent co-evolution therewith for increasing progress and development.'''",729.0
"'''Prospective - A -Day weighed dietary survey, the 'gold standard' adapted by the health professionals, is recorded individually. A description of each food and its weight in grams are recorded before eaten, within days. Retrospective - Data is input into the Foodbase computer software. The intake of energy and nutrients of an individual is then assessed. The report processed is shown below: ResultsDiscussionComparing Results and to the report and Table, my diet is generally low in % more is consumed then recommended - increases the risk of high blood pressure, cardiovascular disease and stroke, which I need to beware of. Meanwhile, there is appropriate intake of protein, magnesium, copper, folate. Ways to Improve my DietTo consume more sea fish and shellfish in order to increase iodine intake in particular. Good sources of potassium include fruit such as bananas, vegetables, pulses, nuts and seeds, milk, beef, chicken, turkey and bread. Meanwhile, milk can also increase calcium intake. To reduce salt intake, I can: Add fresh herbs, black pepper, garlic, ginger and lime which give more flavour Make sauces with ripe ingredients e.g. tomatoes and garlic, again to bring a stronger flavour Marinade meat and fish in advance AdvantagesA very suitable dietary survey method assessing individuals. Few sources of error than past intake e.g. it does not rely on memory; no error in portion size Cheap and easy to carry out - in terms of equipment, only an electronic scale and the food database are needed. Relatively quick method comparing to some other dietary survey methods, which usually take more than six days. Limitations of Methodology'Diet histories of this type are fraught with interpretation difficulties' (Bingham, 985/8 and 987) Patience and care required for proper data entry i.e. it is rather tedious to have to enter the data for every food that consumed in six days. High degree of cooperation of the subject is needed. Data on some food items not available in the database, my own interpretation is required to select the nearest food material. E.g. chocolate drink is chosen as there is no cereal drink available. My high salt intake could be due to no option for boiling some kinds of vegetables in unsalted water, and 'boiled with salted water' is the only choice. Selecting the wrong or different item can make a big difference to the final data. The weighing scale has a low accuracy to only about g, salt and sugar intake or other small dietary additions e.g. a small clover of garlic are not being able to weigh Weighing is not always possible due to embarrassment caused especially in public areas, simply as having a meal in the restaurant. Estimations have to be made. Therefore the reliability and accuracy of the survey will be affected. Biases caused - reported diet may not reflect the actual diet as subjects choose not to have certain food types to avoid the difficulties in weighing every ingredient of the item. E.g. sandwich with a mixture of fillings. Heavily dependent on food composition table used to estimate nutrient intake that are likely to contain errors. ConclusionAny measurement of diet will be biased in some way by the measurement process itself, so in practice, there is no entirely objective measures of an individual's food consumption. Since the Foodbase report processed has determined my intake of energy and other nutrients by the -day weighed dietary survey, the aim of the experiment has been reached. This again emphasises the importance of a balanced diet.'''",739.0
"'''In order to examine this question, it is important to establish what the term 'revolutionary' actually means - a change that can be considered groundbreaking, which has never been experienced before, fundamentally altering the current situation. Therefore, it would be fair to argue that there were many things that were revolutionary about the French Revolution which occurred in 789 that included not just legal and political changes, introduced for the first time in French society, totally reforming it, but also a whole new way of thinking that was influential in causing the Revolution and implementing these changes in the first place. These new ideas first came about during the middle of the eighteenth-century during a period known as Enlightenment. This essay will attempt to outline the major revolutionary changes that occurred during the French Revolution. However, the general focus of the essay will be on the early years of the Revolution because it could be argued that the it lasted until 815/8 with the fall of Napoleon and covering this whole period would be both unfeasible and lacking in depth for such a short essay. Before analyzing what was revolutionary about the French Revolution, it is important to spend some time to examining France before this momentous event took place in order to provide a comparison between the two periods. Previously France had been an absolute monarchy with the King having enormous power. There was no constitution, and there were three very clear classes in society: at the top were the clergy; next came the aristocracy and finally the 'Third Estate' (the rest of the population). The power lay with the first two groups and Andress describes France as 'a society of feudal aristocratic domination' - the up one percent of the population but owned twenty per cent of the land. The nobility also held many privileges such as exemption from tax or rights to special judicial treatment. Meanwhile, however, the lower classes were severely repressed. France was predominantly agricultural with twenty-four out of twenty-seven million of its population living in the countryside. There was a policy of high and variable taxation, but the 'feudal' or 'seigniurial' system produced even greater bitterness, as this meant peasants had to pay dues in addition to rent for the land. The taxation system was iniquitous 'With the most wealthy and powerful individuals and from most taxes, and with more and more of the better-off buying into such privileges, the state had little choice to burden the poor'. Ultimately the Bourbon monarchy failed to modernize society, which consequently led to problems for the government and eventually culminated in the French Revolution itself - Forrest even claims that 'By the later 780s even many of the privileged members of society were prepared to concede that they must sacrifice some of their privileges if the monarchy and the social system were to survive'. David Andress, French society in revolution 789 - free speech, press and freedom of religion were granted for the first only were a large number of rights granted to the population for the first time because of the French Revolution, other rights and privileges were withdrawn from certain sectors of society, especially from the aristocracy. The writer abbe Sieyes 'demonstrated that the clergy was not strictly an estate at all but a profession. and that the aristocracy was isolated from the rest of the community by privilege'. There was a radical attack on aristocratic privileges including the withdrawl of exemption from tax, special judicial treatment and the collection of dues from peasants and by November 790 all ranks of nobility had been abolished. The clergy were also targeted and the Church had vast areas of land confiscated while the population was no longer forced to pay tithes to support the Church either. Therefore, the withdrawl of privileges was equally as revolutionary as the granting of rights, simply because it had never been done before and it also contributed to a fairer society. A. Goodwin, The French Revolution (London 986), p.4 Another significant revolutionary change was that France was also vastly geographically altered due to the Revolution. The country was divided into eighty-three departments of roughly equal size, population and wealth. This was done to create a 'unitary form of administration, replacing the hodge-podge of different boundaries for indirect and direct taxes, military affairs, religion, justice and the rest which had characterized Bourbon polity'. Previously there had been provinces, generalities, principalities and municipalities and the change was introduced in order to decentralize power from the government and instead spread it to the individual departments. Thus, the altering of the internal geographical boundaries of France is yet another revolutionary change brought on by the Revolution. Jones, The Great Nation, p.27 Therefore, in conclusion, there were many revolutionary aspects of the French Revolution, as the ways of the ancien regime were completely destroyed and a new French society emerged. A totally new way of thinking known as Enlightenment was important in contributing to the Revolution and to many of these changes. The main revolutionary features included a completely new system of ruling, a constitutional rather than an absolute monarchy; new rights that the vast majority of the population had never held before, outlined in the declaration of the Rights of Man, including the extension of the electorate; the abolition of many aristocratic privileges which also affected the Church, as well as the decentralization of power through the geographical division of the country into eighty-three departments. These were all revolutionary changes in that they had never existed before and altered the shape of French society forever.'''",754.0
"'''Nineteenth century Peru witnessed great changes in the state's approach to the indigenous majority, with the issue of the 'Indian Problem' proving central to debate about the country's postcolonial direction. Peru emerged after independence as a thoroughly divided nation, comprising a small pool of largely city-residing elites and a peasant mass scattered throughout its diverse landscape. With the development of a significant mestizo class, in addition to the existence of black slaves and imported indentured Chinese labourers, Peru was characterised by ethnic heterogeneity. The peasantry remained overwhelmingly Indian in composition however, inhabiting the composite network of community ayllus littered across the Andean highlands. Though incorporated within the state apparatus - just as they had been under the colonial tribute system - the maintenance of traditional towns and villages would be deemed in opposition to the modernising and republican values of an emergent Creole elite. By the century's end, Peru's Indian mass would see repeated efforts to catalyse its integration within the enterprising trajectory of Lima's intellectuals. Despite the liberal republican discourse that fuelled such a drive, Indians were routinely contained along established lines of 'paternalistic exploitation'. Maintenance of the kuraka system of local chieftainships served the state well, providing a mix of tribute, mita draftees, and various forms of taxation which were rescinded and reinstated as different governments interests lobbied for power. Broadly speaking, this upholding of the municipal system ensured that the Indian worldview remained confined to within the community, providing little scope for wider conception of the world or developing a national consciousness. Though these conditions upheld indigenous isolation, it would be inaccurate to regard Andean people as possessing no political awareness however, as communities continued established traditions of challenging the state along material and moral lines. Furthermore, the military conflict of 821 that had spawned Peruvian independence had naturally entailed much participation from Indian soldiers, just as later generations would be called upon in defence of the patria against Chilean invaders in the 880s. Despite the continued physical and ideological distance of Andean communities in the nineteenth century, a progressively greater proportion of Peru's indigenous population became affected by the state's integrationist drive. Both as communities and individuals, Indians could more readily envisage the making of a nation, though this did not necessarily transpire as a desire to belong. Thurner, Mark, From Two Republics to One Divided: Contradictions of Postcolonial Nationmaking in Andean Peru. (London, 997) P.5/81 Piel, John, 'The place of the peasantry in the nation life of Peru in the nineteenth century', Past and Present, 970, 6, 08-33, P.15/8 Klaiber, Jeffrey L., Religion and Revolution in Peru 834-976. (Indiana, 976) P.8 Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.69 In the immediate period preceding independence from Spain, the Peruvian State sought to alter its relationship to its indigenous subjects with the repeal of the tribute system in 810. With independence being effectively consolidated in the early 820s, competing political figures pursued differing approaches to the Indian majority that formed the bulk of the incipient nation's population. As political power remained essentially concentrated within the hands of a metropolitan elite, Creole ideology's overriding view of a disparate indigenous mass became that of an obstacle to be overcome; competing lines of debate would revolve around an essential design for modernity. In an era in which Enlightenment principles of liberty, equality, and citizenship featured strongly, the deep divisions created by ethnic, cultural, and class differences proved problematic to a state model seeking to increase its sovereignty over a diverse landscape. Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.5/88 Rurally speaking, the nation comprised three distinct geographical areas of a 'desert-like' pacific coast, the mountainous Andean range, and low tropical valleys in the Amazon basin to the country's east. Such diversity served to highlight the physical and psychological distance between regions, and resultant lack of a common identity and history for their inhabitants. Ethnic heterogeneity, both in terms of the internal diversity of indigenous groups and divisions of people along caste lines of white, mestizo, Indian, black, and Chinese, further eroded a sense of universality. In spite of the progressive slant that liberal republican discourse would take as the century progressed, the postcolonial system upheld the model of paternalistic exploitation rooted in local kuraka authority. Owing to the economic irrigation created by a prosperous guano-export boom however, tribute could remain abolished in the immediate postcolonial years, though a new judicial system would require personal tax contributions in light of Indians' citizen status. It was the kurakas who largely filled this new fiscal role, cementing ultimately the continuance of the elite's position within a stratified social hierarchy. Peru's masses were overwhelming poor and indigenous: a 795/8 official census calculated the population to have been at,49,23, a figure that the historian John Piel suggests as seventy-five percent composed of the Indian peasantry. With the bulk of this population scattered across the vast highlands, Indian communities remained fragmented sites of ethnic, cultural, and linguistic diversity stretching back beyond pre-conquest times. Though they acknowledged, and would often rebel against, an overbearing authority constantly imposing and rescinding tribute and tax obligation, individual Indian communities did not at this stage project a sense of solidarity with one another, much less an idea of the nation as a whole. Piel, John, 'The place of the peasantry in the nation life of Peru in the nineteenth century', Past and Present, 970, 6, 08-33. P.10 Piel, John, 'The place of the peasantry in the nation life of Peru in the nineteenth century', Past and Present, 970, 6, 08-33. P.11 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.06 Piel, John, 'The place of the peasantry in the nation life of Peru in the nineteenth century', Past and Present, 970, 6, 08-33. P.12 Following the suppression of the great rebellion of Tupac Amaru in 780, Peru's elite ruling oligarchy had cemented its dominance of the Indian majority. Owing to their geographical dispersion, indigenous villages continued to be easily controlled through the use of the parochial kuraka aristocracy. As the country moved into the postcolonial period, the kuraka role officially became that of a 'varayoc', a position filled by local village leaders who would collect the contribucion personal. Given the high levels of illiteracy among Andean peasants, their view of such development remains confined to oral history and the contemporary observations of whites and mestizos. It is fair to say, however, that the State erosion of community land rights and the endeavour to impose of model of individual status proved objectionable. Indian rebellions, much as they had been during the colonial period, were often sparked by localised abuse of financial responsibilities, a trend that hinted at widespread dissatisfaction. Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.06 Following the removal of the dual Republicas system, the nation's diverse citizens were lauded as Peruvian, but Indians were frequently loath to endorse a progressive liberal ideology. While the state model suggested equality based on common status, the peasantry suffered greatly from the impositions of tax and sporadic restoration of the tribute system. With tribute reinstated in 826 and surviving until 85/84, the peasantry became increasingly disaffected with a state that pursued a judicial attack on their communal land rights whilst tightening its grip on taxation. Though hardly a popularist, Agustin Gamarra's ascendancy to the presidency in 829 relied heavily on harnessing this localised discontent within the Cuzco department. Through challenging abuses of state power, revolting Indians, just as they did during other uprisings and rebellions, readily displayed a political consciousness and sense of mistreatment, a consciousness similarly manifested itself in their petitioning of the regional audiencia courts. While illiterate, villagers made use of local secretaries to challenge kuraka abuses of power and overthrow disagreeable figures, acts which potently illustrated their engagement with the nation's political system and the rights it theoretically afforded them. Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.60 Piel, John, 'The place of the peasantry in the nation life of Peru in the nineteenth century', Past and Present, 970, 6, 08-33. P.15/8 Coinciding with the slump in the guano nitrate export sector that had underpinned elite prosperity in the period 840-870, President Mariano Ignacio Prado restored the head tax in 868 in an attempt to maintain state revenue. Such an act was at odds with the country's drive to modernise and challenge the communal existence of its peasant majority, as it plunged individuals into further financial difficulties and heightened their reliance on the community. Rebellions such as that of Hunacame in 867 displayed the persistence of indigenous chagrin, as the country's liberal republican direction continued to erode communal property rights. Such changes further aggravated the peasantry's sense of detachment from state governmental power, despite the efforts of the succeeding civilista president Manual Pardo to inaugurate a programme of assimilation through schooling. This renewed desire to integrate Peru's population reiterated its diversity and the extent of regional isolation. Indian appreciation of the nation's development depended necessarily, then, on proximity to state power and exposure to integrationist efforts, in much the same way that communities' geographical dispersion had impeded their complete dominance in the colonial and pre-Colombian eras. Indians were conscious of state authority's endeavour to exact greater money and increase its power, but their response was to maintain a worldview orientated towards community and existing local ties, with little appreciation for a government project of nationhood. Klaiber, Jeffrey L., Religion and Revolution in Peru 834-976. (Indiana, 976) P.0 Klaiber, Jeffrey L., Religion and Revolution in Peru 834-976. (Indiana, 976) P.7 Peru's participation in the War of the Pacific in 879 would, however, lead to greater Indian involvement in the country's development, obligating many individuals to be conscripted within local militias in defence of the patria against the Chilean invaders. This is not to claim that the onset of the war stimulated a wave of untapped patriotism on the part of the indigenous masses, but rather that it exposed the extent to which localities remained essentially inward-looking and with little perception of belonging to a national system. As an investigation by the historian Heraclio Bonilla elucidates, parochial Indians maintained an intense dislike of the 'misti' class - mestizos and whites - which extorted taxes from them and drafted their sons for heavy labour. They saw themselves as divided from the domineering, enterprising culture of the elites, appreciation of which led local merchants in central areas such as Colca and Acostambo to abandon their homes once the war got fully underway. The rise of bands of guerrilla soldiers as defenders of towns and individual regions spelled a plunging into full civil war by 883, with political authority crumbling across the entire central highland range. Thurner, Mark, From Two Republics to One Divided: Contradictions of Postcolonial Nationmaking in Andean Peru. (London, 997) P.6 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.2 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.4 Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.41 Chilean incursions during the war, though highly deleterious to local economies in destroying stocks and livestock, often fomented mobilised resistance in response. Whilst President Iglesias negotiated the cessation of hostilities between the two nations by signing the Treaty of Ancon in 883, General Andres Caceres continued to oversee popular resistance in the Mantaro region. Though many were involved in incidents of banditry and opportunistic abuse in this period, the war provided the nation's indigenous participants an avenue towards greater appreciation of belonging to a wider cause. In defending their homelands from a foreign threat, the conflict permitted the forging of a heightened consciousness of an inter-community experience, helping to establish 'bonds of solidarity'. Practically speaking, this entailed the erosion of longstanding ethnic tensions between Indian groups that had considered themselves culturally and often linguistically distinct from their neighbours, in the same way that the Tupac Amaru rebellion had achieved some one hundred years before. By exposing a trend of exploitation on the part of the state government, the war granted Indians a heightened sense of sharing a common experience. Particularly after the withdrawal of Chilean forces, peasant mobilisation sustained political instability in the central sierra, creating a pervasive sense of a rejection of Lima's nation making project. If the war advanced the state's concept of national consciousness for the masses, it did not appear to be endorsed by many. Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.41 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.15/8 Serulnikov, Sergio, Subverting colonial authority: challenges to Spanish rule in eighteenth-century southern Andes. (Durham, 003) P.16 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.15/8 With Miguel Iglesias presiding over weak political legitimacy in the post-war period, disaffection with the state would materialise as the rebellion led by Pedro Pablo Atusparia in the central Huaraz region. As a direct response to Prefect Noriega's designs on Indian labour and taxation as means of revitalising depleted finances, Atusparia mediated a wave of Indian discontent at state exploitation. Though they had participated in national and local armies in defence of the patria during the war, Indian men were to remain subordinated as the nation endeavoured to rebuild, a marginalisation that fuelled the persistence of guerrilla activity. These groups, in demonstrating a response to external, ruling forces, regenerated an established tradition of questioning state legitimacy. While Indian conception of the nation developed as a consequence of the war, the deleterious legacy of the Chilean army's social and economic destruction undermined confidence in the state's direction. Though maintenance of an exploitative model had facilitated elite control of a peasant mass in preceding years, it ultimately inhibited commitment to the country's liberal trajectory, leading intellectuals to once again examine the 'Indian problem' that was retarding modern development. By the end of the nineteenth century, indigenous appreciation of the nation had grown markedly, albeit accompanied by the continuance of divisions over the roles and positions it granted. Larson, Brooke, Andean Highland Peasants and the trials of Nation Making during the Nineteenth Century. In: The Cambridge history of the native peoples of the Americas, Vol. III, 5/88-03. P.69 Bonilla, Heraclio, 'The War of the Pacific and the National and Colonial Problem in Peru', Past and Present, 978, 1, 2-19. P.06 In conclusion, nineteenth century Indian conceptions of the nation developed considerably as Peru established itself after independence. The bulk of the population would remain scattered across a diverse geographical landscape, but state alterations to tribute and taxation systems, the erosion of communal property rights, and participation in a war with a foreign power all contributed to heighten Indian acknowledgement of the nation state. The general trend towards a liberal republic direction would however prove at odds with the indigenous population's desire to maintain their traditional communities, and the gulf between the state's modernising rhetoric and conservative use of the kuraka system inspired significant periods of instability. In challenging financial mismanagement and abuse of power on a local level, Indian groups had an established political consciousness and general distaste for the state's failure to keep its side of the bargain. This did not necessarily equate to a national consciousness however, and it was not until their defence of the patria during the War of the Pacific that Andean communities would begin to more concretely perceive their position within a broader nation. Chilean destruction of local communities advanced notions of a common cause and bridged regional divisions, but such notions did not automatically evolve into patriotism and faith in state power. With the state looking to refill its coffers after the war, much of the central Peruvian highlands descended into revolt. In light of the state's wartime conscription demands, this action highlighted the peasantry's disdain for the government's renewed emphasis on taxation and oppression, and the direction the nation was taking. While the elite would return its attention to the issue of the problematic indigenous majority, Indians themselves appeared at odds with the position imposed upon them, rejecting its assault on their prosperity and rights.'''",764.0
"'''Libben describes the study of aphasia as 'by far the most important tool in the investigation of language in the brain'. In general it has been noted that the extent of a language deficit depends on how much the brain has been damaged and the area of damage. Certain theorists claim that particular locations of errors result in specific language deficits such as production and comprehension. I am going to look at whether research into aphasia proves or disproves these claims. I will be looking at the viewpoints of the antilocalizationists in terms of lesion location, selection of patients and briefly a comparison with normal speakers. I will also attempt to determine if generalizing group studies is reliable, finally I will consider the role of the right hemisphere in language. Historical background-: Interest in the location of language in the brain began in the 9 th century when the first scientific studies on the brain were undertaken. The work of Paul Broca was innovative. Broca's worked stemmed from the ongoing phrenological theory that 'the moral, intellectual, and spiritual faculties of man were each the result of particular portions of the brain' (Caplan 987:3). By the time Broca had begun his work in 861 most of the phrenologists claims had been refuted however the claim that language was located in a specific area of the brain remained. Broca undertook an in-depth and ongoing case study of a patient who had a severe language deficit. His patient appeared to have good comprehension but their only verbal output consisted of the syllable 'tan'. Upon the death of the patient an autopsy showed a severe lesion to the frontal lobe of the brain. Broca's findings were innovative in that they claimed to have located a particular language function to an area of the brain. Broca claimed that 'the expressive apparatus for speech is related to a small area of cortex' on the frontal that the right side of the body was controlled by the left side of the brain and vice versa. The work of Broca concluded that language was localised in the frontal lobe and thus this area of the brain became known as Broca's area. Shortly after Broca published his findings Carl Wernicke put forward a set of contradictory ideas when he discovered that 'other aphasic syndromes related to lesions elsewhere in the brain' (Caplan 987:7).Cases of aphasia were discovered which had lesions elsewhere in the left hemisphere and 'cases came to light of patients whose autopsied brains showed lesions of Broca's area, but who had not had disorders of language in life'. In 874 Wernicke suggested that as there had been discoveries of sub-types of aphasia in the brain resulting from lesions in different areas; 'different different tasks' (Caplan 987:0). Wernicke's case studies showed patients who's speech was fluent and plentiful but were unable to make sense. These approaches to aphasia dominated the field until recent years. Anatomical diagrams of the brain label Broca's area and Wernicke's area as crucial in the location of language within the brain. Broca's area has been associated with the ability to produce language and Wernicke's solely with the ability to comprehend language. There are however some criticisms to these particular findings. Anti-LocalizationistsThe anti-localizationists disagree with the theory that language functions can be localized within the brain and suggest that 'evidence for widespread cerebral activation in higher functions has been accumulating physiologically and anatomically' (Kertesz 983:). Lesion Specific:One of the main problems with limiting the localisation of a language feature to one area of the brain is the fact that in the majority of cases there is a 'co-occurrence of symptoms' (Caplan 987:3), that is that most if not all of aphasic patients have more than one language deficit. One explanation as to why this could be is due to the anatomical structure of the brain. For example, 'agrammatism', the omission of grammatical words, is often accompanied by 'dysarthia', a disturbance of articulation. It is suggested that the reason these two disturbances occur together is due to the fact that 'the neurological areas responsible.partially overlap, or are in close proximity in the brain' (Caplan 987:4). Thus in most cases a lesion in the brain will affect both these features of speech, however it is also important to note that on occasion a 'lesion will spare enough of one region to allow one of these functions to escape without disruption' (Caplan 987:4). Another problem with the localizationists is that one of their main arguments claims that the site of a lesion will cause the exact same language problem in all individuals. Basso et.al suggest that this is not always the case. The research of Basso et al. focussed on the correlation between lesion location and the type of aphasia experienced by the patient. Their findings suggested that not all patients omitted expected results. For example: Three of the subjects were classed as 'non-aphasic' but had lesions in the classic speech area. There were also two patients that were aphasic but had lesions outside the classic speech area. There were also patients that had been diagnosed with global aphasia but had lesions that spared Wernicke's area. The researchers admit that the number of published cases is 'too small to consider as 'exceptional cases'' (Bassoal. 985/8:25/8) and that more research is necessary offer a 'satisfactory explanation' (Basso et al.985/8:26). However their findings do suggest that the theory of localization is not as clear cut as 'current tenets would have them'. Cappaal. suggest that the diagnostic labels of aphasia, Broca's aphasia in particular, are too broad and that they should be replaced by 'more detailed linguistic and neurological descriptions of the clinical cases'. This suggests that the 'characteristics' of Broca's aphasia are not as clear cut as originally implied and that 'Broca's aphasics.show a highly variable pattern of impairment'. This supports the work of Ulman who claims that the ideas of localizationist Grodzinsky are 'hampered by problems of patient selection'. Grodzinsky, fundamentally a localizationist, published a paper claiming that the function of Broca's area was more localized that had originally been thought. Testing patients regarding their comprehension skills primarily takes the form of assessing the ability of subjects to understand sentences both in the active and the, more difficult, passive form. This comprehension skill is classified as a syntactic ability. Grodzinsky claimed that Broca's area was responsible for syntactic ability, as this was affected by damage to this area. Bastiaanse & Edwards however found that the same function was also evident in patients with Wernicke's aphasia. This suggested that the localisation of syntactic functioning is not necessarily located in one specific area of the brain. Ulman further criticized Grodzinsky's claim by suggesting that 'conclusions regarding the function of Broca's region would be less problematic if patients were selected solely on the basis of their lesions'. Ulman suggested that the patients upon which Grodizinsky's claims were based had additional lesions outside Broca's area, and 'even worse, have no reported lesions at all' (e.g. Friedmann & Grodzinsky 997). Subjects:The selection of subjects has proven problematic in the study of aphasia. Edwards notes that diagnosis is a fundamental issue in that individuals may diagnose patients differently depending on experience in the field. Aphasics can also be diagnosed via non-aphasic testing. Equally certain methods can be interpreted differently, Kerschensteineral. for example found that the fluency continuum was problematic in diagnosis as six aphasic speakers remained unclassified. Although there are standard characteristics associated with the different types of aphasia these can overlap or may not be evident under limited testing sessions. Research into localization suggest that patients experiencing certain symptoms will have lesions which correlate. For example: Non-fluent speech correlates with Broca's aphasia. However making generalisations into the localization of all language is limited by taking into account the selection of subjects. In order to limit the variables in research, patients are selected according to certain specific criteria. However as Basso et.al note as the patients are 'essentially right-handed, unilingual, literate adults who speak a language without tonal oppositions and write with an alphabetic or kindred code' they only represent one-fourth of the human population. However as humans have language and their brains are ultimately the same it should be presumed that the location of language would also be the same. Therefore if localisation theories are to be accepted they should be expected to include bilinguals, illiterates and populations who speak tone languages but Bassoal. suggest 'there is reason to doubt these concepts apply in toto'. There is also criticism that the localisationists' research fails to compare to normal speakers. Young & Hutchinson suggest that there is no assurance that all 'neurologically normal competent speakers would perform ideally' to the tasks that aphasics struggle with. This suggests that the research of localising language functions within the brain pays little attention to normal functioning brains. Dick & Bates suggest that when research has been done on normal brains evidence has shown that 'Broca's area itself is involved in many different linguistic and non-linguistic tasks' This could explain why diagnosing the specific features of Broca's aphasia is difficult as it is suggested that the area performs many functions. This weakens the localisationist argument that specific language functions are solely located in this area of the brain. Reliability of generalizing from studies: It is also important to look at how group studies and individual studies can inform our knowledge about the localisation of functions within the brain. The argument adopted by the functional analysis approach claims that 'agrammatism' is a result of the 'dysarthia' because the patient simplifies his speech purposely. This is so as to produce the fewest words possible as pronunciation is difficult for them. It is important to note that if the functional account of the co-occurrence of symptoms is correct then 'the symptoms in question should always co-occur because both are a consequence of the same functional disturbance' (Caplan 987:5/8). If we look at group studies the symptoms should in theory be universal across everyone. Thus all damage to that particular area of the brain should result in the same language deficiency. In practice, matters are much more complex. Caplan notes that often published studies do not 'show consistent groupings of symptoms or subjects'. It is often possible to find explanations for 'exceptions to symptom groupings'. Caplan notes how individuals may be exceptional in the way their cognitive functions are organized thus the disturbances they experience may lead to different overall disturbances. For example; a person may speak by accessing purely motor representations bypassing auditory memories of the sounds of words. Therefore a disturbance of permanent memories for the sounds of words might lead to a disturbance in comprehension with disturbances in spontaneous speech. This indicates that although we can map certain language processes within the brain it is sometimes difficult to generalize as there are exceptions to how individuals may function. The patient you are looking at could either be an exception or representative of many. However, it is therefore interesting to note that 'there are very few examples of associations of symptoms which hold reliably across any number of patients' (Caplan 987:6). Inter-individual variability suggests that making inferences about groups of patients is difficult, as there can be exceptions which weaken the exact theory of localization. Left Hemisphere Dominance:Broca's original findings suggested that lateralisation of the brain meant that the left hemisphere was dominant for language use. This was originally hypothesised by Broca when after his patient's death he discovered damage to the left hand side of the brain. His patient had paralysis to the right hand side and severe language problems. Therefore Broca concluded that language was controlled by the left hemisphere. This has been further proven by experiments such as the dichotic listening task. This test found that most of input into the right ear goes to the left hemisphere of the brain and this became known as the right ear advantage. However recent research has claimed that suggestions that the left hemisphere is exclusive in language representation are 'no longer sustainable' (Cappaal. 000:7). It must be noted that speech can still be understood via the left ear too. There are two key reasons as to why this is; firstly 'the auditory pathways to the brain are not completely crossed' (Libben 996:24) and secondly information between the two hemispheres can be transmitted across a 'bundle of fibres' known as the corpus callosum. Studies on 'split-brain' individuals whereby the corpus callosum is severed show interesting findings. Libben concludes that from the behaviour of split-brain patients 'that although the right hemisphere does show some language understanding, it is mute'. For example when blindfolded the patients could name an object in their right hand but not when it was placed in their left hand. This showed that 'the right hemisphere, which receives information from the left hand, knows what is there, but it can neither put this into words nor transfer the information across the severed corpus callosum to the left brain'. Both the above experiments supported Broca's theory of lateralisation. However more recent research has placed more emphasis on the role of the right hemisphere on language. Although the left hemisphere is seen to be the more dominant side in language the right side contributes more than was originally thought. Libben for example notes how in some adults the removal of the left cerebral hemisphere results in most 'but not all of their linguistic competence'. This shows that the right hemisphere does play a role in language and that certain language features could be localised in the right hand side of the brain. It is suggested that the right hemisphere has a distinct role in the normal language use of humans as those with damage to this side of the brain 'exhibited difficulty in understanding jokes and metaphors in everyday conversation'. Patients with such damage were only able to take the literal meaning of a figurative sentence. Cappa et.al claim that neuroimaging work has shown 'right brain involvement in both language comprehension and production'. These findings suggest that language functions are located across the brain and may not just be limited to the left hemisphere. Having said this it is important to note that it is generally agreed that complex grammar skills are localized to only one hemisphere (Lustepal. 995/8). Conclusion:Research into the location of language within the brain is ongoing. Using aphasic patients to help locate specific language functions within the brain has helped to suggest certain theories. Over the years it has become more clear that although the left hemisphere is dominant in language the right hemisphere does have a role to play. Lesions to particular areas of the brain do for the majority of the time cause specific language deficits however it is still unclear as to the 'precise topography and extent of cerebral damage required to produce Broca's aphasia' (Levine & Sweet 983:85/8), thus it is difficult to make associations between lesion location and lesion damage. As I have discussed, findings have shown that there can be 'exceptions' as to where the lesion is located and the type of aphasia found. Although these findings are limited to single case studies and may be down to inter-individual variability they provide enough doubt to suggest that localisation of specific language functions within the brain is not as clear cut as originally thought.'''",769.0
"'''IC. B. MacPherson's Political Origins of Possessive Individualism was published in 962 and has caused great controversy. The book set up a model of a fully competitive market society and examined, with its aid, the political theory of Hobbes, the Levellers, Harrington and Locke. This essay will concentrate on the thesis it proposed on the Levellers and their position regarding franchise reform in the seventeenth-century. MacPherson's thesis has resulted in a lively debate between himself, supported by Christopher Hill, on the one hand, and J. C. Davis, Peter Laslett, A. L. Morton and Keith Thomas, on the other, although many other historians have made valuable contributions. MacPherson essentially argues that the Levellers 'always intended. a franchise excluding servants and alms-takers; and that they saw no inconsistency between this exclusion and their assertion of the natural right of every man to a vote, because of certain assumptions they made about the nature of freedom'. The greatest criticism of this thesis has been directed at MacPherson's definition of the term servant, which he argues encompassed all wage-earners. Objections have also been raised concerning the use of statements made by Maximillian Petty at the Putney Debates and the inferences made therein, the interpretation of what the Levellers meant by alms-takers and the use of statistics from Gregory King's Natural and Political Observations and Conclusions upon the State and Condition of England. In 973 MacPherson replied to his critics in Democratic Theory: Essays in Retrieval, yet many of the problems with his original arguments still remain. Peter Laslett, 'Market Society and Political Theory', The Historical Journal,, p. 5/80 Christopher Hill, 'Possessive Individualism', Past and Present, 4, pp. 6 - 9, J. C. Davis, 'The Levellers and Democracy', Past and Present, 0, pp. 74 - 80, Laslett, 'Market Society and Political Theory', pp. 5/80 - 5/84, A. L. Morton, The World of the Ranters: Religious Radicalism in the English. B. MacPherson, Democratic Theory: Essays in main criticisms of MacPherson's thesis that this essay will highlight, and consequently argue as being fundamental to understanding the position the Levellers took towards the issue of the franchise, are twofold. First, that it is not possible to make a single theory applicable to the whole of the movement; it was full of internal differences of opinion, and was therefore not the homogenous party required for MacPherson's thesis. Second, that the Levellers were prepared to compromise their position on the franchise according to political events and to secure the acceptance of other equally important parts of their programme, and thus their standpoint changed. This essay will focus on evidence from the authoritative documents on the franchise, the Agreements of the People and the Case of the Armie Truly Stated, and a plethora of other Leveller tracts and especially the debates at Putney, around which MacPherson's argument centres. An attempt will be made, therefore, not only to dispute much of MacPherson's argument, but to propose a different hypothesis of how the Levellers interpreted franchise reform, based around the notions of compromise and heterogeneity. IIThe starting point must be the Putney Debates, for it is from here that MacPherson commences and from which he makes all his later inferences that form the crux of his argument. The Levellers set out their franchise proposals to be debated at Putney in Article I from An Agreement of the People, the first Agreement, which stated: 'That the people of England, being at this day very unequally distributed by counties, cities, and boroughs, for the election of their deputies to Parliament, ought to be more indifferently proportioned, according to the number of the inhabitants; the circumstances whereof, for number, place, and manner, are to be set down before the end of the present Parliament.' An Agreement of the A. S. P. the Clarke Manuscripts with Supplementary Woodhouse, Puritanism and Liberty, p. 2 MacPherson highlights Petty's response: 'We judge that all inhabitants that have not lost their birthright should have an equal voice in elections.' The Putney Woodhouse, Puritanism and Liberty, p. 3 MacPherson argues that in this first Leveller statement on the franchise in the debate, 'one category of inhabitants was excluded'. Even at this early stage in the proceedings however, the full range of interpretations have been made by historians, with Morton stating that such a response illustrates a 'note of ambiguity almost weakness', and Thomas arguing that 'in modern terminology' this 'stood for manhood suffrage'. Yet, if MacPherson's interpretation is correct, and the Levellers proposed a small extension of the franchise, it is curious that Ireton objected so strongly, supported by Colonel Rich who stated that: MacPherson, The Political Theory of Possessive Individualism, p. 22 Morton, The World of the Ranters, p. 02 Thomas, 'The Levellers and the Franchise', p. 74 'If the master and servant be equal electors, then clearly those that have no interest in the kingdom will make it their interest to choose those that have no interest.' The Putney Woodhouse, Puritanism and Liberty, p. 3 It is important to notice that Rich clearly understands Ireton's argument 'to be directed against someone who would include servants in the franchise' and that there is 'no dissenting voice to this imputation'. Rich's remark would also appear strange if, as MacPherson argues, both the Grandees and Levellers tacitly agreed that they were discussing a non-servant franchise. Iain Hampsher-Monk, 'The Political Theory of the Levellers: Putney, Property and Professor MacPherson', Political Studies, 4, p. 02 Morton, The World of the Ranters, p. 04 However, when the debate reaches the discussion of the details of the franchise extensions MacPherson uses another statement by Petty to interpret his initial declaration: Cromwell: 'Servants, while servants, are not included. Then you agree that he that receives alms is to be excluded?' Petty: 'I conceive the reason why we would exclude apprentices, or servants, or those that take alms, is because they depend on the will of other men and should be afraid to displease.' The Putney Woodhouse, Puritanism and Liberty, pp. 2 - 3 He argues that it becomes clear that the Levellers had always been assuming the exclusion of servants and alms-takers and this was understood by their opponents; Cromwell starts from this agreed point. Petty does not refute the exclusions, which MacPherson asserts would be expected if the Levellers advocated manhood suffrage, but actually states the reason. MacPherson, The Political Theory of Possessive Individualism, p. 22 However, MacPherson's interpretation of the debate does not seem to concur with the progress of discussion. Colonel Rolfe realised the debate had entered a position of stalemate, recommending that: '.a medium, or some thoughts of a compromise, in relation to servants or foreigners, or such others that shall be agreed upon.' The Putney Woodhouse, Puritanism and Liberty, p. 0 Ireton consequently introduced the argument about the dependence on the will of other men: 'If you do extend the latitude that any man shall have a voice in the election who has not that interest upon which he may have his freedom in this kingdom without dependence, you will put it into the hands of men to choose, of men to preserve their liberty, who will give it away.' The Putney Woodhouse, Puritanism and Liberty, p. 2 Cromwell continues this line of argument, taking up Rolfe's suggestions and does not start from an agreed point, as MacPherson argues, but responds to a period in the debate. Hence 'Petty's remarks after this could be interpreted as an examination of the proposal rather than an endorsement of it'. If it was a Leveller proposal, then it can be assumed that it would have been suggested far earlier in the debate to appease the Grandees, who were obviously concerned about the rights of property. 'It is much more likely, therefore, that his initial remark about inhabitants who had lost their birthright was a reference to the exclusion of the supporters of Charles I.' Davis, 'The Levellers and Democracy', p. 79 Christopher Thompson, 'Maximillian Petty and the Putney Debate on the Franchise', Past and Present, 8, p. 7 The position of the Levellers becomes far clearer if the section that MacPherson neglects is considered. After interpreting the opening exchanges of the discussion, he leaps to Cromwell's interjection ignoring nearly 0 pages of debate. In this section each side set out their position on the franchise. Ireton advocated the freeholder franchise, those with a 'permanent fixed interest', whilst the Levellers proposed enfranchising 'any man that is born in England'. On more than six occasions in the next 0 pages 'one or two of the other protagonists reiterates the basis of the issue that divides them'. Nonetheless, MacPherson explores the idea that the claims by the Grandees that the Levellers advocated manhood suffrage were merely exaggerations, but he concludes that 'we cannot tell whether these phrases as used by Cromwell and Ireton in the earlier part of the Putney debate were hyperbole or not.' John Boy's record of Cromwell's subsequent speech to Parliament 'reveals he sincerely believed his own and Ireton's rhetoric about the thrust behind the Agreement'. The Levellers never denied these accusations, for example Wildman, when asked by Cromwell 'where is there any bound or limit set?' replied: The Putney Woodhouse, Puritanism and Liberty, pp. 4 - 2 The Putney Woodhouse, Puritanism and Liberty, pp. 4, 5/8 Hampsher-Monk, 'The Political Theory of the Levellers', p. 99 MacPherson, The Political Theory of Possessive Individualism, p126 MacPherson, The Political Theory of Possessive Individualism, p127, supported by Hill in A. L. Merson, 'Problems of the English Bourgeois Revolution, Some Reflections on the Recent Work of Christopher Hill', Marxism Today,, p. 14 Ian Gentles, 'The Agreements of the People and their political contexts, 647 - 649', in Michael Woodhouse, Puritanism and Liberty, p. 9 'Every person in England hath as clear a right to elect his representative as the greatest person in England.' The Putney Woodhouse, Puritanism and Liberty, p. 6 Yet when falsely accused on other issues the Levellers were quick to repudiate such allegations. For example, when charged that they intended the abolition of property Rainsborough retorted 'that it is fully answered: God hath set down that thing as to propriety with this law of his, Thou shalt not steal'. Hampsher-Monk, 'The Political Theory of the Levellers', p. Putney Woodhouse, Puritanism and Liberty, p. 9 Nevertheless, MacPherson argues that in light of Petty's statements it is possible to infer that servants and alms-takers had 'lost their birthright', and were therefore ineligible to vote under Leveller proposals. There is the question therefore, which MacPherson addresses, of how the unqualified statements at Putney are to be understood, if the Levellers always intended such exclusions. He argues that they 'may quite as well have been understood to exclude servants as they undoubtedly were understood to exclude women'. Therefore, broad terms such as Rainsborough's 'poorest man in England' and 'every man born in England' are assumed to have been the equivalent of 'all free born men who have not lost their birthright'. In this case MacPherson is able to illustrate consistency in Leveller proposals, despite the apparent advocation of a manhood franchise. MacPherson, The Political Theory of Possessive Individualism, pp. 22 - 24 MacPherson, The Political Theory of Possessive Individualism, p. 26 The Putney Woodhouse, Puritanism and Liberty, pp. 3, 6 The main problem for MacPherson's argument is his use of Petty. Not only is there great doubt as to the way in which Petty's later statement on the exclusions are interpreted, but there is a significant question concerning him as a Leveller spokesman. MacPherson assumes that Petty's views were synonymous with those of the Levellers, but apart from this appearance, the fact that he sat on some of the Leveller committees, and that he later became a member of Harrington's Rota Club, whose aristocratic republican tone was very different from that of the Leveller's, little is known about him. In any case Petty's proposals for the exclusion of servants and alms-takers, whether they are taken as implicit throughout Putney or as a response to the suggestions of the Grandees, do not commit the other Levellers. For, as will be described at length, the Levellers were a disparate movement with a wealth of opinions. Petty explained that he came to Putney 'to give my own reason why I do assent to it '. Moreover, on the first and third days of debate Petty said nothing, whilst Wildman and Rainsborough acted as Leveller spokesmen. On the second day when he made the statements upon which MacPherson places so much emphasis, it was once again Wildman and Rainsborough who did much of the negotiating. There is no reason therefore to take Petty as more representative of the Leveller proposals than, for example, Rainsborough whose response was far clearer, and arguably was 'the simplest claim for equality ever made in English history': Davis, 'The Levellers and Democracy', p. 75/8 and Thomas, 'The Levellers and the Franchise', p. 7 Thompson, 'Maximillian Petty and the Putney Debate on the Franchise', p. 3 The Putney Woodhouse, Puritanism and Liberty, pp. 2 Davis, 'The Levellers and Democracy', p. 76 H. N. Brailsford, The Levellers and the English Woodhouse, Puritanism and Liberty, p. 3 If this is to be accepted then it is far more likely that the Levellers were more democratic than MacPherson would admit. Yet Rainsborough was also somewhat of a peculiar figure in terms of the Levellers. A trend is therefore becoming apparent in analysing the individuals of the movement and subsequently trying to find any consistent principles, which will be explored. In considering Petty's position at Putney it is interesting and important to note a change, for which MacPherson does not account. Petty began as a supporter of the Agreement and manhood suffrage, but soon recognised the need to gain the support of the Army Grandees if the Levellers were to maintain their political importance. Once it was clear that manhood suffrage would not be accepted by the Cromwell and Ireton, Petty was prepared to compromise towards the end of the debate by excluding certain groups. On the th November 647 the General Council of the Army agreed to extend the franchise to all men except beggars and servants: 'the Agitators and their Levellers allies regarded this as a substantial victory'. Although they had to compromise on their original proposal for manhood suffrage, they had secured an agreement on a much wider franchise than ever before. MacPherson, therefore, was correct in using Petty as representative of the Levellers, although for a different reason. His shift 'was the first sign of the movement the Levellers subsequently made on the issue for tactical reasons' that will be fundamental to the argument of this essay. Thompson, 'Maximillian Petty and the Putney Debate on the Franchise', p. 9 IIIEven if MacPherson is incorrect in asserting that the Levellers always implied the exclusion of those who had lost their birthright, they eventually compromised and agreed to a non-servant franchise. It is therefore necessary to understand who they understood to be servants and alms-takers. One of the greatest controversies surrounding MacPherson's thesis has been regarding his interpretation of the term servant. In The Political Theory of Possessive Individualism MacPherson stated in a footnote that 'in seventeenth century usage servants meant wage-earners, anyone who worked for an employer for wages', discussing the matter further in an appendix. Although this came under much criticism he reiterated his statement eleven years later: 'it can also I think be shown that my more sweeping statement - that servants meant wage-earners - remains valid generally'. MacPherson, The Political Theory of Possessive Individualism, pp. MacPherson, Democratic Theory, p. 13 MacPherson, Democratic Theory, pp. 14 - 15/8 MacPherson, Democratic Theory, pp. 16 - 17 It is difficult to argue against MacPherson's assertion that the dependence of in-servants and out-servants on their masters was, in part, of a market nature. However, the out-servant had, in general, a greater level of independence from the employer, due to short term contracts. Although he clearly depended on the will of other men, the out-servant had a certain level of freedom to choose, or at least leave, his master. The in-servant was bound to his master for the whole year during which he was in a patriarchal relationship. This is of importance when related to the process of voting, as part of the reason for excluding servants was to avoid intimidation at the hustings. 'It was not likely that the general body of wage-earners would be intimidated, but the servants of single employers would certainly have feared to vote by publicly lifting their hands against the wishes of the lord and master.' Under the existing economic situation servants and beggars were therefore not free to follow their conscience, and for this reason could be justifiably excluded. Fenner Brockway, Britain's First Socialists: The Levellers, Agitators and Diggers of the English servants, who served by the year, from artificers and labourers being hired for wages by the day or week. A servant's contract could only be broken with the consent of the Justice of Peace, whereas the day-labourer was employed casually, frequently changed employers, often worked on a piece-work basis and could be dismissed at will. In the wage assessments by the Justices of Peace, wages of servants were given by the year and labourers by the day or week. An Agreement of the An Agreement of the Free People of Wolfe, Leveller Manifestoes, pp. 97, 03 and Thomas, 'The Levellers and the Franchise', p. 3 Thomas, 'The Levellers and the Franchise', p. 1 MacPherson does accept that there were certain administrative and statistical classifications the term servant was sometimes only used for a sub-class of wage-earners. For example, parish lists by household detailed the composition and the occupation of the head of the household. The term servant was used to indicate an in-servant, whereas wage-earners living out and being heads of their own households were listed by occupation, such as labourer or thatcher. MacPherson argues that 'in each class of cases there is a simple reason, of logic or convenience, for the narrow usage' and thus can be treated as 'subordinate or exceptional'. It is clear therefore that it was possible in seventeenth-century usage for the term servant to mean a domestic in-servant, especially when used in a narrow sense describing occupations. Yet, MacPherson does not consider that the Levellers and their opponents at Putney might both have understood that servants in this narrow sense, domestic in-servants and not the whole body of wage-earners, were being discussed. MacPherson, Democratic Theory, pp. 21 - 23 Disregarding this MacPherson concludes that as a 'general rule' the term servant meant all wage-earners. This, he asserts, is strengthened by the historical continuity of the terms master and servant. Where social and legal relations were being described, he argues, the most natural term for a wage-earner was servant, as it described on part of the master-servant relation, which had been in usage far before relations of a contractual nature were common. Yet, Thomas argues that the contemporary usage of the term servant was inconsistent, and reflected the antiquated vocabulary describing feudal relations of the master and servant, being related to the new employee and wage-earner association. This is also highlighted in MacPherson's other reason in asserting the 'general rule', that there was a lack of any other suitable term, as 'some word was needed to denote those described in our day as wage-earners'. Labourer, for example, was sometimes used in this context, but it was generally not suitable as it could have a status connotation reflecting those a grade below skilled tradesmen. But why, therefore, if labourer was not appropriate due to its other possible meanings, was servant, for it too, as MacPherson concedes, had other implications. In any case why is 'some word needed' for all wage-earners? This period was characterised by the rapid increase of wage-earners and it is very likely for there to have been a 'time lag between development of new social relationships and the invention of a vocabulary adequate to describe them'. MacPherson, Democratic Theory, p. 20 Thomas, 'The Levellers and the Franchise', p. 2 MacPherson, Democratic Theory, p. 19 Thomas, 'The Levellers and the Franchise', p. 2 The term servant therefore had a great number of connotations in the seventeenth-century, but the Levellers when they excluded servants were more likely to have been describing the traditional meaning of the term, the domestic in-servant, than the emerging wage-earning class as a whole. The Leveller programme contained proposals that increased 'the opportunities for apprentices and servants to become masters'. If the they believed that servants were only under the temporary control of their lord, and could under Leveller reforms break free of these shackles, then it is 'easier to explain why their spokesmen apparently attached so little importance to the disenfranchisement of servants and took so little pains to justify what would otherwise have been in glaring contradiction to their very sweeping and emphatic assertions of the rights of every man to have a voice in choosing the government he lived under'. Merson, 'Problems of the English Bourgeois Revolution', p. 15/8 IVThere is also a certain amount of ambiguity concerning the term alms-taker. The Levellers used both terms alms-taker and beggar, which can have significantly different meanings. A beggar is different from a cottager forced to seek emergency parish relief and different again from those habitually dependent. Until the second Agreement only beggars were excluded; they were formally voted out in the resolution passed after Putney, and were excluded in the terms of the Earnest Petition. At Putney it is only Petty that mentions 'those that take alms' and, as described, this can be understood as an examination of the proposals put forward by Cromwell and Ireton. In any case Petty continued to describe 'those that receive alms from door-to-door', which is surely a reference to beggars and not those in receipt of parish relief. Even the 'persons receiving Almes' excluded from the franchise in the Officer's Agreement were taken by a contemporary, Marchament Nedham, to be synonymous with vagabonds. The Levellers evidently did not want to exclude from the franchise those who sought emergency parish relief, for the Levellers felt great sympathy towards them. Such people had been temporarily impoverished by the Civil Wars, and 'we know that they regarded alms-takers as capable of taking their own decisions'. The Levellers therefore certainly wanted to exclude beggars from the franchise and, until the Officer's Agreement around which there is an element of doubt, wanted to enfranchise alms-takers. However, MacPherson argues that the Levellers sought not only to exclude beggars, but also alms-takers that were 'notoriously marked out as dependent'. Although this fits in neatly into his theory of exclusion from the franchise as a result of the dependence on the will of other men, it is not corroborated by evidence that was unfortunately not available to him. On 3 rd December 647 Cromwell reported to the House of Commons that the London Agents had insisted that 'such as received alms' were persons 'competent for elections'; 'perhaps drawing a distinction between door-to-door beggars and those who were supported by the poor rate'. The statistical difference between these two groups is enormous. From MacPherson's estimates for 648 there were 43,00 alms-takers, but only 0,00 beggars. The Levellers therefore only intended to exclude a marginal minority of adult males, and this can hardly been seen as contradictory to the principle of manhood suffrage. Morton, The World of the Ranters, p. 15/8 A Letter from Several Agitators to their Woodhouse, Puritanism and Liberty, p. 5/82 William Haller and Godfrey Woodhouse, Puritanism and Liberty, p. 2 An Agreement of the Don M. Woodhouse, Puritanism and Liberty, p. 33 Thomas, 'The Levellers and the Franchise', p. 6 'I being a freeman of England and never tainted with malignancie against the just freedome of the Nation. do not know that I did any act that disenfranchised me of my freedom.'John Lilburne, Innocency and Truth Woodhouse, Puritanism and Liberty, p. 3 Thomas, 'The Levellers and the Franchise', p. 5/8 VIMacPherson also uses Petty's remarks at Putney to make inferences about the nature of Leveller franchise reform proposals in the pre-Putney pamphlets. He argues that none of the pre-Putney documents were specific concerning Leveller proposals for the franchise, and that only by understanding the issues at Putney, where the extent of the proposed franchise enlargement was 'first made explicit', can interpretations be made about earlier statements. That none of the pre-Putney pamphlets stated specific exclusions is not significant for MacPherson, as the Levellers were in a period in which they were concerned with other matters. It was only at Putney that the franchise became the pre-eminent issue, because the Levellers had reached a strong enough political position to be able to think as far ahead as to the extent of the franchise reforms. As noted MacPherson argues that at Putney, in light of Petty's statements, when the Levellers talked of, for example, 'freeborn men', they were not considering all men, but those that had not lost their birthright. Thus, MacPherson argues, this interpretation can be used to construct a better understanding of The Case of the Armie Truly Stated: MacPherson, The Political Theory of Possessive Individualism, p. 19 '.all the freeborn at the age of 1 years and upwards, be the electors, excepting those that have or shall deprive themselves of that their freedome.' The Case of the Army Truly Wolfe, Leveller Manifestoes, p. 12 In light of the assumptions made at Putney servants and alms-takers therefore 'deprived themselves' and were not eligible for the vote under Leveller reform proposals. The same approach can be taken with A Remonstrance of Man Thousands of Citizens, when it demanded that 'all men that have a Right to be there' in elections. Joseph Frank argues that this statement illustrated the Levellers' commitment to manhood suffrage, but 'the proposal is for compulsory voting by 'all men that have a right', not for all men to be given the right to vote'. MacPherson continues to cite numerous other examples accordingly from England's Birthright Justified, London's Liberty in Chains, Jonah's Cry from the Whale's Belly and Rash Oaths Unwarrantable. MacPherson, The Political Theory of Possessive Individualism, p. 30 Richard Overton, A Remonstrance of Many Thousand Wolfe, Leveller Manifestoes, p. 29 Joseph Frank, The Levellers, A History of the writings of three seventeenth century Social Democrats: John Lilburne, Richard Overton, William and Brewster, 'Reconsidering the Levellers', p. 7 Howell and Brewster, 'Reconsidering the Levellers', p. 7 Howell and Brewster, 'Reconsidering the Levellers', p. 9 The attitudes of William Walwyn are the best example of individual diversity within the movement. He has been described as 'one of the most thorough-going revolutionaries in an age of revolution', by questioning commonly accepted ideas challenging the whole social structure. Not long after the second Agreement Walwyn appears to have ceased playing an active part in Leveller affairs for some time. When he, Lilburne, Overton and Prince were arrested on 8 th March on the charge of publishing the second part of England's New Chains Discovered, Lilburne was surprised as Walwyn had played no part in its preparation: Morton, The World of the Ranters, p. 43 'We could not but wonder at the apprehending of M. Walwyn about that, he having for some months bin at any of our meetings, where any such things were managed.'John Lilburne, The Picture of the Councell of Wolfe, Leveller Manifestoes, p. 95/8 It is also possible to see other differences between Walwyn and the majority of the Leveller leadership. His opponents constantly tried to show that he was in favour of equality of condition and the abolition of private property and to therefore infer such beliefs on the movement. On the latter point Walwyn responded unequivocally, referring to Article XXX of the final Agreement: Morton, The World of the Ranters, p. 83 'That it shall not be in the power of any Representative, in any wise, to render up, or give, or take away any part of the Agreement, nor level men's Estates, destroy Propriety, or make all things Common.' An Agreement of the Free People of Wolfe, Leveller Manifestoes, p. 09 Thus the Agreement repudiated all charges directed against the Levellers, especially that they favoured levelling. But Walwyn, who wrote the preface 'was a convinced egalitarian, favouring equality in education and advocating a near approach to equality of income'. Thus, on Walwyn's personal views 'we are less certain ground'. Walwyn's Wiles, while obviously exaggerated, gives an explicit and lengthy account of what ideas were attributed to Walwyn. He was, for example, accused being of communist: Brockway, Britain's First Socialists, pp. 3 - 4 Morton, The World of the Ranters, p. 84 '.that it would never be well until all things were common; and it being replyed, will that be ever? Answered, we must endeavour it; It being said, That this would destroy all government; answered, That then there would be lesse need of Government, for then there would be no theeves, no covetousness persons, no deceiving and abusing of each other'. Walwyn's Wiles (May, 649), pp. 3 - 4 in Morton, The World of the Ranters, p. 85/8 'The arguments here are so apt, and the tone of the actual speech so well caught that it is very hard to think this passage is pure invention', for Walwyn never denied having made such comments. Walwyn was thus quite different from much of the Leveller leadership who, whilst many being close to advocating manhood suffrage, were staunch defenders of private property. Morton, The World of the Ranters, p. 86 The Levellers were therefore a group of radicals drawn together in the 640s by shared grievances. At the zenith of their political influence, between 647 and 648, the Levellers had to begin formulating concrete proposals for political, social and economic reform. It is in this period that the extent of the diversity within the movement became pronounced. The Levellers were heterogeneous and therefore, to look for a single theory on the franchise that all Levellers supported is to misunderstand the movement. What can be done instead is to understand what the Levellers proposed at a given time concerning the franchise and why this was the case. For the Levellers were astute politicians, more than political theorists, and it is therefore necessary to interpret the development of their franchise reform proposals in terms of political reality and not abstract theory, as MacPherson has done. VIIIMacPherson dismisses the notion of a 'temporary change in the Leveller position', but this is to misinterpret the Levellers and the political situation. Morton argues that the Leveller pamphlets were not merely abstract statements of political theory, but 'they were party programmes, weapons in an active political campaign and modified from time to time in accordance with the changing political situation and the political needs of the struggle'. It is here that the second fundamental reason for Leveller inconsistency can be found. As the Levellers became increasingly politically influential and made a serious bid for power, their programme underwent frequent tactical changes reflecting political developments, which will be assessed chronologically. It is also necessary to remember that Leveller franchise proposals were 'not meant to be taken in isolation but as part of a programme of democratic reform which would transform England'. MacPherson, The Political Theory of Possessive Individualism, p. 10 Morton, The World of the Ranters, p. 02 Morton, The World of the Ranters, p. 15/8 The first sign of Leveller compromise was at the Putney debates. This has already been discussed in depth and therefore it should suffice to merely highlight the main developments. The compromise was first suggested by the Army Officers, and Petty was the only Leveller to accept the need for concession. Petty realised that although the Levellers were in a politically strong position, for them to further their cause they required the support of the Army. Compromise was therefore necessary, for the Grandees would never have accepted manhood suffrage. This tactical compromise 'had the desired effect of winning moderate opinion to their side'; only three officers dissented in the resulting vote. Although the Levellers had conceded a certain amount of ground from their initial position of manhood suffrage (yet it must be remembered that due to internal inconsistencies not all advocated such reforms), they had obtained an agreement for the extension of a far wider franchise than ever considered possible. Gentles, 'The Agreements of the People and their political contexts', p. 5/82 The Putney debates were followed by a resolution proposed by Rainsborough for a general rendezvous of the Army, where the Agreement was to be endorsed as a step towards national implementation. Yet Cromwell and Ireton were 'soon able to launch an effective counter-strike', for the Levellers were becoming too powerful within the Army and they felt the need to reassert their control. It was therefore announced that there would be three separate meetings. At the first rendezvous at Corkbush Field in Ware the Grandees were to present their Remonstrance to the seven invited regiments, designed to reunite the Army. However, two further regiments joined the rendezvous uninvited, those of Colonel Robert Lilburne and Colonel Thomas Harrison, the latter wearing copies of the Agreement in their hats. The Army leadership responded by ordering the radical officers off the field, some were arrested and one was shot in an attempt to regain control of the situation. In the aftermath of Ware and the recovery of full control by the Grandees, the General Council once more became exclusively consistent of officers; 'the Levellers had therefore lost their platform inside the Army'. Thus there was a greater necessity for the Levellers to compromise with the Generals to gain their support once again, but in the short term the Levellers were forced to renew the emphasis on petitioning. Morton, The World of the Ranters, p. 06 G. E. Aylmer (ed.), The Levellers in the English Revolution (London, 975/8), p. 9 Accordingly the Large Petition of 1 th September 648 was published. It was a compromise document and therefore extreme proposals, notably demands for manhood suffrage, were omitted in an attempt to regain moderate and especially Army support. It still contained demands for much far-reaching reform; it rejected any treaty with the King, advocated religious freedom, equal justice, the end to oppressive tithes and taxes, but unlike the first Agreement it said nothing on the dramatic reform of the franchise. It was not a document written theorising about a Leveller utopia, but was a reflection of the current situation in which the Levellers had been marginalised and were striving for reincorporation. Such sentiments were echoed by Wildman regarding the Earnest Petition, which contained the exclusion of servants and alms-takers from the franchise. Wildman stated that the authors 'inserted no such particular grievances as might disengage any considerable party, and so continue our distractions.' Thus the Leveller leadership recognised the need to be politically astute and whilst proposing radical reform, in order to for such proposals to have the best chance of being implemented they required widespread support, at least with the politically powerful. The Levellers were therefore willing to compromise and continue with the exclusion of servants and alms-takers, if this provision was to enable the movement to further its other causes. Brockway, Britain's First Socialists, p. 0 Jack R. McMichael, and Barbara Taft, The Writings of William Walwyn (Georgia, 989), p. 4 Thomas, 'The Levellers and the Franchise', p. 8 This is best illustrated by the second Agreement, in which the franchise clause 'embodies the greatest concessions which both the Levellers and their opponents were prepared to make'. Facing the apparently imminent conclusion of a treaty between Charles I and the Presbyterian majority in Parliament, Cromwell and Ireton decided it was necessary to reopen relations with the Levellers, and a new Agreement was thus drafted. MacPherson argues that 'we can dispose at once of the complication of the second Agreement', as the ratepayer franchise it proposed was only slightly narrower than the non-servant franchise of the previous Agreement. However, this takes a far too statistical approach. What is of more significance is that the Levellers, and the Grandees, were prepared to make yet more concessions in order to maintain their political influence, and for the acceptance of the Leveller programme as a whole: 'it shows the Levellers at their most practical and realistic'. 'The Leveller's proposals would have destroyed the domination of the landowners as the ruling class', and the concessions on the franchise were therefore worth conceding if the rest of the Leveller programme was to be adopted. Morton, The World of the Ranters, p. 11 Aylmer, The Levellers in the English Revolution, p. 0 MacPherson, The Political Theory of Possessive Individualism, pp. 15/8 - 16 Gentles, 'The Agreements of the People and their political contexts', p. 60 Brockway, Britain's First Socialists, p. 1 Despite the best efforts of the Levellers to maintain their political influence, by 649 the Army leaders and their parliamentary allies were in firm control of events. The King had been executed and the country was in a state of peace; taxes were being collected, and law and order was imposed. The 'new rulers seemed to be setting up as tight-knit and oligarchical regime as any which had been seen in England before'. The Levellers were therefore intensely dissatisfied with the situation that had developed and published England's New Chains Discovered, which criticised the increasingly tyrannical nature of the regime. As a result of the publication of the second part of England's New Chains Discovered Overton, Prince and Walwyn were arrested on 8 th March 649 and imprisoned in the Tower of London. It was from the Tower that they produced the final Agreement, which in terms of the franchise 'may fairly be taken as the final expression of what they considered practicable under existing circumstances'. This Agreement was not necessarily a manifesto of proposed reforms, but an attempt to produce consensus and 'unite all democratic elements'; thus it was radical, but was not extreme. In the Agreement therefore the Levellers 'stripped away the qualifying causes found in the second Agreement'; it demanded the franchise for all men over 1 except for servants, recipients of alms and those who had served for the late King, thus removing the ratepayer qualification. The Levellers still did not demand manhood suffrage, as they had to compromise in order to regain their broad base of support. 'The lineaments of their vision of England stood out not as much as democratic as libertarian and decentralist.' Aylmer, The Levellers in the English Revolution, p. 2 Morton, The World of the Ranters, p. 12 Brockway, Britain's First Socialists, p. 5/8 Gentles, 'The Agreements of the People and their political contexts', pp. 70 - 71 Throughout the short life of the movement it is clear that the Levellers were prepared to make tactical concessions for political gains. Yet MacPherson refutes this; why does he assume that the Levellers could not be democrats if Petty was not and why does he believe that they could never be democrats it they were not at Putney? MacPherson asserts that 'the Levellers were zealots for principle and had they ever embraced the full principle of universal suffrage they could scarcely have withdrawn it from the agricultural labourers on such wholly expedient grounds'. 'Such uncompromising zeal for principle is not, however, a feature of the Levellers' record on, for example, tithes.' The Levellers thought that the issue of tithes was a matter of principle, and in 645/8 Overton devoted a whole pamphlet to the subject. The March Petition and the July Appeal, both of 647, demand the abolition of tithes, without compensation, but in the first Agreement there was no clause relating to the issue. It was again deliberately left out of the January Petition of 648, but reintroduced in the Humble Petition and second Agreement. It is not necessary to assess why the Levellers compromised on the issue of tithes, but should indicate that the concessions on the franchise were not isolated. The Levellers were 'capable of compromise, when they thought they were being taken seriously', and had a real opportunity to affect political reality. Similar actions can be traced on the issues of local government, position of the King, of the House of Lords and parliamentary reform in general. The Levellers were able to make such concessions as they were political realists and not simply theorists. Their real zeal did not lie in one particular issue, but in the demand for a more equal and just society, and they were prepared to make concessions for the acceptance of their radical programme as a whole. 'They were interested in political and constitutional arrangements as a means and not an end in themselves'. MacPherson, The Political Theory of Possessive Individualism, p. 95/8 Davis, 'The Levellers and Democracy', p. 76 Davis, 'The Levellers and Democracy', p. 77 Davis, 'The Levellers and Democracy', p. 80 IXThe aim of this essay has been not only to highlight many of the problems of MacPherson's thesis, but also to propose an alternative interpretation of Leveller franchise reform proposals. MacPherson's analysis centres round his understanding of the proceedings at the Putney debates. He uses remarks made by Petty on the exclusion of servants and alms-takers to argue that the Levellers assumed such exclusions throughout the debates and infers such an interpretation on pamphlets published before Putney, which include no such qualifications. The main criticism of this understanding has been levelled at his use of Petty as representative for the rest of the movement. Moreover greater controversy has surrounded his assertion that the term servant meant all wage-earners. There is much evidence that has been highlighted to question such an understanding, and it seems that 'this was simply not the intention of the Levellers'. For MacPherson's analysis does not consider the great social changes that were occurring in this period; the Levellers 'are more likely to have been thinking in terms of a social order that was passing away than one still incompletely developed'. Thus the Levellers only intend to exclude domestic servants from the franchise. There is also a certain amount of uncertainty regarding the exclusion of alms-takers, for it appears that the Levellers only wanted to exclude beggars and those habitually dependent on alms relief. MacPherson has therefore vastly over exaggerated the number of men that the Levellers would have excluded from the franchise, under their non-servant franchise proposals. MacPherson took his thesis further by attempting to find an underlying theory that guided their franchise demands. His proposal for a Leveller theory of the 'self-propriety' of labour seems to have some credibility when analysed in the case of servants, but it does not explain why beggars and soldiers would have been enfranchised and not supporters of the King. Brockway, Britain's First Socialists, p. 8 Merson, 'Problems of the English Bourgeois Revolution', p. 15/8 Not only does this highlight the main problem with MacPherson's thesis, but illustrates one of two fundamental factors that this essay has stressed as vital in understanding the Levellers and the franchise. The Levellers were political realists, willing to compromise on specific issues if it meant that there was more chance of the acceptance of their programme as a whole. Throughout their short political life the Levellers had changed their demands accordingly with political developments; the final goal was more important than single issues. The Levellers 'adopted a democratic stance when they believed it was indispensable to their purposes, and equally they abandoned it when it was a hindrance to their achievement'. What also needs to be stressed is that when the Levellers are analysed it must be understood that they were not the homogenous movement necessary for MacPherson's thesis. They came together with shared grievances, but often they did not share the same solutions. The Levellers were thus 'a more heterogeneous party advocating a programme that has not been fully worked out in all its details, but prepared to make a series of compromises to achieve its ends.' Thus any attempt to discover a single principle that guided the Levellers on the issue of the franchise would seem fruitless, for there were a myriad of opinions. Yet certain generalisations can be made. The Levellers were not necessarily all democrats, although it was manhood suffrage that was being discussed at Putney, but they strove to create an egalitarian order. There would be greater opportunity to own property in a Leveller society, and thus people would not be reliant on others for wage-labour or alms. The voting body would be widely extended, significantly more than stated by MacPherson under the non-servant franchise for there would be fewer servants and beggars, and thus there would be greater political participation, heightened by a decentralised state. Thus it is questionable whether so much emphasis should be placed simply on their proposals for franchise reform. They proposed an incredibly radical and 'modern' set of ideals that were far more important than one issue, proposing a written constitution that England has not adopted to this day. Davis, 'The Levellers and Democracy', p. 80 Thompson, 'Maximillian Petty and the Putney Debate on the Franchise', p. 3 '''",774.0
"''' Induction generators are simpler, smaller and more robust than synchronous generators, and are not limited by fixed speed requirements. As such, they are increasingly being used in the field of renewable energy. In this experiment, an induction motor/generator was investigated in relation to being applied to hydro-power. A.5/8 kW pole motor with a synchronous speed of 5/800 rpm was used in the experiment. Firstly, the motor characteristics were investigated with the motor connected to an exterior power supply. Secondly, the characteristics of the motor acting as a generator were investigated, after the motor was disconnected from the grid and a water turbine was used to power the generator. MethodologyThe motor used was hardwired in a three-phase delta connection, with a line current rating I L of. A and a line voltage V L of 20 V. The system was set up as shown in figures and. The first parts of the to determine the value of these circuit parameters. Magnetising curve and Running Light Equivalent Circuit Parameter testThe motor was connected to a three-phase 00V, 0Hz supply, which was controlled with a -phase auto-transformer so that the supply voltage could be varied. In the running light test, the slip of the motor is approximately zero, and so the motor circuit in figure becomes simplified: With the motor running, the supply voltage was varied between 20 to 60 V, in increments of 0V. At each line voltage V measured. From these measurements, the magnetising curve could be obtained from a plot of V L against I L. The total volt-amp reaction Q the motor circuit was then obtained using could then be used to find the magnetisation reactance X the motor: V ph is the phase voltage of the system: for a delta configuration, V ph=V L. Q ph is the phase volt-amp reaction of the system. In a three-phase system, Q total=Q ph. The voltage stabilisation of a stand alone system depends on the variation of the magnetisation reactance. R c, the electrical loss in the magnetic P ph, the power in each phase of the -phase system, is equated to the total power by ) Locked Rotor testThis test involved locking the motor rotor, then passing a line current close to the rated value through the system, and recording the line voltage and total power in the system. The circuit in figure is now approximated by figure: The remaining circuit parameters can now be obtained: R, the stator coil resistance, is determined by R ph-to-ph is the d.c. resistance between two phases. The rotor resistance, R ', is then obtained by: ph is the phase current, determined by I L= I ph for the delta configuration. The stator and rotor leakage reactances, X and X ' are found from: two values do not need to be split; they can be considered as one value. A computer program was then used to produce power/speed, electrical machine efficiency/speed, and current/speed curves for the motor, using the obtained values of the circuit parameters. Load testThe motor was set running at a fixed supply voltage of 20 V, but water was run into the turbine at increasing pressure. The water pressure was increased from - 5/8 psi in increments of psi, and I L, P total, and motor speed were recorded at each stage. At the point when the turbine forces the motor speed to become supersynchronous, the motor will become a generator, and P total will become negative. The motor efficiency, turbine efficiency, and overall system efficiency can then be determined. Motor efficiency can be found from the efficiency/speed curve. The overall efficiency is the electrical power out divided by the power from the water pressure. The turbine water pressure power is obtained from a graph of power/water pressure. Turbine power is the mechanical power output divided by the water pressure power in. Three-phase stand alone operation The motor was then disconnected from the three-phase supply, and run as a generator connected to a three-phase load. The system is now as follows: In order to start the motor running, some residual magnetism needs to present in the motor. Capacitors in the circuit are used to excite the machine: resonance between the magnetising reactance X m of the system and the capacitative reactance amplifies the small residual magnetic field. The volt-amp reactance X m obtained therefore be generated by the capacitors if the motor is to run in a stand alone is given by: a line voltage of 60V, the output frequency of the induction motor is given by: L is the inductance of the system, obtained from: so the synchronous speed N the generator is: P is the number of poles in the generator. For the machine used, P=. The generator is run as a stand alone system, with the load in the system being increased in steps. For each load configuration, the water pressure is increased so that the line voltage output becomes 20 V. The line current, power, water pressure and rotation rate were recorded. The turbine efficiency and overall efficiency could then be obtained as in part c). Single-Phase Ballast operation The machine is operated stand-alone, and a load is connected across two-phases of the system: a single phase load. This load consists of a ballast load controller connected to a variable load: a bank of parallel connected lamps. Each lamp can be switched on individually, increasing the resistive load in increments. The ballast load controller effectively maintains a constant load on the generator: if the load demand of the power into the ballast load controller is diverted to the lamps, and less is dissipated by the ballast load controller's internal resistance. If the load demand decreases, the ballast control increases the load from its internal resistance so that the total load on the generator is constant. In the experiment, the water pressure was set so that the generator voltage output was 20V. The number of lamps on was increased, and the percentage of the generator power into the ballast load was recorded. Resultsa) Magnetising curve and Running Light Equivalent Circuit Parameter testUsing Rotor testThe circuit parameters measured in the locked rotor test are shown in table. R phase-to-phase was measured as.. Using testThe circuit parameters from the load test are shown in table. Note how the power in the circuit becomes negative when the motor starts acting as a generator - when the water pressure is greater than 0 psi. Up until this point the line current is roughly constant, and only increases after generation starts to occur. The three sets of circuit values for the plotted on the power/speed and current/speed graphs. From these it can be seen that the generator is not producing the expected powers and currents for the measured speed of the motor. The generator is producing less power, but a greater current than expected based on the measured circuit resistances and reactances. By using the measured line current, and reading off the expected motor speed from the current/speed graph, the generator efficiency can be found from the efficiency/speed graph, by using the motor speed values just obtained. The turbine input power is found from a graph of turbine power vs. water pressure. (Dorrell, 997) The water pressure value from table is reduced by 0% to account for pressure losses in the pipes. This altered value is used to obtain the value of turbine power from the graph. The overall efficiency is then the ratio of the electrical the turbine power. A measure of the turbine efficiency is then the overall efficiency divided by the generator efficiency. The efficiencies are shown in table. The efficiencies increase with increasing water pressure. Three-phase stand alone operation From , the capacitor size needed for stand-alone operation of the system was found to be 5/8.6F. Three capacitors of this size in delta configuration would provide the reactive power needed for the magnetising branch of the circuit to become excited and the generator to turn, provided adequate water pressure into the turbine. In reality, capacitors of size 8F are used, as a slightly greater capacitance is needed to overcome losses in the circuit. For a stand-alone system with 18F capacitors in delta-configuration, the output frequency can be calculated using this frequency to a synchronous speed of 695/8 rpm. This is larger than the synchronous speed for the grid connected system. The operating frequency of a stand alone system will drift more than that of a grid connected system, since this is linked to slip. As can be seen in table, the rotational speed of the motor increases with water pressure, and so slip is increasing. The generator was then run as a stand-alone operation. Load in the system was increased using resistors; for each load configuration, water pressure was altered to maintain a line voltage of 20V. Using the same method as in part c), overall efficiency can be found. The results are in table. The efficiencies from table are shown in figures and plotted against motor speed. No clear curves are visible for the turbine efficiency and overall efficiency since the data set is only four points. It is possible that one of the data sets is anomalous. Single-Phase Ballast operationFor fixed values as shown below, the load was increased in terms of number of lights switched on. Table shows the % of the power from the generator that is dissipated in the ballast resistor bank. This shows a measure of the efficiency of the system. The more power dissipated in the resistor bank, the less efficient the system is: since less power is being used 'usefully' in the lamps. For a ballast controlled system, it is possible to have 00% inefficiency, if all the power were dissipated in the resistor bank. DiscussionThe synchronous speed of the motor is about 5/800rpm, as can be seen from table. The motor speed remains roughly the same while line voltage and line current increase: the power output increases due to the magnetic field strength increase. Table shows how power is generated when the motor is pushed supersynchronous: when the motor speed goes above 5/800 rpm. The overall efficiency of the system is not high, but increases as the motor runs faster. Using ballast load control, the generator can be run at a constant load, however this decreases the efficiency of the system as there is a lot of waste power dissipated in the resistor bank.'''",778.0
"'''The overall Harcourt - Essen reaction is: with a proposed mechanism of bimolecular steps: differential rate equation is then: The slow, rate determining step was investigated by measuring the rate of loss of hydrogen peroxide, this being proportional to d / dt. Any iodine formed was reconverted to iodide by addition of E is the activation energy, A the pre-exponential constant, R the gas constant and T the temperature in Kelvin. Linearising: Therefore a plot of /T enables calculation of A and E. Experimental - Method4 different runs of the experiment were carried out sequentially using: Approx vol H O Sulphuric were kept in thermostatted water baths for 5/8 mins for temperature equilibration and mixed vigorously and continuously. 0 drops starch indicator were added to each mixture. H O kept in a separate flask at the required temperature, prior to addition. Sodium added to the iodide/acid mixture, then the H O and a stopclock started. When the starch indicator turned green/blue, the time was noted and.cm thiosulphate added. This was repeated until cm of thiosulphate had been added. The reaction flask was kept to one side for later use. Note: the blue colour was due to iodine complexing with starch; the iodine being formed by H O oxidising I- and so being consumed. The immediate addition of thiosulphate reduced the iodine back to I- rendering the solution colourless again until more H O oxidised I- to reform iodine. Thus the cumulative volume of thiosulphate was inversely proportional to the concentration of H O remaining in the reaction flask. Note: Towards the end of run, the appearance of the blue/green colour was not so sharp, so the individual error in time recorded will be greatest here. By the time all runs had been flask was assumed to have gone to completion and reaction flask heated in a 5/8 oC water bath for 0mins to achieve completion, i.e all H O used up. Reaction flasks & were simultaneously titrated with sodium thiosulphate in.cm portions as before until no blue/green colour appeared for 0minutes. The final thiosulphate titre volume was proportional to the initial concentration of peroxide: t= Experimental - Result and Therefore, H O: S O 2- ratio is:mol. S O 2- used=5/8./0000.9 =.5/810 - Therefore mol. H O in 5/8cm =.5/8310 - =(.5/8310 -)/5/81000 =.101M In the table below: A is equivalent to t=, x is the vol. of S O added c is equivalent to t which is A-x For a plot of c - against time, a straight line would indicate a second order reaction w.r.t to peroxide since for: when integrated. Looking closely at the above graph, the relationship between c - and time is not linear but an upward curve and so the Harcourt-Essen reaction is not nd w.r.t to peroxide. Plotting /time: There is a clear linear correlation corresponding to first order kinetics w.r.t peroxide. Similarly for the runs, and: The gradient of each graph gives k', the pseudo-first order rate constant where k'=k k is calculated in the table below. Note: values for k' calculated in MS Excel to more significant figures than shown in the above graphs. Where: total vol. in each reaction flask = 5/80cm. I- in 5/80cm = Vol KI/.4819 = mol. I- in 5/80cm3 k' is regression coefficient calculate in MS ExcelRun has half the concentration of iodide as Run;both at the same temperature, and k' is almost half, within limits of experimental error. This is consistent with a directly proportional relationship between rate and iodide concentration and so the reaction is also st order w.r.t to iodide. Runs and, at higher temperatures, show faster rates. The empirical rule of an approximate doubling of rate for every 0 oc increase in temperature seems borne out by the values of k for runs and:.8/.1 =.14 The following table sets out the data needed to calculate Arrhenius parameters: Gradient of regression line = -E/R where R=.145/81 JK -mol - Intercept of regression line = lnA Conclusions and DiscussionDuring all runs, the concentration of iodide can be assumed to be constant due to the regular addition of thiosulphate, so reducing the iodine formed back to iodide. Therefore, assuming the rate determining step involves no other species than H O + and I-, the straight line graph of time for all runs, shows st order w.r.t H O the reaction to be st order w.r.t to I- and thus, nd order overall. The mechanism discussed in the introduction is a valid proposal. The difficulty in determining the initial concentration of peroxide will have been a significant source of error for the actual calculation. Reaction flask had been left to stand for hours, and flask for.5/8 hours as well as being heated for 0mins. It was assumed all the peroxide had been used up by then. However, during this 'infinite time' titration, even after periods as long as 0mins, the blue colour would reappear; due to time limits in the laboratory, there had to be a cut-off point. This would not affect the values of the calculated rate constant since the gradient of time will have been the same. The linear regression equation used for calculating the Arrhenius parameters was based on measurements. For a more precise and accurate determination of the collision frequency factor A, and activation energy E, the experiment would need to be repeated at many more temperatures. This would allow for statistically meaningful confidence intervals to be measured for each parameter.'''",779.0
"''') Selfish Genes and Group SelectionThe term 'selfish gene', was originally coined by Richard Dawkins in his book The Selfish Gene. Dawkins argues that the fundamental unit of selection, and therefore of self-interest, is not the species, nor the group, nor even, strictly the individual. It is the gene, the unit of heredity. Dawkins does not define the term 'gene' by way of a cistron, the genetic material between START and END codons; he defines it as G.C. Williams does in Adaptation and Natural Selection: I use the term gene to mean 'that which segregates and recombines with appreciable frequency.'. A gene could be defined as any hereditary information for which there is a favourable or unfavourable selection bias equal to several or many times its rate of endogenous exchange. (966: 6)For Dawkins, a gene is defined as any portion of a chromosomal material that potentially lasts for enough generations to serve as a unit of natural selection, a genetic unit small enough not to be frequently split by crossing-over during and Kin SelectionPrior to 964, no theorist had come up with a satisfactory answer to the apparent altruistic acts that some individuals perform within groups. An example of this could be a group of vervet individual within which gives off an alarm call in sight of a various predators, though making itself more conspicuous. The question was; how does such an altruistic behaviour arise in evolutionary terms when it so obviously lowers the genetic fitness of the individual giving the call? And in comparison raises fitness of the individuals of the rest of the group who did not call, and can not call. As shown with the failings of group selection behaviours can not be selected just because they are beneficial to the group as a whole. Instead according to this example selection will favour genes for suppressing calling. Natural Selection can favour altruistic behaviour if altruistic individuals are more likely to interact with each other than chance alone would dictate. (Boyd & Silk 003: 10)An understanding of this behaviour came with W.D. Hamilton's 964 maths based paper The Genetic Evolution of Social Behaviour who made a series of fundamental contribution to the theory of evolutionary behaviour. Hamilton's insight was to see that any process that benefits altruists to be more likely to interact with other altruists than they would by chance could facilitate the evolution of altruism. Now if regard groups as breeding populations containing the kin group and extended members, if an individual is a caller by the rules of Mendelian genetics there is a 0 percent chance a sibling will share the genes for calling, and related percentages of chance for other family ) Reciprocal AltruismThe theory of reciprocal altruism was originally introduced by Robert Trivers, 971 in The Evolution of Reciprocal Altruism. This is the idea that altruistic behaviour can evolve in a balanced relationship of interacting individuals. In these reciprocal relationships individuals can turn being the actor and recipient, in this respect reciprocal altruism is favoured by selection because over time the fitness gained by the reciprocal acts outweighs the cost incurred. Boyd and there are three conditions occurring together that favour the development of reciprocal altruism, individuals must: ) have opportunity to interact often,) have the ability to keep track of support given and received, and3) provide support only to those who help them,It is important to note that exchange does not have to be in kind. As shown with vervet other primates such as chimpanzees, for example, the act of grooming an individual can be reciprocated by the recipient by way of political coalitionary support, and other such examples. The big problem with reciprocal altruism is that it is costly to interact with individuals who do not reciprocate. Thus human be attune to look for cheaters in social exchanges. Game theory, such as the 'Prisoner's Dilemma' explored by the logical problems of a behaviour for exchange, and can also shed light on the selective process of evolutionary altruistic behaviour. If there is only to ever be one exchange between individuals it is always most self-serving to not to co-operate, but with iterated exchanges so called 'nice' strategies are most beneficial to the individual, the most successful by way of 'Tit-for-Tat'. ) Innate and Environmental InfluencesI'm sure the debate of this subject has been and will be contained within the covers of very many large volumes of work. It is possible to say for definite a very intimate relationship exists between what is innate within us by way of programming of genetic information, and that of facts of mere physics. When observing any organism other than can, and do easily recognise behaviour in individuals that can be generalised across all individuals within the species, behaviours that are so universal to that species that they must be innately encrypted within its genome. Multitudes of universals exist within human behaviour as documented by Donald E. Brown, humans has large amount of diversity in environmental habitation, yet it is manifest we have a distinct material human nature universal to all of us, whatever our environment. If we take human language acquisition for example; opposing arguments against any theory of innateness appear thin on the ground. Chomsky himself professes to be puzzled at any objections to an innate hypothesis, in that an empirically determined language would be immediately problematic: Is the idea supposed to be that there is no difference between my granddaughter, her pet kitten, a rock, a chimpanzee? No one can be that crazy. But if there is a relevant difference, then we must accept the 'innatist scenario.' So what can we possibly be under discussion, except for the nature of the innate endowment? (Smith 999:70)A mind of any variety can not be a blank slate, a tabula rasa, you cannot get something form nothing. ) Social: Solitary and GregariousIf we take the social organisation of primates for example; most diurnal and some nocturnal species are gregarious - they feed, travel and sleep in groups. Their social complexity can range from the most primitive form, the noyau, which characterises most primitive nocturnal mammals, up to the large complex societies of gelada baboons comprising of up to 00 individuals, when composed of the joining of bands. There is a fine line between defining the simplistic gregarious primate and the solitary primate species. A solitary system in primates could operate much like the noyau system, and yet unlike in the noyau the male who has fathered some offspring will not regularly access the development of the offspring, an example such a solitary system could be the orang-utan. Robert Trivers explains in evolutionary terms the evolution of fundamental social organisation in his thesis of 'Parental Investment': 'any investment by the parent in an individual offspring that increases the offspring's chance of surviving at the cost of the parent's ability to invest in other offspring'. The determining factors for this are measures of resources that a parent can invest, the variable being the environment. Other environmental factors governing formation social structure and constituent numbers are factors such as protection from predators, access to mates, assistance in protecting and rearing offspring, and improved access to food. ) Monogamy, Polygyny, Polyandry, PromiscuityAre all examples of mating systems: As point out by Trivers, the mammalian reproductive system commits females to invest in their offspring, making some mating systems a more likely option than others. Monogamy - one female forms a mating bond with one male. Monogamy is common in birds, but relatively rare among primates, an example of which among primates would be the gibbon. Polygyny - a system in which a single male mates with many females. The most common mating system among primates. Polyandry - a single female forms a stable pair bond with two or more different males at the same time. Polyandry is rare among mammals but is known to occur in a handful of human societies such as the fraternal arrangements of the Nyinda of northwest Nepal, and is also known in tamarins and marmosets Promiscuity - the act of sex takes a social role more of confirmation of connectedness, a social cement, in which every individual mates with every other applicable individual. Though, there is no truly promiscuous system among primates, the nearest of which being among bonobos, because of the universal inhibiting behaviour among mammals of inbreeding avoidance. Although, bonobo mothers have been known to initiate their own offspring into the system. ) Inbreeding AvoidanceInbreeding avoidance among closely related kin is a 'human universal' (Donald E. Brown 991). Humans that share large amounts of time in proximity in early childhood are not sexually attracted to each other when sexually mature, this explains partly why humans rarely mate with close relatives, although incestuous defined boundaries vary among societies. Evidence of this also from the attempted utopian communities of the Israeli kibbutzim, Spepher demonstrated for collected data that out 769 marriages in 11 kibbutzim, only 4 marriages were from the same kibbutz, in all cases one partner joined the peer group after the age of six. Such a strong aversion to incestuous relationships is also demonstrated among primates and other mammals, in social mammals incest is usually prevented by the emigration of sub-adult males form the social group. Although less common, for example in chimpanzees and gorillas it is the sub-adult female that transfers between TraditionThe transmission of a belief, of set of beliefs passed on from one generation to the next by learning, that affects the behaviour of individuals within the society concerned. The cultural relativist might suggest our social traditions are created by society on a purely logical basis, to aid economic relationships and marriage between groups and so on, but in many cases there is an obvious determinant connection with our biological basis, although the relationship is often unclear. An example of this in continuation from the last definition could be the human universal of incest 's Questions Why? Tindergen showed there are four ways of answering the question why in behavioural ecology; function, causation, development, and evolutionary history. Using Krebs and Davies's example of a starling foraging for food, if we ask why it is foraging in a particular way we could answer as follows: In terms of function; how can patch choice and prey choice contribute to the survival of the bird and its offspring. In terms of causation; the proximate factors that caused the starling to select the foraging site or prey site. These may include clues to prey abundance, such as type of soil or vegetation, or the activities of other birds. In terms of development; this answer is concerned with the role of genetic predispositions and learning in an individual's decision making. In terms of evolutionary history; how starling behaviour has evolved from its ancestors. This answer might include a study of the starling adaptive radiation to fill ecological niches and the influence of competition from other species on the evolution of starling behaviour and morphology. (997: ) 0) describes 'memes' as the new replicators, a replicator in analogous fashion to a strip of DNA selected by natural selection fro its phenotypic survival value. In Dawkins's own words: I think that a new kind of replicator has recently emerged on this very planet. It is staring us in the face. It is still in its infancy, still drifting clumsily about in primeval soup, but already it is achieving evolutionary change at a rate that leaves the old gene panting behind. (989: 92)Dawkins took the word 'meme' as an abbreviation of the Greek rook 'mimeme', to represent a unit of imitation. He gives examples of memes to be tunes, ideas, catch-phrases, clothes fashions, belief in life after death, God, etc. Memes are information encrypted in the brain, culturally transmitted from brain to brain by representational methods of human communication in through the sensory input systems and out through the motor systems. Dawkins describes memes in analogous fashion as having their own 'meme pool' in which they propagate themselves in much the same way as alleles, yet instead of leaping from body to body via eggs and sperm, memes jump from brain to brain by a process he roughly calls scientific study of the interaction of organisms with their environment, including both the physical environmental aspects and the other organisms that live within it. As demonstrated by Brown & E.O. Wilson in The evolution of the dacetine ants, who related the colony size and structure of dacetine ants to their feeding habitats. 2) Population'A set of organisms belonging to the same species and occupying a clearly delimited space at the same' (E.O. Wilson 975/8). It might also be useful to define it as a breeding population in the same respect. A population can also be defined its genetic constituent terms. Boyd and Silk suggest that: 'Biologists describe the genetic composition of a population by specifying the frequency of alternative genotypes' (003: 3). Gene frequency is calculated by the total number of the particular allele within a determined pool of gametes. Gene frequency is the total number of an individual allele at a particular locus on a chromosome within a determined population possessing the gene. (Summation of all gene frequencies for genotypes at a particular locus equals, therefore is not proportionally affected by the size of the population). As long as there are only two alleles at the genetic locus of interest in the gamete pool, gene frequency can also be calculated from collected genotypic information at the locus. After basic calculation the following equation is possible, taken from Boyd and Species, mutually beneficial relationships can form between groups of different species, benefiting the individuals contained within the groups when the ecological environment allows. This relationship is perhaps more common than is at first though, and exists between a variety of organisms. One widely known symbiotic relationship is that of the zebra and gnu, for in respect to W.D Hamilton's idea of the 'selfish herd' there is safety in numbers from predators for individuals within the respective groups, and on that individual selective basis, ecological factors allowing, a gnu is as good as another zebra. Trivers refers to the reciprocal relationships that have evolved between 'cleaner-fish' and there much larger predatory clients, because the benefits of having the cleaner-fish remove unwanted parasites from the large host outweigh the benefits of eating the cleaner fish, and the cleaners get a good supply of food it has attained a privileged position. Large fish genes for allowing the cleaner-fish, approaching them in a certain fashion, to clean them and not eat them have been favoured in gene pools. Cleaner-fish genes for approaching a large predatory fish in a certain fashion and entering its mouth to clean it have been favoured in gene pools. Symbiotic relationships of mutual benefit are also common among plants. Lichen appears superficially to be an individual plant like no other. But it is really an intimate symbiotic union between fungus and green alga. Neither partner could live without the other. If their union had just become a little more intimate it would not be possible to tell they were a double organism at all. Richard Dawkins, in this respect, comes up with a more radical thesis that there could more double, multiple organisms than we have recognised:.it has been plausibly argued that mitochondria are, in origin, symbiotic bacteria who joined forces with our type of cell very early on in evolution. I shall speculate that we shall come to accept the more radical idea that each one of our genes is a symbiotic unit. We are giant colonies of symbiotic genes. Don't we also share our bodies in many mutually beneficial ways with innumerable parasitic organisms? 4) Selective PressureThis can be defined as any feature of the environment that results in natural selection. This can come from a wide range of sources such as impoverished food resources, predation, or competition from members of the same sex for a mate can cause male individuals of a certain genetic types to survive to different average ages, to reproduce at different rates, or both of these factors. 5/8) Ecological NicheEcologists use the term niche to refer to a particular way of 'making a living' (Boyd & Silk 003), a particular food resource within the ecological habitat a species is adapted to, or can adapt to. It is also concerned with the kinds of food eaten and when, how, and where the food is acquired. Speciation is concerned with ecological niches; the rate of speciation depends on the number of available niches. Darwin's finches provide a good example of exploitation of ecological Exclusion The supposed principle of ecology, competitive exclusion states that two species with very similar adaptations cannot coexist in the same ecological niche. The principle is questionable. For example, it has come under question due to the falsification of the hominin evolutionary theory of 'the single-species hypothesis' of Dobzhansky and Mayr, which stated that only one species of hominin could exist at one time. In this case, culture was viewed as such a novel and powerful behavioural adaptation that two cultural species simply could not exist side by side. This thesis collapsed in the mid 970s, after fossil discoveries in Kenya indisputably demonstrated the coexistence of two quite different types of hominin; Homo ergaster and Australopithecus 's RuleKleiber's rule regards the metabolic rate of mammals and the way it changes in proportion to body mass. For every unit of weight heavier mammal, the mammal only induces a proportional 5/8 percent equivalent increase in energy requirement per unit. For example if the mammal's weight increased 00 percent, it would only have a 5/8 percent increase in energy requirement. It therefore follows that the heaviest mammal would have the lowest metabolic rate, and the lightest mammal would have the highest metabolic rate per unit of body weight. Therefore, if the ecological environment allows, food resources being proportional to body size, the bigger the mammal the more energy efficient it is less time spent feeding. Kleiber's rule also gives explanation to the reason why there are not any leaf eating primates under 00g; leaves are just too impoverished in energy to sustain a small primate with a high metabolic and EcosystemHabitat is a species specific term relating to the organism physical environment in a particular place. While the term ecosystem refers to all the organisms living within that particular physical and SympatricAllopatry refers to an absence of overlap of geographic range of two species or populations. Sympatry refers to an overlap of geographic range of two species or appears at first to be some differing opinion over what a gene actually is. The American geneticist T.H. Morgan was first to coin 'gene'. Some molecular biologists refer to the term 'gene' in the same way as that of a cistron; the genetic material contained on a chromosome between START and END codons. For Dawkins this is insufficient in the evolutionary sense, he defines it as G.C. Williams does in Adaptation and Natural Selection: I use the term gene to mean 'that which segregates and recombines with appreciable frequency.'. A gene could be defined as any hereditary information for which there is a favourable or unfavourable selection bias equal to several or many times its rate of endogenous exchange. (966: 6)For Dawkins, a gene is defined as any portion of a chromosomal material that potentially lasts for enough generations to serve as a unit of natural selection, a genetic unit small enough not to be frequently split by crossing-over during 'A group of organism classified together at the lowest level of taxonomic hierarchy.' (Boyd & Silk 003: A15/8) There is much disagreement among biologists about how to define a species; there are many different types of species concept: The biological species concept is defined by the extend of the group that an organism is willing to mate within it's natural habitat, though some more distant individuals are willing to mate but can not produce fertile offspring. In a similar respect the isolation a species by the extended by members can produce fertile offspring, in connection to 'isolating mechanisms'. Though this is problematic due to some hybrids being fertile, others not, such as with the donkey and ass. The recognition determined by members of a species sharing a common fertilisation system including in animals a specific mate recognition FlowBoyd & Silk define it as 'the movement of genes from one population to another, or one part of a population to another, as a result of interbreeding' (003: A8). Gene flow reduces variation between Drift'Changes in gene frequencies over generations, resulting from chance rather than selection' (Dawkins 982: 94). Sometimes known as a random force, and operates on small genetically isolated populations. To give a simple example, if we had a genetically and physically isolated Polynesian island population of 0 individuals, and during a storm a tree collapses killing of the most successful, genetically fit individuals within the population. Much potentially advantageous genetic material could be lost. This could potentially have great changes on gene frequencies within the small population. Genetic drift in small populations causes random changes in gene frequencies. Gene frequency can change by chance alone bypassing the operations of natural selection. If a certain locus has roughly equal gene frequencies of two different alleles acting on it, analogy could be pretty much like two people repeatedly flipping a hand full of SelectionDarwin's theory of 'sexual selection' has often been an item of controversy and debate. Original debates raged between the 'Fisherians' and the 'good geners' of the neo-Darwinists. Sexual selection is a form of natural selection that results form differential mating success within one gender. In mammals it is usually males that compete in male to male competition over access to females. Such behaviour is determined by facts of reproduction; for a female to have an offspring there is much investment at stake and there are large periods of time between potential offspring, in most mammalian species having to raise the infant themselves. Males on the other hand in most mammals can have as many offspring as physically able without the burden of investment. Sexual selection is often much stronger than ordinary selection. The most successful of males will in mammals will often have many more offspring than the most successful female, while it is also the case that usually a larger percent of males will fail to reproduce than females, selection is harder on the male. Sexual selection an be broken into two forms; intrasexual selection that results from competition among males, and intersexual selection resulting from female Speciation The widely supported view that divergence of population into distinct place in geographically separate places. An example of this could come from Roger Kingdom; populations of guenons in the course of their evolution were left isolated in patches of forest due to the ebb at flow of forestation during climatic change, this leading to genetic drift and distinct species. The alternative gives rise difficulties in understanding how the incipient species can separate if they are continuously in a position to interbreed with one another, and therefore mix their gene-pools. Although Darwin's the divergence of a single species into multiple empty ecological niches. 7) Adaptive RadiationAdaptive radiation occurs when there are many empty ecological niches. It is the process in which a single species diversifies into a number of species, each with its own distinct adaptations. The most well known of these adaptive radiations coming at the end of the Cretaceous era, when the dinosaurs disappeared. The mostly small, nocturnal mammals that had coexisted with dinosaurs until that point then diversified to fill all the now empty niches evolving in to elephants, killer whales, bats and multitudes of disproportionate relationship between size of a body part and the size of the whole body, the comparisons being made either across individuals or across different life stage in the same Phenotype'All effects of a gene upon the world' (Dawkins 999: 92). Dawkins argues for the biological perspective that recognises the beaver's dam, the spider's web, the bird's nest as not just merely products of the phenotype, the individual organism considered the functional whole, but parts of the phenotype, in the same way as the beaver's teeth, the spider's legs and the bird's and Classification'Ancestral history on the evolutionary time scale' (Dawkins 999: 96).'The evolutionary relationships among a group of species, usually diagrammed in the form of a 'tree of life'' (Boyd & Silk 003: A8).Classification is the method in which humans physically represent the world, we consciously and sub-consciously do this even when no definite defining line exists between concepts. Visually classified information aids humans in comprehension of reliably classified knowledge, for aid in learning and in formulation of new ideas. There are several important reasons why reconstructing phylogenies play an important role in the study of evolution: Phylogeny is the basis for the identification and classification of organisms. The arrangement of phylogenetic relationships between organisms in taxonomic hierarchies. Knowing phylogenetic relationships often helps to explain why species evolved certain adaptations and others not. New species form due to natural selection, modifying body structures to perform new functions. As Boyd and Silk suggest from Phylogenetic trees, for example, it is possible to observe the adaptations of quadrupeds, knuckle walkers and bipedalism in evolutionary order, an aid in determining relatedness. It is possible to deduce the function of morphological features or behaviours by comparing the traits of several species. The comparative method, by which it is possible for example to aid in argumentation of whether arboreal or terrestrial primates live in larger groups involving the collation and systematic display of data. (Boyd & Silk 003: 05/8) 1) Grade vs. CladeDue to the increased use of cladistics and stricter government of phylogenetic analysis, it has become clear that while clades are 'real' representations, grades, although an established concept in classification, are far more problematic. Clade is derived from Greek, and simply means branch, and refers to the evolutionary branches on the 'tree of life'. It is theoretically possible that an 'objective' phylogenetic tree could actually be constructed and represent what actually happened in evolution. Grades, on the other hand, are far more harder define. Basically a grade is a group of organism that share similar biological organisation, and system of adaptive traits. Grades have their origins in the 'Systema Naturae' of Linneas, the concepts of are deep rooted in biological phylogeny. For the main part grades and clades coincide, but at certain levels it is questionable whether the old fashioned grade is a useful term. Many problematic examples exist among classification of the primates. Lewin and Foley give the following example; monkeys can be said to represent a grade relative to both apes and prosimians, but the groups that constitute them the platyrrhines and catarrhines are not monophyletic clade. The tarsier for example is a prosimians grade of animal, yet in terms of clade it is an anthropoid. There is much dispute over hominins, as they are clearly a grade it is impossible to tell where to draw the line for that grade. 2) Adaptation and AdaptabilityA feature of an organism created by the process of natural selection. It is important to note all organisms are capable of producing more offspring that can there were only a few genes at a couple of loci affecting beak size, with no environmental affects such as nourishment affecting growth, a stratified effect would be observed in the collect information of beak dimensions of different individuals. Could be analogous to the way we buy our clothes, 'small, medium or large'. In reality, empirical data shows the majority of expressed characteristics we see as un-stratified, complex gradual continuous variation, with no visible increments amongst data collected. Environment change and variation have large effects on gene frequencies within populations. Using Darwin's as an example, when the climate changed and drought ensued on Daphne Major, the mean relative beak size of the finches increased due to pressures of natural selection to adapt to the change of available food. Larger beaked individuals survived better than small beaked individuals due to the increased size and hardness of nut and seed food source. This therefore increased gene frequencies affecting large beak size and growth. What is theoretically alleles controlling growth hormones, or calcium supply to the beak. Data collected from Daphne Major has shown a positive correlation between beak width and beak depth. Although, this was actually maladaptive. Whatever genotypes were increasing the advantageous trait of beak depth, were also by pleiotropic effect, increasing the beak width at the same time. It turns out selection favoured beak depth, and not beak width. The thinner beak could apply more pressure, than an individual with a wide beak. It therefore follows, as the finches neared selective equilibrium in the environment, the threshold for deletion also included birds with the largest beaks as well as the smallest beaks, altering gene frequencies for large and small beak characteristics. 3) Parallel and Convergent EvolutionThe power of natural selection can be seen in the phenomenon of. Typically if two species share the same adaptive characteristics, it is thought that this reflects shared ancestry, in that they both inherited the trait from a common ancestor. Shared traits are thus homologies, in that they have a common origin. The basic bones of the vertebrate are excellent examples of and Punctuated EquilibriumThese terms refer to two modes of evolution. Gradualism views evolution as proceeding by the steady accumulation of small changes over long periods of time, Darwin suggested 'we see nothing of these slow changes in progress, until the hand of time has passed the ages.' The idea was further developed by B.S. Haldane a Neo-Darwinist of the Modern Synthesis. In contrast, punctuated morphological change as being concentrated in brief burst of change, periods of a few thousand years, usually associated with the origin of a new species. Darwin often expressed concerned at the impoverished evidence in the fossil records, Lewin and Foley suggest it equates to taking a photograph of a football game every ten minutes, then afterwards trying to determine what happened. Dawkins, in chapter six of 'the extended phenotype' expresses concern that the theory of punctuated equilibrium is being manipulated to attack the validity of Darwinism, due to the impoverished fossil record and Darwinism apparently being a gradualist theory, as Darwin said in this respect 'nature does to make leaps'. It might be completely feasible that both modes of evolution are possible, rapid adaptation to new/empty niches or gradual isolated environmental change etc. There is possibly evidence of rapid change coming from the rapid adaptation and speciation of the finches of the Hawaiian Archipelago and Daphne Major. I don't think Darwin's got any worries. 5/8) Describe Darwin's theory of Natural Selection in modern genetic terms. If different genotypes are associated with the different phenotypes and those phenotypes differ in their ability to reproduce, then the alleles that lead to the development of the favoured phenotype will increase in frequency. The differential survival of different alleles.'''",783.0
"'''Official statistics are those produced by either the state, or by one of its agencies. There has been a huge increase in the number of official statistics since the Central Statistics Office was set up in 941, and now large quantities of statistics are produced on a variety of different topics, for example income, housing and population. Although they are widely used there are many limitations of the use official statistics in sociology. In this essay I plan to talk about how the internal, or posivitist schools view statistics, looking at how they are critical of the reliability and validity of official statistics, and also how they feel that the processes involved in producing the statistics limit their uses. I will also explore the uses that statistics do have in sociology, and come to a conclusion on whether they should be use or not. The internal school of thought emphasises the need for reliability and validity in order to produce realistic statistics, however there are many problems with official statistics in this aspect, and as Hindess points out 'they cannot be taken as a.reliable account' (Hindess, 973). The term reliability refers to whether the statistics are replicable or not, and validity is defined as whether they paint a true picture of what they are looking at, and there are many problems with regards to both. The first problem is that of the definition of concept, and can cause problems with the reliability of the statistics. Different people define concepts in different ways so this alters the reliability of the study, and also means that readers may interpret the statistics in a different way to that which they were the aims of those with political power (May, 997). One example of this is the way in which the government produced official statistics relating to unemployment under Margaret Thatcher. During her time in power the definition of unemployment changed over twenty times, as the aim of the statistics was to show how unemployment was decreasing, and the most successful way in which to achieve this was to alter the definition of the concept of unemployment. This shows how the aims and motives of those collecting the data can influence the final statistics. Radical thinkers also believe that statistics only tell us about the groups in society who hold power, and are simply a reflection of the balances of power in society (Hesteretal, 996, cited in May, 997). Official statistics do not exist on all topics that sociologists may want to look at, and as a result can be very limiting for them, but also only present a one sided view of society. One example of this is servants in the Victorian era. Many statistics from this time were produced by those in positions of power, for example mistresses, so they tell us little about the lives of the servants, who were working class and held little power. However, despite these limitations official statistics do have some uses. According to posivitists as long as the statistics are reliable and valid then hey are very useful, and one example of this is birth and death rates. As the registration of births and deaths are legal requirements the statistics are reliable, and paint a valid picture of the contemporary and past population levels. Statistics that are not produced using legal requirements can also be useful, however. Bulmer claims that statisticians often go to many lengths to avoid problems with reliability and validity, and he claims that as a result official statistics pose no more of a problem than sociological research. He also argues that if sufficient thought is given to the production of official statistics, and more scientific, rather than theoretical concepts are used, then these problems can be corrected, however it is hard to apply this to sociological research (Bulmer, 984, cited in May, 997). Using the radical approach statistics can be useful to tell us about the state and those in power, and what they are interested in. However radicals argue that if the processes involved in the construction of official statistics are carefully considered when analysing the results then the statistics can be seen to present a useful and valid picture of society (Hindess, 973). However radicals also argue that official statistics are used most successfully, and paint the most realistic picture when they are combined with another method (May, 997), for example self report studies when the topic of crime is being studied, as this allows the decision making process involved in the official statistics to be balanced out, as people are more likely to be honest in a self report study. Overall, according to the posivitists the main limitations of official statistics arise from the issues of reliability and validity, however they feel that in many cases these limitations are overcome by careful planning, so argue that sociologists should use official statistics. Radicals on the other hand, believe that official statistics are a construction of the state, and this means that although they are useful for examining the state and its interests they do not provide a realistic picture of society. I feel sociologists should use official statistics especially when examining those with power, or exploring the state, however they should treat official statistics produced on other topics with care, and be aware of the process of decision making and methodology that occurs before the statistics are finally produced.'''",788.0
"'''The experience of the mathematical and the dynamic sublimes are both occasioned by the revelation of the inferiority of the imagination to that of reason. Kant believes that in considering how our faculties deal with instances of the massively extended and the massively powerful we can see how reason can exceed the capabilities of imagination; the ideas of reason and the force of our moral freedom exceed what can be presented in nature. This excessive capability of reason is linked to our moral nature. In the case of the mathematically sublime the rule that reason subjects our thinking to is analogous to the moral law and hence strengthens the prioritising of the common source of both - reason. In the case of the dynamic sublime, the link to morality is direct. It is our free moral choice which the experience of the massively powerful draws our attention to. The Mathematical SublimeIn section 5/8 Kant considers how we measure extension. He distinguishes between the mathematical and the aesthetic methods. The question is how we can gain a foundation for our measurements. How do we get an 'absolute' concept of magnitude - how do I get a concept of magnitude that isn't related to other measures in an infinite regress? The problem arises if we try to define the length of a centimetre. We can do so by relating it to other measures: for example, it is one hundredth of a metre, or ten times the length of a millimetre. But then, of course, the question arises as to the definition of this further measure, and any used to answer that question. Kant's solution is to resort to the aesthetic method: we measure an object in comparison to some other constituent of experience. I measure the pyramids in terms of their building blocks, for example, or I measure my sister in comparison to my brother. We can thereby come to some concrete end to our search for definitions which allows us to use mathematical measures practically. If we were not able to relate the length cm to some such experience as 'the length of a house fly' we would not be able to use the measure in any but pure mathematical contexts. What is this intended to show? Kant's concern is with what can be experienced sensibly. By considering the aesthetic method we can see the limits of the measurement we can carry out in sensible experience. The aesthetic measurement of magnitude proceeds on two stages Kant calls 'apprehension' and 'comprehension'. The former amounts to the synthesising of parts. In the case of measuring my brother I need to synthesise the part of my brother equal to the height of my sister and the remainder. In the case of measuring a mansion I may have to synthesis twelve parts of the size of the car sitting in front of it. 'Comprehension' refers to that act of the mind that grasps the totality. It is important to recognize that these are not temporally distinct moments. Comprehension refers to the holding together of all the synthesised parts, apprehension to the act of synthesising. To comprehend the magnitude I need to be able to hold in synthesis all the parts of the object. A mountain disappearing into the mists above me therefore does not meet this requirement, because all the parts are not available to me to synthesise. The point at which I can no longer hold together the synthesised representations - the point when I begin to lose representations as I apprehend new ones - shows the limit of imagination in thinking magnitude. It is as well to emphasise that Kant's concern here is with aesthetic measurements of magnitude. For mathematical measurements, 'understanding is as well served and as satisfied whether imagination selects for the unit a magnitude which can be taken in at a glance, e.g. a foot, or a perch, or else a German mile, or even the earth's diameter.' In aesthetic measurements of magnitude we select a measurement - a person, a building block - and size up what we are presented with in experience. But there is a limit to what can be presented this way. If we attempt to represent the magnitude of a vast object - an object that exceeds my ability to comprehend all its representations - we are led to try to find a measure for it. But this we can not do, for no matter how large the measure it cannot allow us to grasp the magnitude of the object. For Kant, this is where reason supplies the idea of the infinite: my imagination is inadequate to cognising a vast object, and as a result the idea of infinity is supplied by the faculty of reason. Kant, I. Critique of the Power of Judgement quoted in Crowther, P. 'The Kantian Sublime' Oxford: OUP p.7. Kant's claim may seem to be that the measure we are driven to attempt to use is infinite because the object itself is infinite. This comes up against the simple objection that we are not presented with infinite objects in experience. The infinity of an object is what I add to it's representation in thought. The fact that the night sky is fathomless to my perception does not mean my perception is of it as infinite: I may not be able to grasp its depths in my perception but that is merely to say that it exceeds my perceptive capacities. However, infinity for Kant is only properly predicated of the state of our faculties. Just as beauty is the pleasurable sensation of the free play of the faculties, infinity is the idea evoked by the immensely large in nature. In other words, the failure of the imagination to grasp an object of immense magnitude does not rely on the infinity of that object, merely that it exceeds the ability of our imagination. 'True sublimity must be sought only in the mind of the one who judges, not in the object in nature.' If we read Kant this way we can agree that infinity is added by thought to an immensely large object. 'That is sublime which even to be able to think of demonstrates a faculty of the mind that surpasses every measure of the senses.' In the light of this it is no objection to Kant that he claims that what is sublime is absolutely great. To say that something is great is to say that it is so, 'grounded in a subjective purposiveness of the representation in relation to the power of judgement.' In other words, the concept of magnitude implies a relation of the object to the power of judgement of the subject. In the case of aesthetic judgements the measure can be selected by the subject - always implying the relation of the object to the subject as determinative of what can be said of its to a certain magnitude. Beyond that magnitude the subject supplies infinity automatically as the sublime. The object is absolutely great means 'I can not grasp an aesthetic measure for this object, it exceeds the capacity of imagination for presenting the world to me'. In fact, from this formulation we can see that the infinite can not be in the world. If that was so our idea of the infinite would be a concept to fit a synthesis of representations of the imagination. It would thus be a product of the understanding, not reason. Kant, I. Critique of the Power of Judgement Cambridge: CUP p.5/86. I have used the standard pagination for Kant's work throughout. ibid. p.5/80 ibid p.48 ibid The negative moment of the mathematical sublime occurs when the imagination is revealed as inadequate to grasping the magnitude of vast objects. The positive moment is the supplying of the idea of infinity by reason. Thus reason shows itself to exceed the ability of imagination for estimating magnitudes. Through reason we can think more than the world can ever present us with. I shall postpone further critical discussion to look at the dynamic sublime. The Dynamic SublimeThe dynamic sublime concerns the judgement of nature as having no dominion over us despite the immensity of its power. When confronted with examples of nature's might - storms perhaps - I am confronted with my physical inability to defend results in a feeling of pleasure. Despite my physical impotence in the face of nature, my moral nature is not subject to its might. In such cases we consider nature to be dynamically sublime. Critical AnalysisBudd finds a problem with how the imagination enters into the dynamic sublime. Is Kant saying that we attempt to think a measure of the power of nature as in the mathematically sublime? However, I think Budd is just confusing our customary notion of the imagination with Kant's. The imagination enters just in presenting us with representations of the object of nature. There is no need to talk of us 'imagining' a measure or 'imagining' ourselves being at the mercy of the storm - this fear is indeed there, but this is not the central Kantian meaning of the imagination. The imagination is that faculty which brings sensibility to concepts - or at least attempts to. The imagination presents us with the powerful object of nature. However, our adherence to the moral law within us through the rational faculty is shown to be more powerful by reflection. There is no need for more of a role for imagination than that: we are made aware of the superior power of the rational faculty to anything that could be presented to us through imagination. This realisation does not come about by the comparison of the might of reason with the most might we can imagine nature presenting us with; rather, we realise that as of a different order, our rational free will is untouchable by nature. Crowther's similar objection can be countered in the same way. He too suggests the crucial role of the imagination lies in the production of the thought of the unreal presence of the awesome power. After discarding this possibility he too claims that subsequently, 'there is nothing. to stretch imagination to its limits.' The problem seems to be in getting the notion of infinity into the story and thereby explaining the notion of the limits of the imagination. This is what motivates Crowther and Budd to claim that Kant may be claiming that I attempt to form a measure of the power of nature - and therefore end up on the rocks of infinity as in the mathematical sublime. There is no need for the infinite to enter into the discussion and no need for us to suppose the production of a measure on analogy with the mathematical sublime. The dynamical sublime for Kant is, 'Nature considered in aesthetic judgement as a power that has no dominion over us.' When Kant says, 'Nature is thus sublime in those of its appearances the intuition of which brings with them the idea of its infinity,' the context makes clear that he is only considering the mathematically is no question of an object being represented as infinite: the idea of infinity is what the subject throws up when the imagination fails to comprehend the totality of an object. Budd, M. The Aesthetic Appreciation of Nature Oxford: OUP p.6 ibid p.7 Kant p.5/84 One should perhaps note that we are well aware of the transcendental idealism which relates all objects ultimately to the subject's constitution. Here we are concerned with the fact that the idea of the infinite is not represented in the empirical world but is the product of reason unhooked from the imagination. Conclusion: The Role of MoralityI have attempted to outline and briefly defend the Kantian sublime in the preceding; now I wish to show the significance of the sublime's privileging of reason. In the case of the mathematical sublime we saw that reason could surpass the imagination's capacity for representing magnitude. In the case of the dynamic sublime we saw that our free will was shown to be more powerful than anything that could be presented to us by the imagination. How does this relate to morality? In the case of the dynamic sublime things are fairly straightforward. We are led to recognise the fact that our free will cannot be impinged upon by the sensible world. This means that the rational part of our nature is more powerful than the sensible. The rational part of our nature is the source of our moral nature for Kant. Consequently the source of our moral nature is superior in power to our sensible nature. In the case of the mathematical sublime reason is shown to be able to think further than the imagination when it comes to estimating magnitude. Again, the implication is that the source of morality is superior. Whether the argument in the dynamic sublime really shows the superiority of reason or its independence is an interesting question. There is not really a sense in which the power of free will can be compared to the power of nature: the one is physical power the other is rational will and commitment. The result is really that no magnitude of physical power in nature can alter the fact that our free will reveals, 'a self-preservation of quite another kind than that which can be threatened and endangered by nature outside us.' This is not to say that one 'self-preservation' should be valued over the other. This question can also be raised in the case of the mathematically sublime. Reason is capable of thinking infinity, which can not be presented to us in experience. In what sense is this superior? What is the source of the valuation here? Why is it a boon to be able to think an idea which can not be presented in experience? Kant p. 62 We can consider here as analogous issues the antinomies of the first critique, where the ideas of reason lead us into error. As in the case of those antinomies however, the key to the arguments for the valuation Kant gives to the experience of the sublime is to be found in his system of transcendental idealism. Independently he will argue that the distinction between noumenon and phenomenon when thought through shows the reasonableness of supposing freedom to be sourced from outside of empirical causality. Independently Kant will argue for morality as sourced from reason. The arguments of the analytic of the sublime can therefore only fully be completed and the conclusion of the superiority of reason justified in the light of further work by Kant outside the analytic. However, I think that Kant is committed to claiming more. He believes that the experience of the sublime is universal and necessary to all those subjects who have been educated to recognise their moral natures. Hence Kant wishes to claim that the feeling itself reveals reason's superiority: just as the pleasure felt in the experience of the beautiful is necessarily communicable and hence indicative of a universally shared propensity of the faculties, so must the pleasure felt in the sublime be. The difference is of course that only those with a sufficient moral education will experience the awesome extent or power of nature as sublime and as consequently showing the superiority of their rational natures. The nature and quality of the feeling itself - the feeling of the superiority of our rational natures - is its own deduction. Hence one who does not recognise this feeling or does not ascribe it the significance Kant does must fall back on one of two options: either accept the above claim that the justification of the claim of the superiority of reason lies outside the analytic; or conclude their moral education was poor.'''",792.0
"'''Both 'marginal Costing' and 'full costing' information are methods of valuing and costing stock. They differ in one conceptual respect: whether fixed manufacturing costs are 'inventoriable' cost, i.e. if they are costs associated with the acquisition and conversion of manufacturing inputs into finished individual products. Even though fixed overhead costs are part of manufacturing costs, the variable costing information considers them as fixed costs and adds them to the profit and Loss account directly as a lump sum, without assigning these costs to the individual finished goods. The full costing or absorption costing method on the other hand regards fixed manufacturing costs as product costs and allocates them to each individual product. Non-manufacturing costs are considered as fixed costs in both costing methods and added directly to the profit and loss account. Tables and graphically show the difference between the two costing methods. ProfitabilityThe effect on operating profits of the two costing methods will depend on the relation between production and number of sales, because the resulting change in inventory levels is valued differently. Three scenarios can be analysed. Production = Sales. If production levels coincide with the number of sales, the inventory will be unchanged as the closing stock will be the same as the opening stock. Hence profit levels under both methods will be identical. Production > Sales. This would imply that inventory levels increase and the closing stock will be positive. As the costs associated with the closing stock can be deferred by one period, the overall production costs in the current period will fall under both methods. As the Absorption costing method associates fixed costs to each individual product, the deductible variable added than under the absorption costing method, inflating costs and reducing profits. Hence operating profits under marginal costing will be larger than under full costing. Advantages and disadvantagesWhich method better to use is a question that can not clearly be answered and arguments for and against the different costing systems have to be considered. Variable Costing: Variable Costing information is easier to use as it highlights the individual impacts of fixed and variable costs. Consequently, it is easier to make cost effective decisions. When using the absorption costing method, sales fluctuations can have strange effects on profits. Profits can fall while sales rise, even though the cost structure and selling price remain constant. This is due to the consideration of over and under absorption, i.e. the difference between the budgeted fixed overhead rate and the actual incurred fixed overheads. By only taking a lump sum as fixed overhead costs, the marginal costing information avoids any contradictory impact of sales fluctuations. In addition, the marginal costing information avoids managerial behaviour that aims at inflating inventory levels to defer costs onto latter periods. Absorption costing:As a result of cost deferral up to the period where the goods are sold, full costing information allows for a steady profit level in industries that are highly seasonal, instead of large losses in the period where inventories are stocked up and high profits in the period where the produced goods are sold. The absorption costing method is regarded as the international measure of company performance. Top Management might prefer their internal costing information to match their external costing measure for financial markets to have a clear idea of company performance.'''",795.0
"'''In 'Street Corner Society' Whyte undertakes the relatively new and undiscovered research method of participant observation, otherwise known as Ethnography, to conduct a detailed study an Italian Street Slum in Boston's North End, America. As a book very much part of the foundation of Social Research today Whyte's thesis has been widely accepted, and with this has evolved a general acceptance of participant observation as a recognized and valid research method. However if this assumption is made too easily we risk undermining the very complexity of social research and the methods involved in it. Can the theoretically sound notions of participant observation ever be enacted without fault into societies where research is undertaken? Did Whyte achieve this? Can a society ever be fully informed as to the researcher's goal without the aims of the research becoming endangered? Is it ethically acceptable not to inform research participants of their role? We thus need to endeavour to discover the reliability and accuracy of Whyte's research so we can make observations as to the poignancy of 'Street Corner Society', and also judge the effectiveness of Participant Observation as a research method attempting to uncover objective truths and structures in societies today. Participant Observation is a longitudinal research method, that is to say data is collected on numerous occasions from a sample representing the wider majority. As such Ethnography is able to make a detailed and precise study on a particular community, then draw general observations from these findings and make judgments and predictions about similar groups of people. Participant Observation is greatly favoured methodologically for Research within communities because it allows the researcher to gain 'a foothold on social reality' within the group and thus understand, even adopt, their perspective. The researcher typically has more time in the collection of data for their research so is less likely to misunderstand informants because of cultural differences or language barriers. There is less likelihood of a researcher's background altering the results of the research because, as an accepted member of that community, any withheld or less notable information would make itself apparent and the researcher would be able to make fully informed observations. In a similar vein it is felt that the researcher would benefit from having more upon which to base his/her findings than merely answers to questions. The underlying attitudes and behaviour within a society are often far more telling, especially for those conducting research where they are attempting to uncover all activities and analyse or identify social hierarchies. Indeed in situations where illegal or ambiguous activities are co-ordinated the only way of researching such deviant activity is through covert ethnography, without such a research method we would know little about the habits or motivations of drug dealers, prostitutes or criminals. The final advantage we can note in using ethnography is the flexibility involved in reference to the subject or focus of the researchers study. The researcher, having chosen a topic upon which to focus, is not shackled to this topic should they discover new evidence to suggest something else more relevant. Whyte describes how, after some time, he realized the importance of bowling to the group structure and he designated time to study its effect. In a questionnaire based research experiment the researcher would be unable to change his research so readily without huge upheaval to the whole process. Bryman, A. Social Research Methods. United States: Oxford University Press. p.04 from Glossary Bryman, A. Social Research Methods. United States: Oxford University Press. p.28 However the use of Ethnography also poses some significant doubts and questions when used so readily, with relatively little structure, as in Whyte's work. Participant Observation entails working closely with a community and thus developing not only complex relationships within that community but also gaining trust which carries with it a certain responsibility to those whom you are studying. Whyte himself acknowledged in his book that he felt indebted to his ally Doc and wondered if he should note Doc's contribution to his research. This suggests that participant observation is not as unobtrusive as researchers would have us imagine and seems to involve a certain intrusion on the lives of at least the key informants. This can be dangerous if the informants feel misrepresented and betrayed by the researcher as the research then has a negative effect on the very community the researcher intended to help. Not only does Participant Observation represent an intrusion for informants but, for feminist critics, it is tantamount to an exploitative relationship where the researcher uses key informants for their value without empowering them or acknowledging their input to the study. Many people feel that as informants play such a crucial role in any ethnographic research it is the responsibility of an ethical researcher to tell the informant that they are being researched and the object of that research. To ignore this, they argue, would be not only deceit but also an ignorance of the rights of the individual, namely the right to privacy, to not have their lives documented and studied without permission. For the researcher this could mean compromising his research, if a community knew the researchers aims would they really welcome him with open arms and would they show real honesty? Could any progress be made in social ethics at all? The researcher is faced with a decision between the ethics of conduct and the research issue in question. This idea forms part of the ethical conduct prescribed as mandatory by several key sociologists and associations. Diener and Crandall talk of the four 'cardinal sins' which they feel should be avoided in research Finch, J. 'Ethics and Politics of Interviewing Women' Social Researching; politics, problem, practice Routledge:London. p.67-79 'harm to participants.lack of informed consent.invasion of privacy. deception'. Bryman, A. Social Research Methods. United States: Oxford University Press. p.79 These basic prescriptions for any sociological study need to be considered when assessing the use of ethnography as a research method and whether it can be so loosely applied to social research. There are other difficulties highlighted by Participant Observation and the researcher's role within its design. How far can a researcher go in the name of research, and when does it fail to make him exempt from law breaking? In theory participant observation involves observing more than acting so being able to reflect from within a society yet as an impartial onlooker with no motives and no influence on any situation. In reality it is questionable whether a researcher can ever be as invisible as he/she would like to be, whether they can so easily opt out of undesirable behaviour and avoid directly affecting their own results. On a practical note, perhaps another flaw that has arisen out of the blurred boundaries of ethnographic research, is that one cannot be sure on the accuracy of any field notes taken under such intense circumstances and, often, after hazy recollection. Whyte wrote his notes up daily from the previous twenty four hours, can we be sure that they are valid and true and can we know that what he has chosen to mention is all that was mentioned? In the selectivity of recall made by the researcher we need to question how reliable his research becomes and whether we are reading the situation as it is or as Whyte sees it through his own blinkers? This is another danger that has been highlighted by sociologists who feel participant observation allows a certain mobilization of bias to be enacted by the researcher whose own culture or understanding can shape his sociological analysis of an entirely different society. As a research method which is so vague in prescribing an exact step by step methodology participant observation falls prey to many obstacles and the researcher in particular, who is at the helm of the research more than with other research methods, has to be sure not to become lost in the sheer depth of their research in what is often such a small and precise field. Neither should the researcher generalize broadly about a given topic nor apply their findings to other unrelated scenarios. Thus for the researcher using Ethnography several precautions need to be taken, yet they are hard both to enact and to regulate. This can lead us to ask whether using Participant Observation as a research method does not create more problems for researchers than it seeks to solve with its more open approach to research. However despite the obvious dangers involved with Ethnography it is not necessarily an unworkable research method and its results remain impressive and effective in contrast with many other modes of social research. It only highlights the importance of working with some sort of structure and implementing certain measures to ensure against ethical transgressions or flaws in research results. In her article for the 'Journal of Contemporary Ethnography' Boelen makes a fierce and specific attack on Whyte and his research method used in 'Street Corner Society'. Justifying her argument with her own research of the same slum and armed with methodological criticisms of Whyte Boelen's argument makes convincing claims to undermine Whyte and his research. For Boelen Whyte was too academic in his study attempting to theorise too deeply into his Cornerville experiences to establish any pattern or hierarchy which she feels never existed in the way Whyte documented. Boelen considers that Whyte was so immersed into the academic world of sociology that he was led to interpret his research around the popular framework existent in sociology, such as from a 'zeal for social reform'. Boelen makes many other criticisms of Whyte, she considers that he had an 'implicit cultural bias' in his research which centred around viewing slums as a 'sociological problem' for society, a hive of illegal activity. Therefore she accuses Whyte of interpreting his research within the parameters of viewing Cornerville culture as somewhat delinquent and malfunctioning society. For Boelen this is a danger implicit to Ethnographic Research where researchers use their own 'value and belief systems' and thus 'impose normative judgments on situations unknown to them'. This was only augmented for Boelen by the fact that in his long term Ethnographic research into the Italian immigrant community Whyte neither learned Italian nor studied the Italian culture in sufficient depth to understand the workings of an inherently Italian community. This, for Boelen indicates how drastically Whyte misinterpreted Cornerville and why his research is inaccurate and inherently flawed because Whyte could not attempt to understand the nature of Cornerville nor attempt to theorise about it. She dedicates much time to discussing the importance of family for Italian culture to illustrate the bias of Whyte who she claims was sensationalist, preferring to concentrate on illegal activities and their significance within the community and its structure Boelen, M. 'Cornerville Revisited', Journal of Contemporary Ethnography. Vol. April 992 p.2-1 Boelen, M. 'Cornerville Revisited', Journal of Contemporary Ethnography. Vol. April 992 p.6 Boelen, M. 'Cornerville Revisited', Journal of Contemporary Ethnography. Vol. April 992 p.8 Boelen, M. 'Cornerville Revisited', Journal of Contemporary Ethnography. Vol. April 992 p.2. Many of the faults found in 'Street Corner Society' are, for Boelen, centred around the research method employed by Whyte. Boelen asserts that Participant Observation was so new that no boundaries or rules challenged Whyte in his conducting of research and, later, in his findings. Boelen feels the nature of Whyte's research and the fact that it was so open ended and open to interpretation meant that he was able to make false and unsubstantiated claims which were never contested because of the very nature in which the data was collected: no-one else worked with Whyte for the whole duration of his research; he received no feedback from the community about his conclusions; and the location of Cornerville was not disclosed until many years later. Whyte replied to Boelen's critique with a fierce defense of his work. He deconstructed the research of Boelen and found it patchy, bias and inaccurate. Whyte's defense of his research method implies how much he felt he learned from his experience in the field of research. He speaks with informed authority about Cornerville as it was and refers to notes made from the field. Perhaps this best serves to defend not only Whyte's research but the research method of participant observation as a whole when the researcher is able to defend with such accuracy and detail the findings he made. Whyte's research assistant, Orlandella who was a corner boy himself also writes in response to Boelen's thesis. He feels Boelen own research method and her failure to consult informants before printing her article highlights the inaccuracy for her work. Orlandella goes as far as to accuse Boelen of trying to 'manufacture' an argument against Whyte which he feels is largely unsuccessful. Whyte illustrates how Boelen's argument lacked detailed analysis and convincing evidence to discount participant observation however he does not seek to deny the implicit and often flagrant weaknesses or risks involved with participant observation although he defends his own research from these charges. Markedly Whyte does not deny that the researcher's identity and own cultural background can largely affect their research results which are often, particularly with Participant Observation, uncontested. Orlandella, A 'Boelen may know.but.', Journal of Contemporary Ethnography. Vol. April 992 p.1 In order to assess the accuracy of Whyte's research we ought to refresh ourselves with the aims of Whyte's study. Whyte sought to understand the 'slum' culture and find out about its organisation, he sought to disprove claims that slums were a 'mass of confusion' which were 'at odds with the rest of the community'.It is generally agreed that a research hypothesis attempting to be so perceptive within society could not be enacted using simple social survey technique. Whyte sought to deconstruct a society and identify its characteristics and hierarchy not merely to gauge opinion polls on issues. Thus, for the research involved we can conclude that Whyte chose the most appropriate research method and equated the possible costs involved as acceptable for the importance for the research cause. In doing so he not only broke new ground in research but pioneered a way of research, that of Participant Observation, which was largely unexplored. We cannot claim that Whyte's research is infallible but nor too can we accurately seek to disprove it so many years on, we can only consign it to research history and build upon it foundations. What is clear is that by using Participant Observation as a research method Whyte was able to pioneer research that could get deeper beyond the opinions or actions of a society to actually attempt to understand or identify pillars which made up that community. In doing so Whyte was able to dispel myths about 'slum' communities and portray the richness of a diverse and unique community. Whyte, W. Street Corner Society Chicago: University of Chicago Press '''",803.0
"'''The ASB has defined the objective of financial statements as being: 'to provide information about the financial position, performance, and the financial adaptability of an enterprise that is useful to wide range of users in making economic decisions' Financial statements are primary information that firms publish about themselves to the investors, who are the primary users of financial statements, to make reasoned investment decisions about alternative uses of scarce resources in the conduct of business and economic activities. The three main financial statements are the Balance Sheet, the Cash Flow statement, and the Income statement. These statements help analyze the business by translating economic factors into accounting numbers like assets, sales, cash flows and earnings. Usefulness of Financial statement analysis Financial statement analysis is an art of extracting information from financial statements. Valuation models, which in turn provide the basis for understanding and evaluating the decision usefulness of accounting practices, are based on information in the financial statements and consistent forecasts of future performance. 'Financial statements are the lens on the business, which may often produce a blurred picture. Analysis and reporting of the financial statements focuses the lens to generate a clearer picture when accounting measurement is defective.' In order to generate plausible predictions about the future performance, we should use industry, strategy and governance analysis in the forecasting process, differentiate between recurring and non-recurring items in the income statement, use the correct valuation model in step with the accrual system of accounting and clean surplus, and check that accounting policies are appropriate and do not give a misleading indication of future potential. Financial statement analysis 'is not an end in itself,' but is an information system that measures, processes, and communicates financial information about an identifiable economic entity. According to Ben Best, Comparison of financial statements forms the basis for much financial analysis., Stephan H. Penman - Financial Statement analysis and Security valuation Issues concerning the usefulness and quality of financial analysisFinancial statements contain information of varying quality, sometimes even poor quality. As Stephen Penman states, there are three reasons for poor accounting. First is the 'subversion of sound accounting principles' such as excessive restructuring charges, off-balance sheet financing, and capacity swapping. These are violations of sound principles of revenue recognition, expense matching and debt recognition stemming from conflict of interests between the different parties involved. The second reason is the compliance with regulations rather than capturing the economies and regulations that encourage form over substance. The last reason derives from poor thinking as well as the gaming of poor regulation. Many suspect practices are sanctioned by the GAAP and issues that need attention are unaddressed. Some of the problems hindering the use of the financial statements to present unambiguous results are: Impact of different valuation practices:The main valuation models can be systematically divided into two groups. The first group is the cash flow based valuation approaches consisting of the Free Cash and Dividend Discount the Abnormal Operating profit R&D is the most conservative accounting, as it expenses all drug development costs when incurred, as required under GAAP. Then comes successful efforts method, which capitalizes development costs, writes off unsuccessful projects and amortizes successful projects. Full costing is the least conservative method, it capitalizes development costs and amortizes them straight line. Under expensing, firms with high R&D have high P/B ratios and ROE, while full capitalization leads to substantially lower P/B ratios and ROE. While capitalization and amortization undo accounting conservatism they introduce the problem of estimating amortization rates to measure the decline in the value of intangible assets. Knowledge Assets - The conventional financial reporting was blamed during the bubble for not recognizing the value of knowledge assets. Such assets have value because they lead to earnings. Bill gates remarked 'Our primary assets which are our software and software-development skills do not show up on the balance sheet at all'. Revenue Recognition - 'Internet companies are moving into areas where accounting rules do not exist' say Caroline Daniel and Michael Peel. The key concerns in start-ups are non-financial measures such as website hits, customer base and the commitment of the founders. These have brought forward questionable accounting practices such as: Showing gross turnover figures where GAAP would suggest net figures Booking license fees immediately Incorporating gross value of assets facilitated in circumstances where the company is only acting as an agent Contingent equity securities - The liability for convertible debt and convertible preferred stock is understated by GAAP and losses on conversion are not recognized. Security equity-linked loans also need a contingent issue of stock possibly at much reduced share prices, resulting in a loss for shareholders. Impact of pro forma earnings:Pro forma earnings numbers involve mismatching, typically omitting expenses. Lynn Turner's witticism was to tag these low-quality earnings numbers as 'Ebs - Everything but the Bad Stuff'. The most pertinent pro forma earning number is EBITDA, which omits taxes and interest and depreciation. However this results in increased borrowing, substitution of capital for labor, investment in overcapacity and provides incentives to capitalize expenses. Craig Schneider, CFO.com - 'Get up to speed on the latest accounting rule changes for treating goodwill and intangibles.' Financial Times, March 5/8, 000. Accounting Quality:Accounting quality refers to the impact of accounting practices on usefulness of financial statements data for predicting future operating performance. According to Penman, when analyzing the quality of accounting, we seek answers to five questions: Are generally accepted accounting? Is the firm violating GAAP or committing outright fraud? Is the firm using GAAP accounting to manipulate reports? Is the firm manipulating its business to accommodate the accounting? Are disclosures adequate to analyze the business? He defines the purpose of accounting quality as distinguishing 'hard' numbers resulting from cash flows from 'soft' numbers resulting from accrual accounting. A broader assessment of the quality is that of the earnings quality analysis. Katherine Schipper and Linda Vincent, consider earning quality constructs derived from: Time series properties of earningsSelected qualitative characteristics in the FASB's Conceptual FrameworkThe relations among income, cash and accrualsImplementation decisionsAccounting Manipulation:Accounting conservatism or liberalism does not necessarily lower accounting quality. However inconsistent application of accounting polices and manipulation of accruals leads to impaired accounting. Such manipulations distort the predictions of future performance and valuations. Manipulation that inflates current operating income to possibly increase the share price or managerial rewards is known as borrowing income from the future and one that reduces current operating income to increase future managerial rewards is known as banking income for the future. It undermines the ability of past RNOA to predict future RNOA. The term 'aggressive accounting' is best used to indicate manipulation that temporarily increases income and 'big-bath accounting' used to signify large reductions in income. Detecting manipulation requires understanding the business and the accounting policy and then investigate business areas, institutional and accounting conditions most susceptible to manipulations. Indicators of manipulations are commonly referred to as quality diagnostics. Empirical research on financial statement analysisThe constant research conducted on financial statement analysis, provide us with much food for thought. Different aspects of reporting and valuation have been tested to shed light on the grey areas and give rise to better accounting standards while at same time making sure that the value relevance of financial analysis is not diminishing. A paper by Paul Hribar & Daniel Collins on 'Errors in Estimating Accruals: Implications for Empirical Research', describes the role played by measurement of accrual in the body of accounting. It is based on the presumed articulation between changes in balance sheet working capital accounts and accrued revenues and expenses on the income statement, which breaks down when non-operating activities like M&A, divestitures and translation of foreign subsidiary' accounts are present. Another article by David Aboody, John Hughes & Jing Liu discusses 'Measuring value relevance in market'. They analytically examine the impact of market inefficiencies on the estimation of coefficients in value relevance regressions and derive a procedure that corrects potential biases caused by such inefficiencies in ) the value relevance of earnings and book values; ) the value relevance of residual income value estimates; and ) the value relevance of accruals and cash flows. The findings show that cash flows map into returns with a statistically significantly higher coefficient than accruals after adjustment for future returns, while the two coefficients are statistically indistinguishable from each other when stock price is not adjusted. The topic of stock options is another popularly tested one. Carol A Marquardt conducts an empirical analysis on 'The cost of employee cost option grants' and the results suggest that the Black-Scholes model adjusted for concavity in the time to exercise using the Hemmer, Matsunaga, and Shevlin procedure, provides reasonable estimates of ex post ESO costs. Valuation models and their applicability have undergone several analyses. J. Francis, P.Olsson and D.R Oswald in their study on 'Comparing the accuracy and explainability of dividend, free cash flow and abnormal earning equity value estimates' find that AE value estimates are more accurate and provide larger explanation of the variation is security prices than do FCF or DIV value estimates. This superiority of the AE value is mainly driven by the sufficiency of book value of equity as a measure of intrinsic value and the predictability of abnormal earnings. Measures to make reported financial accounting more useful Accounting policy and financial standards must evolve. As the economy progresses, and the financial environment is revolutionized, it calls for a need for greater regulation, a better conceptual framework and global accounting standards that integrate differences in economy, allowing more transparency, reliability and non-manipulation of accounting statements. Stephen Penman, in his article on the quality of financial statements, puts forth certain changes that need to be implemented: An analysis of net revenue, a reconciliation of gross revenue to net revenue and a breakdown of booked and deferred revenue is needed. Operating income/assets/liabilities should be clearly distinguished from those of a financial nature. Transitory items need to be clearly displayed on the income statement Consolidation prevents proper understanding of how assets and liabilities are structured; this calls for more transparency and desegregations. Clarity about accruals need to be established, to give readers a better sense of 'hard' and 'soft' numbers and the likelihood that earnings will be sustained. Russell J. Lundholm in the article, 'Reporting on the past: A new approach to improving accounting today' proposes that financial reporting be amended to report on the expost accuracy of a firm's prior estimates. This will identify firms that have abused their reporting discretion. With a system to report on the expost accuracy, regulators might be more willing to allow the booking of difficult-to-measure assets, such as the value of R&D expenditures. Other issues are: Accounting applicability in the dotcom business even though on the 'emerging issues task force' of the FASB, needs action taken. FASB should look into explosive issues of accounting for pension costs, for post-retirement costs such as health and insurance plan, interperiod income tax allocation and translation of foreign currency financial statements. Apart from new standards, a supplemental quality analysis is required. ConclusionIn summary, the traditional way of accounting should be altered to incorporate the ever-changing ways of the economy, and reflect the true picture of a company to its investors. Only then can accounting statements justify the decision of investors and actions of firms. In the words of Roger Davis, (ICAEW representative), '.the advance of corporate reporting will require innovation and experimentation rather than rule setting. The portrait of a company in a new era of accountability means crafting the picture rather than painting by numbers.''''",805.0
"''''Organic food, also referred to as organics, is food grown under a production system that, in addition to the avoidance of synthetic chemicals, also promotes soil health, biodiversity, low stress treatment of animals and sound environmental practices' (Cunningham, 001). Nowadays, organic agriculture is in practice nearly in all countries with the total organic area being more than 4 million hectares today UK is dominating the European as well as the world organic market with a value of. billion in Croatian the positive attitudes towards organic food, however, their actual purchasing activity was low. This might be attributed to the fact that even though younger people may be more concerned about the environment, they do not have the purchasing power. Instead of young people themselves purchasing organic products, their impact may be seen as 'pester power', thus trying to convince their parents to buy organic food. In another study carried out in Croatia, it was also found that women buy organic food more often compared to men. Apart from the gender characteristic, education was also important factor with people of higher education level showing bigger organic purchase activity. Finally, people from cities who live in urban areas purchase organic food more often. Any other socio-economic or demographic characteristic did not have any apparent that it is of importance that organic food is not more expensive than conventional indicating that price is a major inhibiting factor in purchasing organic food. Also Scottish consumers have stated that they would buy more organic food if the difference in price compared to conventional food was lower. Availability of organic products is also another inhibiting factor. The study by Magnusson et al. revealed that availability is also product dependent. For example, organic meat and bread were considered to be the most difficult to find (0% of the respondents). On the other hand, 1% of the respondents stated that it is quite or very easy to find organic milk. Apart from the basic obstacles of price and availability there are also secondary inhibiting factors. One of these is habit and convenience. According to Jolly, the extra time required to find the organic products was an obstacle for Californian consumers. Furthermore, according to Mathisson and Schollin, habit is a reason accounting for consumers' refrain from purchasing organic food. Poor presentation of organic products is another obstacle. In a study carried out in Wales, 6% of the respondents did not know where to find an organic product (Padel and Foster, 005/8). Among the reasons why consumers do not buy organic food is also the appearance of organic products (e.g. bruises and blemishes in fruits and vegetables) (Makatouni, 001). Finally, consumers find it difficult to know whether a product is organically produced. This was the problem especially with meat for which Swedish consumers found it difficult to know whether is was organically produced. To sum up, there are many motives for buying organic food, with health and environmental considerations being the most important. Increases in the demand for organic food have been observed over the last years and consumers have become more willing to purchase organic food, however, there are many obstacles, with price and availability being the most important.'''",815.0
"'''Discussion of the program:This program is made up of functions: ExecuteCommandLine, main and NumberSpace. The main function:The main function prompts the user to enter a command line. This command line can be 'exit' if the user wants to quit the program. This main function contains a main loop which runs until the user enters 'exit'. After the user has entered a command line, the function called in order to create a child process which will execute the command line. This child process calls the function the parent process waits its child end with the function then to execute this command line. This function has just one parameter, a string which is the command line. This function creates an will contain the pathname and all the parameters. This array is called args in the program. In order to 'extract' the argument from the command line, a 'while loop' is used. This loop reads the command line character by character and then fills the array. The following schema show how is structured this array: After the array is filled, we can call the execv function which executes a program. This function is a member of the exec family. The synopsis of this function is, Where path is the pathname of the program and argv is an contains all the argument which have to be added to the command Reflection on results:Expected results are similar than the results which are obtained. The user can enter commands line with any arguments necessary. He can do that until he enters 'exit'. The command line is executed by an child process and the parent process wait for the end of the child process. If an error has occurred, then child process returns a special then the parent process inform the user about this error. Conclusion on the problem:The system function to a process to delegate some tasks to another times, it can create child process which will execute this task in the same time (parallel execution).'''",821.0
"''' play with the normal codes of cooperation between people in a conversation. The way every script is constructed is carefully analysed and discussed by the writers in order to create the expected humour effect. They might not know but one of the principles that they use to achieve this is the Pragmatics one. According to Cutting, Pragmatics takes a socio-cultural perspective on language usage and studies its context, text and function. Therefore, this essay will provide a pragmatic analysis on one of the scripts taken from the American sitcom Friends. First, a short introduction to the Sitcom and its characters will be presented. Then Grice's conversational maxims of the Cooperative Principle, Brown and Levinson's Politeness theory and Leech's Politeness Maxims will be summarized and then illustrated throughout the text analysis. Finally, a conclusion will be drawn on the effectiveness of these frameworks to understand the text chosen and on the peculiarities discovered about the humour used in Friends. As described by Nash, 'humour is a specifying characteristic of humanity'. And although the sense of humour varies in different cultures, it seems to have some similarities that enabled Friends to be a huge success around the world. The sitcom involves the everyday life of six friends showing an exaggeration of real life situations. The characters themselves have distinct characteristics that help us to understand their ways of expression and reaction during the conversations. The chosen script is a scene from the tenth season of the series where five of the main characters - Rachel, Joey, Monica, Chandler and Phoebe - interact in their favourite coffee shop. Rachel is the 'fashion woman' and just had a baby with Emma. Joey is an actor and is very 'airhead'; he often takes a lot of time to understand jokes and indirect speeches. We could even argue that he would have a really hard time to understand Pragmatics. Monica and Chandler are married. Monica is a chef and is very perfectionist. Chandler works in advertisement and is very sarcastic and ironic at times. He loves making jokes and fun of other people. Finally, Phoebe is similar to Joey in 'airheadness'. She is the crazy one in the group who always have strange hypotheses for everything and has very unexpected reactions like the one seen on lines 2/3 of the text. She is a masseuse and has been dating Mark for a year now. A study on sitcom that 'humour can be derived from the deliberate scripting of flouted maxims'. These maxims are part of Grice's theory of the Cooperative Principle, cited in the on record with positive politeness. Finally, when the speaker is direct but trying to save negative face - the need to be independent and not be imposed on by or she is doing a on record with negative politeness. It will also be considered for this analysis the politeness maxims proposed by Leech. As seen in Cruse, there are types of politeness maxims: tact, generosity, praise, modesty, agreement and sympathy. The ones observed and flouted in this analysis are, as described in Cruse: Tact: minimize cost to hearer; maximize benefit to hearerGenerosity: minimize benefit to self; maximize cost to selfPraise: minimize dispraise of the hearer; maximize praise of the hearerModesty: minimize praise of self; maximize dispraise of selfThe conversation starts with Rachel making a comment about letting her baby, Emma, have her first cookie. This is then followed by Joey flouting the maxim of quality by exaggerating his statement in line with the use of a hyperbole - 'all the time'. What he intends to say is not that she eats cookies all the time but that it is certainly not the first. Because of this statement Joey puts himself in a very occurred situation where people can assume that he has given cookies to Emma before. Rachel's reaction is of a baldly on record face threatening act with a direct question to Joey in line. She violates the politeness maxim of tact by not being cautious, and leaves Joey no other choice but to violate the maxim of quality by not answering with the truth. In order to create a stronger comic effect he flouts the maxim of relevance and quality when saying that he also never gave her a frosting from a can. On line a new interaction starts between Monica, Rachel, Chandler and Joey. First, Monica uses on record negative politeness to minimize imposition on Rachel when asking her to write the letter to the adoption company. She gives Rachel the option to refuse it by inserting in her question an intentionally noncommittal statement: 'we were wondering'. Rachel being best friends with Monica surely doesn't refuse the request and accepts it flouting the maxim of quantity; adding more then a simply 'yes' to her answer in line 0. The whole situation upsets Joey who, on line 4, tries to catch everybody's attention by clearing his throat and consequently flouting the maxim of relevance and manner by saying that it has been an oversight. He produces an off record face threatening act giving a hint that he feels left out of their decision. The hearers, Monica and Chandler, can opt to comment on it or not. And so Chandler do it on lines 5/8 and 6 trying to save Joey's positive face when saying 'we would've asked you', and his negative face by 'we thought you wouldn't be interested'. Monica's reply is less tact than Chandler's though, probably because Chandler is Joey's best friend. In lines 7 and 8 she wants to give him some sympathy but she slightly insults him by saying he is not much 'with the words'. Either way, they are both flouting the maxim of quality because knowing Joey we can deduce that they didn't really thought of asking him after all. Joey then infringes - 'his performance is impaired by nervousness' as defined in Cutting - the maxim of quantity by not giving any information but just babbling along. He doesn't really know what to say, what provokes Monica to flout the maxim of quality by being sarcastic on line 0. She means the complete opposite of what she says. Joey continues to try convincing Monica and Chandler that he could write the letter. He flouts the maxim of quantity by giving more information than it is make his point. He also appeals to their positive face showing sympathy, claiming common ground and applying the politeness maxim of generosity. This generates Monica response of saying that they want him to do it. She doesn't need any politeness strategy here since Joey wants to write the letter and then there's no need of asking but just directly saying it. The seriousness is then broken by his open thoughts of how he is going to start the letter (lines 5/8 and 6). Chandler realizes their mistake of letting Joey write the letter and flouts the maxim of quality by being sarcastic in line 7. He is not at all excited because Joey just showed that he can be really bad 'with the words'. A new interaction is introduced with Phoebe arriving and saying 'hello' in line 9. Everybody answers back and Joey repeats his 'hello' implying something more to it and therefore flouting the maxim of quantity. He probably noticed that Phoebe is looking better dressed than usual. This is followed by Monica's remark to Phoebe's look on line 2. She is being indirect, and flouting the maxim of quantity and manner by not asking what she really wants to know. She both implies 'where are you going all nice' or 'why are you dressed all nice', and leaves Phoebe to interpret it and to answer if she wants. By this indirect action she is being polite off record also applying the politeness maxim of praise. Subsequently, Phoebe completely violates the politeness maxim of modesty by agreeing that she looks nice. However, this is expected of Phoebe and is what gives the humour to the passage. She also opts to answer Monica's implication making the statement that it is Mike's and her anniversary. It could be argued that Phoebe flouted the maxim of quantity since her statement invited questions to be made. First, Rachel asks a very direct question on line 4 that leaves Phoebe no choice but to answer it. This baldly on record question is followed by options to what the anniversary could be of. Phoebe then answers it with a simple 'yeah', not specifying which anniversary and so flouting the maxim of manner. We can assume she says 'yeah' for everything or just for the last part - 'first time you had sex'. Next it is Chandler's time to ask the question on line 7 deducing that Phoebe and Mike are going somewhere fancy to celebrate. He uses an off record politeness by flouting the maxim of manner. His intentions are to know where Phoebe and Mark are going but he only implies it so Phoebe can choose to answer 'yes' or 'no', or the name of the place they are going. She then flouts the maxim of quality when she says 'yes' to going to a fancy place and them ironically adding that the place is a basketball game, which is not fancy at all. Realizing that, Joey makes a direct - bald on record - question to Phoebe insinuating that she is not properly dressed for it. She understands the hint and consequently flouts the maxim of quantity by giving more information than necessary in order to her friends stop judging her. She also flouts the maxim of relevance when she highlights on line 3 that they are going to have sex in a public restroom. Monica then makes use of an on record positive politeness questioning Phoebe, on line 4, about having sex in the public restroom. She is very direct but makes a remark after the question that shares something about herself and Chandler, assuring Phoebe of their friendship and that is it alright to talk about it. To end the scene, Chandler tries to defend himself from the accusation that he doesn't even want to have sex in their bathroom. In order to do that he flouts the maxim of quality using a euphemism - saying 'number two' for defecating. Through this type of analysis one can come to the conclusion that the frameworks used were significantly effective to help comprehending the humour in the script. A constant flout of the maxims can be seen, specially the quantity and quality ones which create the typical comedy effect desired. It becomes clear that the sense of humour used in Friends is common among different cultures because of these basic principles of cooperation and politeness.'''",822.0
"'''Neurasthenia is a psychological disorder characterised by profound physical and mental exhaustion. Hysteria is a disease which produces symptoms of excessive or uncontrollable emotion, such as fear or panic. However, neither has a clear organic, medical cause and has multiple symptoms, such as bad dreams, insomnia, fidgetiness, impotence, claustrophobia and vague pains. This list is far reaching and thus could surely be applied to numerous diseases. The vagueness make neurasthenia and hysteria subjective and therefore suggestibly socially constructed. This essay will attempt to assess how plausible this suggestion of social construction is. Sicherman, Barbara 'The uses of a diagnosis: doctors, patients and neurasthenia', Journal of the History of Medicine, 2 p. 3 Sicherman, 'The uses of a diagnosis: doctors, patients and neurasthenia' p.3 Both diseases spread rapidly. Was this because there was a genuine rise in the number of sufferers, with people struggling to cope with modern society, or was it, as Beard's one-time partner Rockwell suggested: that neurasthenia became almost a household word. Physicians often diagnosed neurasthenia because this pleased the patient. However, it was regarded as 'the newest garbage can of medicine' because as it became a term used by everybody its medical status lowered. The disorders spread easily by imitation and suggestion because they were widely publicised. For example, being labelled as suffering from neurasthenia provided 'rest cure' as a reason for vacations so people did not seem lazy. Micale suggested that 'in our psychological century, new or emergent forms of psychopathy are not limited to technical medical discussion, but rather develop strong social and cultural resonances.' This means that diseases were in tune with society and could change. Diseases become new and fashionable. However, simply by becoming fashionable does not mean that they did not always exist. Rather it means they have more media coverage. For example, tuberculosis bacteria is natural and has always existed. However, this does not mean that if you died from TB before this label was put on it by society you did not die from the same disease. Micale argued that diseases like anorexia, chronic fatigue syndrome and hysteria are all heavily context dependent. 'They are perceived as social and cultural diseases reflective in some direct.way of social and cultural conditions unique to the present.' Illustrating that society labels the disease and shapes its development. Ibid p. 5/8 Ibid p. 5/8 Micale, Mark Approaching hysteria: Disease and its. 91 Micale, Approaching hysteria p. 91 Ibid p. 90 This could similarly explain why neurasthenia faded as a medical diagnosis in the United States by the 930s. Does this mean the disease disappeared or it became unfashionable to give it as a diagnosis or simply that it was re-branded and re-labelled? The latter ideas are the most likely because people still suffer from symptoms that were once classed as neurasthenia for example, a lack of energy resources and fatigue. Similarly, new labels were placed upon hysteria, for example, 'historionic personality type.' What is in a name? A name is simply a label put on symptoms to ease social anxieties. Neurasthenia and hysteria could simply be seen as labels put on conditions which society felt uneasy with because there was no organic cause. This does not mean the disease was not real, simply that it was psychological and the label was placed on it by society. Schuster, David 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914', Bulletin of the History of Medicine, 9 p. 97 Micale, Approaching hysteria p. 92 During the second half of the nineteenth century, there was a rising need for a disease to have scientific respectability because of the germ theory and discoveries by neurologists and anatomists. 'If hysteria was a disease, and not the imposition of self-pitying women striving to avoid their traditional roles and responsibilities - as was frequently charged - it must be a disease with a specific etiology and a predictable course.' To be a disease it needed a specific organic malfunction, however, hysteria lacked these characteristics to make it a scientific disease. This is partly because both neurasthenia and hysteria were subjective in their diagnosis. A patient could have a desire to be labelled sick. The physician only had their word that they could not move or were suffering serve pain. A patient could mimic a heart attack or blindness, but a physician could find contradictory evidence that proves they are in perfect physical health. In addition, their symptoms changed constantly. For example, 'headaches would replace contracture of a limb, loss of voice, the inability to taste.' This is something that hindered the mental illnesses medical position and made them seem more socially constructed. It has been argued that the patient was in control. If the diagnosis a physician provided was unacceptable, the patient may take his business elsewhere. For example, a patient was often happy with the diagnosis of neurasthenia because it provided a respectable label to their distress and was not life-threatening. This perhaps encouraged physicians to diagnose neurasthenia too readily. 'In the late nineteenth century, neurasthenia proved a satisfactory label to doctors and patients alike.' Smith-Rosenberg, C 'The hysterical woman: sex roles and role conflict in nineteenth century America', Social Research, 9 p. 03 Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 03 Sicherman, 'The uses of a diagnosis: doctors, patients and neurasthenia' p. 8 However as Weir Mitchell said 'we are hardly wise to stamp these pains as non-existent.' For example, palpitations of the heart and depression, often inducing momentary paralysis. There is no denying that hysterics and neurasthenics were experiencing pain, therefore to deny them an illness seems harsh. Treatment for hysteria was often similar to that of other mental illnesses: electric shock, blistering, multiple operations and amputations. The harsh treatment could mean that physicians and society looked down on hysterics. Neurologists such as Mitchell, Beard and Dana defined hysteria as a disease despite lacking an organic cause. They saw hysteria as caused by indolent and unconstructive life of the fashionable middle- and upper-class woman or by the ignorant, exhausted life of the lower class woman. Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 04 'The perception of pain, the significance attached to symptoms, even the symptoms themselves vary greatly, depending not only on individual needs but on class and ethnic patterns.' This clearly illustrates the social construction of these mental illnesses. Some physicians have claimed that in the patient's eyes neurasthenia was 'a reservoir of class prejudices, status desires, urban arrogance, repressed sexuality and indulgent self-centeredness' thus making it solely a socially and culturally constructed disease. However, this is surely unfair on the doctors because it is in the consulting room and hospital clinic where these illnesses are treated. These mental diseases could only be diagnosed after a physical examination, but once the physician had decided there was no organic disease present in the patient they must still label the condition. Sicherman, 'The uses of a diagnosis: doctors, patients and neurasthenia' p. 1 Ibid p. 7 Beard describes neurasthenia as principally a disease of the comfortable class. Patients were from the business and upper classes in large cities. In comparison, Weir Mitchell diagnosed it in male working class patients. This debate over the class of people suffering the disease perhaps indicates it is socially constructed, because the disease changes in different context. Most diseases cross class boundaries. For example, plague. Although it affected more lower classes this was because of their living situation and inability to flea plague ridden towns like the rich. Surely for a disease to be real it should be able to affect all humans lacking natural immunity. Class does not give you natural immunity. Likewise, to suggest a class is excluded is wrong. For example, to assume that lower class women escaped hysteria is pessimistic; the prescriptions of proper female behaviour were internationalised in all classes. Leading from this is the idea that mental illnesses were specific to a gender. 'The hysterical woman can be seen as both product and indictment of her culture.' Nineteenth century American society provided only one socially respectable role for women: that of a loving wide and mother. Therefore, all women had to try to adjust to one prescribed social role, which demanded continual self-abnegation and desire to please others. Hysterical patients 'did not function as women were expected to function.' Ibid p. 4 Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 15/8 Ibid p. 13 Ibid p. 02 It was not until the mid nineteenth century that hysteria emerged as an endemic disease among bourgeois women in America. Therefore we can conclude that it is a disease particular to the Victorian bourgeois family. As already discussed, any disease that is particular to one era already indicates that it was potentially socially constructed or that there was a cure. There were many discontinuities between an ideal of womanhood and the real world. Many contemporises noted in the 870s, 880s, 890s that middle class American girls were not ready to assume the intense trials of marriage, motherhood and maturation. 'Physicians reported a high incidence of nervous disease and hysteria among women who felt overwhelmed by the burdens of frequent pregnancies, the demands of children, the daily exertions of housekeeping and family management.' The case study of Sarah Butler Wister illustrates society's role in her illness. She lived within the traditional domestic sphere. She cherished taking care of her family and their estate. However, Dr Mitchell believed this was the root cause of her neurasthenia. She could not put housekeeping out of her mind; she saw it as a chore and cherished it as a responsibility. Society placed pressure on women to fulfil the role of good housewives and mothers. Her desperate attempts to successfully fulfil this role meant she was trying to conform to societies pressures, therefore society was to blame for her disease. Ibid p. 99 Schuster, 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914' p. 14 Similarly, The Autobiography of a Neurasthene by Dr Margaret Cleaves is, in many ways, an excellent example of how society and culture caused her mental illness. Overwork led to a sprained brain and a sensation of blood pouring into her ears, depression, weeping and fears of going insane. Social events played particular strain on her life. Vital to her cure was her relationship with her physician because during her rest cure she was isolated from New York City life. Rest cure enabled patients to step away from society where they struggled to survive, therefore suggesting that the disease was socially constructed. In addition the case of Amelia Gere Mason, who had gained a degree and became a headmistress in a private school, but had developed neurasthenia. It could have been the fact she stepped away from her subscribed social role that led to her neurasthenia. Her illness forced her into seclusion from the city to hope for recovery. If seclusion was necessary and doctor-patient relations vital as Schuster illustrates, then surely society is key to the illness. Ibid p. 03 It could be argued that social changes such as a more mobile economy and larger population, but fixed family and gender roles affected people's mental illness. Neurasthenia was a method for women to cope with changes in the economy, society and gender roles. Dr Mitchell's work suggests that neurasthenia was a distinctly modern condition that occurred whilst American's began to leave their traditional family roles. For example, families left the spacious countryside for the bourgeoning cities; men moved from farms to offices; women left family for university and society was modernising with fast trains and telegraphs which created a very fast paced world that 'drained people of their mental strength.' Educated women struggled to reconcile their desire to be independent and still fulfil their traditional family roles. For example, Jane Addams described years of backaches, depression and purposelessness following her graduation from college. Mitchell saw the diagnosis of neurasthenia as proof that American society was modernising faster than people's minds could keep up. He argued that America's pursuit of the 'dollar devil' stole energy from the nation. Ibid p. 99 Schuster, 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914'p. 02 Sicherman, 'The uses of a diagnosis: doctors, patients and neurasthenia' p. 6 Schuster, 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914'p. 21 Ibid p. 08 Similarly, Smith-Rosenberg argues that 'hysteria may have served as one option or tactic offering particular women, otherwise unable to respond to these changes, a chance to redefine or restructure their place within the family.' Taking to one's bed may have been a passive aggression. In this sense, neurasthenia is clearly socially constructed because these women were manifesting illness in themselves. Their illness was psycho-somatic. They saw neurasthenia as a chance to bargain with traditional patriarchy. No longer would she devote herself to the needs of her family. For example, household activities were reoriented and children were hushed. 'Consciously or unconsciously, they had opted out of their traditional role.' However, as with all classes being affected, so were both genders. However, this was not the common conception. Therefore, the disease could affect everybody, but society's public construction of the disease differed seeing it as primarily a female malady. Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 00 Schuster, 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914'p. 98 Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 08 Micale, Approaching hysteria p. 4 Gender and class have been discussed as affecting the perception of society's image of mental illness; what about social outcasts such as criminals? Jackson discusses the belief that photographs were a reflection of reality. The feeble minded were seen to threatened national prosperity and social order, by being the root cause of social problems such as crime, unemployment and poverty. Crime itself was seen as a physiological dysfunction. Ten to twenty percent of the prison inmates were mentally deficient. Photographs of mentally ill people in text books illustrated the 'stigmata of degeneration'. This stigma is socially constructed, as is the label on these people as mentally ill. 'By capturing on camera the anomalous appearance of those considered to be educationally and socially deficient.defectives could be weeded out from normal population and segregated for society's protection.' Perhaps photographs labelling people mentally ill was a way to scapegoat people thought to be a threat to society? Jackson concludes that the photographs and accompanying verbal descriptions in medical texts portray broader social, political and professional interests. The photographs fixed the idea that the mentally ill are an inferior class of society, a threat, linked with deviancy. Photographs have clear social and cultural implications as a form of social control and therefore suggest mental illnesses could be socially constructed to label deviants. Similarly, some historian's have argued that neurasthenia 'represented a medicalised tool of social control that victimised Victorian women.' Smith-Rosenberg conveys that hysteria should be dealt with as a social product 'produced by and functional within a specific set of social circumstances.' Much evidence suggests this. For example, the neurasthenia label only being applied in a set time frame. However, George Beard believed mental illnesses were real diseases. He 'insisted it was as real a disease, with as genuinely somatic a course, as smallpox or cholera.' Beard made a clear medical explanation for neurasthenia, believing that everyone had a fixed amount of nervous energy, which was mainly hereditary, which were messengers between body parts. Neurasthenia occurred when demand exceeded supply. A tract by S. Weir Mitchell titled Wear and Tear clearly indicated that it was society that was to blame for this disease, but that it was a medical disease nonetheless. Although hysteria and neurasthenia were not the same, we can place them under one umbrella for answering this question because the themes of this essay, such as being labelled by society, modern life causing a breakdown in traditional values and the disease being more specific to certain gender and classes show the diseases similarities. It is undeniable that people suffered from mental illness. The illnesses had always existed and continued to exist outside the period the labels of neurasthenia and hysteria were used. Society was trying to make explanations for diseases that had no apparent organic cause. 'Writing history of hysteria becomes a way of achieving an understanding of and perspective on, ourselves and our social world.' Therefore, it is clear that an argument can be made that mental illness is socially constructed with respect to hysteria and neurasthenia, but this does not deny mental illness is a real disease because people are in pain either physically or psychologically. Gilman, Sander in Jackson, Mark, 'Images of Deviance: Visual Representations of Mental Defective in Early Twentieth-Century Medical Texts', British Journal for the History of Science, 8 p. 21 Jackson, 'Images of Deviance: Visual Representations of Mental Defective in Early Twentieth-Century Medical Texts' p. 34 Ibid p. 27 Ibid p. 35/8 Ibid p. 37 Schuster, 'Personalising Illness and Modernity: S. Weir Mitchell, Literary Women, and Neurasthenia, 870-914' p. 98 Smith-Rosenberg, 'The hysterical woman: sex roles and role conflict in nineteenth century America' p. 15/8 Sicherman, 'The uses of a diagnosis: doctors, patients and neurasthenia' p. 4 Micale, Approaching hysteria p. 92 '''",826.0
"'''Yes, functionalism offers a more plausible theory of intentional states than it does of sensations and other states of consciousness. I intend to argue my thesis by initially providing an account of the functionalist theory. I will then outline the criticisms that have been raised in response to functionalism concerning the theories' ability to account for sensations and phenomenal consciousness and evaluate whether they are successful in disproving functionalism. Finally I will illustrate how I arrived at my thesis - that functionalism offers a more plausible theory of intentional states than it does of sensations and other states of consciousness as the functionalist theory cannot provide a satisfactory account with reference to qualia and Nagel presents the most influential criticism of functionalisms ability to account for phenomenal consciousness. Functionalism maintains types of mental states are types of functional/causal states. What tokens of any distinct mental types have in common is the functional/causal role they play. For example, pain plays a distinct causal role in our internal economies and is specified by a number of generalisations; pain is caused by tissue damage/types of nerve stimulation, pain causes worry, moaning, crying etc. Occupying the causal role is part of the essence of pain. Therefore, to be in pain is to token an internal state occupying the relevant causal role. Each distinct type of mental state plays a particular causal role central to its identity. To token a state of any given mental type is to token an internal state playing the appropriate role in ones internal economy. The majority of functionalists are physicalists as they regard minded agents to be complex physical systems and maintain that the token states occupying these roles are internal physical states of such systems. An object possesses a functional property in virtue of filling a particular role; something occupies a particular role if it responds in certain ways to causal inputs and produces certain kinds of outputs e.g. a heart pumps blood around the body, consequently an object possesses the property of being a heart provided it occupies this causal role. Heil, J 'Philosophy of Mind: A Contemporary Introduction' nd ed. London: Routledge Cain, M 'Fodor: Language, Mind and Philosophy' Cambridge: Polity Press Functionalism regards mental states to be multiply realisable, mental properties are realised by physical properties. The same mental property might be realised by one property in a human being and another in a different creature; for any type of mental specific terms associated with human pain. One is able to describe crying in detailed terms and include a characterisation of a relevant output in ones theory of pain. This theory will be chauvinistic as it implies octopi cannot feel pain as their pain behaviour is different from it does not feel pain as it has no inner qualitative character - qualia is absent. Functionalism therefore implies the robot is experiencing something it is not, committing liberalism. Consider the possibility of 'inverted qualia'; it is conceivable that when I look at a tomato my colour experience is like the colour you experience when you look at spinach and vice versa. Your experience of green is like my experience of red. These differences are not revealed in any observable behavioural differences - we both say 'red' when asked what colour a tomato is and 'green' when asked the colour of spinach. Therefore it is conceivable that your colour spectrum and my colour spectrum are systematically inverted without being revealed by behavioural differences. If inverted/absent qualia are possible in functionally equivalent systems, qualia cannot be captured by functional definitions. It has been replied that in the functionalist account, mental states are realised by the internal physical states of the psychological subject, therefore for humans the experience of red as a mental state is realised by a specific neural state, consequently two people cannot differ in respect of the qualia they experience if they are in the same neural state. If they are both in the same neural state, either both experience red or neither does. I do not find this response to be sufficient in overcoming the criticism as it does not successfully render qualia inversion to be impossible and does not address the problem presented by absent qualia. Smith, D and Thomasson, A 'Phenomenology and Philosophy of Mind' Oxford: Clarendon Press Kim, J Philosophy of Mind' nd ed. Oxford: Westview Press Kim presents another example of inverted qualia in response to functionalism. He presents an idealised model of how pain and itch mechanisms operate. Each of us possesses a 'pain box' and an 'itch box' within our brains. It is imaginable this pain box consists of numerous neural fibres that are activated when one experiences pain and similarly for the itch box. When ones pain sensors are stimulated, neural signals are sent along the pain input channel to the pain box which activates and sends signals along its output channels to one's motor signals causing appropriate pain behaviour, (the itch mechanism works in the same way). Suppose ones brain is rewired so the input and output channels of ones pain and itch centres are crisscrossed. Signals from ones pain receptors now activate ones itch box which instigates ones motor system to display pain behaviour (crying, moaning etc). Correspondingly signals from ones itch receptors activate ones pain box which sends signals to ones motor system causing itch behaviour (scratching). Even though ones brain is cross wired with reference to mine we both emit the same functional psychology - we both scratch when bitten by a mosquito and moan when we burn our hands, to the functionalist we instantiate the same itch/pain psychology. The functionalist would argue that when one with this cross wired brain cuts themselves they are in pain and ones former itch box has become ones pain box, therefore when activated one is in pain. However I do not find this to be a sufficient response as if ones brain has been cross wired what one experiences when cutting themselves is an itch not pain despite the input/output relation exhibiting behaviour appropriate for pain as it will feel like an itch. Kim, J Philosophy of Mind' nd ed. Oxford: Westview Press Kim, J Philosophy of Mind' nd ed. Oxford: Westview Press Phenomenal consciousness maintains a mental state is conscious when there is something that it is like to have that state. Nagel presents what I regard to be the strongest criticism of functionalism as a successful theory of mind with his paper 'what is it like to be a bat?' Nagel argued forms of physicalim, including functionalism cannot account for consciousness. The argument upholds that there is something that it is like to be a bat - something it is like for the bat and to have a bat's sensations/experiences. Correspondingly there is something that it is like to be human and to have any human experience. This 'what it is like' aspect of experience is connected to holding a point of view which is further connected to possessing a particular kind of perceptual system. Bats hold a different point of view to humans and we therefore cannot appreciate what it is like to be a bat and bats cannot appreciate what it is like to be human. The 'what it is like' aspect is intrinsic to it and appreciating the aspect involves adopting the relevant point of view. If functionalism is to explain consciousness it must explain the intrinsic element of experience. However, functionalism cannot do this as uncovering a systems' physical properties e.g. a bats brain, doesn't necessitate one to adopt that particular point of view as we do not have its kind of perceptual system - we can uncover the physical properties of a bats brain without being able to appreciate what it is like to be a bat. I find this to be a significant criticism of functionalism as the properties concerning what it is like to be a particular creature or have a particular experience cannot be physical properties and understanding physical properties of a certain creature/experience is insufficient in explaining what it is like to be that creature. Nagel therefore successfully shows that phenomenal consciousness is a mystery with reference to functionalism as it is not physical and consequently cannot be explained in physical terms. Therefore functionalism fails to provide an account for phenomenal consciousness. Chalmers, D 'Philosophy of Mind: Classical and Contemporary Readings' Oxford: Oxford University Press This apparent mystery of consciousness presents a problem for all forms of physicalism including functionalism. Physicalists have attempted to overcome this problem of consciousness by proposing several responses; Fodor and Chomsky maintain physicalism cannot explain phenomenal consciousness in lower level scientific terms due to our cognitive limitations. McGinn argues consciousness is grounded in properties of the brain however there is no hope of understanding how the physical accounts for consciousness. He maintains that to identify a theory for consciousness one must either refer to introspection or to the scientific study of the brain. Introspection involves looking within our minds to discover a physical basis for consciousness however McGinn maintains this will not provide a theory of consciousness compatible with functionalism/physicalism as introspection does not reveal any physical properties which make consciousness intelligible. Similarly scientific study of the brain will not provide a theory of consciousness as science observes phenomena and explains these phenomena by constructing theories which usually postulate further unexplained phenomena; scientists refer to the theory proposing the best explanation. The properties of the brain scientists observe wont explain consciousness and neither will the unobserved properties postulated by scientists as these properties will be directed at explaining observable properties of the brain, therefore scientific study will not provide an explanation of consciousness as it seeks to explain a different type of phenomena. I do not find either of these arguments to successfully defend functionalism as Fodor, Chomsky and McGinn are simply providing excuses for the theory regarding sensations and other states of consciousness rather than providing a sufficient explanation. Cain, M 'Fodor: Language, Mind and Philosophy' Cambridge: Polity Press Ultimately, despite problems that arise for functionalism regarding intentional states, functionalism offers a more plausible theory of intentional states than it does of sensations and other states of consciousness. It is extremely difficult to provide an account of functionalism that is neither chauvinistic nor liberalistic weakening the overall theory and consequently its ability to provide a plausible account of all aspects of functionalism including sensations and other states of consciousness. Functionalism fails to provide a successful theory of sensations as it does not account for the qualia of a sensation as this is not a feature/product of its causal role. Kim successfully illustrates this criticism by providing examples of inverted and absent qualia that cannot be explained with reference to functionalism. I regard Nagel's argument, 'what is it like to be a bat?' to be the most significant criticism of functionalism as the properties regarding what it is like to be a particular creature or to have a particular experience cannot be physical properties and understanding physical properties of a certain creature/experience is insufficient in explaining what it is like to be that creature. Therefore functionalism fails to provide a plausible account of phenomenal consciousness. The responses raised by Fodor, Chomsky and McGinn are unsuccessful in defending functionalism, consequently functionalism offers a more plausible account of intentional states than it does of sensations and other states of consciousness.'''",829.0
"'''Translation into ItalianIn Italy, one in five new titles is translated from a foreign status of the Italian languageItaly has a population of 0 million, and Italian is spoken by another million scattered around the world. The literacy rate is 9%, and 3% of Italians read at least one book every year. Say that backwards, and you will understand the common complain about lack of 'reading habit' in Italy: 7% of the population reads less than one book every year. On top of that, according to a recent survey published by the European Commission, Italian as a foreign language ranks only sixth in Europe: it is spoken by only % of non-Italian Europeans as a foreign Department for the Promotion of Italian Publishing Abroad, there actually is a new trend favouring Italian culture in the world, particularly strong in the USA. American college students, apparently, pick up Italian after having studied Spanish as a first foreign language, attracted by the language of fashion, food, Firenze, and sometimes of their forefathers. Interview with Paola Seghi, AIE International Department for the Promotion of Italian Publishing Abroad, London Book Fair, March th 006 Ironically, the Italian language is threatened in Europe - by effect of the EU enlargement to the same countries that have strong immigration towards Italy, and are an opportunity for the Italian publishing industry - while it appeals to readers in a market which is difficult to enter by exporting or selling private.' The Italian book market, report published by the initiatives supporting translations are many also on the international level. However, they usually give the priority to endangered or minority. seminars and workshops, and has an online searchable database of its 5/80 members, who are either translators or interpreters or both, and have had to pass an entry test to attest their skills. However, it doesn't seem to have many connections within the AIE. Interview with Paola Seghi, AIE International Department for the Promotion of Italian Publishing Abroad, London Book Fair, March th 006 Beatrice Verri, a part-time freelance translator for three years, sums up its flaws: 'to many to the guarantees it gives. I don't know anyone who belongs to it.' E-mail interview with Beatrice Verri, freelance translator, March th 006 What some professional translators are campaigning for in Italy, is the creation of an 'albo' - similar to those existing for doctors and engineers - which would mean that only people who passed an exam and belonged to the category could work as translators. It would also mean the category as a whole could establish minimum fees, and contrast the negative effect that non-professional competition and the internet have had on translators' finances in the past decade. Various posts on Proz.com Because of the underpayment (a common complain of translators in most countries), it seems advisable to become a professional translator only if you are fluent in a rare language or knowledgeable in a specific subject which have a market. 'Being a translator - in an agency, freelancing, technical or general, Pashto or Basque - is being part of a community of creative minds, who share an amazing ability to transcend borders and make the implicit understood, everywhere.' (professional translator Edurne Alvarez, So You Want to be a Translator, from Translatorscafe.com, December st 005/8)'Translators are ghastly: poor devils who get nothing for a translation, only the lowliest fee - shamefully low, as they are wont to say - and they accomplish a ghastly job. In other words: the balance is restored. If a person does something that is worth nothing, then they should get nothing for it. Why does anyone translate? Why don't they write their own stuff instead?' (writer Thomas Bernhard, quoted in Why does anyone translate? by Tim Wilkinson, on URL )'''",834.0
"'''In this essay I will examine the decision I made to use bed-rails on the bed of one of my patients. Gibbs' reflective cycle is used as means of structuring my reflection. In the essay I will explain what a decision is and how evidence can and should be used to support decision making. I will describe my decision, how I made it at the time and consider what type of decision I made with reference to the literature. In researching this essay I have collected various journal articles that examine if bed-rails are ethically justifiable, why bed-rails are used, the pros and cons of their use, other ways of managing falls and alternatives to their use. The evidence will be critically appraised using the Critical Appraisal Skills and I will review how I found the evidence and how I limited my search. Finally I will draw conclusions from the research that will be used to improve my clinical practice. Before I examine the decision I made I will explain what a decision is, and why evidence should be used to support nursing decision making. The Cambridge Advanced Learner's Dictionary defines a decision as 'a choice that you make about something after thinking about several possibilities'. Muir states that decisions are made in an environment of uncertainty and that if there were a clear relationship between problem and outcome no decisions would be required. So if decisions are made by examining several possibilities, how are we to choose the correct one? Thompson et al argue that a culture of evidence based care delivery has evolved in recent years, and that 'evidence based practice and the development of solid and transparent rationales for decisions are not optional extras for doctors, nurses, allied health professionals and managers.' (002: 0). Nurses are compelled by their professional body to use evidence based practice. The Nursing and Midwifery Council's code of professional conduct sub-heading. states 'You have a responsibility to deliver care based on current evidence, best practice and where applicable, validated research when it is available.' (002: ). My decision was to use bed-rails on the bed of one of my patients. I decided to use them as the patient had vascular dementia, had been admitted to hospital following a fall, had had a previous cerebrovascular accident resulting in a left sided weakness, was unsteady when walking and had fallen already on the ward. I used the bed-rails as a means to discourage the patient from getting out of bed at night and in the periods of rest in the day, in order to reduce the chances of him falling. I made the decision in conjunction with my mentor and now realise that my decision would be classified as a peer-aided judgement on Hamm's cognitive Thompson et al argue that the lack of time nurses have for decision making results in intuitive decisions. However, Muir states that pattern recognition - comparing new decisions with previous cases and stored knowledge - is used in both intuitive and analytical decision making. Thompson et al use a study carried out by the University of York that examined how nurses used information in clinical decision making. The report discovered that the only text based resources used by the nurses were the British National were used and the value of every article and opinion piece was considered. Before I examine why bed-rails are used I will consider whether they are ethically justifiable. Horsburgh argues that cot-sides are a form of restraint as they deny a person's autonomy. Autonomy is a prima facie principle meaning 'that, at first sight, the principle appears to be one that should be respected by others' (Horsburgh: 003: 6). However, it can be argued that one must possess insight in to the consequences of their actions before being considered truly autonomous. My patient's dementia interfered with their rational thought processes and it could therefore be argued that I was using the principle of non- overriding their autonomy. On the other hand Strumpf cited in Hamers et poor mobility. This was one of the reasons I decided to use bed-rails on my patient, as I wanted to reduce the chances of a fall. Kelly and Dowling list both intrinsic and extrinsic factors that increase the risk of fall related injury. Intrinsic factors relate specifically to the individual and include acute illness, changes in vision, changes in balance, cardiovascular does not explain how or why it came up with it's recommendations and lists at least two bed rail manufacturing the list of organisations that signed on to the clinical guidance provided by the report and therefore should be ignored. But the fact that the report recommends how to reduce the dangers that poorly fitted and incorrectly sized bed-rails cause warrants the inclusion of the manufacturing companies. The report is included as it is extremely thorough in its recommendations and examines all aspects of the bed rail use from correct fitting to the assessment of risk factors to clinical interventions that can prevent happening. The HBSW adds some well thought out alternatives/additions to Hughes list of wandering-management guidelines. In their sleeping environment assessment they consider the proximity of the patient to the toilet and whether it is in view. My patient would regularly wander to the toilet, having forgotten that he had only recently been, and was catheterised at one point and still went to the toilet to 'spend a penny' despite my exhortations that he was catheterised. Perhaps if the toilet had not been in view he may not have wandered so much. The HBSW also recommend that diuretics are not given at night. One of the best recommendations is that if bed-rails are to be used, then their efficacy and continued relevance should be reviewed and evaluated regularly. The Department of Health estimate that 4000 people each year die after suffering osteoporotic hip fractures. If bed-rails could reduce the numbers of deaths then that would be a good thing. But many of the articles I have read show that bed-rails cause not only injury but even death. The Medical Devices Agency and Nursing Times give examples of patients who died when their heads became trapped between the bed-rails and were asphyxiated. The Hospital Bed Safety Workgroup acknowledges that bed-rails pose a risk of entrapment and a risk of falls when the patient climbs over the top of the bars. The report goes further by saying that 'agitation, delirium, confusion, pain, uncontrolled body movement, hypoxia, faecal impaction and acute urinary retention. may also contribute to the risk of entrapment' (003: 46). Unlike the above reports Everitt & Bridel-Nixon carried out their own research to discover the injuries caused by bed-rails. They rightly identify that there is not much research into falls from beds with bed-rails but do identify some small studies and a large study carried out in America in the 95/80s. These showed that of the total number of falls from bed, a large from beds with bed-rails. Unfortunately, having identified the need for further research, Everitt and Bridel-Nixon proceeded to carry out a very poorly planned and executed trial. They obtained all the accident printout Seacroft University Hospitals in Leeds over a 5/8 month period. The authors acknowledge that the data was limited by the inaccuracy of the accident reporting and found that of the 73 falls only % were from beds with bed rails. The data is pretty meaningless as the total number of beds with rails is not recorded. The report is included as it shows how CASP guidelines can be used, and does show that more research is needed into the affects of falling from beds with bed-rails. A very well researched qualitative paper produced by Gallinagh et al examined the perceptions of the families of patients in beds with bed-rails. The researchers used a previously used interview guide, the Family Interview. Kelly and Dunn who found that 'when a restraint free period was instituted in a long-term care facility, there was a significant decline in the number and severity of injuries'. If bed rails don't work and worse, actually cause harm then alternatives must be considered. Both measures to reduce the risk of falls and alternatives to the use of bed rails must be considered. Hughes suggests that adequate nutrition should be maintained with calcium and vitamin D supplements given to promote bone strength, the use of door alarms, and the use of a safe and supervised wandering area. Kelly and Dowling suggest an alarm called the Ambularm that is attached to the leg and is activated when a patient moves to a vertical position, although they acknowledge that this would not be a cost effective measure. They also suggest skid proof strips near the bed and placing commodes by the bedside at night. Using rolled up blankets and pillows under the mattress is suggested as an alternative to bed-rails. The Hospital Bed Safety Workgroup suggests that if bed-rails are to be used than the underlying reasons for their use should be treated and reviewed. For example if the patient is confused because of hypoxia or a urinary tract infection then these should be treated and if the patient improves the use of bed-rails can be reviewed and possibly removed. Despite the fact that the evidence highlights that bed-rails are a form of restraint, can cause harm as well as prevent it, and are perhaps ethically unsound, they are still widely used. As Kelly and Rowling point out, few studies have investigated nursing attitudes to restraint use. It is my opinion that they are necessary. There will never be enough staff to keep and eye on all the patients all the time. Falls will always happen, but by trying to treat the causes, monitoring if bed-rails are correctly fitted, and reviewing the need for them, nurses can reduce their negative affects. I have learnt a lot in researching this essay, and my clinical practice will benefit. I now realise how important it is to monitor their use, and will not use them without correctly and thoroughly assessing the patient. I will question whether they are necessary, consider alternatives, ensure they are safely fitted, and discuss the findings of this essay with my mentors and colleagues. The main limitation to the quality of this essay is my inexperience in literature searching. Since writing this essay, I realise I could of defined my search terms better. I could also use the reference lists of the journal articles I read to find more material. My sources come from a wide range of texts, including literature reviews, opinion pieces, clinical guidance, and qualitative and quantitative research, but feel that I did not find as much good quality researched data as I should. However, many of the authors did point out that more research is needed and that in some areas there is very little research (e.g. nursing attitudes to bed rails). This essay has raised my awareness of the implications of the use of bed-rails. They play a valuable safety roll, but can also cause harm and distress. I have looked at the ethics of their use, the reasons for use, their dangers, and alternatives to their use. I have critically appraised the research and drawn conclusions that will improve my clinical practice. The use of bed-rails deserves greater consideration by nurses, and I hope to raise awareness in my clinical practice areas.'''",837.0
